[{
  "history_id" : "5ir2oj1oyf8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462265224,
  "history_end_time" : 1694185608587,
  "history_notes" : null,
  "history_process" : "525l8q",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "9292ivev44d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311130,
  "history_end_time" : 1694185608588,
  "history_notes" : null,
  "history_process" : "78vedq",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "1x6z4ru9nar",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311246,
  "history_end_time" : 1694185608593,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "dv4v5cucfbw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311331,
  "history_end_time" : 1694185608594,
  "history_notes" : null,
  "history_process" : "mxpyqt",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "wua18ic6xiv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311360,
  "history_end_time" : 1694185608595,
  "history_notes" : null,
  "history_process" : "rmxece",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "18w0way3eeg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311402,
  "history_end_time" : 1694185608596,
  "history_notes" : null,
  "history_process" : "c2xkhz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "knhs7wmrego",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311413,
  "history_end_time" : 1694185608616,
  "history_notes" : null,
  "history_process" : "illwc1",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "04wjgjhk2pb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311444,
  "history_end_time" : 1694185608618,
  "history_notes" : null,
  "history_process" : "rauqsh",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "6n539em0z7e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311456,
  "history_end_time" : 1694185608618,
  "history_notes" : null,
  "history_process" : "sjs5by",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "hylfvh21jvf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311486,
  "history_end_time" : 1694185608620,
  "history_notes" : null,
  "history_process" : "mi3e5n",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "6y2faoexs6u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311538,
  "history_end_time" : 1694185608621,
  "history_notes" : null,
  "history_process" : "y7nb46",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "gmaq9hginca",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\n# exit() # uncomment to download new files\nee.Authenticate(quiet=True)\nee.Initialize(credentials='/home/chetana/.config/earthengine/credentials/swe-workflow1.json')\n\n'''\ntry:\n  ee.Initialize(credentials='/home/chetana/.config/earthengine/credentials/swe-workflow1.json')\n  except Exception as e:\n    ee.Authenticate(quiet=True) # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = os.path.join(homedir, 'Documents', 'GitHub', 'SnowCast')\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = '2018-10-01'\nend_date = '2019-09-30'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for ind in station_cell_mapper_df.index:\n\n        try:\n\n          current_cell_id = station_cell_mapper_df['cell_id'][ind]\n          print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              print(\"exists skipping..\")\n              continue\n\n          longitude = station_cell_mapper_df['lon'][ind]\n          latitude = station_cell_mapper_df['lat'][ind]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\") '''",
  "history_output" : "['gcloud', 'auth', 'application-default', 'login', '--scopes=https://www.googleapis.com/auth/earthengine,https://www.googleapis.com/auth/devstorage.full_control', '--client-id-file=/home/chetana/.config/earthengine/credentials/swe-workflow1.json-client-id.json', '--no-browser']\nFetching credentials using gcloud\norig_exe:  gcloud\nelse -child gcloud\nenum 2 No such file or directory gcloud\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 299, in _load_app_default_credentials\n    subprocess.run(command, check=True)\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 505, in run\n    with Popen(*popenargs, **kwargs) as process:\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 951, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 1825, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'gcloud'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/gmaq9hginca/data_gee_gridmet_station_only.py\", line 13, in <module>\n    ee.Authenticate(quiet=True)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 104, in Authenticate\n    return oauth.authenticate(authorization_code, quiet, code_verifier, auth_mode,\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 401, in authenticate\n    _load_app_default_credentials(auth_mode == 'gcloud', scopes, quiet)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 302, in _load_app_default_credentials\n    raise Exception('gcloud command not found. ' + tip) from e\nException: gcloud command not found. Please ensure that gcloud is installed.\nMore information: https://developers.google.com/earth-engine/guides/python_install\n\n",
  "history_begin_time" : 1677462312013,
  "history_end_time" : 1694185608622,
  "history_notes" : null,
  "history_process" : "a8p3n7",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "goi0bprwuyt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311617,
  "history_end_time" : 1694185608623,
  "history_notes" : null,
  "history_process" : "2wkl6e",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "c61no3nmtv0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311635,
  "history_end_time" : 1694185608624,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "q0yqeqo4v6h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311680,
  "history_end_time" : 1694185608624,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "8cxe8w1tf2t",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311693,
  "history_end_time" : 1694185608625,
  "history_notes" : null,
  "history_process" : "4i0sop",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "dw8525og05i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311748,
  "history_end_time" : 1694185608626,
  "history_notes" : null,
  "history_process" : "b63prf",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "qzjtp5vgvn4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311759,
  "history_end_time" : 1694185608627,
  "history_notes" : null,
  "history_process" : "h1qp9v",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "knx07p89co2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311796,
  "history_end_time" : 1694185608628,
  "history_notes" : null,
  "history_process" : "zh38b6",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "r6dnxql297w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311807,
  "history_end_time" : 1694185608629,
  "history_notes" : null,
  "history_process" : "urd0nk",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "4jiph9vi31h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311855,
  "history_end_time" : 1694185608630,
  "history_notes" : null,
  "history_process" : "wdh394",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ozo6q7cpt2u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311866,
  "history_end_time" : 1694185608630,
  "history_notes" : null,
  "history_process" : "525l8q",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "lussx3y9f2l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311911,
  "history_end_time" : 1694185608631,
  "history_notes" : null,
  "history_process" : "p87wh1",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ihm7b0lw5i5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311925,
  "history_end_time" : 1694185608631,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "a6oaagznvj7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311966,
  "history_end_time" : 1694185608631,
  "history_notes" : null,
  "history_process" : "ilbqzg",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "uzekdxtiq7s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311978,
  "history_end_time" : 1694185608632,
  "history_notes" : null,
  "history_process" : "rmxece",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "67j24c2t0bn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312052,
  "history_end_time" : 1694185608635,
  "history_notes" : null,
  "history_process" : "do86ae",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ls8732ah9wv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312064,
  "history_end_time" : 1694185608645,
  "history_notes" : null,
  "history_process" : "illwc1",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fbxjrb61qmy",
  "history_input" : "# 2019 first https://nsidc.org/data/nsidc-0719/versions/1#anchor-1\n\n# TODO: change LAT LONG TO GRID CELL COORDS\n# TODO: adjust using grid cell geojson in data integration\n# TODO: adjust to make model validation working (model_train_validate)\n\n\"\"\"\nBroxton, P., X. Zeng, and N. Dawson. 2019. Daily 4 km Gridded SWE and Snow Depth from\nAssimilated In-Situ and Modeled Data over the Conterminous US, Version 1. 2019-2021.\nBoulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center.\nhttps://doi.org/10.5067/0GGPB220EX6A. 11/02/2022.\n\nTo enable wget to directly download netcdf from NSIDC, use:\n\necho 'machine urs.earthdata.nasa.gov login <uid> password <password>' >> ~/.netrc\nchmod 0600 ~/.netrc\n\n\"\"\"\n\nfrom math import cos, asin, sqrt, radians\nimport pandas as pd\nimport numpy as np\nimport os.path\nimport netCDF4 as nc\nimport datetime\nimport geojson\nfrom sklearn import neighbors as sk\nimport sys\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngrid_cells = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n# open nsidc data file (netCDF)\n# crs, lat, lon, time, time_str, DEPTH, SWE, SWE_MASK\n# change to make it work\nend_year = 2019\n# https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0719_SWE_Snow_Depth_v1/4km_SWE_Depth_WY2019_v01.nc\nnsidc_data_file = f\"{homedir}/Documents/data/4km_SWE_Depth_WY{end_year}_v01.nc\"\nnsidc_data_ds = nc.Dataset(nsidc_data_file)\n'''\nprint(nsidc_data_ds)\nfor dim in nsidc_data_ds.dimensions.values():\n    print(dim)\nfor var in nsidc_data_ds.variables.values():\n    print(var)\n'''\n# dates based on Water Year 2019 (not normal year)\norg_name = 'nsidc'\nproduct_name = 'NSIDC'\nstart_date = '2018-10-01'\nend_date = '2019-09-30'\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Removes duplicate indices\nscmd = set(station_cell_mapper_df['cell_id'])\n\nlat = nsidc_data_ds.variables['lat'][:]\nlon = nsidc_data_ds.variables['lon'][:]\ndepth = nsidc_data_ds.variables['DEPTH']\nswe = nsidc_data_ds.variables['SWE']\ntime = nsidc_data_ds.variables['time']\ncolumns = ['Year', 'Month', 'Day', 'Lat', 'Lon', 'SWE', 'Depth']\n\nstart_date_dt = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n# conversion factor so we can get days from 0-364 for array\ndays_1900_start = int((start_date_dt - datetime.datetime(1900,1,1)).days)\n\nall_cells_df = pd.DataFrame(columns=columns)\nind = 0\n\n\n# haversine formula\ndef coord_distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295\n    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n    return 12742 * asin(sqrt(hav))\n\n\n# inefficient and bad, don't use this\ndef find_nearest(find_lat, find_lng):\n    min_dist = 999999999\n    curr_min_lat_idx = 0\n    curr_min_lon_idx = 0\n\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng) < min_dist:\n                if depth[23, lat_idx, lon_idx] != '--':\n                    min_dist = coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng)\n                    curr_min_lat_idx = lat_idx\n                    curr_min_lon_idx = lon_idx\n\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\n# for generating the list of all valid lat long pairs\ndef gen_pairs():\n    temp = []\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if depth[23, lat_idx, lon_idx] != '--':\n                temp.append((lat[lat_idx], lon[lon_idx]))\n    temp = np.array(temp)\n    print(temp)\n    np.save(f\"{dfolder}/valid_pairs.npy\", temp)\n\n\n# use balltree to find closest neighbors, convert to radians first so the haversine thing works correctly\n# (that's why there's a separate rad thing)\ndef find_nearest_2(find_lat, find_lng):\n    # generate valid pairs, or just load if they already exist\n    if not os.path.exists(f\"{dfolder}/valid_pairs.npy\"):\n        print(\"file doesn't exist, generating new\")\n        gen_pairs()\n    lat_lon_pairs = np.load(f\"{dfolder}/valid_pairs.npy\")\n    lat_lon_pairs_rad = np.array([[radians(x[0]), radians(x[1])] for x in lat_lon_pairs])\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\n\n    dist, ind = ball_tree.query([(radians(find_lat), radians(find_lng))], return_distance=True)\n    print(dist)\n    print(ind)\n    print(lat_lon_pairs[ind])\n    curr_min_lat_idx = lat_lon_pairs[ind][0][0][0]\n    curr_min_lon_idx = lat_lon_pairs[ind][0][0][1]\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\ndef turn_nsidc_nc_to_csv():\n    \n\n    # comment out if bulk writing!!\n    # all_cells_df.to_csv(f\"{dfolder}/test.csv\", index=False)\n\n    for ind, current_cell_id in enumerate(scmd):\n        # comment out if bulk writing\n        # all_cells_df = pd.DataFrame(columns=columns)\n\n        # Location information\n        longitude = station_cell_mapper_df['lon'][ind]\n        latitude = station_cell_mapper_df['lat'][ind]\n\n    #     print(latitude)\n    #     print(longitude)\n\n        # find closest lat long\n        lat_val, lon_val = find_nearest_2(latitude, longitude, )\n        lat_idx = np.where(lat == lat_val)[0]\n        lon_idx = np.where(lon == lon_val)[0]\n    #     print(lat_val)\n    #     print(lon_val)\n\n        depth_time = depth[:, lat_idx, lon_idx]\n        swe_time = swe[:, lat_idx, lon_idx]\n\n        for ele in time:\n            time_index = int(ele.data - days_1900_start)\n            time_index_dt = datetime.datetime(1900, 1, 1, 0, 0) + datetime.timedelta(int(ele.data))\n            depth_val = depth_time[time_index][0][0]\n            swe_val = swe_time[time_index][0][0]\n\n            all_cells_df.loc[len(all_cells_df.index)] = [time_index_dt.year, time_index_dt.month, time_index_dt.day, lat_val, lon_val, swe_val, depth_val]\n\n        # comment out if bulk writing\n        # all_cells_df.to_csv(f\"{dfolder}/test.csv\", mode='a', header=False, index=False)\n\n    # uncomment to bulk write at end of program\n    all_cells_df.to_csv(f\"{dfolder}/{end_year}nsidc_data.csv\")\n\n    print(\"finished\")\n\n# call this method to extract the \nturn_nsidc_nc_to_csv()",
  "history_output" : "/home/chetana\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.00036589]]\n[[180957]]\n[[[  37.708332 -119.125   ]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00033864]]\n[[164419]]\n[[[  37.083332 -118.75    ]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[0.00015398]]\n[[164425]]\n[[[  37.083332 -118.5     ]]]\n[[0.00031948]]\n[[154543]]\n[[[  36.708332 -118.833336]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00021309]]\n[[267031]]\n[[[  40.791668 -121.791664]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.0002125]]\n[[202215]]\n[[[  38.5      -119.791664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00015498]]\n[[193151]]\n[[[  38.166668 -120.041664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.00024992]]\n[[173209]]\n[[[  37.416668 -119.5     ]]]\n[[0.00013956]]\n[[147950]]\n[[[  36.458332 -118.541664]]]\n[[0.00020465]]\n[[156750]]\n[[[  36.791668 -118.416664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00037612]]\n[[186492]]\n[[[  37.916668 -119.25    ]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00017002]]\n[[178752]]\n[[[  37.625    -119.083336]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.0002125]]\n[[202215]]\n[[[  38.5      -119.791664]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00015417]]\n[[146849]]\n[[[  36.416668 -118.583336]]]\n[[0.00016601]]\n[[183167]]\n[[[  37.791668 -119.208336]]]\n[[0.00032432]]\n[[182046]]\n[[[  37.75     -119.791664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.0003812]]\n[[151250]]\n[[[  36.583332 -118.75    ]]]\n[[0.00032729]]\n[[194278]]\n[[[  38.208332 -119.875   ]]]\n[[0.00032678]]\n[[176538]]\n[[[  37.541668 -119.25    ]]]\n[[0.00022214]]\n[[174321]]\n[[[  37.458332 -119.291664]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00025497]]\n[[167711]]\n[[[  37.208332 -119.208336]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00025197]]\n[[193160]]\n[[[  38.166668 -119.666664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00010902]]\n[[238201]]\n[[[  39.791668 -120.875   ]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00021309]]\n[[267031]]\n[[[  40.791668 -121.791664]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00024862]]\n[[277959]]\n[[[  41.166668 -121.958336]]]\n[[0.00019348]]\n[[178753]]\n[[[  37.625    -119.041664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00017594]]\n[[155643]]\n[[[  36.75     -118.708336]]]\n[[0.00032588]]\n[[189821]]\n[[[  38.041668 -119.666664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00035749]]\n[[144646]]\n[[[  36.333332 -118.625   ]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00020109]]\n[[174334]]\n[[[  37.458332 -118.75    ]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[0.00010902]]\n[[238201]]\n[[[  39.791668 -120.875   ]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n",
  "history_begin_time" : 1677462314459,
  "history_end_time" : 1694185608646,
  "history_notes" : null,
  "history_process" : "gkhtc0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "z3hw11quev6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312122,
  "history_end_time" : 1694185608656,
  "history_notes" : null,
  "history_process" : "sjs5by",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "6m42zlfsw02",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312139,
  "history_end_time" : 1694185608658,
  "history_notes" : null,
  "history_process" : "lbd6cp",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "f2utualgk0m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312189,
  "history_end_time" : 1694185608659,
  "history_notes" : null,
  "history_process" : "y7nb46",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "qpswmiqb7g2",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\n# exit() # uncomment to download new files\nee.Authenticate(quiet=True)\nee.Initialize(credentials='/home/chetana/.config/earthengine/credentials/swe-workflow1.json')\n\n'''\ntry:\n  ee.Initialize(credentials='/home/chetana/.config/earthengine/credentials/swe-workflow1.json')\n  except Exception as e:\n    ee.Authenticate(quiet=True) # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = os.path.join(homedir, 'Documents', 'GitHub', 'SnowCast')\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = '2018-10-01'\nend_date = '2019-09-30'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for ind in station_cell_mapper_df.index:\n\n        try:\n\n          current_cell_id = station_cell_mapper_df['cell_id'][ind]\n          print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              print(\"exists skipping..\")\n              continue\n\n          longitude = station_cell_mapper_df['lon'][ind]\n          latitude = station_cell_mapper_df['lat'][ind]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\") '''",
  "history_output" : "['gcloud', 'auth', 'application-default', 'login', '--scopes=https://www.googleapis.com/auth/earthengine,https://www.googleapis.com/auth/devstorage.full_control', '--client-id-file=/home/chetana/.config/earthengine/credentials/swe-workflow1.json-client-id.json', '--no-browser']\nFetching credentials using gcloud\norig_exe:  gcloud\nelse -child gcloud\nenum 2 No such file or directory gcloud\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 299, in _load_app_default_credentials\n    subprocess.run(command, check=True)\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 505, in run\n    with Popen(*popenargs, **kwargs) as process:\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 951, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 1825, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'gcloud'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/qpswmiqb7g2/data_gee_gridmet_station_only.py\", line 13, in <module>\n    ee.Authenticate(quiet=True)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 104, in Authenticate\n    return oauth.authenticate(authorization_code, quiet, code_verifier, auth_mode,\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 401, in authenticate\n    _load_app_default_credentials(auth_mode == 'gcloud', scopes, quiet)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 302, in _load_app_default_credentials\n    raise Exception('gcloud command not found. ' + tip) from e\nException: gcloud command not found. Please ensure that gcloud is installed.\nMore information: https://developers.google.com/earth-engine/guides/python_install\n\n",
  "history_begin_time" : 1677462313013,
  "history_end_time" : 1694185608660,
  "history_notes" : null,
  "history_process" : "a8p3n7",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "0x3s23apols",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312279,
  "history_end_time" : 1694185608676,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "y2ntfgq0z7j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312300,
  "history_end_time" : 1694185608677,
  "history_notes" : null,
  "history_process" : "4i0sop",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "tu4sscjwicn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312323,
  "history_end_time" : 1694185608697,
  "history_notes" : null,
  "history_process" : "b63prf",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ulscco0x5zi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312345,
  "history_end_time" : 1694185608698,
  "history_notes" : null,
  "history_process" : "zh38b6",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "v8qxnu8und2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312372,
  "history_end_time" : 1694185608699,
  "history_notes" : null,
  "history_process" : "wdh394",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "7y0hqr5qg5t",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312399,
  "history_end_time" : 1694185608700,
  "history_notes" : null,
  "history_process" : "p87wh1",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "wl43ry1soe2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312434,
  "history_end_time" : 1694185608701,
  "history_notes" : null,
  "history_process" : "ilbqzg",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fyxvs7v724k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312467,
  "history_end_time" : 1694185608702,
  "history_notes" : null,
  "history_process" : "do86ae",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "moe8sfpqky1",
  "history_input" : "# 2019 first https://nsidc.org/data/nsidc-0719/versions/1#anchor-1\n\n# TODO: change LAT LONG TO GRID CELL COORDS\n# TODO: adjust using grid cell geojson in data integration\n# TODO: adjust to make model validation working (model_train_validate)\n\n\"\"\"\nBroxton, P., X. Zeng, and N. Dawson. 2019. Daily 4 km Gridded SWE and Snow Depth from\nAssimilated In-Situ and Modeled Data over the Conterminous US, Version 1. 2019-2021.\nBoulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center.\nhttps://doi.org/10.5067/0GGPB220EX6A. 11/02/2022.\n\nTo enable wget to directly download netcdf from NSIDC, use:\n\necho 'machine urs.earthdata.nasa.gov login <uid> password <password>' >> ~/.netrc\nchmod 0600 ~/.netrc\n\n\"\"\"\n\nfrom math import cos, asin, sqrt, radians\nimport pandas as pd\nimport numpy as np\nimport os.path\nimport netCDF4 as nc\nimport datetime\nimport geojson\nfrom sklearn import neighbors as sk\nimport sys\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngrid_cells = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n# open nsidc data file (netCDF)\n# crs, lat, lon, time, time_str, DEPTH, SWE, SWE_MASK\n# change to make it work\nend_year = 2019\n# https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0719_SWE_Snow_Depth_v1/4km_SWE_Depth_WY2019_v01.nc\nnsidc_data_file = f\"{homedir}/Documents/data/4km_SWE_Depth_WY{end_year}_v01.nc\"\nnsidc_data_ds = nc.Dataset(nsidc_data_file)\n'''\nprint(nsidc_data_ds)\nfor dim in nsidc_data_ds.dimensions.values():\n    print(dim)\nfor var in nsidc_data_ds.variables.values():\n    print(var)\n'''\n# dates based on Water Year 2019 (not normal year)\norg_name = 'nsidc'\nproduct_name = 'NSIDC'\nstart_date = '2018-10-01'\nend_date = '2019-09-30'\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Removes duplicate indices\nscmd = set(station_cell_mapper_df['cell_id'])\n\nlat = nsidc_data_ds.variables['lat'][:]\nlon = nsidc_data_ds.variables['lon'][:]\ndepth = nsidc_data_ds.variables['DEPTH']\nswe = nsidc_data_ds.variables['SWE']\ntime = nsidc_data_ds.variables['time']\ncolumns = ['Year', 'Month', 'Day', 'Lat', 'Lon', 'SWE', 'Depth']\n\nstart_date_dt = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n# conversion factor so we can get days from 0-364 for array\ndays_1900_start = int((start_date_dt - datetime.datetime(1900,1,1)).days)\n\nall_cells_df = pd.DataFrame(columns=columns)\nind = 0\n\n\n# haversine formula\ndef coord_distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295\n    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n    return 12742 * asin(sqrt(hav))\n\n\n# inefficient and bad, don't use this\ndef find_nearest(find_lat, find_lng):\n    min_dist = 999999999\n    curr_min_lat_idx = 0\n    curr_min_lon_idx = 0\n\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng) < min_dist:\n                if depth[23, lat_idx, lon_idx] != '--':\n                    min_dist = coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng)\n                    curr_min_lat_idx = lat_idx\n                    curr_min_lon_idx = lon_idx\n\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\n# for generating the list of all valid lat long pairs\ndef gen_pairs():\n    temp = []\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if depth[23, lat_idx, lon_idx] != '--':\n                temp.append((lat[lat_idx], lon[lon_idx]))\n    temp = np.array(temp)\n    print(temp)\n    np.save(f\"{dfolder}/valid_pairs.npy\", temp)\n\n\n# use balltree to find closest neighbors, convert to radians first so the haversine thing works correctly\n# (that's why there's a separate rad thing)\ndef find_nearest_2(find_lat, find_lng):\n    # generate valid pairs, or just load if they already exist\n    if not os.path.exists(f\"{dfolder}/valid_pairs.npy\"):\n        print(\"file doesn't exist, generating new\")\n        gen_pairs()\n    lat_lon_pairs = np.load(f\"{dfolder}/valid_pairs.npy\")\n    lat_lon_pairs_rad = np.array([[radians(x[0]), radians(x[1])] for x in lat_lon_pairs])\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\n\n    dist, ind = ball_tree.query([(radians(find_lat), radians(find_lng))], return_distance=True)\n    print(dist)\n    print(ind)\n    print(lat_lon_pairs[ind])\n    curr_min_lat_idx = lat_lon_pairs[ind][0][0][0]\n    curr_min_lon_idx = lat_lon_pairs[ind][0][0][1]\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\ndef turn_nsidc_nc_to_csv():\n    \n\n    # comment out if bulk writing!!\n    # all_cells_df.to_csv(f\"{dfolder}/test.csv\", index=False)\n\n    for ind, current_cell_id in enumerate(scmd):\n        # comment out if bulk writing\n        # all_cells_df = pd.DataFrame(columns=columns)\n\n        # Location information\n        longitude = station_cell_mapper_df['lon'][ind]\n        latitude = station_cell_mapper_df['lat'][ind]\n\n    #     print(latitude)\n    #     print(longitude)\n\n        # find closest lat long\n        lat_val, lon_val = find_nearest_2(latitude, longitude, )\n        lat_idx = np.where(lat == lat_val)[0]\n        lon_idx = np.where(lon == lon_val)[0]\n    #     print(lat_val)\n    #     print(lon_val)\n\n        depth_time = depth[:, lat_idx, lon_idx]\n        swe_time = swe[:, lat_idx, lon_idx]\n\n        for ele in time:\n            time_index = int(ele.data - days_1900_start)\n            time_index_dt = datetime.datetime(1900, 1, 1, 0, 0) + datetime.timedelta(int(ele.data))\n            depth_val = depth_time[time_index][0][0]\n            swe_val = swe_time[time_index][0][0]\n\n            all_cells_df.loc[len(all_cells_df.index)] = [time_index_dt.year, time_index_dt.month, time_index_dt.day, lat_val, lon_val, swe_val, depth_val]\n\n        # comment out if bulk writing\n        # all_cells_df.to_csv(f\"{dfolder}/test.csv\", mode='a', header=False, index=False)\n\n    # uncomment to bulk write at end of program\n    all_cells_df.to_csv(f\"{dfolder}/{end_year}nsidc_data.csv\")\n\n    print(\"finished\")\n\n# call this method to extract the \nturn_nsidc_nc_to_csv()",
  "history_output" : "/home/chetana\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.00036589]]\n[[180957]]\n[[[  37.708332 -119.125   ]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00033864]]\n[[164419]]\n[[[  37.083332 -118.75    ]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[0.00015398]]\n[[164425]]\n[[[  37.083332 -118.5     ]]]\n[[0.00031948]]\n[[154543]]\n[[[  36.708332 -118.833336]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00021309]]\n[[267031]]\n[[[  40.791668 -121.791664]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.0002125]]\n[[202215]]\n[[[  38.5      -119.791664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00015498]]\n[[193151]]\n[[[  38.166668 -120.041664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.00024992]]\n[[173209]]\n[[[  37.416668 -119.5     ]]]\n[[0.00013956]]\n[[147950]]\n[[[  36.458332 -118.541664]]]\n[[0.00020465]]\n[[156750]]\n[[[  36.791668 -118.416664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00037612]]\n[[186492]]\n[[[  37.916668 -119.25    ]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00017002]]\n[[178752]]\n[[[  37.625    -119.083336]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.0002125]]\n[[202215]]\n[[[  38.5      -119.791664]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00015417]]\n[[146849]]\n[[[  36.416668 -118.583336]]]\n[[0.00016601]]\n[[183167]]\n[[[  37.791668 -119.208336]]]\n[[0.00032432]]\n[[182046]]\n[[[  37.75     -119.791664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.0003812]]\n[[151250]]\n[[[  36.583332 -118.75    ]]]\n[[0.00032729]]\n[[194278]]\n[[[  38.208332 -119.875   ]]]\n[[0.00032678]]\n[[176538]]\n[[[  37.541668 -119.25    ]]]\n[[0.00022214]]\n[[174321]]\n[[[  37.458332 -119.291664]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00025497]]\n[[167711]]\n[[[  37.208332 -119.208336]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00025197]]\n[[193160]]\n[[[  38.166668 -119.666664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00010902]]\n[[238201]]\n[[[  39.791668 -120.875   ]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00021309]]\n[[267031]]\n[[[  40.791668 -121.791664]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00024862]]\n[[277959]]\n[[[  41.166668 -121.958336]]]\n[[0.00019348]]\n[[178753]]\n[[[  37.625    -119.041664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00017594]]\n[[155643]]\n[[[  36.75     -118.708336]]]\n[[0.00032588]]\n[[189821]]\n[[[  38.041668 -119.666664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00035749]]\n[[144646]]\n[[[  36.333332 -118.625   ]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00020109]]\n[[174334]]\n[[[  37.458332 -118.75    ]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[0.00010902]]\n[[238201]]\n[[[  39.791668 -120.875   ]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n",
  "history_begin_time" : 1677462314459,
  "history_end_time" : 1694185608703,
  "history_notes" : null,
  "history_process" : "gkhtc0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "3ovzc0prpk6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312533,
  "history_end_time" : 1694185608713,
  "history_notes" : null,
  "history_process" : "lbd6cp",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
}]
