[{
  "history_id" : "2hxfm7zwwyj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678206364187,
  "history_end_time" : 1678206377194,
  "history_notes" : null,
  "history_process" : "78vedq",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "9lusub8f56v",
  "history_input" : "# Create LSTM model\n\nprint(\"Create LSTM\")\n\n",
  "history_output" : "Create LSTM\n",
  "history_begin_time" : 1678206370373,
  "history_end_time" : 1678206377194,
  "history_notes" : null,
  "history_process" : "mxpyqt",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "19za86dhhd7",
  "history_input" : "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom base_hole import BaseHole\nfrom sklearn.model_selection import train_test_split\nfrom datetime import datetime\n\nhomedir = os.path.expanduser('~')\ngithub_dir = os.path.join(homedir, 'Documents', 'GitHub', 'SnowCast')\n\nclass RandomForestHole(BaseHole):\n  \n  def get_model(self):\n    rfc_pipeline = Pipeline(steps = [\n      ('data_scaling', StandardScaler()),\n      ('model', RandomForestRegressor(max_depth = 15,\n                                       min_samples_leaf = 0.004,\n                                       min_samples_split = 0.008,\n                                       n_estimators = 25))])\n    return rfc_pipeline\n\n  def evaluate(self):\n    mae = metrics.mean_absolute_error(self.test_y, self.test_y_results)\n    mse = metrics.mean_squared_error(self.test_y, self.test_y_results)\n    r2 = metrics.r2_score(self.test_y, self.test_y_results)\n    rmse = math.sqrt(mse)\n\n    print(\"The random forest model performance for testing set\")\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    return {\"mae\":mae, \"mse\": mse, \"r2\": r2, \"rmse\": rmse}",
  "history_output" : "Running",
  "history_begin_time" : 1678206371249,
  "history_end_time" : 1678206377673,
  "history_notes" : null,
  "history_process" : "c2xkhz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ilrmgi2ocmc",
  "history_input" : "# GhostNet\n\nprint(\"Create GhostNet\")\n\n",
  "history_output" : "Create GhostNet\n",
  "history_begin_time" : 1678206371948,
  "history_end_time" : 1678206378209,
  "history_notes" : null,
  "history_process" : "rauqsh",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "crscfmncepb",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378210,
  "history_notes" : null,
  "history_process" : "mi3e5n",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "pzz6nt9l4rh",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378217,
  "history_notes" : null,
  "history_process" : "u7xh2p",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "yzvuyfir7k3",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378222,
  "history_notes" : null,
  "history_process" : "2wkl6e",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "m034ssfu4jr",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378227,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "mh37cffkegi",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378230,
  "history_notes" : null,
  "history_process" : "e8k4wq",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "dbhbngejtki",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378235,
  "history_notes" : null,
  "history_process" : "h1qp9v",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "vkuk2fb0tq1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678206364314,
  "history_end_time" : 1678206378237,
  "history_notes" : null,
  "history_process" : "urd0nk",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "72ybvl101z0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678206364320,
  "history_end_time" : 1678206378238,
  "history_notes" : null,
  "history_process" : "525l8q",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "2svw4fyu7ns",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678206364325,
  "history_end_time" : 1678206378238,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fp5igdrsl26",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nimport math\n\n#pd.set_option('display.max_columns', None)\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngridcells_file = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nmodel_dir = f\"{github_dir}/model/\"\ntraining_feature_file = f\"{github_dir}/data/snowcast_provided/ground_measures_train_features.csv\"\ntesting_feature_file = f\"{github_dir}/data/snowcast_provided/ground_measures_test_features.csv\"\ntrain_labels_file = f\"{github_dir}/data/snowcast_provided/train_labels.csv\"\nground_measure_metadata_file = f\"{github_dir}/data/snowcast_provided/ground_measures_metadata.csv\"\n\nready_for_training_folder = f\"{github_dir}/data/ready_for_training/\"\n\nresult_mapping_file = f\"{ready_for_training_folder}station_cell_mapping.csv\"\n\n\nif os.path.exists(result_mapping_file):\n    exit()\n\n\ngridcells = geojson.load(open(gridcells_file))\ntraining_df = pd.read_csv(training_feature_file, header=0)\ntesting_df = pd.read_csv(testing_feature_file, header=0)\nground_measure_metadata_df = pd.read_csv(ground_measure_metadata_file, header=0)\ntrain_labels_df = pd.read_csv(train_labels_file, header=0)\n\nprint(\"training: \", training_df.head())\nprint(\"testing: \", testing_df.head())\nprint(\"ground measure metadata: \", ground_measure_metadata_df.head())\nprint(\"training labels: \", train_labels_df.head())\n\n\ndef calculateDistance(lat1, lon1, lat2, lon2):\n    lat1 = float(lat1)\n    lon1 = float(lon1)\n    lat2 = float(lat2)\n    lon2 = float(lon2)\n    return math.sqrt((lat1-lat2)**2 + (lon1-lon2)**2)\n  \n# prepare the training data\n\nstation_cell_mapper_df = pd.DataFrame(columns = [\"station_id\", \"cell_id\", \"lat\", \"lon\"])\n\nground_measure_metadata_df = ground_measure_metadata_df.reset_index()  # make sure indexes pair with number of rows\nfor index, row in ground_measure_metadata_df.iterrows():\n  \t\n    print(row['station_id'], row['name'], row['latitude'], row['longitude'])\n    station_lat = row['latitude']\n    station_lon = row['longitude']\n    \n    shortest_dis = 999\n    associated_cell_id = None\n    associated_lat = None\n    associated_lon = None\n    \n    for idx,cell in enumerate(gridcells['features']):\n    \n      current_cell_id = cell['properties']['cell_id']\n\n      #print(\"collecting \", current_cell_id)\n      cell_lon = np.unique(np.ravel(cell['geometry']['coordinates'])[0::2]).mean()\n      cell_lat = np.unique(np.ravel(cell['geometry']['coordinates'])[1::2]).mean()\n\n      dist = calculateDistance(station_lat, station_lon, cell_lat, cell_lon)\n\n      if dist < shortest_dis:\n        associated_cell_id = current_cell_id\n        shortest_dis = dist\n        associated_lat = cell_lat\n        associated_lon = cell_lon\n    \n    station_cell_mapper_df.loc[len(station_cell_mapper_df.index)] = [row['station_id'], associated_cell_id, associated_lat, associated_lon]\n    \nprint(station_cell_mapper_df.head())\nstation_cell_mapper_df.to_csv(f\"{ready_for_training_folder}station_cell_mapping.csv\")\n    \n\n\n      \n",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678206364582,
  "history_end_time" : 1678206378239,
  "history_notes" : null,
  "history_process" : "rmxece",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "o7s0dkwhmx3",
  "history_input" : "# This script will download modis data for all the testing sites from Google Earth Engine.\n# The start date is the last stop date of the last run.\n\nfrom all_dependencies import *\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_df = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'modis'\nproduct_name = f'MODIS/006/MOD10A1'\nvar_name = 'NDSI'\ncolumn_name = 'mod10a1_ndsi'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sat_testing/modis\", \"%Y-%m-%d\")\nend_date = test_end_date\n\nfinal_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/sat_testing/{org_name}/{column_name}_{start_date}_{end_date}.csv\"\nprint(f\"Results will be saved to {final_csv_file}\")\n\nif os.path.exists(final_csv_file):\n    #print(\"exists exiting..\")\n    #exit()\n    os.remove(final_csv_file)\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\nprint(\"start to traverse the cells in submission_format_eval.csv..\")\n\nfor current_cell_id in submission_format_df.index:\n    \n    try:\n      \n  \t  longitude = all_cell_coords_df['lon'][current_cell_id]\n  \t  latitude = all_cell_coords_df['lat'][current_cell_id]\n\n  \t  # identify a 500 meter buffer around our Point Of Interest (POI)\n  \t  poi = ee.Geometry.Point(longitude, latitude).buffer(30)\n\n  \t  def poi_mean(img):\n  \t      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=30)\n  \t      mean = reducer.get(var_name)\n  \t      return img.set('date', img.date().format()).set(column_name,mean)\n        \n  \t  viirs1 = ee.ImageCollection(product_name).filterDate(start_date, end_date)\n  \t  poi_reduced_imgs1 = viirs1.map(poi_mean)\n  \t  nested_list1 = poi_reduced_imgs1.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n  \t  # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n  \t  df = pd.DataFrame(nested_list1.getInfo(), columns=['date',column_name])\n      \n  \t  df['date'] = pd.to_datetime(df['date'])\n  \t  df = df.set_index('date')\n  \t  df['cell_id'] = current_cell_id\n  \t  df['latitude'] = latitude\n  \t  df['longitude'] = longitude\n  \t  #df.to_csv(single_csv_file)\n\n  \t  df_list = [all_cell_df, df]\n  \t  all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      print(traceback.format_exc())\n      print(\"failed\", e)\n      pass\n    \n    \nall_cell_df.to_csv(final_csv_file)  \n\nprint(f\"All points have been saved to {final_csv_file}\")\n\n\n",
  "history_output" : "today date = 2023-03-07\n/home/chetana\n",
  "history_begin_time" : 1678206377835,
  "history_end_time" : 1678206406934,
  "history_notes" : null,
  "history_process" : "illwc1",
  "host_id" : "45wlwr",
  "indicator" : "Failed"
},{
  "history_id" : "9v3xo46l817",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nfrom all_dependencies import *\nfrom snowcast_utils import *\nimport eeauth as e\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\n\nprint(\"submission_format_df shape: \", submission_format_df.shape)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_df = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sat_testing/sentinel1\",\"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nfinal_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/sat_testing/{org_name}/{column_name}_{start_date}_{end_date}.csv\"\nprint(f\"Results will be saved to {final_csv_file}\")\n\n\nif os.path.exists(final_csv_file):\n    #print(\"exists skipping..\")\n    #exit()\n    os.remove(final_csv_file)\n\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor current_cell_id in submission_format_df.index:\n  \n    try:\n  \t\n      #print(\"collecting \", current_cell_id)\n      \n      longitude = all_cell_coords_df['lon'][current_cell_id]\n      latitude = all_cell_coords_df['lat'][current_cell_id]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(10)\n\n      viirs = (ee.ImageCollection(product_name)\n               .filterDate(start_date, end_date)\n               .filterBounds(poi)\n             .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n               .select('VV'))\n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      #print(e)\n      pass\n    \nall_cell_df.to_csv(final_csv_file)\n\n",
  "history_output" : "today date = 2023-03-07\n/home/chetana\n",
  "history_begin_time" : 1678206378401,
  "history_end_time" : 1678206406928,
  "history_notes" : null,
  "history_process" : "sjs5by",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "q1nrzst2uml",
  "history_input" : "'''\nThe wrapper for all the snowcast_wormhole predictors\n'''\nimport os\nimport joblib\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nclass BaseHole:\n  \n  all_ready_file = f\"{github_dir}/data/ready_for_training/all_ready_new.csv\"\n  \n  def __init__(self):\n    self.classifier = self.get_model()\n    self.holename = self.__class__.__name__ \n    self.train_x = None\n    self.train_y = None\n    self.test_x = None\n    self.test_y = None\n    self.test_y_results = None\n    self.save_file = None\n    \n  def save(self):\n    now = datetime.now()\n    date_time = now.strftime(\"%Y%d%m%H%M%S\")\n    self.save_file = f\"{github_dir}/model/wormhole_{self.holename}_{date_time}.joblib\"\n    print(f\"Saving model to {self.save_file}\")\n    joblib.dump(self.classifier, self.save_file)\n  \n  def preprocessing(self):\n    all_ready_pd = pd.read_csv(self.all_ready_file, header=0, index_col=0)\n    input_columns = [\"year\", \"m\", \"day\", \"eto\", \"pr\", \"rmax\", \"rmin\", \"tmmn\", \"tmmx\", \"vpd\", \"vs\", \n                     \"lat\", \"lon\", \"elevation\", \"aspect\", \"curvature\", \"slope\", \"eastness\", \n                     \"northness\", \"swe_0719\", \"depth_0719\"]\n    \n    all_cols = input_columns\n    all_cols.append(\"swe_snotel\")\n    print(\"all columns: \", all_cols)\n    print(type(i) for i in all_cols)\n    all_ready_pd = all_ready_pd[all_cols]\n#     all_ready_pd = all_ready_pd.fillna(10000) # replace all nan with 10000\n    all_ready_pd = all_ready_pd[all_ready_pd[\"swe_snotel\"]!=-1]\n    all_ready_pd = all_ready_pd.dropna()\n    train, test = train_test_split(all_ready_pd, test_size=0.2)\n#     \"cell_id\", \"year\", \"m\", \"day\", \"eto\", \"pr\", \"rmax\", \"rmin\", \"tmmn\", \"tmmx\",\"vpd\", \"vs\", \"lat\", \"lon\",\n#                  \"elevation\", \"aspect\", \"curvature\", \"slope\", \"eastness\", \"northness\", \"swe_0719\", \"depth_0719\", \"swe_snotel\"\n    self.train_x, self.train_y = train[input_columns].to_numpy().astype('float'), train[['swe_snotel']].to_numpy().astype('float')\n    self.test_x, self.test_y = test[input_columns].to_numpy().astype('float'), test[['swe_snotel']].to_numpy().astype('float')\n  \n  def train(self):\n    self.classifier.fit(self.train_x, self.train_y)\n  \n  def test(self):\n    self.test_y_results = self.classifier.predict(self.test_x)\n    return self.test_y_results\n  \n  def predict(self, input_x):\n    return self.classifier.predict(input_x)\n  \n  def evaluate(self):\n    pass\n  \n  def get_model(self):\n    pass\n  \n  def post_processing(self):\n    pass",
  "history_output" : "",
  "history_begin_time" : 1678206364588,
  "history_end_time" : 1678206378247,
  "history_notes" : null,
  "history_process" : "y7nb46",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "11bx0d64bjp",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378248,
  "history_notes" : null,
  "history_process" : "a8p3n7",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "uq5ak1o73m6",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378252,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "h85hb3delxa",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378254,
  "history_notes" : null,
  "history_process" : "4i0sop",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "de5uq91uoe7",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378257,
  "history_notes" : null,
  "history_process" : "b63prf",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "i5uvbiw9g9j",
  "history_input" : "from datetime import date\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nimport math\nimport datetime\n\ntoday = date.today()\n\n# dd/mm/YY\nd1 = today.strftime(\"%Y-%m-%d\")\nprint(\"today date =\", d1)\n\ntrain_start_date = \"\"\ntrain_end_date = \"\"\n\ntest_start_date = \"2022-01-01\"\ntest_end_date = d1\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\n\ndef calculateDistance(lat1, lon1, lat2, lon2):\n    lat1 = float(lat1)\n    lon1 = float(lon1)\n    lat2 = float(lat2)\n    lon2 = float(lon2)\n    return math.sqrt((lat1-lat2)**2 + (lon1-lon2)**2)\n\ndef create_cell_location_csv():\n  # read grid cell\n  gridcells_file = f\"{github_dir}/data/snowcast_provided/grid_cells_eval.geojson\"\n  all_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\n  if os.path.exists(all_cell_coords_file):\n    os.remove(all_cell_coords_file)\n\n  grid_coords_df = pd.DataFrame(columns=[\"cell_id\", \"lat\", \"lon\"])\n  #print(grid_coords_df.head())\n  gridcells = geojson.load(open(gridcells_file))\n  for idx,cell in enumerate(gridcells['features']):\n    \n    current_cell_id = cell['properties']['cell_id']\n    cell_lon = np.unique(np.ravel(cell['geometry']['coordinates'])[0::2]).mean()\n    cell_lat = np.unique(np.ravel(cell['geometry']['coordinates'])[1::2]).mean()\n    grid_coords_df.loc[len(grid_coords_df.index)] = [current_cell_id, cell_lat, cell_lon]\n    \n  #grid_coords_np = grid_coords_df.to_numpy()\n  #print(grid_coords_np.shape)\n  grid_coords_df.to_csv(all_cell_coords_file, index=False)\n  #np.savetxt(all_cell_coords_file, grid_coords_np[:, 1:], delimiter=\",\")\n  #print(grid_coords_np.shape)\n  \ndef get_latest_date_from_an_array(arr, date_format):\n  return max(arr, key=lambda x: datetime.datetime.strptime(x, date_format))\n  \n  \ndef findLastStopDate(target_testing_dir, data_format):\n  date_list = []\n  for filename in os.listdir(target_testing_dir):\n    \n    f = os.path.join(target_testing_dir, filename)\n    # checking if it is a file\n    if os.path.isfile(f) and \".csv\" in f:\n        pdf = pd.read_csv(f,header=0, index_col=0)\n        #print(pdf)\n        date_list = np.concatenate((date_list, pdf.index.unique()))\n        \n  latest_date = get_latest_date_from_an_array(date_list, data_format)\n  #print(latest_date)\n  date_time_obj = datetime.datetime.strptime(latest_date, data_format)\n  return date_time_obj.strftime(\"%Y-%m-%d\")\n\n#create_cell_location_csv()\nfindLastStopDate(f\"/home/chetana/Documents/GitHub/SnowCast/data/sim_training/gridmet/\", \"%Y-%m-%d %H:%M:%S\")\n#findLastStopDate(f\"{github_dir}/data/sat_testing/sentinel1/\", \"%Y-%m-%d %H:%M:%S\")\n#findLastStopDate(f\"{github_dir}/data/sat_testing/modis/\", \"%Y-%m-%d\")\n\n\n\n      \n",
  "history_output" : "",
  "history_begin_time" : 1678206373968,
  "history_end_time" : 1678206378260,
  "history_notes" : null,
  "history_process" : "zh38b6",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "2ir8fhus98n",
  "history_input" : "\nfrom base_hole import *\n\nclass KehanModel(BaseHole):\n\t\n  def preprocessing():\n    pass  \n  \n  def train():\n    pass\n  \n  def test():\n    pass",
  "history_output" : "",
  "history_begin_time" : 1678206364785,
  "history_end_time" : 1678206378261,
  "history_notes" : null,
  "history_process" : "wdh394",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "vq8r3tfr6av",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378262,
  "history_notes" : null,
  "history_process" : "p87wh1",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "9s50qx7caob",
  "history_input" : "from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport json\nimport pandas as pd\nimport ee\nimport eeauth \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\n#pd.set_option('display.max_columns', None)\n",
  "history_output" : "",
  "history_begin_time" : 1678206365457,
  "history_end_time" : 1678206378267,
  "history_notes" : null,
  "history_process" : "ilbqzg",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "7tj7tghkzyv",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378268,
  "history_notes" : null,
  "history_process" : "do86ae",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "dsxqr923psu",
  "history_input" : "# 2019 first https://nsidc.org/data/nsidc-0719/versions/1#anchor-1\n\n# TODO: change LAT LONG TO GRID CELL COORDS\n# TODO: adjust using grid cell geojson in data integration\n# TODO: adjust to make model validation working (model_train_validate)\n\n\"\"\"\nBroxton, P., X. Zeng, and N. Dawson. 2019. Daily 4 km Gridded SWE and Snow Depth from\nAssimilated In-Situ and Modeled Data over the Conterminous US, Version 1. 2019-2021.\nBoulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center.\nhttps://doi.org/10.5067/0GGPB220EX6A. 11/02/2022.\n\nTo enable wget to directly download netcdf from NSIDC, use:\n\necho 'machine urs.earthdata.nasa.gov login <uid> password <password>' >> ~/.netrc\nchmod 0600 ~/.netrc\n\n\"\"\"\n\nfrom math import cos, asin, sqrt, radians\nimport pandas as pd\nimport numpy as np\nimport os.path\nimport netCDF4 as nc\nimport datetime\nimport geojson\nfrom sklearn import neighbors as sk\nimport sys\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngrid_cells = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n# open nsidc data file (netCDF)\n# crs, lat, lon, time, time_str, DEPTH, SWE, SWE_MASK\n# change to make it work\nend_year = 2019\n# https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0719_SWE_Snow_Depth_v1/4km_SWE_Depth_WY2019_v01.nc\nnsidc_data_file = f\"{homedir}/Documents/data/4km_SWE_Depth_WY{end_year}_v01.nc\"\nnsidc_data_ds = nc.Dataset(nsidc_data_file)\n'''\nprint(nsidc_data_ds)\nfor dim in nsidc_data_ds.dimensions.values():\n    print(dim)\nfor var in nsidc_data_ds.variables.values():\n    print(var)\n'''\n# dates based on Water Year 2019 (not normal year)\norg_name = 'nsidc'\nproduct_name = 'NSIDC'\nstart_date = '2018-10-01'\nend_date = '2019-09-30'\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Removes duplicate indices\nscmd = set(station_cell_mapper_df['cell_id'])\n\nlat = nsidc_data_ds.variables['lat'][:]\nlon = nsidc_data_ds.variables['lon'][:]\ndepth = nsidc_data_ds.variables['DEPTH']\nswe = nsidc_data_ds.variables['SWE']\ntime = nsidc_data_ds.variables['time']\ncolumns = ['Year', 'Month', 'Day', 'Lat', 'Lon', 'SWE', 'Depth']\n\nstart_date_dt = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n# conversion factor so we can get days from 0-364 for array\ndays_1900_start = int((start_date_dt - datetime.datetime(1900,1,1)).days)\n\nall_cells_df = pd.DataFrame(columns=columns)\nind = 0\n\n\n# haversine formula\ndef coord_distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295\n    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n    return 12742 * asin(sqrt(hav))\n\n\n# inefficient and bad, don't use this\ndef find_nearest(find_lat, find_lng):\n    min_dist = 999999999\n    curr_min_lat_idx = 0\n    curr_min_lon_idx = 0\n\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng) < min_dist:\n                if depth[23, lat_idx, lon_idx] != '--':\n                    min_dist = coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng)\n                    curr_min_lat_idx = lat_idx\n                    curr_min_lon_idx = lon_idx\n\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\n# for generating the list of all valid lat long pairs\ndef gen_pairs():\n    temp = []\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if depth[23, lat_idx, lon_idx] != '--':\n                temp.append((lat[lat_idx], lon[lon_idx]))\n    temp = np.array(temp)\n    print(temp)\n    np.save(f\"{dfolder}/valid_pairs.npy\", temp)\n\n\n# use balltree to find closest neighbors, convert to radians first so the haversine thing works correctly\n# (that's why there's a separate rad thing)\ndef find_nearest_2(find_lat, find_lng):\n    # generate valid pairs, or just load if they already exist\n    if not os.path.exists(f\"{dfolder}/valid_pairs.npy\"):\n        print(\"file doesn't exist, generating new\")\n        gen_pairs()\n    lat_lon_pairs = np.load(f\"{dfolder}/valid_pairs.npy\")\n    lat_lon_pairs_rad = np.array([[radians(x[0]), radians(x[1])] for x in lat_lon_pairs])\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\n\n    dist, ind = ball_tree.query([(radians(find_lat), radians(find_lng))], return_distance=True)\n    print(dist)\n    print(ind)\n    print(lat_lon_pairs[ind])\n    curr_min_lat_idx = lat_lon_pairs[ind][0][0][0]\n    curr_min_lon_idx = lat_lon_pairs[ind][0][0][1]\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\ndef turn_nsidc_nc_to_csv():\n    \n\n    # comment out if bulk writing!!\n    # all_cells_df.to_csv(f\"{dfolder}/test.csv\", index=False)\n\n    for ind, current_cell_id in enumerate(scmd):\n        # comment out if bulk writing\n        # all_cells_df = pd.DataFrame(columns=columns)\n\n        # Location information\n        longitude = station_cell_mapper_df['lon'][ind]\n        latitude = station_cell_mapper_df['lat'][ind]\n\n    #     print(latitude)\n    #     print(longitude)\n\n        # find closest lat long\n        lat_val, lon_val = find_nearest_2(latitude, longitude, )\n        lat_idx = np.where(lat == lat_val)[0]\n        lon_idx = np.where(lon == lon_val)[0]\n    #     print(lat_val)\n    #     print(lon_val)\n\n        depth_time = depth[:, lat_idx, lon_idx]\n        swe_time = swe[:, lat_idx, lon_idx]\n\n        for ele in time:\n            time_index = int(ele.data - days_1900_start)\n            time_index_dt = datetime.datetime(1900, 1, 1, 0, 0) + datetime.timedelta(int(ele.data))\n            depth_val = depth_time[time_index][0][0]\n            swe_val = swe_time[time_index][0][0]\n\n            all_cells_df.loc[len(all_cells_df.index)] = [time_index_dt.year, time_index_dt.month, time_index_dt.day, lat_val, lon_val, swe_val, depth_val]\n\n        # comment out if bulk writing\n        # all_cells_df.to_csv(f\"{dfolder}/test.csv\", mode='a', header=False, index=False)\n\n    # uncomment to bulk write at end of program\n    all_cells_df.to_csv(f\"{dfolder}/{end_year}nsidc_data.csv\")\n\n    print(\"finished\")\n\n# call this method to extract the \nturn_nsidc_nc_to_csv()",
  "history_output" : "/home/chetana\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.00036589]]\n[[180957]]\n[[[  37.708332 -119.125   ]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00033864]]\n[[164419]]\n[[[  37.083332 -118.75    ]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[0.00015398]]\n[[164425]]\n[[[  37.083332 -118.5     ]]]\n[[0.00031948]]\n[[154543]]\n[[[  36.708332 -118.833336]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00021309]]\n[[267031]]\n[[[  40.791668 -121.791664]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.0002125]]\n[[202215]]\n[[[  38.5      -119.791664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00015498]]\n[[193151]]\n[[[  38.166668 -120.041664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.00024992]]\n[[173209]]\n[[[  37.416668 -119.5     ]]]\n[[0.00013956]]\n[[147950]]\n[[[  36.458332 -118.541664]]]\n[[0.00020465]]\n[[156750]]\n[[[  36.791668 -118.416664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00037612]]\n[[186492]]\n[[[  37.916668 -119.25    ]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00017002]]\n[[178752]]\n[[[  37.625    -119.083336]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.0002125]]\n[[202215]]\n[[[  38.5      -119.791664]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00015417]]\n[[146849]]\n[[[  36.416668 -118.583336]]]\n[[0.00016601]]\n[[183167]]\n[[[  37.791668 -119.208336]]]\n[[0.00032432]]\n[[182046]]\n[[[  37.75     -119.791664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.0003812]]\n[[151250]]\n[[[  36.583332 -118.75    ]]]\n[[0.00032729]]\n[[194278]]\n[[[  38.208332 -119.875   ]]]\n[[0.00032678]]\n[[176538]]\n[[[  37.541668 -119.25    ]]]\n[[0.00022214]]\n[[174321]]\n[[[  37.458332 -119.291664]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00025497]]\n[[167711]]\n[[[  37.208332 -119.208336]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00038418]]\n[[239381]]\n[[[  39.833332 -121.333336]]]\n[[0.00025197]]\n[[193160]]\n[[[  38.166668 -119.666664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00010902]]\n[[238201]]\n[[[  39.791668 -120.875   ]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00021309]]\n[[267031]]\n[[[  40.791668 -121.791664]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00024862]]\n[[277959]]\n[[[  41.166668 -121.958336]]]\n[[0.00019348]]\n[[178753]]\n[[[  37.625    -119.041664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.00017594]]\n[[155643]]\n[[[  36.75     -118.708336]]]\n[[0.00032588]]\n[[189821]]\n[[[  38.041668 -119.666664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[0.00017579]]\n[[145757]]\n[[[  36.375    -118.291664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00035749]]\n[[144646]]\n[[[  36.333332 -118.625   ]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[0.00018052]]\n[[234637]]\n[[[  39.666668 -120.625   ]]]\n[[0.00020109]]\n[[174334]]\n[[[  37.458332 -118.75    ]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[0.00010902]]\n[[238201]]\n[[[  39.791668 -120.875   ]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00035973]]\n[[279150]]\n[[[  41.208332 -122.791664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.0002125]]\n[[202215]]\n[[[  38.5      -119.791664]]]\n[[0.0002774]]\n[[279156]]\n[[[  41.208332 -122.541664]]]\n[[0.00027356]]\n[[196529]]\n[[[  38.291668 -119.625   ]]]\n[[0.0002125]]\n[[202215]]\n[[[  38.5      -119.791664]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00010902]]\n[[238201]]\n[[[  39.791668 -120.875   ]]]\n[[0.00034271]]\n[[166626]]\n[[[  37.166668 -118.541664]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00021444]]\n[[166610]]\n[[[  37.166668 -119.208336]]]\n[[0.00010017]]\n[[184265]]\n[[[  37.833332 -119.458336]]]\n[[0.00013865]]\n[[185376]]\n[[[  37.875    -119.333336]]]\n[[0.00038687]]\n[[167717]]\n[[[  37.208332 -118.958336]]]\n[[0.00031303]]\n[[153453]]\n[[[  36.666668 -118.416664]]]\n[[0.00019106]]\n[[172122]]\n[[[  37.375    -118.916664]]]\n[[0.00022016]]\n[[189830]]\n[[[  38.041668 -119.291664]]]\n[[9.7935995e-05]]\n[[213680]]\n[[[  38.916668 -120.375   ]]]\n[[4.44927463e-05]]\n[[213684]]\n[[[  38.916668 -120.208336]]]\n[[0.00025795]]\n[[185368]]\n[[[  37.875    -119.666664]]]\n[[0.00018855]]\n[[144647]]\n[[[  36.333332 -118.583336]]]\n[[0.00013633]]\n[[163319]]\n[[[  37.041668 -118.916664]]]\n[[0.00022181]]\n[[324594]]\n[[[  42.791668 -121.958336]]]\n[[0.00045162]]\n[[185710]]\n[[[  37.875    -105.416664]]]\n[[0.00025435]]\n[[429279]]\n[[[  46.916668 -110.875   ]]]\n[[0.00021788]]\n[[322295]]\n[[[  42.708332 -120.791664]]]\n[[0.00026951]]\n[[462456]]\n[[[  48.708332 -121.916664]]]\n[[0.00026125]]\n[[411879]]\n[[[  46.166668 -121.916664]]]\n[[0.00032815]]\n[[292970]]\n[[[  41.666668 -111.416664]]]\n[[0.00031911]]\n[[237369]]\n[[[  39.75     -105.916664]]]\n[[0.00025279]]\n[[275892]]\n[[[  41.083332 -106.958336]]]\n[[0.00040204]]\n[[388480]]\n[[[  45.166668 -115.958336]]]\n[[0.00014205]]\n[[136228]]\n[[[  36.       -106.541664]]]\n[[0.00041858]]\n[[256517]]\n[[[  40.416668 -106.625   ]]]\n[[0.0003979]]\n[[256536]]\n[[[  40.416668 -105.833336]]]\n[[0.00019507]]\n[[260145]]\n[[[  40.541668 -105.875   ]]]\n[[0.00033677]]\n[[268603]]\n[[[  40.833332 -106.75    ]]]\n[[0.00030705]]\n[[71813]]\n[[[  33.375    -107.833336]]]\n[[0.00039466]]\n[[260006]]\n[[[  40.541668 -111.666664]]]\n[[0.00035358]]\n[[232605]]\n[[[  39.583332 -106.5     ]]]\n[[0.00010963]]\n[[447727]]\n[[[  47.875    -117.083336]]]\n[[0.00035303]]\n[[336197]]\n[[[  43.208332 -122.125   ]]]\n[[0.00042276]]\n[[284429]]\n[[[  41.375    -106.208336]]]\n[[0.00042276]]\n[[284429]]\n[[[  41.375    -106.208336]]]\n[[0.00030705]]\n[[71813]]\n[[[  33.375    -107.833336]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[9.13684685e-05]]\n[[202219]]\n[[[  38.5   -119.625]]]\n[[0.00022309]]\n[[466617]]\n[[[  48.958332 -115.958336]]]\n[[0.00041662]]\n[[270934]]\n[[[  40.916668 -111.833336]]]\n[[0.00020189]]\n[[173518]]\n[[[  37.416668 -106.625   ]]]\n[[0.00041858]]\n[[256517]]\n[[[  40.416668 -106.625   ]]]\n[[0.00030302]]\n[[176687]]\n[[[  37.541668 -113.041664]]]\n[[0.00030302]]\n[[176687]]\n[[[  37.541668 -113.041664]]]\n[[3.15345512e-05]]\n[[207931]]\n[[[  38.708332 -120.041664]]]\n[[0.00030815]]\n[[436457]]\n[[[  47.291668 -121.333336]]]\n[[0.00022181]]\n[[324594]]\n[[[  42.791668 -121.958336]]]\n[[0.00035873]]\n[[413974]]\n[[[  46.25  -117.375]]]\n[[0.00026204]]\n[[346610]]\n[[[  43.583332 -111.208336]]]\n[[0.0003001]]\n[[374050]]\n[[[  44.625    -122.208336]]]\n[[0.00029972]]\n[[432364]]\n[[[  47.083332 -121.583336]]]\n[[0.00032815]]\n[[292970]]\n[[[  41.666668 -111.416664]]]\n[[0.00029815]]\n[[187786]]\n[[[  37.958332 -111.833336]]]\n[[0.0001205]]\n[[208256]]\n[[[  38.708332 -106.416664]]]\n[[0.00013927]]\n[[224389]]\n[[[  39.291668 -106.541664]]]\n[[0.00026125]]\n[[411879]]\n[[[  46.166668 -121.916664]]]\n[[0.00025921]]\n[[389637]]\n[[[  45.208332 -110.25    ]]]\n[[0.00012545]]\n[[444361]]\n[[[  47.708332 -123.458336]]]\n[[0.00026125]]\n[[411879]]\n[[[  46.166668 -121.916664]]]\n[[0.00031334]]\n[[143618]]\n[[[  36.291668 -115.666664]]]\n[[0.00031334]]\n[[143618]]\n[[[  36.291668 -115.666664]]]\n[[0.00032815]]\n[[292970]]\n[[[  41.666668 -111.416664]]]\n[[0.00032815]]\n[[292970]]\n[[[  41.666668 -111.416664]]]\n[[0.00032815]]\n[[292970]]\n[[[  41.666668 -111.416664]]]\n[[0.00025279]]\n[[275892]]\n[[[  41.083332 -106.958336]]]\n[[0.00035358]]\n[[232605]]\n[[[  39.583332 -106.5     ]]]\n[[0.00026446]]\n[[109297]]\n[[[  34.958332 -111.5     ]]]\n[[0.00034654]]\n[[256538]]\n[[[  40.416668 -105.75    ]]]\n[[0.00034654]]\n[[256538]]\n[[[  40.416668 -105.75    ]]]\n[[0.00029183]]\n[[185681]]\n[[[  37.875 -106.625]]]\n[[0.00038069]]\n[[78266]]\n[[[  33.666668 -109.291664]]]\n[[0.00016855]]\n[[202538]]\n[[[  38.5      -106.333336]]]\n[[0.00030129]]\n[[416899]]\n[[[  46.375    -121.083336]]]\n[[0.00012986]]\n[[373281]]\n[[[  44.583332 -107.208336]]]\n[[3.87134852e-05]]\n[[362136]]\n[[[  44.166668 -107.125   ]]]\n[[0.00015419]]\n[[330682]]\n[[[  43.   -109.75]]]\n[[0.00023674]]\n[[319102]]\n[[[  42.583332 -108.833336]]]\n[[8.83810871e-05]]\n[[267286]]\n[[[  40.791668 -110.875   ]]]\n[[0.00027775]]\n[[296540]]\n[[[  41.791668 -116.041664]]]\n[[0.00034885]]\n[[116759]]\n[[[  35.25 -108.25]]]\n[[0.00034215]]\n[[107190]]\n[[[  34.875 -111.625]]]\n[[0.0001517]]\n[[104042]]\n[[[  34.75     -111.416664]]]\n[[0.00013821]]\n[[216303]]\n[[[  39.   -106.75]]]\n[[0.00016356]]\n[[174581]]\n[[[  37.458332 -108.458336]]]\n[[0.00033874]]\n[[457740]]\n[[[  48.416668 -113.916664]]]\n[[0.00024296]]\n[[230122]]\n[[[  39.5      -111.708336]]]\n[[0.00032894]]\n[[232381]]\n[[[  39.583332 -115.833336]]]\n[[0.00022015]]\n[[177796]]\n[[[  37.583332 -112.916664]]]\n[[0.00029815]]\n[[187786]]\n[[[  37.958332 -111.833336]]]\n[[0.00032894]]\n[[232381]]\n[[[  39.583332 -115.833336]]]\n[[0.00032894]]\n[[232381]]\n[[[  39.583332 -115.833336]]]\n[[0.00022015]]\n[[177796]]\n[[[  37.583332 -112.916664]]]\n[[0.00032894]]\n[[232381]]\n[[[  39.583332 -115.833336]]]\n[[0.00035619]]\n[[202393]]\n[[[  38.5   -112.375]]]\n[[0.00028668]]\n[[462486]]\n[[[  48.708332 -120.666664]]]\n[[0.00035391]]\n[[177932]]\n[[[  37.583332 -107.25    ]]]\n[[0.00019507]]\n[[260145]]\n[[[  40.541668 -105.875   ]]]\n[[0.00012476]]\n[[269738]]\n[[[  40.875    -110.541664]]]\n[[0.0003001]]\n[[374050]]\n[[[  44.625    -122.208336]]]\n[[0.0003001]]\n[[374050]]\n[[[  44.625    -122.208336]]]\n[[0.00032386]]\n[[148270]]\n[[[  36.458332 -105.208336]]]\n[[0.00032386]]\n[[148270]]\n[[[  36.458332 -105.208336]]]\n[[0.00032386]]\n[[148270]]\n[[[  36.458332 -105.208336]]]\n[[0.00039874]]\n[[459718]]\n[[[  48.541668 -120.75    ]]]\n[[0.00028356]]\n[[162526]]\n[[[  37.       -106.291664]]]\n[[0.00031999]]\n[[219632]]\n[[[  39.125    -111.458336]]]\n[[0.00014601]]\n[[183432]]\n[[[  37.791668 -108.166664]]]\n[[0.00031911]]\n[[237369]]\n[[[  39.75     -105.916664]]]\n[[0.00026176]]\n[[250509]]\n[[[  40.208332 -105.583336]]]\n[[0.00019668]]\n[[266072]]\n[[[  40.75  -110.625]]]\n[[0.00034733]]\n[[255062]]\n[[[  40.375 -116.875]]]\n[[9.15488263e-05]]\n[[283188]]\n[[[  41.333332 -106.375   ]]]\n[[0.00022015]]\n[[177796]]\n[[[  37.583332 -112.916664]]]\n[[0.00017289]]\n[[258783]]\n[[[  40.5   -112.625]]]\n[[0.00022445]]\n[[185613]]\n[[[  37.875    -109.458336]]]\n[[0.00025986]]\n[[240815]]\n[[[  39.875 -111.25 ]]]\n[[0.00021975]]\n[[225438]]\n[[[  39.333332 -111.5     ]]]\n[[0.00012938]]\n[[252783]]\n[[[  40.291668 -111.25    ]]]\n[[0.00031999]]\n[[219632]]\n[[[  39.125    -111.458336]]]\n[[0.00020894]]\n[[263633]]\n[[[  40.666668 -110.958336]]]\n[[0.00021975]]\n[[225438]]\n[[[  39.333332 -111.5     ]]]\n[[0.00021975]]\n[[225438]]\n[[[  39.333332 -111.5     ]]]\n[[0.00031999]]\n[[219632]]\n[[[  39.125    -111.458336]]]\n[[0.00030129]]\n[[416899]]\n[[[  46.375    -121.083336]]]\n[[0.00026128]]\n[[234882]]\n[[[  39.666668 -110.416664]]]\n[[0.00014923]]\n[[213691]]\n[[[  38.916668 -119.916664]]]\n[[0.0003611]]\n[[269634]]\n[[[  40.875    -115.208336]]]\n[[0.00030221]]\n[[272081]]\n[[[  40.958332 -115.083336]]]\n[[0.00017289]]\n[[258783]]\n[[[  40.5   -112.625]]]\n[[0.00022015]]\n[[177796]]\n[[[  37.583332 -112.916664]]]\n[[0.00029815]]\n[[187786]]\n[[[  37.958332 -111.833336]]]\n[[0.00026176]]\n[[250509]]\n[[[  40.208332 -105.583336]]]\n[[0.00025279]]\n[[275892]]\n[[[  41.083332 -106.958336]]]\n[[0.00020455]]\n[[139488]]\n[[[  36.125    -105.541664]]]\n[[0.00010963]]\n[[447727]]\n[[[  47.875    -117.083336]]]\n[[0.00012719]]\n[[426421]]\n[[[  46.791668 -121.75    ]]]\n[[0.00019681]]\n[[302446]]\n[[[  42.       -120.166664]]]\n[[0.00028668]]\n[[462486]]\n[[[  48.708332 -120.666664]]]\n[[0.00029815]]\n[[187786]]\n[[[  37.958332 -111.833336]]]\n[[0.00027775]]\n[[296540]]\n[[[  41.791668 -116.041664]]]\n[[0.00026125]]\n[[411879]]\n[[[  46.166668 -121.916664]]]\n[[0.00029815]]\n[[187786]]\n[[[  37.958332 -111.833336]]]\n[[0.00036997]]\n[[84911]]\n[[[  33.958332 -109.5     ]]]\n[[7.66642558e-05]]\n[[292876]]\n[[[  41.666668 -115.333336]]]\n[[0.00010902]]\n[[238201]]\n[[[  39.791668 -120.875   ]]]\n[[0.00035619]]\n[[202393]]\n[[[  38.5   -112.375]]]\n[[0.00024296]]\n[[230122]]\n[[[  39.5      -111.708336]]]\n[[0.00011195]]\n[[400403]]\n[[[  45.666668 -113.958336]]]\n[[0.00033222]]\n[[369791]]\n[[[  44.458332 -113.      ]]]\nfinished\n",
  "history_begin_time" : 1678206375332,
  "history_end_time" : 1678206948375,
  "history_notes" : null,
  "history_process" : "gkhtc0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "q17o676sm48",
  "history_input" : "from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom base_hole import BaseHole\nfrom sklearn.model_selection import train_test_split\nfrom datetime import datetime\nfrom model_creation_rf import RandomForestHole\nfrom sklearn.ensemble import ExtraTreesRegressor\n\nclass ExtraTreeHole(RandomForestHole):\n\n  def get_model(self):\n    \"\"\"\n    rfc_pipeline = Pipeline(steps = [\n      ('data_scaling', StandardScaler()),\n      ('model', RandomForestRegressor(max_depth = 15,\n                                       min_samples_leaf = 0.004,\n                                       min_samples_split = 0.008,\n                                       n_estimators = 25))])\n    #return rfc_pipeline\n  \t\"\"\"\n    etmodel = ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse', max_depth=None, max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0,\n                    #min_impurity_split=None, \n                    min_samples_leaf=1,\n                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n                    n_estimators=100, n_jobs=-1, oob_score=False,\n                    random_state=123, verbose=0, warm_start=False)\n    return etmodel\n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1678206373516,
  "history_end_time" : 1678206379284,
  "history_notes" : null,
  "history_process" : "lbd6cp",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "hzwl6x6ou71",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678206364593,
  "history_end_time" : 1678206379284,
  "history_notes" : null,
  "history_process" : "lbd6cp",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
}]
