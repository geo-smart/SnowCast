[{
  "history_id" : "syo4xqsxkaa",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1688416860238,
  "history_end_time" : 1688416907377,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "nc875nusle7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1688416833718,
  "history_end_time" : 1688416848468,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "cb9ljrwt53r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1688416668380,
  "history_end_time" : 1688416822957,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "wr795t387m6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1688416628778,
  "history_end_time" : 1688416660675,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "ebfrtgvyvn8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1688416567326,
  "history_end_time" : 1688416575019,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "9njtbzq3fmu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1687463685024,
  "history_end_time" : 1687463685024,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "aky18103e2s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1687463635438,
  "history_end_time" : 1687463635438,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mf4fnl0w6j0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1686236147018,
  "history_end_time" : 1686237909496,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "crroqfbou9n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1686235960975,
  "history_end_time" : 1686235985414,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "kgyjifmj8w3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1686235529631,
  "history_end_time" : 1686235529631,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Skipped"
},{
  "history_id" : "odrl9k0j5zc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1686235448229,
  "history_end_time" : 1686235482630,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "bfeugsbg7h8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1686235402215,
  "history_end_time" : 1686235424784,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "uz60b9iifee",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1686153654215,
  "history_end_time" : 1686153654215,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Skipped"
},{
  "history_id" : "c48my1lbxmm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682984798069,
  "history_end_time" : 1682984800295,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "tnjx172xedk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1681516927643,
  "history_end_time" : 1681516927643,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "y9ki5i2w449",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1681039707715,
  "history_end_time" : 1681039707715,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5kbf9ougj9i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1681039689409,
  "history_end_time" : 1681039697767,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "7qmeh6w40if",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1681007820131,
  "history_end_time" : 1681007820131,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0xmkw8yalnw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678748546947,
  "history_end_time" : 1678748546947,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0s16bs21511",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677582848601,
  "history_end_time" : 1677582848601,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1i3h2akv1gv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676063613441,
  "history_end_time" : 1676063613441,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "js3lmdo1amd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675783782337,
  "history_end_time" : 1675783782337,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lBHsHi1Fu3GA",
  "history_input" : "# 2019 first https://nsidc.org/data/nsidc-0719/versions/1#anchor-1\n\n# TODO: change LAT LONG TO GRID CELL COORDS\n# TODO: adjust using grid cell geojson in data integration\n# TODO: adjust to make model validation working (model_train_validate)\n\n\"\"\"\nBroxton, P., X. Zeng, and N. Dawson. 2019. Daily 4 km Gridded SWE and Snow Depth from\nAssimilated In-Situ and Modeled Data over the Conterminous US, Version 1. 2019-2021.\nBoulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center.\nhttps://doi.org/10.5067/0GGPB220EX6A. 11/02/2022.\n\nTo enable wget to directly download netcdf from NSIDC, use:\n\necho 'machine urs.earthdata.nasa.gov login <uid> password <password>' >> ~/.netrc\nchmod 0600 ~/.netrc\n\n\"\"\"\n\nfrom math import cos, asin, sqrt, radians\nimport pandas as pd\nimport numpy as np\nimport os.path\nimport netCDF4 as nc\nimport datetime\nimport geojson\nfrom sklearn import neighbors as sk\nimport sys\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngrid_cells = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n# open nsidc data file (netCDF)\n# crs, lat, lon, time, time_str, DEPTH, SWE, SWE_MASK\n# change to make it work\nend_year = 2019\n# https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0719_SWE_Snow_Depth_v1/4km_SWE_Depth_WY2019_v01.nc\nnsidc_data_file = f\"{homedir}/Documents/data/4km_SWE_Depth_WY{end_year}_v01.nc\"\nnsidc_data_ds = nc.Dataset(nsidc_data_file)\nlat_lon_pairs_rad = []\n\nprint(nsidc_data_ds)\nfor dim in nsidc_data_ds.dimensions.values():\n    print(dim)\nfor var in nsidc_data_ds.variables.values():\n    print(var)\n\n# dates based on Water Year 2019 (not normal year)\norg_name = 'nsidc'\nproduct_name = 'NSIDC'\nstart_date = '2018-10-01'\nend_date = '2019-09-30'\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Removes duplicate indices\nscmd = set(station_cell_mapper_df['cell_id'])\n\nlat = nsidc_data_ds.variables['lat'][:]\nlon = nsidc_data_ds.variables['lon'][:]\ndepth = nsidc_data_ds.variables['DEPTH']\nswe = nsidc_data_ds.variables['SWE']\ntime = nsidc_data_ds.variables['time']\ncolumns = ['Year', 'Month', 'Day', 'Lat', 'Lon', 'SWE', 'Depth']\n\nstart_date_dt = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n# conversion factor so we can get days from 0-364 for array\ndays_1900_start = int((start_date_dt - datetime.datetime(1900,1,1)).days)\n\nall_cells_df = pd.DataFrame(columns=columns)\nind = 0\n\n\n# haversine formula\ndef coord_distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295\n    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n    return 12742 * asin(sqrt(hav))\n\n\n# inefficient and bad, don't use this\ndef find_nearest(find_lat, find_lng):\n    min_dist = 999999999\n    curr_min_lat_idx = 0\n    curr_min_lon_idx = 0\n\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng) < min_dist:\n                if depth[23, lat_idx, lon_idx] != '--':\n                    min_dist = coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng)\n                    curr_min_lat_idx = lat_idx\n                    curr_min_lon_idx = lon_idx\n\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\n# for generating the list of all valid lat long pairs\ndef gen_pairs():\n    temp = []\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if depth[23, lat_idx, lon_idx] != '--':\n                temp.append((lat[lat_idx], lon[lon_idx]))\n    temp = np.array(temp)\n    print(temp)\n    np.save(f\"{dfolder}/valid_pairs.npy\", temp)\n\n\n# use balltree to find closest neighbors, convert to radians first so the haversine thing works correctly\n# (that's why there's a separate rad thing)\ndef find_nearest_2(find_lat, find_lng):\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\n\n    dist, ind = ball_tree.query([(radians(find_lat), radians(find_lng))], return_distance=True)\n    print(dist)\n    print(ind)\n    print(lat_lon_pairs[ind])\n    curr_min_lat_idx = lat_lon_pairs[ind][0][0][0]\n    curr_min_lon_idx = lat_lon_pairs[ind][0][0][1]\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\ndef turn_nsidc_nc_to_csv():\n    # generate valid pairs, or just load if they already exist\n    if not os.path.exists(f\"{dfolder}/valid_pairs.npy\"):\n        print(\"file doesn't exist, generating new\")\n        gen_pairs()\n    lat_lon_pairs = np.load(f\"{dfolder}/valid_pairs.npy\")\n    lat_lon_pairs_rad = np.array([[radians(x[0]), radians(x[1])] for x in lat_lon_pairs])\n\n    # comment out if bulk writing!!\n    # all_cells_df.to_csv(f\"{dfolder}/test.csv\", index=False)\n\n    for ind, current_cell_id in enumerate(scmd):\n        # comment out if bulk writing\n        # all_cells_df = pd.DataFrame(columns=columns)\n\n        # Location information\n        longitude = station_cell_mapper_df['lon'][ind]\n        latitude = station_cell_mapper_df['lat'][ind]\n\n    #     print(latitude)\n    #     print(longitude)\n\n        # find closest lat long\n        lat_val, lon_val = find_nearest_2(latitude, longitude)\n        lat_idx = np.where(lat == lat_val)[0]\n        lon_idx = np.where(lon == lon_val)[0]\n    #     print(lat_val)\n    #     print(lon_val)\n\n        depth_time = depth[:, lat_idx, lon_idx]\n        swe_time = swe[:, lat_idx, lon_idx]\n\n        for ele in time:\n            time_index = int(ele.data - days_1900_start)\n            time_index_dt = datetime.datetime(1900, 1, 1, 0, 0) + datetime.timedelta(int(ele.data))\n            depth_val = depth_time[time_index][0][0]\n            swe_val = swe_time[time_index][0][0]\n\n            all_cells_df.loc[len(all_cells_df.index)] = [time_index_dt.year, time_index_dt.month, time_index_dt.day, lat_val, lon_val, swe_val, depth_val]\n\n        # comment out if bulk writing\n        # all_cells_df.to_csv(f\"{dfolder}/test.csv\", mode='a', header=False, index=False)\n\n    # uncomment to bulk write at end of program\n    all_cells_df.to_csv(f\"{dfolder}/{end_year}nsidc_data.csv\")\n\n    print(\"finished\")\n\n# call this method to extract the \n#turn_nsidc_nc_to_csv()\nfor end_year in range(2001, 2022):\n  start_date = f'{end_year-1}-10-01'\n  end_date = f'{end_year}-09-30'\n  turn_nsidc_nc_to_csv()\n",
  "history_output" : "/Users/joe\n<class 'netCDF4._netCDF4.Dataset'>\nroot group (NETCDF4 data model, file format HDF5):\n    dimensions(sizes): lat(621), lon(1405), time(365), time_str_len(11)\n    variables(dimensions): |S1 crs(), float32 lat(lat), float32 lon(lon), float32 time(time), |S1 time_str(time_str_len, time), int16 SWE(time, lat, lon), int16 DEPTH(time, lat, lon)\n    groups: \n<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 621\n<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 1405\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 365\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time_str_len', size = 11\n<class 'netCDF4._netCDF4.Variable'>\n|S1 crs()\n    grid_mapping_name: latitude_longitude\n    long_name: CRS definition\n    longitude_of_prime_meridian: 0.0\n    semi_major_axis: 6378137.0\n    inverse_flattening: 298.257222101\n    spatial_ref: GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]]\n    GeoTransform: -125.0208 0.04166662697178698 0 49.9375 0 -0.04166662697178698 \nunlimited dimensions: \ncurrent shape = ()\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lat(lat)\n    long_name: latitude\n    units: degrees north\nunlimited dimensions: \ncurrent shape = (621,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lon(lon)\n    long_name: longitude\n    units: degrees east\nunlimited dimensions: \ncurrent shape = (1405,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 time(time)\n    long_name: time\n    units: days since 1900-01-01\nunlimited dimensions: \ncurrent shape = (365,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\n|S1 time_str(time_str_len, time)\n    long_name: time (string)\n    format: dd-mmm-yyyy\nunlimited dimensions: \ncurrent shape = (11, 365)\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nint16 SWE(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Water Equivalent\n    grid_mapping: crs\n    units: millimeters h20\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\n<class 'netCDF4._netCDF4.Variable'>\nint16 DEPTH(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Depth\n    grid_mapping: crs\n    units: millimeters snow thickness\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/lBHsHi1Fu3GA/data_nsidc_4km_swe_testing.py\", line 192, in <module>\n    turn_nsidc_nc_to_csv()\n  File \"/Users/joe/gw-workspace/lBHsHi1Fu3GA/data_nsidc_4km_swe_testing.py\", line 162, in turn_nsidc_nc_to_csv\n    lat_val, lon_val = find_nearest_2(latitude, longitude)\n  File \"/Users/joe/gw-workspace/lBHsHi1Fu3GA/data_nsidc_4km_swe_testing.py\", line 128, in find_nearest_2\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\n  File \"sklearn/neighbors/_binary_tree.pxi\", line 955, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 769, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
  "history_begin_time" : 1672791461169,
  "history_end_time" : 1672791462553,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "suFOmxg8B5xy",
  "history_input" : "# 2019 first https://nsidc.org/data/nsidc-0719/versions/1#anchor-1\n\n# TODO: change LAT LONG TO GRID CELL COORDS\n# TODO: adjust using grid cell geojson in data integration\n# TODO: adjust to make model validation working (model_train_validate)\n\n\"\"\"\nBroxton, P., X. Zeng, and N. Dawson. 2019. Daily 4 km Gridded SWE and Snow Depth from\nAssimilated In-Situ and Modeled Data over the Conterminous US, Version 1. 2019-2021.\nBoulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center.\nhttps://doi.org/10.5067/0GGPB220EX6A. 11/02/2022.\n\nTo enable wget to directly download netcdf from NSIDC, use:\n\necho 'machine urs.earthdata.nasa.gov login <uid> password <password>' >> ~/.netrc\nchmod 0600 ~/.netrc\n\n\"\"\"\n\nfrom math import cos, asin, sqrt, radians\nimport pandas as pd\nimport numpy as np\nimport os.path\nimport netCDF4 as nc\nimport datetime\nimport geojson\nfrom sklearn import neighbors as sk\nimport sys\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngrid_cells = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n# open nsidc data file (netCDF)\n# crs, lat, lon, time, time_str, DEPTH, SWE, SWE_MASK\n# change to make it work\nend_year = 2019\n# https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0719_SWE_Snow_Depth_v1/4km_SWE_Depth_WY2019_v01.nc\nnsidc_data_file = f\"{homedir}/Documents/data/4km_SWE_Depth_WY{end_year}_v01.nc\"\nnsidc_data_ds = nc.Dataset(nsidc_data_file)\nlat_lon_pairs_rad = []\n\nprint(nsidc_data_ds)\nfor dim in nsidc_data_ds.dimensions.values():\n    print(dim)\nfor var in nsidc_data_ds.variables.values():\n    print(var)\n\n# dates based on Water Year 2019 (not normal year)\norg_name = 'nsidc'\nproduct_name = 'NSIDC'\nstart_date = '2018-10-01'\nend_date = '2019-09-30'\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Removes duplicate indices\nscmd = set(station_cell_mapper_df['cell_id'])\n\nlat = nsidc_data_ds.variables['lat'][:]\nlon = nsidc_data_ds.variables['lon'][:]\ndepth = nsidc_data_ds.variables['DEPTH']\nswe = nsidc_data_ds.variables['SWE']\ntime = nsidc_data_ds.variables['time']\ncolumns = ['Year', 'Month', 'Day', 'Lat', 'Lon', 'SWE', 'Depth']\n\nstart_date_dt = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n# conversion factor so we can get days from 0-364 for array\ndays_1900_start = int((start_date_dt - datetime.datetime(1900,1,1)).days)\n\nall_cells_df = pd.DataFrame(columns=columns)\nind = 0\n\n\n# haversine formula\ndef coord_distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295\n    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n    return 12742 * asin(sqrt(hav))\n\n\n# inefficient and bad, don't use this\ndef find_nearest(find_lat, find_lng):\n    min_dist = 999999999\n    curr_min_lat_idx = 0\n    curr_min_lon_idx = 0\n\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng) < min_dist:\n                if depth[23, lat_idx, lon_idx] != '--':\n                    min_dist = coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng)\n                    curr_min_lat_idx = lat_idx\n                    curr_min_lon_idx = lon_idx\n\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\n# for generating the list of all valid lat long pairs\ndef gen_pairs():\n    temp = []\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if depth[23, lat_idx, lon_idx] != '--':\n                temp.append((lat[lat_idx], lon[lon_idx]))\n    temp = np.array(temp)\n    print(temp)\n    np.save(f\"{dfolder}/valid_pairs.npy\", temp)\n\n\n# use balltree to find closest neighbors, convert to radians first so the haversine thing works correctly\n# (that's why there's a separate rad thing)\ndef find_nearest_2(find_lat, find_lng):\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\n\n    dist, ind = ball_tree.query([(radians(find_lat), radians(find_lng))], return_distance=True)\n    print(dist)\n    print(ind)\n    print(lat_lon_pairs[ind])\n    curr_min_lat_idx = lat_lon_pairs[ind][0][0][0]\n    curr_min_lon_idx = lat_lon_pairs[ind][0][0][1]\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\ndef turn_nsidc_nc_to_csv():\n    # generate valid pairs, or just load if they already exist\n    if not os.path.exists(f\"{dfolder}/valid_pairs.npy\"):\n        print(\"file doesn't exist, generating new\")\n        gen_pairs()\n    lat_lon_pairs = np.load(f\"{dfolder}/valid_pairs.npy\")\n    lat_lon_pairs_rad = np.array([[radians(x[0]), radians(x[1])] for x in lat_lon_pairs])\n\n    # comment out if bulk writing!!\n    # all_cells_df.to_csv(f\"{dfolder}/test.csv\", index=False)\n\n    for ind, current_cell_id in enumerate(scmd):\n        # comment out if bulk writing\n        # all_cells_df = pd.DataFrame(columns=columns)\n\n        # Location information\n        longitude = station_cell_mapper_df['lon'][ind]\n        latitude = station_cell_mapper_df['lat'][ind]\n\n    #     print(latitude)\n    #     print(longitude)\n\n        # find closest lat long\n        lat_val, lon_val = find_nearest_2(latitude, longitude)\n        lat_idx = np.where(lat == lat_val)[0]\n        lon_idx = np.where(lon == lon_val)[0]\n    #     print(lat_val)\n    #     print(lon_val)\n\n        depth_time = depth[:, lat_idx, lon_idx]\n        swe_time = swe[:, lat_idx, lon_idx]\n\n        for ele in time:\n            time_index = int(ele.data - days_1900_start)\n            time_index_dt = datetime.datetime(1900, 1, 1, 0, 0) + datetime.timedelta(int(ele.data))\n            depth_val = depth_time[time_index][0][0]\n            swe_val = swe_time[time_index][0][0]\n\n            all_cells_df.loc[len(all_cells_df.index)] = [time_index_dt.year, time_index_dt.month, time_index_dt.day, lat_val, lon_val, swe_val, depth_val]\n\n        # comment out if bulk writing\n        # all_cells_df.to_csv(f\"{dfolder}/test.csv\", mode='a', header=False, index=False)\n\n    # uncomment to bulk write at end of program\n    all_cells_df.to_csv(f\"{dfolder}/{end_year}nsidc_data.csv\")\n\n    print(\"finished\")\n\n# call this method to extract the \n#turn_nsidc_nc_to_csv()\nfor end_year in range(2001, 2022):\n  turn_nsidc_nc_to_csv()\n",
  "history_output" : "/Users/joe\n<class 'netCDF4._netCDF4.Dataset'>\nroot group (NETCDF4 data model, file format HDF5):\n    dimensions(sizes): lat(621), lon(1405), time(365), time_str_len(11)\n    variables(dimensions): |S1 crs(), float32 lat(lat), float32 lon(lon), float32 time(time), |S1 time_str(time_str_len, time), int16 SWE(time, lat, lon), int16 DEPTH(time, lat, lon)\n    groups: \n<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 621\n<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 1405\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 365\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time_str_len', size = 11\n<class 'netCDF4._netCDF4.Variable'>\n|S1 crs()\n    grid_mapping_name: latitude_longitude\n    long_name: CRS definition\n    longitude_of_prime_meridian: 0.0\n    semi_major_axis: 6378137.0\n    inverse_flattening: 298.257222101\n    spatial_ref: GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]]\n    GeoTransform: -125.0208 0.04166662697178698 0 49.9375 0 -0.04166662697178698 \nunlimited dimensions: \ncurrent shape = ()\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lat(lat)\n    long_name: latitude\n    units: degrees north\nunlimited dimensions: \ncurrent shape = (621,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lon(lon)\n    long_name: longitude\n    units: degrees east\nunlimited dimensions: \ncurrent shape = (1405,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 time(time)\n    long_name: time\n    units: days since 1900-01-01\nunlimited dimensions: \ncurrent shape = (365,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\n|S1 time_str(time_str_len, time)\n    long_name: time (string)\n    format: dd-mmm-yyyy\nunlimited dimensions: \ncurrent shape = (11, 365)\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nint16 SWE(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Water Equivalent\n    grid_mapping: crs\n    units: millimeters h20\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\n<class 'netCDF4._netCDF4.Variable'>\nint16 DEPTH(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Depth\n    grid_mapping: crs\n    units: millimeters snow thickness\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/suFOmxg8B5xy/data_nsidc_4km_swe_testing.py\", line 190, in <module>\n    turn_nsidc_nc_to_csv()\n  File \"/Users/joe/gw-workspace/suFOmxg8B5xy/data_nsidc_4km_swe_testing.py\", line 162, in turn_nsidc_nc_to_csv\n    lat_val, lon_val = find_nearest_2(latitude, longitude)\n  File \"/Users/joe/gw-workspace/suFOmxg8B5xy/data_nsidc_4km_swe_testing.py\", line 128, in find_nearest_2\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\n  File \"sklearn/neighbors/_binary_tree.pxi\", line 955, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 769, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
  "history_begin_time" : 1672791421565,
  "history_end_time" : 1672791422934,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "EPjestyVWvM2",
  "history_input" : "# 2019 first https://nsidc.org/data/nsidc-0719/versions/1#anchor-1\n\n# TODO: change LAT LONG TO GRID CELL COORDS\n# TODO: adjust using grid cell geojson in data integration\n# TODO: adjust to make model validation working (model_train_validate)\n\n\"\"\"\nBroxton, P., X. Zeng, and N. Dawson. 2019. Daily 4 km Gridded SWE and Snow Depth from\nAssimilated In-Situ and Modeled Data over the Conterminous US, Version 1. 2019-2021.\nBoulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center.\nhttps://doi.org/10.5067/0GGPB220EX6A. 11/02/2022.\n\nTo enable wget to directly download netcdf from NSIDC, use:\n\necho 'machine urs.earthdata.nasa.gov login <uid> password <password>' >> ~/.netrc\nchmod 0600 ~/.netrc\n\n\"\"\"\n\nfrom math import cos, asin, sqrt, radians\nimport pandas as pd\nimport numpy as np\nimport os.path\nimport netCDF4 as nc\nimport datetime\nimport geojson\nfrom sklearn import neighbors as sk\nimport sys\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngrid_cells = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n# open nsidc data file (netCDF)\n# crs, lat, lon, time, time_str, DEPTH, SWE, SWE_MASK\n# change to make it work\nend_year = 2019\n# https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0719_SWE_Snow_Depth_v1/4km_SWE_Depth_WY2019_v01.nc\nnsidc_data_file = f\"{homedir}/Documents/data/4km_SWE_Depth_WY{end_year}_v01.nc\"\nnsidc_data_ds = nc.Dataset(nsidc_data_file)\n\nprint(nsidc_data_ds)\nfor dim in nsidc_data_ds.dimensions.values():\n    print(dim)\nfor var in nsidc_data_ds.variables.values():\n    print(var)\n\n# dates based on Water Year 2019 (not normal year)\norg_name = 'nsidc'\nproduct_name = 'NSIDC'\nstart_date = '2018-10-01'\nend_date = '2019-09-30'\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Removes duplicate indices\nscmd = set(station_cell_mapper_df['cell_id'])\n\nlat = nsidc_data_ds.variables['lat'][:]\nlon = nsidc_data_ds.variables['lon'][:]\ndepth = nsidc_data_ds.variables['DEPTH']\nswe = nsidc_data_ds.variables['SWE']\ntime = nsidc_data_ds.variables['time']\ncolumns = ['Year', 'Month', 'Day', 'Lat', 'Lon', 'SWE', 'Depth']\n\nstart_date_dt = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n# conversion factor so we can get days from 0-364 for array\ndays_1900_start = int((start_date_dt - datetime.datetime(1900,1,1)).days)\n\nall_cells_df = pd.DataFrame(columns=columns)\nind = 0\n\n\n# haversine formula\ndef coord_distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295\n    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n    return 12742 * asin(sqrt(hav))\n\n\n# inefficient and bad, don't use this\ndef find_nearest(find_lat, find_lng):\n    min_dist = 999999999\n    curr_min_lat_idx = 0\n    curr_min_lon_idx = 0\n\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng) < min_dist:\n                if depth[23, lat_idx, lon_idx] != '--':\n                    min_dist = coord_distance(lat[lat_idx], lon[lon_idx], find_lat, find_lng)\n                    curr_min_lat_idx = lat_idx\n                    curr_min_lon_idx = lon_idx\n\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\n# for generating the list of all valid lat long pairs\ndef gen_pairs():\n    temp = []\n    lat_len = len(lat)\n    lon_len = len(lon)\n    # iterate through lat and long to find closest val\n    for lat_idx in range(lat_len):\n        for lon_idx in range(lon_len):\n            if depth[23, lat_idx, lon_idx] != '--':\n                temp.append((lat[lat_idx], lon[lon_idx]))\n    temp = np.array(temp)\n    print(temp)\n    np.save(f\"{dfolder}/valid_pairs.npy\", temp)\n\n\n# use balltree to find closest neighbors, convert to radians first so the haversine thing works correctly\n# (that's why there's a separate rad thing)\ndef find_nearest_2(find_lat, find_lng):\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\n\n    dist, ind = ball_tree.query([(radians(find_lat), radians(find_lng))], return_distance=True)\n    print(dist)\n    print(ind)\n    print(lat_lon_pairs[ind])\n    curr_min_lat_idx = lat_lon_pairs[ind][0][0][0]\n    curr_min_lon_idx = lat_lon_pairs[ind][0][0][1]\n    return curr_min_lat_idx, curr_min_lon_idx\n\n\ndef turn_nsidc_nc_to_csv():\n    # generate valid pairs, or just load if they already exist\n    if not os.path.exists(f\"{dfolder}/valid_pairs.npy\"):\n        print(\"file doesn't exist, generating new\")\n        gen_pairs()\n    lat_lon_pairs = np.load(f\"{dfolder}/valid_pairs.npy\")\n    lat_lon_pairs_rad = np.array([[radians(x[0]), radians(x[1])] for x in lat_lon_pairs])\n\n    # comment out if bulk writing!!\n    # all_cells_df.to_csv(f\"{dfolder}/test.csv\", index=False)\n\n    for ind, current_cell_id in enumerate(scmd):\n        # comment out if bulk writing\n        # all_cells_df = pd.DataFrame(columns=columns)\n\n        # Location information\n        longitude = station_cell_mapper_df['lon'][ind]\n        latitude = station_cell_mapper_df['lat'][ind]\n\n    #     print(latitude)\n    #     print(longitude)\n\n        # find closest lat long\n        lat_val, lon_val = find_nearest_2(latitude, longitude)\n        lat_idx = np.where(lat == lat_val)[0]\n        lon_idx = np.where(lon == lon_val)[0]\n    #     print(lat_val)\n    #     print(lon_val)\n\n        depth_time = depth[:, lat_idx, lon_idx]\n        swe_time = swe[:, lat_idx, lon_idx]\n\n        for ele in time:\n            time_index = int(ele.data - days_1900_start)\n            time_index_dt = datetime.datetime(1900, 1, 1, 0, 0) + datetime.timedelta(int(ele.data))\n            depth_val = depth_time[time_index][0][0]\n            swe_val = swe_time[time_index][0][0]\n\n            all_cells_df.loc[len(all_cells_df.index)] = [time_index_dt.year, time_index_dt.month, time_index_dt.day, lat_val, lon_val, swe_val, depth_val]\n\n        # comment out if bulk writing\n        # all_cells_df.to_csv(f\"{dfolder}/test.csv\", mode='a', header=False, index=False)\n\n    # uncomment to bulk write at end of program\n    all_cells_df.to_csv(f\"{dfolder}/{end_year}nsidc_data.csv\")\n\n    print(\"finished\")\n\n# call this method to extract the \n#turn_nsidc_nc_to_csv()\nfor end_year in range(2001, 2022):\n  turn_nsidc_nc_to_csv()\n",
  "history_output" : "/Users/joe\n<class 'netCDF4._netCDF4.Dataset'>\nroot group (NETCDF4 data model, file format HDF5):\n    dimensions(sizes): lat(621), lon(1405), time(365), time_str_len(11)\n    variables(dimensions): |S1 crs(), float32 lat(lat), float32 lon(lon), float32 time(time), |S1 time_str(time_str_len, time), int16 SWE(time, lat, lon), int16 DEPTH(time, lat, lon)\n    groups: \n<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 621\n<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 1405\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 365\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time_str_len', size = 11\n<class 'netCDF4._netCDF4.Variable'>\n|S1 crs()\n    grid_mapping_name: latitude_longitude\n    long_name: CRS definition\n    longitude_of_prime_meridian: 0.0\n    semi_major_axis: 6378137.0\n    inverse_flattening: 298.257222101\n    spatial_ref: GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]]\n    GeoTransform: -125.0208 0.04166662697178698 0 49.9375 0 -0.04166662697178698 \nunlimited dimensions: \ncurrent shape = ()\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lat(lat)\n    long_name: latitude\n    units: degrees north\nunlimited dimensions: \ncurrent shape = (621,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lon(lon)\n    long_name: longitude\n    units: degrees east\nunlimited dimensions: \ncurrent shape = (1405,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 time(time)\n    long_name: time\n    units: days since 1900-01-01\nunlimited dimensions: \ncurrent shape = (365,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\n|S1 time_str(time_str_len, time)\n    long_name: time (string)\n    format: dd-mmm-yyyy\nunlimited dimensions: \ncurrent shape = (11, 365)\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nint16 SWE(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Water Equivalent\n    grid_mapping: crs\n    units: millimeters h20\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\n<class 'netCDF4._netCDF4.Variable'>\nint16 DEPTH(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Depth\n    grid_mapping: crs\n    units: millimeters snow thickness\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/EPjestyVWvM2/data_nsidc_4km_swe_testing.py\", line 189, in <module>\n    turn_nsidc_nc_to_csv()\n  File \"/Users/joe/gw-workspace/EPjestyVWvM2/data_nsidc_4km_swe_testing.py\", line 161, in turn_nsidc_nc_to_csv\n    lat_val, lon_val = find_nearest_2(latitude, longitude)\n  File \"/Users/joe/gw-workspace/EPjestyVWvM2/data_nsidc_4km_swe_testing.py\", line 127, in find_nearest_2\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\nNameError: name 'lat_lon_pairs_rad' is not defined\n",
  "history_begin_time" : 1672791391638,
  "history_end_time" : 1672791393019,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "R5TuZNX0tohf",
  "history_input" : "import data_nsidc_4km_swe\n\nfor end_year in range(2001, 2022):\n  data_nsidc_4km_swe.end_year = end_year\n  data_nsidc_4km_swe.turn_nsidc_nc_to_csv()\n",
  "history_output" : "/Users/joe\n<class 'netCDF4._netCDF4.Dataset'>\nroot group (NETCDF4 data model, file format HDF5):\n    dimensions(sizes): lat(621), lon(1405), time(365), time_str_len(11)\n    variables(dimensions): |S1 crs(), float32 lat(lat), float32 lon(lon), float32 time(time), |S1 time_str(time_str_len, time), int16 SWE(time, lat, lon), int16 DEPTH(time, lat, lon)\n    groups: \n<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 621\n<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 1405\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 365\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time_str_len', size = 11\n<class 'netCDF4._netCDF4.Variable'>\n|S1 crs()\n    grid_mapping_name: latitude_longitude\n    long_name: CRS definition\n    longitude_of_prime_meridian: 0.0\n    semi_major_axis: 6378137.0\n    inverse_flattening: 298.257222101\n    spatial_ref: GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]]\n    GeoTransform: -125.0208 0.04166662697178698 0 49.9375 0 -0.04166662697178698 \nunlimited dimensions: \ncurrent shape = ()\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lat(lat)\n    long_name: latitude\n    units: degrees north\nunlimited dimensions: \ncurrent shape = (621,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lon(lon)\n    long_name: longitude\n    units: degrees east\nunlimited dimensions: \ncurrent shape = (1405,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 time(time)\n    long_name: time\n    units: days since 1900-01-01\nunlimited dimensions: \ncurrent shape = (365,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\n|S1 time_str(time_str_len, time)\n    long_name: time (string)\n    format: dd-mmm-yyyy\nunlimited dimensions: \ncurrent shape = (11, 365)\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nint16 SWE(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Water Equivalent\n    grid_mapping: crs\n    units: millimeters h20\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\n<class 'netCDF4._netCDF4.Variable'>\nint16 DEPTH(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Depth\n    grid_mapping: crs\n    units: millimeters snow thickness\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/R5TuZNX0tohf/data_nsidc_4km_swe_testing.py\", line 5, in <module>\n    data_nsidc_4km_swe.turn_nsidc_nc_to_csv()\n  File \"/Users/joe/gw-workspace/R5TuZNX0tohf/data_nsidc_4km_swe.py\", line 161, in turn_nsidc_nc_to_csv\n    lat_val, lon_val = find_nearest_2(latitude, longitude)\n  File \"/Users/joe/gw-workspace/R5TuZNX0tohf/data_nsidc_4km_swe.py\", line 127, in find_nearest_2\n    ball_tree = sk.BallTree(lat_lon_pairs_rad, metric=\"haversine\")\nNameError: name 'lat_lon_pairs_rad' is not defined\n",
  "history_begin_time" : 1672791192520,
  "history_end_time" : 1672791193999,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "i7on8JX4KJiS",
  "history_input" : "from data_nsidc_4km_swe import *\n\n\nfor end_year in range(2001, 2021):\n  print(end_year)\n",
  "history_output" : "/Users/joe\n<class 'netCDF4._netCDF4.Dataset'>\nroot group (NETCDF4 data model, file format HDF5):\n    dimensions(sizes): lat(621), lon(1405), time(365), time_str_len(11)\n    variables(dimensions): |S1 crs(), float32 lat(lat), float32 lon(lon), float32 time(time), |S1 time_str(time_str_len, time), int16 SWE(time, lat, lon), int16 DEPTH(time, lat, lon)\n    groups: \n<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 621\n<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 1405\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 365\n<class 'netCDF4._netCDF4.Dimension'>: name = 'time_str_len', size = 11\n<class 'netCDF4._netCDF4.Variable'>\n|S1 crs()\n    grid_mapping_name: latitude_longitude\n    long_name: CRS definition\n    longitude_of_prime_meridian: 0.0\n    semi_major_axis: 6378137.0\n    inverse_flattening: 298.257222101\n    spatial_ref: GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]]\n    GeoTransform: -125.0208 0.04166662697178698 0 49.9375 0 -0.04166662697178698 \nunlimited dimensions: \ncurrent shape = ()\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lat(lat)\n    long_name: latitude\n    units: degrees north\nunlimited dimensions: \ncurrent shape = (621,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 lon(lon)\n    long_name: longitude\n    units: degrees east\nunlimited dimensions: \ncurrent shape = (1405,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\nfloat32 time(time)\n    long_name: time\n    units: days since 1900-01-01\nunlimited dimensions: \ncurrent shape = (365,)\nfilling on, default _FillValue of 9.969209968386869e+36 used\n<class 'netCDF4._netCDF4.Variable'>\n|S1 time_str(time_str_len, time)\n    long_name: time (string)\n    format: dd-mmm-yyyy\nunlimited dimensions: \ncurrent shape = (11, 365)\nfilling on, default _FillValue of \u0000 used\n<class 'netCDF4._netCDF4.Variable'>\nint16 SWE(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Water Equivalent\n    grid_mapping: crs\n    units: millimeters h20\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\n<class 'netCDF4._netCDF4.Variable'>\nint16 DEPTH(time, lat, lon)\n    _FillValue: -999\n    long_name: Snow Depth\n    grid_mapping: crs\n    units: millimeters snow thickness\nunlimited dimensions: \ncurrent shape = (365, 621, 1405)\nfilling on\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n",
  "history_begin_time" : 1672791034625,
  "history_end_time" : 1672791036051,
  "history_notes" : null,
  "history_process" : "8ovvln",
  "host_id" : null,
  "indicator" : "Done"
},]
