[{
  "history_id" : "pswh8wk8m8n",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    \n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n    \n    tr_df = tr_df.drop('date', axis=1)\n    te_df = te_df.drop('date', axis=1)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n    print(\"length: \", len(tr_df.columns))\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        print(i, \" - \", col)\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-09-16\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:            lat      lon  SWE  Flag  ...  curvature  aspect  eastness  northness\n0       49.00 -125.000    0   241  ...        NaN     NaN       NaN        NaN\n1       49.00 -124.964    0   241  ...        NaN     NaN       NaN        NaN\n2       49.00 -124.928    0   241  ...        NaN     NaN       NaN        NaN\n3       49.00 -124.892    0   241  ...        NaN     NaN       NaN        NaN\n4       49.00 -124.856    0   241  ...        NaN     NaN       NaN        NaN\n...       ...      ...  ...   ...  ...        ...     ...       ...        ...\n462199  25.06 -100.196  252   252  ...        NaN     NaN       NaN        NaN\n462200  25.06 -100.160  252   252  ...        NaN     NaN       NaN        NaN\n462201  25.06 -100.124  252   252  ...        NaN     NaN       NaN        NaN\n462202  25.06 -100.088  252   252  ...        NaN     NaN       NaN        NaN\n462203  25.06 -100.052  252   252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 18 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nlength:  19\n0  -  lat\n1  -  lon\n2  -  SWE\n3  -  Flag\n4  -  swe_value\n5  -  air_temperature_tmmn\n6  -  potential_evapotranspiration\n7  -  mean_vapor_pressure_deficit\n8  -  relative_humidity_rmax\n9  -  relative_humidity_rmin\n10  -  precipitation_amount\n11  -  air_temperature_tmmx\n12  -  wind_speed\n13  -  elevation\n14  -  slope\n15  -  curvature\n16  -  aspect\n17  -  eastness\n18  -  northness\n",
  "history_begin_time" : 1696864244643,
  "history_end_time" : 1696864260901,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q5fxa4gfnio",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    \n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n    \n    tr_df = tr_df.drop('date', axis=1)\n    te_df = te_df.drop('date', axis=1)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n    print(\"length: \", len(tr_df.columns))\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        print(i, \" - \", col)\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-09-15\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:            lat      lon  SWE  Flag  ...  curvature  aspect  eastness  northness\n0       49.00 -125.000    0   241  ...        NaN     NaN       NaN        NaN\n1       49.00 -124.964    0   241  ...        NaN     NaN       NaN        NaN\n2       49.00 -124.928    0   241  ...        NaN     NaN       NaN        NaN\n3       49.00 -124.892    0   241  ...        NaN     NaN       NaN        NaN\n4       49.00 -124.856    0   241  ...        NaN     NaN       NaN        NaN\n...       ...      ...  ...   ...  ...        ...     ...       ...        ...\n462199  25.06 -100.196  255   255  ...        NaN     NaN       NaN        NaN\n462200  25.06 -100.160  255   255  ...        NaN     NaN       NaN        NaN\n462201  25.06 -100.124  255   255  ...        NaN     NaN       NaN        NaN\n462202  25.06 -100.088  255   255  ...        NaN     NaN       NaN        NaN\n462203  25.06 -100.052  255   255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 18 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nlength:  19\n0  -  lat\n1  -  lon\n2  -  SWE\n3  -  Flag\n4  -  swe_value\n5  -  air_temperature_tmmn\n6  -  potential_evapotranspiration\n7  -  mean_vapor_pressure_deficit\n8  -  relative_humidity_rmax\n9  -  relative_humidity_rmin\n10  -  precipitation_amount\n11  -  air_temperature_tmmx\n12  -  wind_speed\n13  -  elevation\n14  -  slope\n15  -  curvature\n16  -  aspect\n17  -  eastness\n18  -  northness\n",
  "history_begin_time" : 1696862736766,
  "history_end_time" : 1696862760730,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "b9qkezs10y2",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    \n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n    \n    tr_df = tr_df.drop('date', axis=1)\n    te_df = te_df.drop('date', axis=1)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n    print(\"length: \", len(tr_df.columns))\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        print(i, \" - \", col)\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-06-15\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:            lat      lon  SWE  Flag  ...  curvature  aspect  eastness  northness\n0       49.00 -125.000    0   241  ...        NaN     NaN       NaN        NaN\n1       49.00 -124.964    0   241  ...        NaN     NaN       NaN        NaN\n2       49.00 -124.928    0   241  ...        NaN     NaN       NaN        NaN\n3       49.00 -124.892    0   241  ...        NaN     NaN       NaN        NaN\n4       49.00 -124.856    0   241  ...        NaN     NaN       NaN        NaN\n...       ...      ...  ...   ...  ...        ...     ...       ...        ...\n462199  25.06 -100.196  252   252  ...        NaN     NaN       NaN        NaN\n462200  25.06 -100.160  252   252  ...        NaN     NaN       NaN        NaN\n462201  25.06 -100.124  252   252  ...        NaN     NaN       NaN        NaN\n462202  25.06 -100.088  252   252  ...        NaN     NaN       NaN        NaN\n462203  25.06 -100.052  252   252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 18 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nlength:  19\n0  -  lat\n1  -  lon\n2  -  SWE\n3  -  Flag\n4  -  swe_value\n5  -  air_temperature_tmmn\n6  -  potential_evapotranspiration\n7  -  mean_vapor_pressure_deficit\n8  -  relative_humidity_rmax\n9  -  relative_humidity_rmin\n10  -  precipitation_amount\n11  -  air_temperature_tmmx\n12  -  wind_speed\n13  -  elevation\n14  -  slope\n15  -  curvature\n16  -  aspect\n17  -  eastness\n18  -  northness\n",
  "history_begin_time" : 1696832531719,
  "history_end_time" : 1696832547662,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "scgn1h9tkx9",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    \n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n    \n    tr_df = tr_df.drop('date', axis=1)\n    te_df = te_df.drop('date', axis=1)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n    print(\"length: \", len(tr_df.columns))\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        print(i, \" - \", col)\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-12\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:            lat      lon  SWE  Flag  ...  curvature  aspect  eastness  northness\n0       49.00 -125.000    0   241  ...        NaN     NaN       NaN        NaN\n1       49.00 -124.964    0   241  ...        NaN     NaN       NaN        NaN\n2       49.00 -124.928    0   241  ...        NaN     NaN       NaN        NaN\n3       49.00 -124.892    0   241  ...        NaN     NaN       NaN        NaN\n4       49.00 -124.856    0   241  ...        NaN     NaN       NaN        NaN\n...       ...      ...  ...   ...  ...        ...     ...       ...        ...\n462199  25.06 -100.196  252   252  ...        NaN     NaN       NaN        NaN\n462200  25.06 -100.160  252   252  ...        NaN     NaN       NaN        NaN\n462201  25.06 -100.124  252   252  ...        NaN     NaN       NaN        NaN\n462202  25.06 -100.088  252   252  ...        NaN     NaN       NaN        NaN\n462203  25.06 -100.052  252   252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 18 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nlength:  19\n0  -  lat\n1  -  lon\n2  -  SWE\n3  -  Flag\n4  -  swe_value\n5  -  air_temperature_tmmn\n6  -  potential_evapotranspiration\n7  -  mean_vapor_pressure_deficit\n8  -  relative_humidity_rmax\n9  -  relative_humidity_rmin\n10  -  precipitation_amount\n11  -  air_temperature_tmmx\n12  -  wind_speed\n13  -  elevation\n14  -  slope\n15  -  curvature\n16  -  aspect\n17  -  eastness\n18  -  northness\n",
  "history_begin_time" : 1696832106859,
  "history_end_time" : 1696832122501,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "aYUH9nZvHuoZ",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    \n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n    \n    tr_df = tr_df.drop('date', axis=1)\n    te_df = te_df.drop('date', axis=1)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n    print(\"length: \", len(tr_df.columns))\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        print(i, \" - \", col)\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:            lat      lon  SWE  Flag  ...  curvature  aspect  eastness  northness\n0       49.00 -125.000    0   241  ...        NaN     NaN       NaN        NaN\n1       49.00 -124.964    0   241  ...        NaN     NaN       NaN        NaN\n2       49.00 -124.928    0   241  ...        NaN     NaN       NaN        NaN\n3       49.00 -124.892    0   241  ...        NaN     NaN       NaN        NaN\n4       49.00 -124.856    0   241  ...        NaN     NaN       NaN        NaN\n...       ...      ...  ...   ...  ...        ...     ...       ...        ...\n462199  25.06 -100.196  255   255  ...        NaN     NaN       NaN        NaN\n462200  25.06 -100.160  255   255  ...        NaN     NaN       NaN        NaN\n462201  25.06 -100.124  255   255  ...        NaN     NaN       NaN        NaN\n462202  25.06 -100.088  255   255  ...        NaN     NaN       NaN        NaN\n462203  25.06 -100.052  255   255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 18 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nlength:  19\n0  -  lat\n1  -  lon\n2  -  SWE\n3  -  Flag\n4  -  swe_value\n5  -  air_temperature_tmmn\n6  -  potential_evapotranspiration\n7  -  mean_vapor_pressure_deficit\n8  -  relative_humidity_rmax\n9  -  relative_humidity_rmin\n10  -  precipitation_amount\n11  -  air_temperature_tmmx\n12  -  wind_speed\n13  -  elevation\n14  -  slope\n15  -  curvature\n16  -  aspect\n17  -  eastness\n18  -  northness\n",
  "history_begin_time" : 1696831208728,
  "history_end_time" : 1696831223207,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "GbreSw24JB93",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    \n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n    \n    tr_df = tr_df.drop('date', axis=1)\n    te_df = te_df.drop('date', axis=1)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n    print(\"length: \", len(tr_df.columns))\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        print(i, \" - \", col)\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:            lat      lon  SWE  Flag  ...  curvature  aspect  eastness  northness\n0       49.00 -125.000    0   241  ...        NaN     NaN       NaN        NaN\n1       49.00 -124.964    0   241  ...        NaN     NaN       NaN        NaN\n2       49.00 -124.928    0   241  ...        NaN     NaN       NaN        NaN\n3       49.00 -124.892    0   241  ...        NaN     NaN       NaN        NaN\n4       49.00 -124.856    0   241  ...        NaN     NaN       NaN        NaN\n...       ...      ...  ...   ...  ...        ...     ...       ...        ...\n462199  25.06 -100.196  255   255  ...        NaN     NaN       NaN        NaN\n462200  25.06 -100.160  255   255  ...        NaN     NaN       NaN        NaN\n462201  25.06 -100.124  255   255  ...        NaN     NaN       NaN        NaN\n462202  25.06 -100.088  255   255  ...        NaN     NaN       NaN        NaN\n462203  25.06 -100.052  255   255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 18 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nlength:  19\n0  -  lat\n1  -  lon\n2  -  SWE\n3  -  Flag\n4  -  swe_value\n5  -  air_temperature_tmmn\n6  -  potential_evapotranspiration\n7  -  mean_vapor_pressure_deficit\n8  -  relative_humidity_rmax\n9  -  relative_humidity_rmin\n10  -  precipitation_amount\n11  -  air_temperature_tmmx\n12  -  wind_speed\n13  -  elevation\n14  -  slope\n15  -  curvature\n16  -  aspect\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/GbreSw24JB93/train_test_pattern_compare.py\", line 104, in <module>\n    compare()\n  File \"/home/chetana/gw-workspace/GbreSw24JB93/train_test_pattern_compare.py\", line 85, in compare\n    axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\nIndexError: index 16 is out of bounds for axis 0 with size 16\n",
  "history_begin_time" : 1696831164684,
  "history_end_time" : 1696831172137,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "2ANroc8JqvoD",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    \n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n    \n    tr_df = tr_df.drop('date', axis=1)\n    te_df = te_df.drop('date', axis=1)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        print(i, \" - \", col)\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:            lat      lon  SWE  Flag  ...  curvature  aspect  eastness  northness\n0       49.00 -125.000    0   241  ...        NaN     NaN       NaN        NaN\n1       49.00 -124.964    0   241  ...        NaN     NaN       NaN        NaN\n2       49.00 -124.928    0   241  ...        NaN     NaN       NaN        NaN\n3       49.00 -124.892    0   241  ...        NaN     NaN       NaN        NaN\n4       49.00 -124.856    0   241  ...        NaN     NaN       NaN        NaN\n...       ...      ...  ...   ...  ...        ...     ...       ...        ...\n462199  25.06 -100.196  255   255  ...        NaN     NaN       NaN        NaN\n462200  25.06 -100.160  255   255  ...        NaN     NaN       NaN        NaN\n462201  25.06 -100.124  255   255  ...        NaN     NaN       NaN        NaN\n462202  25.06 -100.088  255   255  ...        NaN     NaN       NaN        NaN\n462203  25.06 -100.052  255   255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 18 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n0  -  lat\n1  -  lon\n2  -  SWE\n3  -  Flag\n4  -  swe_value\n5  -  air_temperature_tmmn\n6  -  potential_evapotranspiration\n7  -  mean_vapor_pressure_deficit\n8  -  relative_humidity_rmax\n9  -  relative_humidity_rmin\n10  -  precipitation_amount\n11  -  air_temperature_tmmx\n12  -  wind_speed\n13  -  elevation\n14  -  slope\n15  -  curvature\n16  -  aspect\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/2ANroc8JqvoD/train_test_pattern_compare.py\", line 104, in <module>\n    compare()\n  File \"/home/chetana/gw-workspace/2ANroc8JqvoD/train_test_pattern_compare.py\", line 85, in compare\n    axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\nIndexError: index 16 is out of bounds for axis 0 with size 16\n",
  "history_begin_time" : 1696831062130,
  "history_end_time" : 1696831069920,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "hG5SiwIBWxQK",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    \n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n    \n    tr_df = tr_df.drop('date', axis=1)\n    te_df = te_df.drop('date', axis=1)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:            lat      lon  SWE  Flag  ...  curvature  aspect  eastness  northness\n0       49.00 -125.000    0   241  ...        NaN     NaN       NaN        NaN\n1       49.00 -124.964    0   241  ...        NaN     NaN       NaN        NaN\n2       49.00 -124.928    0   241  ...        NaN     NaN       NaN        NaN\n3       49.00 -124.892    0   241  ...        NaN     NaN       NaN        NaN\n4       49.00 -124.856    0   241  ...        NaN     NaN       NaN        NaN\n...       ...      ...  ...   ...  ...        ...     ...       ...        ...\n462199  25.06 -100.196  255   255  ...        NaN     NaN       NaN        NaN\n462200  25.06 -100.160  255   255  ...        NaN     NaN       NaN        NaN\n462201  25.06 -100.124  255   255  ...        NaN     NaN       NaN        NaN\n462202  25.06 -100.088  255   255  ...        NaN     NaN       NaN        NaN\n462203  25.06 -100.052  255   255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 18 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/hG5SiwIBWxQK/train_test_pattern_compare.py\", line 103, in <module>\n    compare()\n  File \"/home/chetana/gw-workspace/hG5SiwIBWxQK/train_test_pattern_compare.py\", line 84, in compare\n    axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\nIndexError: index 16 is out of bounds for axis 0 with size 16\n",
  "history_begin_time" : 1696830955501,
  "history_end_time" : 1696830963272,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "h9fZqJYHdb7E",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    data = data.drop('date', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_training():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \ncompare()\n\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:                 lat         lon  SWE  ...      aspect  eastness  northness\n0        37.192360 -118.939041  255  ...   24.605782  0.394541   0.737872\n1        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n2        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n3        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n4        37.192360 -118.939041    0  ...   24.605782  0.394541   0.737872\n...            ...         ...  ...  ...         ...       ...        ...\n1022695  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022696  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022697  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022698  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n1022699  36.682572 -118.427001    0  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 19 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44965  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44965  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44965  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44965  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44965  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44965  25.06 -100.196  255  ...        NaN     NaN       NaN        NaN\n462200  44965  25.06 -100.160  255  ...        NaN     NaN       NaN        NaN\n462201  44965  25.06 -100.124  255  ...        NaN     NaN       NaN        NaN\n462202  44965  25.06 -100.088  255  ...        NaN     NaN       NaN        NaN\n462203  44965  25.06 -100.052  255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['lat', 'lon', 'SWE', 'Flag', 'swe_value', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/h9fZqJYHdb7E/train_test_pattern_compare.py\", line 100, in <module>\n    compare()\n  File \"/home/chetana/gw-workspace/h9fZqJYHdb7E/train_test_pattern_compare.py\", line 81, in compare\n    axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\nIndexError: index 16 is out of bounds for axis 0 with size 16\n",
  "history_begin_time" : 1696830895255,
  "history_end_time" : 1696830902995,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "90tdcmqmi13",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n    data = data.drop('date', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_trainin():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \n#compare()\ncalculate_feature_colleration_in_trainin\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\n",
  "history_begin_time" : 1696830416824,
  "history_end_time" : 1696830421948,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "MZRu0GfMtAEE",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_trainin():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \n#compare()\ncalculate_feature_colleration_in_trainin\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-10\ntest end date:  2023-10-09\n/home/chetana\n",
  "history_begin_time" : 1696829981850,
  "history_end_time" : 1696829984648,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cd49lqdnpj4",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_trainin():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \n#compare()\ncalculate_feature_colleration_in_trainin\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-02-10\ntest end date:  2023-10-08\n/home/chetana\n",
  "history_begin_time" : 1696787740924,
  "history_end_time" : 1696787743771,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "08i6kva4t5r",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ndef calculate_feature_colleration_in_trainin():\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  \n    \n#compare()\ncalculate_feature_colleration_in_trainin\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\n",
  "history_begin_time" : 1696786915899,
  "history_end_time" : 1696786918764,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1D8SEUm3FkYX",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696773734963,
  "history_end_time" : 1696773749392,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "zu6vpafaq3w",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "",
  "history_begin_time" : 1696772041987,
  "history_end_time" : 1696772045819,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "oao7Ig40H5bj",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-19\ntest end date:  2023-10-08\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696732253020,
  "history_end_time" : 1696732272359,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "B8tvnSAJdnJB",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "",
  "history_begin_time" : 1696732219755,
  "history_end_time" : 1696732234946,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "R0wonJChx8FH",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-19\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n",
  "history_begin_time" : 1696731985335,
  "history_end_time" : 1696732002409,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "8ieQGbc4FTh0",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "Running",
  "history_begin_time" : 1696731977244,
  "history_end_time" : 1696732234921,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "bah3XDSdlens",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols)\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696690820777,
  "history_end_time" : 1696690835009,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "X3rqpZodeCou",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    new_num_cols = int(num_cols**0.5)  # Square grid\n    new_num_rows = int(num_cols / new_num_cols) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(new_num_rows, new_num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'{col}')\n        axs[i].legend()\n        \n    \n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696690683503,
  "history_end_time" : 1696690697124,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "tviPZFFGnlo3",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir, test_start_date\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    num_rows = int(num_cols**0.5)  # Square grid\n    num_cols = int(num_cols / num_rows) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(num_rows, num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'Comparison of {col} (Train vs Test)')\n        \n    \n    axs.flatten()[-2].legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{test_start_date}_final_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\ntoday date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696690411402,
  "history_end_time" : 1696690424095,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "iRZAcGMha3in",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    num_rows = int(num_cols**0.5)  # Square grid\n    num_cols = int(num_cols / num_rows) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(num_rows, num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].set_title(f'Comparison of {col} (Train vs Test)')\n        \n    \n    axs.flatten()[-2].legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\ntoday date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696690166975,
  "history_end_time" : 1696690179165,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "pY015grabomn",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    num_rows = int(num_cols**0.5)  # Square grid\n    num_cols = int(num_cols / num_rows) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(num_rows, num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].title(f'Comparison of {col} (Train vs Test)')\n        axs[i].legend()\n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/pY015grabomn/train_test_pattern_compare.py\", line 91, in <module>\n    compare()\n  File \"/home/chetana/gw-workspace/pY015grabomn/train_test_pattern_compare.py\", line 84, in compare\n    axs[i].title(f'Comparison of {col} (Train vs Test)')\nTypeError: 'Text' object is not callable\n",
  "history_begin_time" : 1696689684034,
  "history_end_time" : 1696689689051,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "W7xEWBz0al5h",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n        \n    num_cols = len(tr_df.columns)\n    num_rows = int(num_cols**0.5)  # Square grid\n    num_cols = int(num_cols / num_rows) + 1\n    \n    # Create a figure with multiple subplots\n    fig, axs = plt.subplots(num_rows, num_cols, figsize=(24, 20))\n    \n    # Flatten the axs array to iterate through subplots\n    axs = axs.flatten()\n\n    # Iterate over columns and create subplots\n    for i, col in enumerate(tr_df.columns):\n        axs[i].figure(figsize=(8, 4))\n        axs[i].hist(tr_df[col], bins=100, alpha=0.5, color='blue', label='Train')\n        if col in te_df.columns:\n            axs[i].hist(te_df[col], bins=100, alpha=0.5, color='red', label='Test')\n\n        axs[i].title(f'Comparison of {col} (Train vs Test)')\n        axs[i].legend()\n    \n    plt.tight_layout()\n    plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n    plt.close()\n\ncompare()\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/W7xEWBz0al5h/train_test_pattern_compare.py\", line 92, in <module>\n    compare()\n  File \"/home/chetana/gw-workspace/W7xEWBz0al5h/train_test_pattern_compare.py\", line 80, in compare\n    axs[i].figure(figsize=(8, 4))\nTypeError: 'Figure' object is not callable\n",
  "history_begin_time" : 1696689617746,
  "history_end_time" : 1696689622570,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "L8WBM5vLmMeM",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# This process only analyzes data; we don't touch the model here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n    \"\"\"\n    Clean and preprocess the training data.\n\n    Args:\n        data (pd.DataFrame): The training data to be cleaned.\n\n    Returns:\n        pd.DataFrame: Cleaned training data.\n    \"\"\"\n    data['date'] = pd.to_datetime(data['date'])\n    reference_date = pd.to_datetime('1900-01-01')\n    data['date'] = (data['date'] - reference_date).dt.days\n    data.replace('--', pd.NA, inplace=True)\n    data.fillna(-999, inplace=True)\n    \n    # Remove all the rows that have 'swe_value' as -999\n    data = data[(data['swe_value'] != -999)]\n\n    print(\"Get slope statistics\")\n    print(data[\"slope\"].describe())\n  \n    print(\"Get SWE statistics\")\n    print(data[\"swe_value\"].describe())\n\n    data = data.drop('Unnamed: 0', axis=1)\n\n    return data\n\ndef compare():\n    \"\"\"\n    Compare training and testing data and create variable comparison plots.\n\n    Returns:\n        None\n    \"\"\"\n    new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n    training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n    tr_df = pd.read_csv(training_data_path)\n    tr_df = clean_train_df(tr_df)\n    te_df = pd.read_csv(new_testing_data_path)\n\n    print(\"Training DataFrame: \", tr_df)\n    print(\"Testing DataFrame: \", te_df)\n\n    print(\"Training columns: \", tr_df.columns)\n    print(\"Testing columns: \", te_df.columns)\n\n    var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n    if not os.path.exists(var_comparison_plot_path):\n        os.makedirs(var_comparison_plot_path)\n\n    # Iterate over columns and create subplots\n    for col in tr_df.columns:\n        plt.figure(figsize=(8, 4))\n\n        plt.subplot(1, 2, 1)  # Subplot for the first data frame\n        plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n\n        plt.subplot(1, 2, 2)  # Subplot for the second data frame\n        if col in te_df.columns:\n            plt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n            plt.title(f'Distribution of {col} (Test)')\n\n        plt.title(f'Comparison of {col} (Train vs Test)')\n\n        plt.legend()\n        plt.tight_layout()\n        plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n        plt.close()\n\ncompare()\n",
  "history_output" : "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\ntoday date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nGet slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nGet SWE statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\nTraining DataFrame:            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\nTesting DataFrame:           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\nTraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\nTesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696685397019,
  "history_end_time" : 1696685412090,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ec8T3W0ejbzY",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get slope statistics\")\n  print(data[\"slope\"].describe())\n  \n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (Train)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      if col in te_df.columns:\n        \n      \tplt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      \tplt.title(f'Distribution of {col} (Test)')\n\n      plt.legend()\n      plt.tight_layout()\n      plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\ntoday date = 2023-10-06\ntest start date:  2023-01-19\ntest end date:  2023-10-06\n/home/chetana\nget slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nget swe statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\ntraining_df :            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\ntesting_df :           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44943  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44943  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44943  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44943  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44943  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44943  25.06 -100.196  252  ...        NaN     NaN       NaN        NaN\n462200  44943  25.06 -100.160  252  ...        NaN     NaN       NaN        NaN\n462201  44943  25.06 -100.124  252  ...        NaN     NaN       NaN        NaN\n462202  44943  25.06 -100.088  252  ...        NaN     NaN       NaN        NaN\n462203  44943  25.06 -100.052  252  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696604412377,
  "history_end_time" : 1696604423212,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "pmae1xyo217",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get slope statistics\")\n  print(data[\"slope\"].describe())\n  \n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (Train)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      if col in te_df.columns:\n        \n      \tplt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      \tplt.title(f'Distribution of {col} (Test)')\n\n      plt.legend()\n      plt.tight_layout()\n      plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "",
  "history_begin_time" : 1696603192258,
  "history_end_time" : 1696603198896,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "eTJmEUJUoBBF",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get slope statistics\")\n  print(data[\"slope\"].describe())\n  \n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (Train)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      if col in te_df.columns:\n        \n      \tplt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      \tplt.title(f'Distribution of {col} (Test)')\n\n      plt.legend()\n      plt.tight_layout()\n      plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\ntoday date = 2023-10-06\ntest start date:  2023-01-18\ntest end date:  2023-10-06\n/home/chetana\nget slope statistics\ncount    1.008700e+06\nmean     6.243769e+01\nstd      1.650521e+01\nmin      4.277402e+00\n25%      5.213456e+01\n50%      6.768107e+01\n75%      7.504661e+01\nmax      8.368555e+01\nName: slope, dtype: float64\nget swe statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\ntraining_df :            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\ntesting_df :           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44942  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44942  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44942  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44942  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44942  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44942  25.06 -100.196  255  ...        NaN     NaN       NaN        NaN\n462200  44942  25.06 -100.160  255  ...        NaN     NaN       NaN        NaN\n462201  44942  25.06 -100.124  255  ...        NaN     NaN       NaN        NaN\n462202  44942  25.06 -100.088  255  ...        NaN     NaN       NaN        NaN\n462203  44942  25.06 -100.052  255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696601426552,
  "history_end_time" : 1696601438945,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "oulaf3BlFNJ1",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (Train)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      if col in te_df.columns:\n        \n      \tplt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      \tplt.title(f'Distribution of {col} (Test)')\n\n      plt.legend()\n      plt.tight_layout()\n      plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\ntoday date = 2023-10-06\ntest start date:  2023-01-18\ntest end date:  2023-10-06\n/home/chetana\nget swe statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\ntraining_df :            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\ntesting_df :           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44942  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44942  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44942  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44942  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44942  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44942  25.06 -100.196  255  ...        NaN     NaN       NaN        NaN\n462200  44942  25.06 -100.160  255  ...        NaN     NaN       NaN        NaN\n462201  44942  25.06 -100.124  255  ...        NaN     NaN       NaN        NaN\n462202  44942  25.06 -100.088  255  ...        NaN     NaN       NaN        NaN\n462203  44942  25.06 -100.052  255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696601335131,
  "history_end_time" : 1696601347240,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "HlJDh2DfW1Ji",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned_v3.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (Train)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      if col in te_df.columns:\n        \n      \tplt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      \tplt.title(f'Distribution of {col} (Test)')\n\n      plt.legend()\n      plt.tight_layout()\n      plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\ntoday date = 2023-10-06\ntest start date:  2023-01-18\ntest end date:  2023-10-06\n/home/chetana\nget swe statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\ntraining_df :            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\ntesting_df :           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44942  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44942  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44942  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44942  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44942  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44942  25.06 -100.196  255  ...        NaN     NaN       NaN        NaN\n462200  44942  25.06 -100.160  255  ...        NaN     NaN       NaN        NaN\n462201  44942  25.06 -100.124  255  ...        NaN     NaN       NaN        NaN\n462202  44942  25.06 -100.088  255  ...        NaN     NaN       NaN        NaN\n462203  44942  25.06 -100.052  255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696600652999,
  "history_end_time" : 1696600667972,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "wdMiCiFe0tFR",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (Train)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      if col in te_df.columns:\n        \n      \tplt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      \tplt.title(f'Distribution of {col} (Test)')\n\n      plt.legend()\n      plt.tight_layout()\n      plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\ntoday date = 2023-10-04\ntest start date:  2023-01-18\ntest end date:  2023-10-04\n/home/chetana\nget swe statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\ntraining_df :            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\ntesting_df :           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44942  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44942  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44942  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44942  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44942  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44942  25.06 -100.196  255  ...        NaN     NaN       NaN        NaN\n462200  44942  25.06 -100.160  255  ...        NaN     NaN       NaN        NaN\n462201  44942  25.06 -100.124  255  ...        NaN     NaN       NaN        NaN\n462202  44942  25.06 -100.088  255  ...        NaN     NaN       NaN        NaN\n462203  44942  25.06 -100.052  255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696434037280,
  "history_end_time" : 1696434047984,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "dneAhUZ0w34T",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (DataFrame 1)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      plt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      plt.title(f'Train vs Test - {col} ')\n\n      plt.legend()\n      plt.tight_layout()\n      plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "today date = 2023-10-04\ntest start date:  2023-01-18\ntest end date:  2023-10-04\n/home/chetana\nget swe statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\ntraining_df :            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\ntesting_df :           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44942  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44942  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44942  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44942  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44942  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44942  25.06 -100.196  255  ...        NaN     NaN       NaN        NaN\n462200  44942  25.06 -100.160  255  ...        NaN     NaN       NaN        NaN\n462201  44942  25.06 -100.124  255  ...        NaN     NaN       NaN        NaN\n462202  44942  25.06 -100.088  255  ...        NaN     NaN       NaN        NaN\n462203  44942  25.06 -100.052  255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'swe_value'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/dneAhUZ0w34T/train_test_pattern_compare.py\", line 75, in <module>\n    compare()\n  File \"/home/chetana/gw-workspace/dneAhUZ0w34T/train_test_pattern_compare.py\", line 66, in compare\n    plt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'swe_value'\n",
  "history_begin_time" : 1696433835753,
  "history_end_time" : 1696433841928,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "s4fgWEZpTHZQ",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (DataFrame 1)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      plt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      plt.title(f'Train vs Test - {col} ')\n\n      plt.legend()\n      plt.tight_layout()\n      plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "today date = 2023-10-04\ntest start date:  2023-01-18\ntest end date:  2023-10-04\n/home/chetana\nget swe statistics\ncount    1.008700e+06\nmean     3.333796e+00\nstd      5.245389e+00\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      6.300000e+00\nmax      2.260000e+01\nName: swe_value, dtype: float64\ntraining_df :            date        lat         lon  ...      aspect  eastness  northness\n0        44158  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        44120  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        44093  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        44803  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        43739  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...        ...        ...         ...  ...         ...       ...        ...\n1022695  43787  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  44026  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  44072  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  44444  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  44354  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1008700 rows x 20 columns]\ntesting_df :           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44942  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44942  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44942  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44942  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44942  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44942  25.06 -100.196  255  ...        NaN     NaN       NaN        NaN\n462200  44942  25.06 -100.160  255  ...        NaN     NaN       NaN        NaN\n462201  44942  25.06 -100.124  255  ...        NaN     NaN       NaN        NaN\n462202  44942  25.06 -100.088  255  ...        NaN     NaN       NaN        NaN\n462203  44942  25.06 -100.052  255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/s4fgWEZpTHZQ/train_test_pattern_compare.py\", line 74, in <module>\n    compare()\n  File \"/home/chetana/gw-workspace/s4fgWEZpTHZQ/train_test_pattern_compare.py\", line 58, in compare\n    plt.figure(figsize=(8, 4))\nNameError: name 'plt' is not defined\n",
  "history_begin_time" : 1696433815842,
  "history_end_time" : 1696433820613,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "UXrpTKUfTyHJ",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\n\ndef clean_train_df(data):\n  data['date'] = pd.to_datetime(data['date'])\n  reference_date = pd.to_datetime('1900-01-01')\n  data['date'] = (data['date'] - reference_date).dt.days\n  data.replace('--', pd.NA, inplace=True)\n  data.fillna(-999, inplace=True)\n  #data.dropna(inplace=True)\n\n  #         for column in data.columns:\n  #           data[column] = pd.to_numeric(data[column], errors='coerce')\n  #           print(data[column].describe())\n\n  # remove all the rows that has swe_value is -999\n  data = data[(data['swe_value'] != -999)]\n\n  print(\"get swe statistics\")\n  print(data[\"swe_value\"].describe())\n\n  #data = data.dropna(subset=['swe_value'])\n  data = data.drop('Unnamed: 0', axis=1)\n  #data = data[data['swe_value'] != 0]\n  return data\n\n\ndef compare():\n  new_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\n  training_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned.csv'\n\n  tr_df = pd.read_csv(training_data_path)\n  tr_df = clean_train_df(tr_df)\n  te_df = pd.read_csv(new_testing_data_path)\n\n  print(\"training_df : \", tr_df)\n  print(\"testing_df : \", te_df)\n\n  print(\"training columns: \", tr_df.columns)\n  print(\"testing columns: \", te_df.columns)\n\n  var_comparison_plot_path = f\"{work_dir}/var_comparison/\"\n  if not os.path.exists(var_comparison_plot_path):\n      os.makedirs(var_comparison_plot_path)\n\n  # Iterate over columns and create subplots\n  for col in tr_df.columns:\n      plt.figure(figsize=(8, 4))\n\n      plt.subplot(1, 2, 1)  # Subplot for the first data frame\n      plt.hist(tr_df[col], bins=10, alpha=0.5, color='blue', label='Train')\n      plt.title(f'Distribution of {col} (DataFrame 1)')\n\n      plt.subplot(1, 2, 2)  # Subplot for the second data frame\n      plt.hist(te_df[col], bins=10, alpha=0.5, color='red', label='Test')\n      plt.title(f'Train vs Test - {col} ')\n\n      plt.legend()\n      plt.tight_layout()\n       plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\n      plt.close()\n\n      \ncompare()\n\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/UXrpTKUfTyHJ/train_test_pattern_compare.py\", line 70\n    plt.savefig(f'{var_comparison_plot_path}/{col}_comparison.png')\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1696433798986,
  "history_end_time" : 1696433799041,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "n5IhhNQrFBle",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\n\nnew_testing_data_path = f'{work_dir}/testing_all_ready_for_check.csv'\ntraining_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned.csv'\n\ntr_df = pd.read_csv(training_data_path)\nte_df = pd.read_csv(new_testing_data_path)\n\nprint(\"training_df : \", tr_df)\nprint(\"testing_df : \", te_df)\n\nprint(\"training columns: \", tr_df.columns)\nprint(\"testing columns: \", te_df.columns)\n\n\n",
  "history_output" : "today date = 2023-10-04\ntest start date:  2023-01-18\ntest end date:  2023-10-04\n/home/chetana\ntraining_df :                 date        lat         lon  ...      aspect  eastness  northness\n0        2020-11-25  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        2020-10-18  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        2020-09-21  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        2022-09-01  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        2019-10-03  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...             ...        ...         ...  ...         ...       ...        ...\n1022695  2019-11-20  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  2020-07-16  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  2020-08-31  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  2021-09-07  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  2021-06-09  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1022700 rows x 21 columns]\ntesting_df :           date    lat      lon  SWE  ...  curvature  aspect  eastness  northness\n0       44942  49.00 -125.000    0  ...        NaN     NaN       NaN        NaN\n1       44942  49.00 -124.964    0  ...        NaN     NaN       NaN        NaN\n2       44942  49.00 -124.928    0  ...        NaN     NaN       NaN        NaN\n3       44942  49.00 -124.892    0  ...        NaN     NaN       NaN        NaN\n4       44942  49.00 -124.856    0  ...        NaN     NaN       NaN        NaN\n...       ...    ...      ...  ...  ...        ...     ...       ...        ...\n462199  44942  25.06 -100.196  255  ...        NaN     NaN       NaN        NaN\n462200  44942  25.06 -100.160  255  ...        NaN     NaN       NaN        NaN\n462201  44942  25.06 -100.124  255  ...        NaN     NaN       NaN        NaN\n462202  44942  25.06 -100.088  255  ...        NaN     NaN       NaN        NaN\n462203  44942  25.06 -100.052  255  ...        NaN     NaN       NaN        NaN\n[462204 rows x 19 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value', 'Unnamed: 0',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'air_temperature_tmmn',\n       'potential_evapotranspiration', 'mean_vapor_pressure_deficit',\n       'relative_humidity_rmax', 'relative_humidity_rmin',\n       'precipitation_amount', 'air_temperature_tmmx', 'wind_speed',\n       'elevation', 'slope', 'curvature', 'aspect', 'eastness', 'northness'],\n      dtype='object')\n",
  "history_begin_time" : 1696433347156,
  "history_end_time" : 1696433351209,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "loBgGHlUZwQS",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\n\nnew_testing_data_path = f'{work_dir}/testing_all_ready.csv'\ntraining_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned.csv'\n\ntr_df = pd.read_csv(training_data_path)\nte_df = pd.read_csv(new_testing_data_path)\n\nprint(\"training_df : \", tr_df)\nprint(\"testing_df : \", te_df)\n\nprint(\"training columns: \", tr_df.columns)\nprint(\"testing columns: \", te_df.columns)\n\n\n",
  "history_output" : "today date = 2023-10-04\ntest start date:  2023-01-18\ntest end date:  2023-10-04\n/home/chetana\ntraining_df :                 date        lat         lon  ...      aspect  eastness  northness\n0        2020-11-25  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        2020-10-18  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        2020-09-21  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        2022-09-01  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        2019-10-03  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...             ...        ...         ...  ...         ...       ...        ...\n1022695  2019-11-20  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  2020-07-16  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  2020-08-31  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  2021-09-07  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  2021-06-09  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1022700 rows x 21 columns]\ntesting_df :          Latitude  Longitude rmin  ... AMSR_SWE AMSR_Flag        date\n0          49.00   -125.000   --  ...        0       241  2023-01-18\n1          49.00   -124.964   --  ...        0       241  2023-01-18\n2          49.00   -124.928   --  ...        0       241  2023-01-18\n3          49.00   -124.892   --  ...        0       241  2023-01-18\n4          49.00   -124.856   --  ...        0       241  2023-01-18\n...          ...        ...  ...  ...      ...       ...         ...\n462199     25.06   -100.196   --  ...      255       255  2023-01-18\n462200     25.06   -100.160   --  ...      255       255  2023-01-18\n462201     25.06   -100.124   --  ...      255       255  2023-01-18\n462202     25.06   -100.088   --  ...      255       255  2023-01-18\n462203     25.06   -100.052   --  ...      255       255  2023-01-18\n[462204 rows x 21 columns]\ntraining columns:  Index(['date', 'lat', 'lon', 'SWE', 'Flag', 'swe_value', 'Unnamed: 0',\n       'air_temperature_tmmn', 'potential_evapotranspiration',\n       'mean_vapor_pressure_deficit', 'relative_humidity_rmax',\n       'relative_humidity_rmin', 'precipitation_amount',\n       'air_temperature_tmmx', 'wind_speed', 'elevation', 'slope', 'curvature',\n       'aspect', 'eastness', 'northness'],\n      dtype='object')\ntesting columns:  Index(['Latitude', 'Longitude', 'rmin', 'tmmx', 'vs', 'etr', 'pr', 'rmax',\n       'vpd', 'tmmn', 'x', 'y', 'Elevation', 'Slope', 'Aspect', 'Curvature',\n       'Northness', 'Eastness', 'AMSR_SWE', 'AMSR_Flag', 'date'],\n      dtype='object')\n",
  "history_begin_time" : 1696433289827,
  "history_end_time" : 1696433293930,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ovThrGfmX8cU",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\n\nnew_testing_data_path = f'{work_dir}/testing_all_ready.csv'\ntraining_data_path = f'{work_dir}/final_merged_data_3yrs_cleaned.csv'\n\ntraining_df = pd.read_csv(training_data_path)\ntesting_df = pd.read_csv(new_testing_data_path)\n\nprint(\"training_df : \", training_df)\nprint(\"testing_df : \", testing_df)\n\n\n",
  "history_output" : "today date = 2023-10-04\ntest start date:  2023-01-18\ntest end date:  2023-10-04\n/home/chetana\ntraining_df :                 date        lat         lon  ...      aspect  eastness  northness\n0        2020-11-25  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n1        2020-10-18  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n2        2020-09-21  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n3        2022-09-01  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n4        2019-10-03  37.192360 -118.939041  ...   24.605782  0.394541   0.737872\n...             ...        ...         ...  ...         ...       ...        ...\n1022695  2019-11-20  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022696  2020-07-16  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022697  2020-08-31  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022698  2021-09-07  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n1022699  2021-06-09  36.682572 -118.427001  ...  194.287310 -0.241950  -0.769692\n[1022700 rows x 21 columns]\ntesting_df :          Latitude  Longitude rmin  ... AMSR_SWE AMSR_Flag        date\n0          49.00   -125.000   --  ...        0       241  2023-01-18\n1          49.00   -124.964   --  ...        0       241  2023-01-18\n2          49.00   -124.928   --  ...        0       241  2023-01-18\n3          49.00   -124.892   --  ...        0       241  2023-01-18\n4          49.00   -124.856   --  ...        0       241  2023-01-18\n...          ...        ...  ...  ...      ...       ...         ...\n462199     25.06   -100.196   --  ...      255       255  2023-01-18\n462200     25.06   -100.160   --  ...      255       255  2023-01-18\n462201     25.06   -100.124   --  ...      255       255  2023-01-18\n462202     25.06   -100.088   --  ...      255       255  2023-01-18\n462203     25.06   -100.052   --  ...      255       255  2023-01-18\n[462204 rows x 21 columns]\n",
  "history_begin_time" : 1696433241526,
  "history_end_time" : 1696433245864,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "BKusCny9g9OI",
  "history_input" : "# compare patterns in training and testing\n# plot the comparison of training and testing variables\n\n# this process only analyzes data, we don't touch model at all here.\n\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom snowcast_utils import work_dir\nimport os\nimport pandas as pd\n\nnew_testing_data_path = f'{work_dir}/testing_all_ready.csv'\ntraining_data_path = f'{working_dir}/final_merged_data_3yrs_cleaned.csv'\n\ntraining_df = pd.read_csv(training_data_path)\ntesting_df = pd.read_csv(new_testing_data_path)\n\nprint(\"training_df : \", training_df)\nprint(\"testing_df : \", testing_df)\n\n\n",
  "history_output" : "today date = 2023-10-04\ntest start date:  2023-01-18\ntest end date:  2023-10-04\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/BKusCny9g9OI/train_test_pattern_compare.py\", line 15, in <module>\n    training_data_path = f'{working_dir}/final_merged_data_3yrs_cleaned.csv'\nNameError: name 'working_dir' is not defined\n",
  "history_begin_time" : 1696433229336,
  "history_end_time" : 1696433230630,
  "history_notes" : null,
  "history_process" : "9c573m",
  "host_id" : null,
  "indicator" : "Failed"
},]
