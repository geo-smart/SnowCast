[{
  "history_id" : "xzdumropflf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696863953246,
  "history_end_time" : 1696863953246,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8x27p2pfxyr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696862402946,
  "history_end_time" : 1696862402946,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "170lvghd2es",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696832263667,
  "history_end_time" : 1696832263667,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j1j92lile0n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696831867370,
  "history_end_time" : 1696831867370,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mdqo1420ll6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696830174358,
  "history_end_time" : 1696830174358,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "izvg20hm5as",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696787541908,
  "history_end_time" : 1696787541908,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i3hovp666qx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696786838190,
  "history_end_time" : 1696786838190,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "z2q1vl3bgtf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696771780884,
  "history_end_time" : 1696771780884,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6uweoi6zzpa",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696602943938,
  "history_end_time" : 1696602943938,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k527n7dt6y7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696432484316,
  "history_end_time" : 1696432484316,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8865m7r228p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696432299756,
  "history_end_time" : 1696432482233,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "uq6ik1fyeh7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827991087,
  "history_end_time" : 1695827991087,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p3plneo8zf4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827889173,
  "history_end_time" : 1695827964214,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "72idvvphpze",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827855640,
  "history_end_time" : 1695827867007,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "k75kusu804g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695696616112,
  "history_end_time" : 1695696616112,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "50jlxg9vrje",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695694257324,
  "history_end_time" : 1695694257324,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "glwqvjdb2y3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695693585743,
  "history_end_time" : 1695693585743,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hzb4ezad9si",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695693149365,
  "history_end_time" : 1695693149365,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bddmm6zpfem",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695580915843,
  "history_end_time" : 1695580915843,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "57ddf432kjy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695576291652,
  "history_end_time" : 1695576291652,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1am9bga8yv1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695575931012,
  "history_end_time" : 1695575931012,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "v42gznbzuyf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535769209,
  "history_end_time" : 1695535769209,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3gzptzlcy01",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535478696,
  "history_end_time" : 1695535478696,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "av6o6hs1waq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535214020,
  "history_end_time" : 1695535214020,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pprpr0gnh53",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695534943584,
  "history_end_time" : 1695534943584,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hzl6qy4oskm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695534671824,
  "history_end_time" : 1695534671824,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vwbv2tlwt9w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695533024123,
  "history_end_time" : 1695533024123,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "c5o2aidkzst",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695529187861,
  "history_end_time" : 1695529187861,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "n060echuiz7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695528505183,
  "history_end_time" : 1695528505183,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zh85glc3ivt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695515862395,
  "history_end_time" : 1695515862395,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rap9doi73ey",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695506423843,
  "history_end_time" : 1695506423843,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "n3p3h081jio",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695418741336,
  "history_end_time" : 1695418741336,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3eu8x4w47vv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417619673,
  "history_end_time" : 1695417619673,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "45babd93cqc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417171275,
  "history_end_time" : 1695417171275,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4nex4m7lfkp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417052728,
  "history_end_time" : 1695417052728,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tzxl1p2u6ua",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695416916019,
  "history_end_time" : 1695416916019,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ny3qmk7fwr7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695106488975,
  "history_end_time" : 1695106488975,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j64zh4w5sjh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695106316207,
  "history_end_time" : 1695106316207,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wi2kx9b03q6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695054045023,
  "history_end_time" : 1695054045023,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "63kmwrmv7gu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695054019756,
  "history_end_time" : 1695054032322,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "r2nj71czxm6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053979903,
  "history_end_time" : 1695054019273,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "uzc4b5ufa6a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053793413,
  "history_end_time" : 1695053793413,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x89dja89e3n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053733428,
  "history_end_time" : 1695053733428,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ckwtwmbg795",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694971144821,
  "history_end_time" : 1694972839686,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "a4is1xphc1h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970707921,
  "history_end_time" : 1694970707921,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0i6729u06bv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970594758,
  "history_end_time" : 1694970594758,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1k00qz7xgrz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970131589,
  "history_end_time" : 1694970131589,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "obwbpdhaj2q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694969350062,
  "history_end_time" : 1694969350062,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4hrafkhem59",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694905307690,
  "history_end_time" : 1694905307690,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "c6xgzz6f0s0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694897887126,
  "history_end_time" : 1694897887126,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8rq1orit010",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531335804,
  "history_end_time" : 1691531335804,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "3talf63dgov",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531292759,
  "history_end_time" : 1691531292759,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "rao069u3eo7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531254609,
  "history_end_time" : 1691531284899,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "pnxid79bnxr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531163864,
  "history_end_time" : 1691531163864,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "65l7acmkiru",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531120885,
  "history_end_time" : 1691531120885,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "dc5sqel4kac",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531060930,
  "history_end_time" : 1691531060930,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "uyd2cuvcgwi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530848317,
  "history_end_time" : 1691530848317,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "kxtdua0088g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530717702,
  "history_end_time" : 1691530721104,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "17ltvz0wilb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530690140,
  "history_end_time" : 1691530716748,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "pigks1kcei7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530621031,
  "history_end_time" : 1691530622437,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "q2uwk2l9z7l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530617237,
  "history_end_time" : 1691530617237,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "5coz1dtjnzg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530599837,
  "history_end_time" : 1691530614283,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "UYE3nwlf05UL",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\nprint(\"start to read data\")\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nprint(\"create labelencoder\")\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\nprint(\"rename columns\")\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\nprint(\"Split the data into train and test sets\")\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\nprint(\"Evaluate the AutoKeras regressor on the test set\")\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "2023-07-24 20:52:20.945849: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-24 20:52:22.135416: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-24 20:52:22.137842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/UYE3nwlf05UL/model_creation_autokeras.py\", line 2, in <module>\n    import autokeras as ak\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/autokeras/__init__.py\", line 15, in <module>\n    import keras_nlp\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/__init__.py\", line 8, in <module>\n    from keras_nlp import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/layers/__init__.py\", line 8, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import CachedMultiHeadAttention\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/__init__.py\", line 23, in <module>\n    from keras_nlp.src import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/__init__.py\", line 15, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import (\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/modeling/cached_multi_head_attention.py\", line 16, in <module>\n    from keras_nlp.src.api_export import keras_nlp_export\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/api_export.py\", line 17, in <module>\n    from keras_nlp.src.backend import keras\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/__init__.py\", line 27, in <module>\n    from keras_nlp.src.backend import config\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/config.py\", line 17, in <module>\n    import keras_core\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/__init__.py\", line 8, in <module>\n    from keras_core import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/activations/__init__.py\", line 8, in <module>\n    from keras_core.src.activations import deserialize\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/__init__.py\", line 1, in <module>\n    from keras_core.src import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/__init__.py\", line 3, in <module>\n    from keras_core.src.activations.activations import elu\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/activations.py\", line 1, in <module>\n    from keras_core.src import backend\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/__init__.py\", line 9, in <module>\n    from keras_core.src.backend.common.keras_tensor import KerasTensor\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/__init__.py\", line 2, in <module>\n    from keras_core.src.backend.common.variables import AutocastScope\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/variables.py\", line 7, in <module>\n    from keras_core.src.utils.naming import auto_name\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/__init__.py\", line 1, in <module>\n    from keras_core.src.utils.dataset_utils import audio_dataset_from_directory\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/dataset_utils.py\", line 1, in <module>\n    import tensorflow as tf\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\", line 38, in <module>\n    from tensorflow.python.tools import module_util as _module_util\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n    from tensorflow.python.eager import context\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n    from tensorflow.python.eager import execute\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n    from tensorflow.python.framework import dtypes\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py\", line 38, in <module>\n    _np_bfloat16 = pywrap_bfloat16.bfloat16_type()\nTypeError: Unable to convert function return value to a Python type! The signature was\n\t() -> handle\n",
  "history_begin_time" : 1690231934795,
  "history_end_time" : 1690231943857,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lO1JumQQm8h6",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\nprint(\"start to read data\")\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nprint(\"create labelencoder\")\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\nprint(\"rename columns\")\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\nprint(\"Split the data into train and test sets\")\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\nprint(\"Evaluate the AutoKeras regressor on the test set\")\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "2023-07-24 19:34:11.790568: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-24 19:34:11.840084: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-24 19:34:11.840634: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/lO1JumQQm8h6/model_creation_autokeras.py\", line 2, in <module>\n    import autokeras as ak\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/autokeras/__init__.py\", line 15, in <module>\n    import keras_nlp\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/__init__.py\", line 8, in <module>\n    from keras_nlp import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/layers/__init__.py\", line 8, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import CachedMultiHeadAttention\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/__init__.py\", line 23, in <module>\n    from keras_nlp.src import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/__init__.py\", line 15, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import (\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/modeling/cached_multi_head_attention.py\", line 16, in <module>\n    from keras_nlp.src.api_export import keras_nlp_export\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/api_export.py\", line 17, in <module>\n    from keras_nlp.src.backend import keras\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/__init__.py\", line 27, in <module>\n    from keras_nlp.src.backend import config\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/config.py\", line 17, in <module>\n    import keras_core\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/__init__.py\", line 8, in <module>\n    from keras_core import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/activations/__init__.py\", line 8, in <module>\n    from keras_core.src.activations import deserialize\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/__init__.py\", line 1, in <module>\n    from keras_core.src import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/__init__.py\", line 3, in <module>\n    from keras_core.src.activations.activations import elu\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/activations.py\", line 1, in <module>\n    from keras_core.src import backend\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/__init__.py\", line 9, in <module>\n    from keras_core.src.backend.common.keras_tensor import KerasTensor\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/__init__.py\", line 2, in <module>\n    from keras_core.src.backend.common.variables import AutocastScope\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/variables.py\", line 7, in <module>\n    from keras_core.src.utils.naming import auto_name\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/__init__.py\", line 1, in <module>\n    from keras_core.src.utils.dataset_utils import audio_dataset_from_directory\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/dataset_utils.py\", line 1, in <module>\n    import tensorflow as tf\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\", line 38, in <module>\n    from tensorflow.python.tools import module_util as _module_util\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n    from tensorflow.python.eager import context\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n    from tensorflow.python.eager import execute\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n    from tensorflow.python.framework import dtypes\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py\", line 38, in <module>\n    _np_bfloat16 = pywrap_bfloat16.bfloat16_type()\nTypeError: Unable to convert function return value to a Python type! The signature was\n\t() -> handle\n",
  "history_begin_time" : 1690227251102,
  "history_end_time" : 1690227251967,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "454jygO50XxI",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\nprint(\"start to read data\")\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nprint(\"create labelencoder\")\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\nprint(\"rename columns\")\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\nprint(\"Split the data into train and test sets\")\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\nprint(\"Evaluate the AutoKeras regressor on the test set\")\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "2023-07-24 19:27:39.076741: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-24 19:27:39.123729: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-24 19:27:39.124280: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/454jygO50XxI/model_creation_autokeras.py\", line 2, in <module>\n    import autokeras as ak\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/autokeras/__init__.py\", line 15, in <module>\n    import keras_nlp\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/__init__.py\", line 8, in <module>\n    from keras_nlp import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/layers/__init__.py\", line 8, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import CachedMultiHeadAttention\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/__init__.py\", line 23, in <module>\n    from keras_nlp.src import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/__init__.py\", line 15, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import (\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/modeling/cached_multi_head_attention.py\", line 16, in <module>\n    from keras_nlp.src.api_export import keras_nlp_export\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/api_export.py\", line 17, in <module>\n    from keras_nlp.src.backend import keras\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/__init__.py\", line 27, in <module>\n    from keras_nlp.src.backend import config\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/config.py\", line 17, in <module>\n    import keras_core\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/__init__.py\", line 8, in <module>\n    from keras_core import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/activations/__init__.py\", line 8, in <module>\n    from keras_core.src.activations import deserialize\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/__init__.py\", line 1, in <module>\n    from keras_core.src import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/__init__.py\", line 3, in <module>\n    from keras_core.src.activations.activations import elu\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/activations.py\", line 1, in <module>\n    from keras_core.src import backend\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/__init__.py\", line 9, in <module>\n    from keras_core.src.backend.common.keras_tensor import KerasTensor\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/__init__.py\", line 2, in <module>\n    from keras_core.src.backend.common.variables import AutocastScope\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/variables.py\", line 7, in <module>\n    from keras_core.src.utils.naming import auto_name\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/__init__.py\", line 1, in <module>\n    from keras_core.src.utils.dataset_utils import audio_dataset_from_directory\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/dataset_utils.py\", line 1, in <module>\n    import tensorflow as tf\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\", line 38, in <module>\n    from tensorflow.python.tools import module_util as _module_util\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n    from tensorflow.python.eager import context\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n    from tensorflow.python.eager import execute\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n    from tensorflow.python.framework import dtypes\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py\", line 38, in <module>\n    _np_bfloat16 = pywrap_bfloat16.bfloat16_type()\nTypeError: Unable to convert function return value to a Python type! The signature was\n\t() -> handle\n",
  "history_begin_time" : 1690226858436,
  "history_end_time" : 1690226859324,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "hx4HV94jKIHQ",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\nprint(\"start to read data\")\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nprint(\"create labelencoder\")\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\nprint(\"rename columns\")\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\nprint(\"Split the data into train and test sets\")\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\nprint(\"Evaluate the AutoKeras regressor on the test set\")\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "2023-07-24 19:26:49.472376: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-24 19:26:50.724010: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-24 19:26:50.726088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/hx4HV94jKIHQ/model_creation_autokeras.py\", line 2, in <module>\n    import autokeras as ak\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/autokeras/__init__.py\", line 15, in <module>\n    import keras_nlp\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/__init__.py\", line 8, in <module>\n    from keras_nlp import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/layers/__init__.py\", line 8, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import CachedMultiHeadAttention\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/__init__.py\", line 23, in <module>\n    from keras_nlp.src import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/__init__.py\", line 15, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import (\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/modeling/cached_multi_head_attention.py\", line 16, in <module>\n    from keras_nlp.src.api_export import keras_nlp_export\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/api_export.py\", line 17, in <module>\n    from keras_nlp.src.backend import keras\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/__init__.py\", line 27, in <module>\n    from keras_nlp.src.backend import config\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/config.py\", line 17, in <module>\n    import keras_core\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/__init__.py\", line 8, in <module>\n    from keras_core import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/activations/__init__.py\", line 8, in <module>\n    from keras_core.src.activations import deserialize\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/__init__.py\", line 1, in <module>\n    from keras_core.src import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/__init__.py\", line 3, in <module>\n    from keras_core.src.activations.activations import elu\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/activations.py\", line 1, in <module>\n    from keras_core.src import backend\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/__init__.py\", line 9, in <module>\n    from keras_core.src.backend.common.keras_tensor import KerasTensor\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/__init__.py\", line 2, in <module>\n    from keras_core.src.backend.common.variables import AutocastScope\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/variables.py\", line 7, in <module>\n    from keras_core.src.utils.naming import auto_name\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/__init__.py\", line 1, in <module>\n    from keras_core.src.utils.dataset_utils import audio_dataset_from_directory\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/dataset_utils.py\", line 1, in <module>\n    import tensorflow as tf\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\", line 38, in <module>\n    from tensorflow.python.tools import module_util as _module_util\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 42, in <module>\n    from tensorflow.python import data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n    from tensorflow.python.data import experimental\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/experimental/__init__.py\", line 97, in <module>\n    from tensorflow.python.data.experimental import service\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 25, in <module>\n    from tensorflow.python.data.ops import dataset_ops\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 31, in <module>\n    from tensorflow.python.data.ops import iterator_ops\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 40, in <module>\n    from tensorflow.python.training.saver import BaseSaverBuilder\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 50, in <module>\n    from tensorflow.python.training import py_checkpoint_reader\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/training/py_checkpoint_reader.py\", line 19, in <module>\n    from tensorflow.python.util._pywrap_checkpoint_reader import CheckpointReader\nSystemError: initialization of _pywrap_checkpoint_reader raised unreported exception\n",
  "history_begin_time" : 1690226801514,
  "history_end_time" : 1690226815483,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "XIcwc0ArMeJ6",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\nprint(\"start to read data\")\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nprint(\"create labelencoder\")\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\nprint(\"rename columns\")\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\nprint(\"Split the data into train and test sets\")\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\nprint(\"Evaluate the AutoKeras regressor on the test set\")\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "Using TensorFlow backend\n2023-07-19 19:10:16.699427: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 19:10:16.756186: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 19:10:16.756905: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-07-19 19:10:18.310993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n2023-07-19 19:14:04.433496: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n\nStream closed",
  "history_begin_time" : 1689793935893,
  "history_end_time" : 1689794044437,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "z4QopyLDJ7BI",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\n\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\n# Evaluate the AutoKeras regressor on the test set\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "Running",
  "history_begin_time" : 1689793815150,
  "history_end_time" : 1689793948272,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "1MnGzRHrMH3M",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\n# Evaluate the AutoKeras regressor on the test set\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "Using TensorFlow backend\n2023-07-19 19:08:02.532932: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 19:08:02.580840: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 19:08:02.581389: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-07-19 19:08:03.295591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nTraceback (most recent call last):\n  File \"model_creation_autokeras.py\", line 9, in <module>\n    label_encoder = LabelEncoder()\nNameError: name 'LabelEncoder' is not defined\n",
  "history_begin_time" : 1689793681852,
  "history_end_time" : 1689793751112,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ADEzchcnZBQm",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\n# Evaluate the AutoKeras regressor on the test set\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "Using TensorFlow backend\n2023-07-19 19:07:17.346083: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 19:07:17.397585: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 19:07:17.398165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-07-19 19:07:18.563447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nTraceback (most recent call last):\n  File \"model_creation_autokeras.py\", line 3, in <module>\n    from sklearn.model_selection import train_test_split\nModuleNotFoundError: No module named 'sklearn'\n",
  "history_begin_time" : 1689793636100,
  "history_end_time" : 1689793640288,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "tmKrWhCo3KA1",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\n# Evaluate the AutoKeras regressor on the test set\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "2023-07-19 18:59:04.634864: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 18:59:04.690506: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 18:59:04.691181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/tmKrWhCo3KA1/model_creation_autokeras.py\", line 2, in <module>\n    import autokeras as ak\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/autokeras/__init__.py\", line 15, in <module>\n    import keras_nlp\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/__init__.py\", line 8, in <module>\n    from keras_nlp import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/layers/__init__.py\", line 8, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import CachedMultiHeadAttention\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/__init__.py\", line 23, in <module>\n    from keras_nlp.src import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/__init__.py\", line 15, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import (\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/modeling/cached_multi_head_attention.py\", line 16, in <module>\n    from keras_nlp.src.api_export import keras_nlp_export\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/api_export.py\", line 17, in <module>\n    from keras_nlp.src.backend import keras\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/__init__.py\", line 27, in <module>\n    from keras_nlp.src.backend import config\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/config.py\", line 17, in <module>\n    import keras_core\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/__init__.py\", line 8, in <module>\n    from keras_core import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/activations/__init__.py\", line 8, in <module>\n    from keras_core.src.activations import deserialize\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/__init__.py\", line 1, in <module>\n    from keras_core.src import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/__init__.py\", line 3, in <module>\n    from keras_core.src.activations.activations import elu\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/activations.py\", line 1, in <module>\n    from keras_core.src import backend\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/__init__.py\", line 9, in <module>\n    from keras_core.src.backend.common.keras_tensor import KerasTensor\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/__init__.py\", line 2, in <module>\n    from keras_core.src.backend.common.variables import AutocastScope\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/variables.py\", line 7, in <module>\n    from keras_core.src.utils.naming import auto_name\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/__init__.py\", line 1, in <module>\n    from keras_core.src.utils.dataset_utils import audio_dataset_from_directory\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/dataset_utils.py\", line 1, in <module>\n    import tensorflow as tf\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\", line 38, in <module>\n    from tensorflow.python.tools import module_util as _module_util\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n    from tensorflow.python.eager import context\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n    from tensorflow.python.eager import execute\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n    from tensorflow.python.framework import dtypes\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py\", line 38, in <module>\n    _np_bfloat16 = pywrap_bfloat16.bfloat16_type()\nTypeError: Unable to convert function return value to a Python type! The signature was\n\t() -> handle\n",
  "history_begin_time" : 1689793143946,
  "history_end_time" : 1689793144831,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "jUoIqZv76sPq",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\n# Evaluate the AutoKeras regressor on the test set\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "Cannot run program \"/home/chetana/anaconda3/envs/auto-pytorch/bin/python\" (in directory \"/home/chetana/gw-workspace/jUoIqZv76sPq\"): error=13, Permission denied",
  "history_begin_time" : 1689793030856,
  "history_end_time" : 1689793030901,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "svj1T6l2SKTB",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\n# Evaluate the AutoKeras regressor on the test set\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "Cannot run program \"/home/chetana/anaconda3/conda/bin/python\" (in directory \"/home/chetana/gw-workspace/svj1T6l2SKTB\"): error=2, No such file or directory",
  "history_begin_time" : 1689792998703,
  "history_end_time" : 1689792998706,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "AZwixpCE8QXP",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\n# Evaluate the AutoKeras regressor on the test set\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "2023-07-19 18:49:36.367213: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 18:49:37.581182: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-07-19 18:49:37.583227: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nRuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\nImportError: numpy.core._multiarray_umath failed to import\nImportError: numpy.core.umath failed to import\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/AZwixpCE8QXP/model_creation_autokeras.py\", line 2, in <module>\n    import autokeras as ak\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/autokeras/__init__.py\", line 15, in <module>\n    import keras_nlp\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/__init__.py\", line 8, in <module>\n    from keras_nlp import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/layers/__init__.py\", line 8, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import CachedMultiHeadAttention\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/__init__.py\", line 23, in <module>\n    from keras_nlp.src import layers\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/__init__.py\", line 15, in <module>\n    from keras_nlp.src.layers.modeling.cached_multi_head_attention import (\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/layers/modeling/cached_multi_head_attention.py\", line 16, in <module>\n    from keras_nlp.src.api_export import keras_nlp_export\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/api_export.py\", line 17, in <module>\n    from keras_nlp.src.backend import keras\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/__init__.py\", line 27, in <module>\n    from keras_nlp.src.backend import config\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_nlp/src/backend/config.py\", line 17, in <module>\n    import keras_core\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/__init__.py\", line 8, in <module>\n    from keras_core import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/activations/__init__.py\", line 8, in <module>\n    from keras_core.src.activations import deserialize\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/__init__.py\", line 1, in <module>\n    from keras_core.src import activations\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/__init__.py\", line 3, in <module>\n    from keras_core.src.activations.activations import elu\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/activations/activations.py\", line 1, in <module>\n    from keras_core.src import backend\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/__init__.py\", line 9, in <module>\n    from keras_core.src.backend.common.keras_tensor import KerasTensor\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/__init__.py\", line 2, in <module>\n    from keras_core.src.backend.common.variables import AutocastScope\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/backend/common/variables.py\", line 7, in <module>\n    from keras_core.src.utils.naming import auto_name\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/__init__.py\", line 1, in <module>\n    from keras_core.src.utils.dataset_utils import audio_dataset_from_directory\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/keras_core/src/utils/dataset_utils.py\", line 1, in <module>\n    import tensorflow as tf\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\", line 38, in <module>\n    from tensorflow.python.tools import module_util as _module_util\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n    from tensorflow.python.eager import context\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 36, in <module>\n    from tensorflow.python.eager import execute\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n    from tensorflow.python.framework import dtypes\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py\", line 38, in <module>\n    _np_bfloat16 = pywrap_bfloat16.bfloat16_type()\nTypeError: Unable to convert function return value to a Python type! The signature was\n\t() -> handle\n",
  "history_begin_time" : 1689792568782,
  "history_end_time" : 1689792579271,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "tp3xjcin1o3",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689632033850,
  "history_end_time" : 1689632035391,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "dt5vk9fpoeu",
  "history_input" : "import pandas as pd\nimport autokeras as ak\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndf = pd.read_csv('/home/chetana/gridmet_test_run/five_years_data.csv')\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\ndf.drop('Date', inplace=True, axis=1)\ndf.drop('mapping_cell_id', inplace=True, axis=1)\ndf.drop('cell_id', inplace=True, axis=1)\ndf.drop('station_id', inplace=True, axis=1)\ndf.drop('mapping_station_id', inplace=True, axis=1)\ndf.drop('station_triplet', inplace=True, axis=1)\ndf.drop('station_name', inplace=True, axis=1)\n\ndf.rename(columns={\n                   'Change In Snow Water Equivalent (in)': 'swe_change',\n                   'Snow Depth (in) Start of Day Values': 'swe_value',\n                   'Change In Snow Depth (in)': 'snow_depth_change',\n                   'Air Temperature Observed (degF) Start of Day Values': 'snotel_air_temp',\n                   'Elevation [m]': 'elevation',\n                   'Aspect [deg]': 'aspect', 'Curvature [ratio]': 'curvature',\n                   'Slope [deg]': 'slope', 'Eastness [unitCirc.]': 'eastness',\n                   'Northness [unitCirc.]': 'northness'\n                   }, inplace=True)\n\n# Split the data into features and target variable\nX = df.drop(columns=['swe_value'])\ny = df['swe_value']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the AutoKeras regressor\nreg = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\nreg.fit(X_train, y_train, epochs=10)\n\n# Evaluate the AutoKeras regressor on the test set\npredictions = reg.predict(X_test)\nrmse = mean_squared_error(y_test, predictions, squared=False)\nr2 = r2_score(y_test, predictions)\n\n# Print the evaluation metrics\nprint('RMSE:', rmse)\nprint('R2 Score:', r2)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"model_creation_autokeras.py\", line 1, in <module>\n    import pandas as pd\nImportError: No module named pandas\n",
  "history_begin_time" : 1689631636556,
  "history_end_time" : 1689631638720,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "83kifww4csu",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689135058426,
  "history_end_time" : 1689135060855,
  "history_notes" : null,
  "history_process" : "b7a4fu",
  "host_id" : "100001",
  "indicator" : "Failed"
},]
