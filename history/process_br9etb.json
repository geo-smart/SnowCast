[{
  "history_id" : "dTzLSmHaXMiy",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/dTzLSmHaXMiy/data_snotel_station_only.py\", line 52\n    lines = text.split('\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435447998,
  "history_end_time" : 1690435449046,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "x3KNDLvbtAvp",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/x3KNDLvbtAvp/data_snotel_station_only.py\", line 52\n    lines = text.split('\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435412976,
  "history_end_time" : 1690435413968,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "2TGec8CwG5YS",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    #lines = text.split(\"\\n\")\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/2TGec8CwG5YS/data_snotel_station_only.py\", line 53\n    \")\n      ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435339980,
  "history_end_time" : 1690435340992,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "mUioimE67bkC",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/mUioimE67bkC/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435324515,
  "history_end_time" : 1690435325521,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cKmvfsxkC0tU",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n  lines = text.split(\"\\n\")\n  cleaned_lines = []\n  for line in lines:\n    if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n      cleaned_lines.append(line)\n      cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n      return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/cKmvfsxkC0tU/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435275952,
  "history_end_time" : 1690435276968,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "iEXHrf3gJTag",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n  lines = text.split(\"\\n\")\n  cleaned_lines = []\n  for line in lines:\n    if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n      cleaned_lines.append(line)\n      cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n      return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/iEXHrf3gJTag/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435013488,
  "history_end_time" : 1690435014496,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "bEYVLh3q3RyY",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n            cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n            return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/bEYVLh3q3RyY/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434938239,
  "history_end_time" : 1690434939249,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "OgjJwjOUauMo",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n            cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n            return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/OgjJwjOUauMo/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434932289,
  "history_end_time" : 1690434933299,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "gWG9THFZrUWj",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n  lines = text.split(\"\\n\")\n  cleaned_lines = []\n\n  for line in lines:\n    if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n      cleaned_lines.append(line)\n\n      cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n\n      return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n       \titem['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/gWG9THFZrUWj/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434860319,
  "history_end_time" : 1690434861338,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "oOJ4rclwLg3R",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n\n    return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n       \titem['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/oOJ4rclwLg3R/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434809050,
  "history_end_time" : 1690434810072,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vj6uJwzWo9iL",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")  # Split the text into lines\n    cleaned_lines = []\n\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n\n    return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n       \titem['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/vj6uJwzWo9iL/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434713804,
  "history_end_time" : 1690434714952,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7gbfaosi0ci",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689632034782,
  "history_end_time" : 1689632036286,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "9lvmt7oy7r5",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")  # Split the text into lines\n    cleaned_lines = []\n\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n\n    return cleaned_text\n\n\ncsv_file = 'snotel.csv'\nstart_date = \"2022-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['station_name'] = location_name\n        item['station_triplet'] = location_triplet\n        item['station_elevation'] = location_elevation\n        item['station_lat'] = location_station_lat\n        item['station_long'] = location_station_long\n        item['mapping_station_id'] = row['station_id']\n        item['mapping_cell_id'] = row['cell_id']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1689631636508,
  "history_end_time" : 1689631638722,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Done"
},{
  "history_id" : "mom9jp045sp",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689135058746,
  "history_end_time" : 1689135061420,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Failed"
},]
