[{
  "history_id" : "mljqwknu7y4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704644803700,
  "history_end_time" : 1704644803700,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "582s2gb5t5p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704600008054,
  "history_end_time" : 1704600008054,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "epm2uryhxz8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704566156615,
  "history_end_time" : 1704566156615,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "90bfyoogs0j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704565587371,
  "history_end_time" : 1704565587371,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pty6hnlwual",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704564424151,
  "history_end_time" : 1704564424151,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "oj5da9cxc1k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704562992166,
  "history_end_time" : 1704562992166,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u6jkk6vbew8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704561889786,
  "history_end_time" : 1704561889786,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bvjqtttksrs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704561861157,
  "history_end_time" : 1704561887033,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "j13wsi3qyqs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704555479196,
  "history_end_time" : 1704555479196,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3tejbqdsrpl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704555028186,
  "history_end_time" : 1704555028186,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hvgb3uw2isq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704553241759,
  "history_end_time" : 1704553241759,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ozm3ugso1jg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704552254608,
  "history_end_time" : 1704552254608,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "trhmoc4q55m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704513607268,
  "history_end_time" : 1704513607268,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g7up1yuuv1r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704427207372,
  "history_end_time" : 1704427207372,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gn65ni65ojr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704340807440,
  "history_end_time" : 1704340807440,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u2i0c9kuzyo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704330109289,
  "history_end_time" : 1704330109289,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3dpse4oakma",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704329364840,
  "history_end_time" : 1704329364840,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jx88yvsrycy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704254407369,
  "history_end_time" : 1704254407369,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "84q6n5mqdwb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704208947949,
  "history_end_time" : 1704208947949,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wxzujqc8di7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704207352010,
  "history_end_time" : 1704207352010,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hqc41a8x3fe",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704205859361,
  "history_end_time" : 1704205859361,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "brbdps91vwe",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704168007282,
  "history_end_time" : 1704168007282,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kyaeztelcc3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704081607339,
  "history_end_time" : 1704081607339,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lskd1is169g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703995208167,
  "history_end_time" : 1703995208167,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sk3lnksrimz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703962871395,
  "history_end_time" : 1703962871395,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uvikipr4wew",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703960265436,
  "history_end_time" : 1703960265436,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "z3nsh18tk2p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703959737832,
  "history_end_time" : 1703959737832,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wabzumqaxh0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703958611577,
  "history_end_time" : 1703958611577,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "icvzvk32aww",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703955838215,
  "history_end_time" : 1703955838215,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wpxb634s5z6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703954150350,
  "history_end_time" : 1703954150350,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j694vkhxlb8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703915768061,
  "history_end_time" : 1703915768061,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zdl45r0kulc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703915283476,
  "history_end_time" : 1703915283476,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "s6qltbkuxr4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703914476630,
  "history_end_time" : 1703914476630,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "z3s25nu42g8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703912302162,
  "history_end_time" : 1703912302162,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0rdnaqoydsx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703908806975,
  "history_end_time" : 1703908806975,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "299rnbb269b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703906215368,
  "history_end_time" : 1703906215368,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "chdcsysmze3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703900919133,
  "history_end_time" : 1703900919133,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1d52buccqwt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703899837755,
  "history_end_time" : 1703899837755,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q5qxkn0e52k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703897422940,
  "history_end_time" : 1703897422940,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fiwlp8ry6rt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703896125572,
  "history_end_time" : 1703896125572,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "14xrbbgtzp9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703890275980,
  "history_end_time" : 1703890275980,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rfhuiyhwr9t",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703886800798,
  "history_end_time" : 1703886800798,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9t5r3wx3lxv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703885997755,
  "history_end_time" : 1703885997755,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "el93llj8fkc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703880194705,
  "history_end_time" : 1703880194705,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rmrxf28vd11",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703872753023,
  "history_end_time" : 1703872753023,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "f5n6f18s10r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703869828228,
  "history_end_time" : 1703869828228,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tabv4hfkbqj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703868616919,
  "history_end_time" : 1703868616919,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tgljx49ham0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703867114036,
  "history_end_time" : 1703867114036,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lrcf87rwelf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703864885434,
  "history_end_time" : 1703864885434,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jnk813b7bnm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703862637342,
  "history_end_time" : 1703862637342,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kikdqhgzly7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703827227318,
  "history_end_time" : 1703827227318,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sq716gx96my",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703822411318,
  "history_end_time" : 1703822411318,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zlmbxryunm9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703786924625,
  "history_end_time" : 1703789718819,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ev3jpodls1m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703786053478,
  "history_end_time" : 1703786917610,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ti15kietels",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703778395383,
  "history_end_time" : 1703778395383,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k44a2i24j9l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703739034332,
  "history_end_time" : 1703739034332,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "das6j7jd9t1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703738754399,
  "history_end_time" : 1703792459276,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "621caaztsj0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703736166897,
  "history_end_time" : 1703737316876,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "1sb5sxc840i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703694763552,
  "history_end_time" : 1703694763552,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ulvoj95p10y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703659541194,
  "history_end_time" : 1703659541194,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3c8m2m5px9c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703658144680,
  "history_end_time" : 1703658144680,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2jgk3srtqel",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703650855764,
  "history_end_time" : 1703650855764,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u72gxo4t65m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703646751525,
  "history_end_time" : 1703650812434,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "bnnluw6i36h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703642120888,
  "history_end_time" : 1703646749620,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "eve14h2crl6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703641988922,
  "history_end_time" : 1703642074628,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "qq4y9hmfg25",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703629665498,
  "history_end_time" : 1703629665498,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qzy5xwswkme",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703626687973,
  "history_end_time" : 1703627783050,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "85c8wz4ni1p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703625782086,
  "history_end_time" : 1703625782086,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "351m1m541tu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703624783911,
  "history_end_time" : 1703624783911,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "SYbdJ1CvNYai",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nimport dask\nimport dask.dataframe as dd\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask_all_vars.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    # Create an empty Pandas DataFrame with the desired columns\n    result_df = pd.DataFrame(columns=[\n      'station_name', \n      'date', \n      'lat', \n      'lon', \n      'swe_value', \n      'change_in_swe_inch', \n      'snow_depth', \n      'change_in_swe_inch', \n      'air_temperature_observed_f'\n    ])\n\n    # Function to process each station\n    @dask.delayed\n    def process_station(station):\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n\n        entries = []\n        \n        for entry in json_data:\n            try:\n              # {'Date': '2021-06-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.5'}\n              required_data = {\n                'station_name': location_name,\n                'date': entry['Date'],\n                'lat': location_station_lat, \n                'lon': location_station_long,\n                'swe_value': entry['Snow Water Equivalent (in) Start of Day Values'],\n                'change_in_swe_inch': entry['Change In Snow Water Equivalent (in)'],\n                'snow_depth': entry['Snow Depth (in) Start of Day Values'],\n                'change_in_swe_inch': entry['Change In Snow Depth (in)'],\n                'air_temperature_observed_f': entry['Air Temperature Observed (degF) Start of Day Values']\n              }\n              entries.append(required_data)\n            except Exception as e:\n              print(\"entry = \", entry)\n              raise e\n        return pd.DataFrame(entries)\n\n    # List of delayed computations for each station\n    delayed_results = [process_station(row) for _, row in new_base_df.iterrows()]\n\n    # Compute the delayed results\n    result_lists = dask.compute(*delayed_results)\n\n    # Concatenate the lists into a Pandas DataFrame\n    result_df = pd.concat(result_lists, ignore_index=True)\n\n    # Print the final Pandas DataFrame\n    print(result_df.head())\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\n     station_name        date  ...  snow_depth  air_temperature_observed_f\n0  Adams Ranch #1  2018-01-01  ...                                     8.6\n1  Adams Ranch #1  2018-01-02  ...                                    31.3\n2  Adams Ranch #1  2018-01-03  ...                                    21.4\n3  Adams Ranch #1  2018-01-04  ...                                    39.0\n4  Adams Ranch #1  2018-01-05  ...                                    29.5\n[5 rows x 8 columns]\n",
  "history_begin_time" : 1703600886881,
  "history_end_time" : 1703601001877,
  "history_notes" : "ok, extra all the values snotel/cdec returned",
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "GS8tKhNE8fDp",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nimport dask\nimport dask.dataframe as dd\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask_all_vars.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    # Create an empty Pandas DataFrame with the desired columns\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n\n    # Function to process each station\n    @dask.delayed\n    def process_station(station):\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n\n        entries = []\n        \n        for entry in json_data:\n            try:\n              # {'Date': '2021-06-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.5'}\n              required_data = {\n                'station_name': location_name,\n                'date': entry['Date'],\n                'lat': location_station_lat, \n                'lon': location_station_long,\n                'swe_value': entry['Snow Water Equivalent (in) Start of Day Values'],\n                'change_in_swe_inch': entry['Change In Snow Water Equivalent (in)'],\n                'snow_depth': entry['Snow Depth (in) Start of Day Values'],\n                'change_in_swe_inch': entry['Change In Snow Depth (in)'],\n                'air_temperature_observed_f': entry['Air Temperature Observed (degF) Start of Day Values']\n              }\n              entries.append(required_data)\n            except Exception as e:\n              print(\"entry = \", entry)\n              raise e\n        return pd.DataFrame(entries)\n\n    # List of delayed computations for each station\n    delayed_results = [process_station(row) for _, row in new_base_df.iterrows()]\n\n    # Compute the delayed results\n    result_lists = dask.compute(*delayed_results)\n\n    # Concatenate the lists into a Pandas DataFrame\n    result_df = pd.concat(result_lists, ignore_index=True)\n\n    # Print the final Pandas DataFrame\n    print(result_df.head())\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\n",
  "history_begin_time" : 1703600796223,
  "history_end_time" : 1703600816285,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "5wH3WXpNTlL4",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nimport dask\nimport dask.dataframe as dd\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    # Create an empty Pandas DataFrame with the desired columns\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n\n    # Function to process each station\n    @dask.delayed\n    def process_station(station):\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n\n        entries = []\n        \n        for entry in json_data:\n            try:\n              required_data = {'station_name': location_name,\n                               'date': entry['Date'], \n                               'lat': location_station_lat, \n                               'lon': location_station_long,\n                               'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n              entries.append(required_data)\n            except Exception as e:\n              print(\"entry = \", entry)\n              raise e\n        return pd.DataFrame(entries)\n\n    # List of delayed computations for each station\n    delayed_results = [process_station(row) for _, row in new_base_df.iterrows()]\n\n    # Compute the delayed results\n    result_lists = dask.compute(*delayed_results)\n\n    # Concatenate the lists into a Pandas DataFrame\n    result_df = pd.concat(result_lists, ignore_index=True)\n\n    # Print the final Pandas DataFrame\n    print(result_df.head())\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\n     station_name        date    lat        lon swe_value\n0  Adams Ranch #1  2018-01-01  34.25 -105.41667          \n1  Adams Ranch #1  2018-01-02  34.25 -105.41667          \n2  Adams Ranch #1  2018-01-03  34.25 -105.41667          \n3  Adams Ranch #1  2018-01-04  34.25 -105.41667          \n4  Adams Ranch #1  2018-01-05  34.25 -105.41667          \n",
  "history_begin_time" : 1703600096984,
  "history_end_time" : 1703600211571,
  "history_notes" : "dask works? yup, this works perfect. Thanks Dask!",
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "g2wiO3JAhxfB",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nimport dask\nimport dask.dataframe as dd\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    # Create an empty Pandas DataFrame with the desired columns\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n\n    # Function to process each station\n    @dask.delayed\n    def process_station(station):\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n\n        entries = []\n        \n        for entry in json_data:\n            try:\n              required_data = {'station_name': location_name,\n                               'date': entry['Date'], \n                               'lat': location_station_lat, \n                               'lon': location_station_long,\n                               'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n              entries.append(required_data)\n            except Exception e:\n              print(\"entry = \", entry)\n              raise e\n        return pd.DataFrame(entries)\n\n    # List of delayed computations for each station\n    delayed_results = [process_station(row) for _, row in new_base_df.iterrows()]\n\n    # Compute the delayed results\n    result_lists = dask.compute(*delayed_results)\n\n    # Concatenate the lists into a Pandas DataFrame\n    result_df = pd.concat(result_lists, ignore_index=True)\n\n    # Print the final Pandas DataFrame\n    print(result_df.head())\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/g2wiO3JAhxfB/data_snotel_station_only.py\", line 183\n    except Exception e:\n                     ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1703600039141,
  "history_end_time" : 1703600039205,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "1IKUYuDZYXJW",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nimport dask\nimport dask.dataframe as dd\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    # Create an empty Pandas DataFrame with the desired columns\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n\n    # Function to process each station\n    @dask.delayed\n    def process_station(station):\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n\n        entries = []\n        for entry in json_data:\n            print(\"entry = \", entry)\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            entries.append(required_data)\n\n        return pd.DataFrame(entries)\n\n    # List of delayed computations for each station\n    delayed_results = [process_station(row) for _, row in new_base_df.iterrows()]\n\n    # Compute the delayed results\n    result_lists = dask.compute(*delayed_results)\n\n    # Concatenate the lists into a Pandas DataFrame\n    result_df = pd.concat(result_lists, ignore_index=True)\n\n    # Print the final Pandas DataFrame\n    print(result_df.head())\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\nentry =  {'Date': '2021-06-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.5'}\nentry =  {'Date': '2021-06-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.2'}\nentry =  {'Date': '2021-06-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '73.4'}\nentry =  {'Date': '2021-06-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '77.4'}\nentry = entry =  entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.8'}\n{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '11.8', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '23.0'}entry =  {'Date': '2021-06-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.2'}\nentry =  {'Date': '2021-06-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '76.8'}\nentry = entry =  entry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}\n {'Date': '2021-06-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '77.5'}entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}\nentry = \nentry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '11.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '19.9'}\nentry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '11.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '19.9'}\n entry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '11.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.4'}\n{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.0'}\nentry =  entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.4'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\nentry =  \nentry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  {'Date': '2018-05-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '59.9'}\nentry =  {'Date': '2018-05-31', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '56.1'}entry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '11.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\nentry =   {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.5'}\nentry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}\nentry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.7'}\nentry = {'Date': '2021-06-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.3'}\nentry =  entry = {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''} {'Date': '2018-06-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '44.2'}\nentry =  {'Date': '2018-06-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '46.6'}\nentry =  {'Date': '2021-06-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '77.5'}\nentry =  {'Date': '2021-06-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '62.1'}\nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '12.2', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}\n{'Date': '2018-06-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '53.8'}\nentry =  {'Date': '2018-06-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '61.2'}\nentry =  \n{'Date': '2018-06-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '54.9'}\n{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}\nentry = entry =  entry = entry =    entry =  entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '12.5', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '31.1'}entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '26.8'}\nentry =  {'Date': '2021-06-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '62.4'} {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '19.7', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '27.7'}\n{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \n{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '40.8'}\nentry = {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =   {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '12.7', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '31.8'}entry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}{'Date': '2018-06-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '53.6'}\nentry =  {'Date': '2018-06-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '56.5'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.1'}\nentry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}\nentry = {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '48.7'}\nentry =  \nentry =  \nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.9'}\n {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.5'}\n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '19.4', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '53', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '38.1'}entry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '35.8'}\nentry = entry = entry = entry = \n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '50.5'}\nentry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '19.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '37.2'}\n  entry = {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.6'}entry =   {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '12.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '32.0'}\nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '13.3', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}\nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '13.8', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '49', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}entry = {'Date': '2018-06-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '50.9'}\n  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.2'}\n {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '19.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '41.0'}\nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '19.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '50', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '39.9'}entry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.0'}\nentry = entry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '16.2', 'Change In Snow Water Equivalent (in)': '2.4', 'Snow Depth (in) Start of Day Values': '60', 'Change In Snow Depth (in)': '11', 'Air Temperature Observed (degF) Start of Day Values': '34.0'}\nentry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '4.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '36.1'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =   {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.6'}\nentry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '4.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.3'}\n{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '5.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.7'}\nentry = entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '52.3'}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.8'}entry = \nentry =  \nentry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '5.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}  entry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.1'}\n {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '4.2', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.8'}\nentry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '4.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '41.2'}\n{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '19.2', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\nentry =  entry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}\n{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.2'}\n{'Date': '2018-06-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '59.5'}\nentry = {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '16.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '56', 'Change In Snow Depth (in)': '-4', 'Air Temperature Observed (degF) Start of Day Values': '36.0'}\nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '4.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '39.2'}\nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '-0.4', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}\nentry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '16.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '-9', 'Air Temperature Observed (degF) Start of Day Values': '36.5'}\nentry =  entry = entry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.9'}\nentry = \nentry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n entry = {'Date': '2021-06-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '62.1'}\nentry =  {'Date': '2021-06-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.6'}\nentry = {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '16.1', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '46', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.1'}\n{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '18.6', 'Change In Snow Water Equivalent (in)': '-0.6', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}\nentry =  entry =    entry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.0'}\nentry =   {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '15.9', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.5'}\nentry = {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}{'Date': '2021-07-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '66.4'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '36.7'}\nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}\nentry = entry = {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}\n  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '16.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '44', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}\nentry =   {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''} {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.5'}\nentry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}\nentry =  entry = entry =   {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.0'}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '5.7', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2021-07-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.9'}\nentry =  {'Date': '2021-07-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '67.3'}\n {'Date': '2018-06-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.6'}\n{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '19.0', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}{'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '16.3', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}entry = entry =  {'Date': '2018-06-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '46.0'}\nentry = \nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '4.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.4'}\nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '4.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\nentry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '4.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}\n {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '22.3'}\nentry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '42.8'}\nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '45.7'}\nentry = entry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '16.1', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '44', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.8'}\nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.9'}\nentry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '4.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.0'}\nentry =  \nentry =   {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '16.5', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '31.5'}\nentry = entry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.4'}\n{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.6'}\nentry =  {'Date': '2021-07-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.2'}\n{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '19.4', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}\nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '19.7', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '49', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '25.2'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.1'} {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '16.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '49', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '30.2'}\nentry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '17.0', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '51', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}entry = {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.9'}\nentry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '33', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}\nentry =  entry =  {'Date': '2018-06-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '45.0'}\n entry = entry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '11.8'}\nentry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}\nentry =  {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.4'}\nentry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.2'}\nentry =  entry =  {'Date': '2018-06-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '54.0'}\n {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.4'} \nentry =  \nentry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '17.4', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '54', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '28.8'}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '18.9', 'Change In Snow Water Equivalent (in)': '1.5', 'Snow Depth (in) Start of Day Values': '67', 'Change In Snow Depth (in)': '13', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}\nentry =  entry =  entry = entry =   {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '24.6'}\nentry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.6'}\n{'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2021-07-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '73.6'}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.1'} {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '38.5'}\nentry =  {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\nentry = \nentry =  entry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.2'}\nentry = {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '19.4', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '70', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '30.0'}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}\nentry =  {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '27.3'}\nentry =   {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.9'}\n {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '4.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '37.2'}\n{'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '19.6', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '71', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}\nentry =  entry = entry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '19.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}\nentry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '20.9', 'Change In Snow Water Equivalent (in)': '1.1', 'Snow Depth (in) Start of Day Values': '56', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '34.2'}entry =  {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\n{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '5.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-06-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '63.0'}\n{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '8.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '36.3'}\nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '8.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '33', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '35.2'}\n  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '41.4'}\nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}\nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '5.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}\nentry = {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '20.6', 'Change In Snow Water Equivalent (in)': '1.0', 'Snow Depth (in) Start of Day Values': '81', 'Change In Snow Depth (in)': '10', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}\nentry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '21.9', 'Change In Snow Water Equivalent (in)': '1.3', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}entry = entry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '9.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '33', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.1'}\n{'Date': '2021-07-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.9'}\nentry =  {'Date': '2021-07-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '67.6'}\n {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.3'}\nentry =  \nentry = entry = entry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.4'}\nentry =  entry =   {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '41.4'}\n {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}\nentry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '8.1'}\nentry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '18.0'}entry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '9.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}\nentry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''} {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-19.5'}\nentry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-3.3'}\nentry = {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.4'}\n{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.9'}\nentry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-06-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '53.2'}\n{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '9.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '31', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '35.2'}{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '4.6', 'Change In Snow Water Equivalent (in)': '0.8', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '9', 'Air Temperature Observed (degF) Start of Day Values': '25.3'}entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.2'}\nentry =  entry =  {'Date': '2021-07-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '65.8'}\n {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '1.9'}\nentry =  entry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =  entry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '6.2', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =  \nentry =  \n{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '38.8'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.9'}\nentry =  entry = \n{'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '6.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  entry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '20.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '55', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '36.3'}\nentry = {'Date': '2018-06-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '49.3'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '7.0'}\nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '6.6'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '9.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}\nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '31.3'} \nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '9.0'}\n{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '9.8', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '7', 'Air Temperature Observed (degF) Start of Day Values': '15.8'}entry = \nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '22.2', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '76', 'Change In Snow Depth (in)': '-6', 'Air Temperature Observed (degF) Start of Day Values': '36.5'}\nentry =  {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '22.8', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '74', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}{'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '4.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '17', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}\n {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '20.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '38.8'}\nentry =  {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '20.8', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '42.8'}\n{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '46.6'}\nentry =  entry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.7'}\nentry = entry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-06-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '49.3'}\nentry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '10.1', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.4'}\n entry = {'Date': '2021-07-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.7'}\nentry =  entry =  {'Date': '2018-06-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '45.9'}\nentry = {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}\nentry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '5.2'}\nentry =  entry =  {'Date': '2018-06-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '49.1'}\nentry =  {'Date': '2018-06-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '51.6'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '51.8'}  entry =  {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '20.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '51', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '35.6'}\n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '9.1'}\nentry = {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '5.0', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '24.4'}{'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.3'}\nentry =  entry =  \nentry =  \nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '3.9'}\nentry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '3.9'}entry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}\nentry =  {'Date': '2018-06-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '60.8'}\nentry =  \nentry =  entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '40.1'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '10.4'}{'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-06-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '55.0'}\nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '23.0'}\nentry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '18.9'}{'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '14.5'}{'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.8'}entry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '23.3', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '77', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}\nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '7.0', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '8.3', 'Change In Snow Water Equivalent (in)': '1.3', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '10', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '23.7', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '79', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}\nentry = entry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '16.3'}\n{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}\nentry =  \nentry =  {'Date': '2018-06-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '56.5'}\nentry =  entry =  {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '51.6'} \n{'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '24.7', 'Change In Snow Water Equivalent (in)': '1.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}\nentry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '24.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '38.8'}entry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '31.8'}\n{'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}\nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\nentry = \n{'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '5.3', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '17', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}\nentry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '5.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.5'}\nentry =   {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '0.5'}\nentry =  \nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '21.1', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '53', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}\nentry =  \nentry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '24.6', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '41.2'}\nentry = {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '5.0', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.0'}\nentry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '14.0'}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '32.4'}entry = \n{'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '14.0'}\nentry =  \nentry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.0'}\n {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}\nentry =   \nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}\nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '19.9'}\nentry =  entry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.0'}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}\nentry = {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '10.6', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '26.8'} {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '22.3', 'Change In Snow Water Equivalent (in)': '1.2', 'Snow Depth (in) Start of Day Values': '56', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}\nentry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}\n {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.5'}\n entry = {'Date': '2021-07-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.7'}\nentry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '42.6'}\nentry =  {'Date': '2018-06-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '50.5'}\nentry = entry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n entry =  {'Date': '2018-06-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '58.6'}\nentry =  entry =  entry = entry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '19.8'}\n {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '5.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '19.9'}\nentry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '24.3'}{'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''} \nentry =  {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '40.1'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '10.9', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}\nentry = {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '24.4', 'Change In Snow Water Equivalent (in)': '2.1', 'Snow Depth (in) Start of Day Values': '70', 'Change In Snow Depth (in)': '14', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry =  \nentry =  {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '43.0'}\nentry = {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}\nentry = entry =  entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '4.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.1'}\nentry = entry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '21.9'}entry =  {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\n {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-15.5'}\n {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '23.7', 'Change In Snow Water Equivalent (in)': '-0.9', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '37.0'}\nentry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '30.0'}entry = {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '5.6', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '23', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '25.7'}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.2'}\nentry =   {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   {'Date': '2018-06-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '61.3'}\n {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.7'}entry =   {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-16.6'}\nentry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '7.2'}\n entry = {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '4.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '21.9'}\nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '24.9', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '71', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '25.3'}\nentry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '26.5', 'Change In Snow Water Equivalent (in)': '1.6', 'Snow Depth (in) Start of Day Values': '74', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}\n{'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.2'} \nentry = {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '0.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}\nentry = entry =  entry =  {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-6.5'}\nentry =  {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-18.4'}\n {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '10.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '24.1'}\nentry =  {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '10.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.0'}entry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '27.8', 'Change In Snow Water Equivalent (in)': '1.3', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '8', 'Air Temperature Observed (degF) Start of Day Values': '27.3'}\n{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '19.8'}\nentry =  \nentry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '28.5', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '86', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '26.2'} entry =   {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '4.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}\nentry = {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '23.3', 'Change In Snow Water Equivalent (in)': '-0.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '10.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}\nentry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '11.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '39.0'}{'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.2'}\nentry =  {'Date': '2021-07-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '73.4'}\nentry =  {'Date': '2021-07-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.8'}\nentry =  {'Date': '2021-07-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.9'}\nentry =  {'Date': '2021-07-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '63.7'}\nentry =   entry =  {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}\n {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.0'}\nentry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '1.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '5.0'}\n{'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '23', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry =  {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  entry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '41.7'}\nentry =  entry =  entry = {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '23.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.1'}\nentry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\nentry =  {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '11.3', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}\nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '11.9', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '50', 'Change In Snow Depth (in)': '8', 'Air Temperature Observed (degF) Start of Day Values': '17.2'}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '-0.6', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '23.5'}\n {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry = {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.3'}\nentry =   {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '30.7'}{'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '40.6'}\n {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '23.1', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '39.2'}\nentry =  {'Date': '2018-06-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '55.8'}\nentry =  {'Date': '2018-06-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '65.8'}{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '36.3'}\nentry =  \nentry =  {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '34.2'}\nentry =  \nentry =  \n{'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '1.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '27.5'}\n{'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '22', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '37.4'}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '20', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '36.3'}\n{'Date': '2021-07-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.0'}{'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.1'}{'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '31.0', 'Change In Snow Water Equivalent (in)': '2.5', 'Snow Depth (in) Start of Day Values': '97', 'Change In Snow Depth (in)': '11', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}\nentry =  {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '31.7', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '98', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '24.4'}\nentry = {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry =  {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '22.9', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '30.0'}\nentry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '32.1', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '99', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '22.5'}\nentry =  entry = entry = {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '4.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.7'} {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.8'}\nentry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}\nentry =  entry =  {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '6.5', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '42.6'}\nentry =   {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '0.1', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.0'}\nentry =  {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.3'}{'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '12.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '50', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.3'}\n{'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '32.7', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '101', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry =  {'Date': '2021-07-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.5'}\nentry =  {'Date': '2021-07-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '71.6'}\nentry =  \nentry =  entry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '12.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '25.2'}entry =  {'Date': '2018-06-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '54.1'}\nentry = entry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '18', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}\nentry =   {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.1'}\n{'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '6.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '17', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '37.4'}{'Date': '2021-07-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '66.6'}\nentry =  \n {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''} entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.1'}\nentry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.2'}\nentry =  {'Date': '2021-07-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '67.6'}\nentry =  entry = \nentry =  {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2018-06-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '50.5'}\nentry = {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '3.2'}\nentry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '33.8', 'Change In Snow Water Equivalent (in)': '1.1', 'Snow Depth (in) Start of Day Values': '100', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}\nentry =   {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '12.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '17.1'}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '12.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '25.5'}\nentry =  {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '12.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}entry = \nentry =  {'Date': '2018-07-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '53.8'}\nentry =  {'Date': '2018-07-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '63.0'}entry = entry =  {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '22.6', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}{'Date': '2021-07-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '66.2'}\nentry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '16.5'}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '33.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '95', 'Change In Snow Depth (in)': '-5', 'Air Temperature Observed (degF) Start of Day Values': '37.0'}\n {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \n {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\n {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '4.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}\nentry =  {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '22.5', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}\n{'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '9.3'}\nentry = \nentry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\n{'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''} {'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '25.5'}entry =  entry =  {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.6'}\nentry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}\nentry =  {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '46.0'}entry =  \nentry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2021-07-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.8'}\n{'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '34.1', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '91', 'Change In Snow Depth (in)': '-4', 'Air Temperature Observed (degF) Start of Day Values': '26.1'}entry = \n {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '12.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '17.4'}\nentry =  {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '22.4', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '24.6'}\nentry =  entry =  {'Date': '2021-07-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '60.8'} \nentry = \nentry =  {'Date': '2018-07-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '53.4'}\nentry =  entry = entry =  \nentry =  \nentry =  entry = entry =  {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '6.6', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '38.1'}\nentry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '6.4', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '39.9'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.8'}\n{'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '4.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '18', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '31.3'} \nentry =  {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \nentry =  entry =  \n{'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}\nentry = {'Date': '2021-07-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.2'}\nentry =  {'Date': '2021-07-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '66.4'}{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '13.3'}\nentry =  {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '22.2', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.1'}\nentry =  {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '22.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}\nentry =   {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '34.9', 'Change In Snow Water Equivalent (in)': '0.8', 'Snow Depth (in) Start of Day Values': '97', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '23.5'}entry = {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''} {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '12.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.3'}\nentry =   {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '38.5'}\nentry =  entry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.5'}{'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '3.1', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}\nentry =  \n{'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '6.2', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '40.1'}\nentry =  \nentry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '22.7', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.3'}\nentry =  \n{'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '22.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\n{'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '3.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '30.2'} {'Date': '2018-07-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '48.9'}{'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '6.0', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '40.1'}\nentry = entry = {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '9.1'}\n{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.3'}entry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\nentry =  \nentry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '35.1', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '97', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\nentry =  {'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}\nentry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '12.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '23.5'}\n{'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.1'} {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '36.9'}\nentry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '34', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '7.0'}\nentry =  {'Date': '2018-07-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '65.1'}\nentry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '13.5'}\nentry =  \nentry =  {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '35.5', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '96', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}\nentry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '35.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '93', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '36.0'}entry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '3.0', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '-4', 'Air Temperature Observed (degF) Start of Day Values': '41.9'}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '2.5', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-4', 'Air Temperature Observed (degF) Start of Day Values': '51.4'}{'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '16.9'}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '14.5'}\nentry =  entry =  entry = entry =  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '34', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '19.0'}\nentry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '35.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '88', 'Change In Snow Depth (in)': '-5', 'Air Temperature Observed (degF) Start of Day Values': '39.2'}\nentry =  {'Date': '2018-07-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '67.3'}\nentry =  {'Date': '2018-07-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '59.5'}\nentry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}\nentry =  {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.5'}entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '34', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '-4.9'}\nentry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '33', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '19.9'}\n {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}\nentry =  {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.4'}\nentry =  {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.7'}\n{'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.6'}\nentry =  {'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '24.2', 'Change In Snow Water Equivalent (in)': '1.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.4'}entry = {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\nentry =  {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '35.3', 'Change In Snow Water Equivalent (in)': '-0.4', 'Snow Depth (in) Start of Day Values': '86', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '32.5'}\nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '35.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '85', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.2'}\nentry = \nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.9'}\nentry =  entry = entry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '33', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '6.6'}\nentry =  {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '38.8'}\nentry =  {'Date': '2021-07-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '72.0'}\nentry = {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '21.4'}\nentry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.6'}\nentry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}\nentry = entry = \nentry =  {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '41.7'}\nentry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}\nentry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.2'}\nentry = {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '22.6'}entry =  \nentry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '18', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.0'}\nentry =   {'Date': '2021-07-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '69.1'}\nentry =  {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '25.9', 'Change In Snow Water Equivalent (in)': '1.7', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry =  {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.0'}\nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}{'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''} {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '8.9', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '35', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}\nentry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '-0.4', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.0'}\n{'Date': '2021-07-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.7'}\nentry =   {'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '25.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '15.4'}\nentry =  \nentry =  {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}\nentry =  {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.0'}\nentry =  entry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '5.7', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '41.2'}\n {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '12.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.0'}\nentry =  {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '19.0'}\nentry =  \nentry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.2'}\n{'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '25.8', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '13.6'}\nentry =  {'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '25.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '12.6'}\n {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.4'}\n entry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '44.6'}entry =  {'Date': '2021-07-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.9'}\nentry =  {'Date': '2021-07-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.9'}\n{'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '8.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '8.8'}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '9.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '34', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}{'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.3'}\nentry =  {'Date': '2018-07-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '67.6'}\nentry =  {'Date': '2018-07-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '69.3'} {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '8.6', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.7'}\n {'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  \nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '9.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '34', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\nentry = {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '2.1', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '7', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry =  {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '30.4'}\nentry =  entry =  {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '9.2', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry = entry = \nentry =  {'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '12.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '-4', 'Air Temperature Observed (degF) Start of Day Values': '36.3'} {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '9.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '16.7'}\nentry = \nentry = entry =  entry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '37.9'}\nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '9.7', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '18', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '21.0'}{'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  entry =   {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}{'Date': '2018-07-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '74.3'}\nentry =  {'Date': '2018-07-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '60.1'}\nentry =  \nentry =  \nentry =  {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '0.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \nentry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '2.5'}\nentry =   {'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '25.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '18.0'}{'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}\n {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '9.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '17.6'}\nentry =  {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '15.8'}\nentry = entry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '9.6', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-07-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '62.1'}\n{'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '37.9'}\nentry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.6'}\n entry =  \nentry =  entry =  entry = {'Date': '2021-07-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '67.5'}\nentry = {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry = entry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry = {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '1.1', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '46.9'}{'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '12.9', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '46', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '16.2'}\nentry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '12.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '44', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '12.7'}\n  {'Date': '2021-07-31', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.9'}\n{'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.0'}\n {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '35.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '85', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.7'}\nentry = {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}\n {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '39.6'}\n{'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '9.8', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '20.5'}\nentry =   {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '41.2'}\nentry = entry =  {'Date': '2021-08-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.5'}\nentry =  {'Date': '2021-08-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.9'}\nentry =   {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.0'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '9.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '19.8'}{'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.6'}\nentry =   {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}\nentry =  {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.9'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '18', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\nentry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '5.2', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '20', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}\nentry =  \nentry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '-0.7', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '45.7'}\nentry =  {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}\nentry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '13.6', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}\nentry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '13.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '46', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '11.8'}\nentry =  \n{'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '1.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2021-08-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '60.8'}\n{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '5.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '22', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '13.1'}\nentry = \n{'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '1.2'}\nentry =  {'Date': '2018-07-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '64.6'}entry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}\nentry =   {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   \nentry =  {'Date': '2021-08-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '62.2'}\nentry =  {'Date': '2021-08-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '59.4'}entry =  {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '9.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '20.3'}\nentry = {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '16.2'}entry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '46.9'}\nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '0.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}\nentry =  entry = {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '23', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '27.5'}\nentry = {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2021-08-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '66.2'}\nentry =  {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}\nentry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '40.8'}\nentry =  {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '48.9'}entry = {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '9.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '22', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '22.6'}\nentry =  {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '21', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '24.6'}\nentry = {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.2'}\nentry =  {'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}\nentry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}{'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '35.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '83', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '38.7'}\nentry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '-0.4', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '48.2'}\nentry =  {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '46.8'}\nentry =  entry = \nentry =  \nentry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry = entry =  {'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '26.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '15.6'}\n {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =    {'Date': '2021-08-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '69.3'}\nentry = {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.9'}\nentry = entry =  \nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.3'}\nentry =  {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.4'}entry =  {'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '26.3', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}\nentry = entry =  {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\nentry =    {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '9.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '9.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '-7.6'}\nentry =  {'Date': '2018-07-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '71.4'}\nentry =  {'Date': '2018-07-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '67.6'}\nentry =  \n  {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '19.8'}\n{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '5.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '21', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}\nentry =  {'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '5.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '21', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}\nentry = \nentry =  \nentry =  {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}\nentry = {'Date': '2018-07-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '66.2'}\n {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.2'}\n {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '14.6', 'Change In Snow Water Equivalent (in)': '0.9', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}\nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '14.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '53', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '23.0'}\n{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '31.5'}\nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.7'}\nentry = entry = {'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '27.5', 'Change In Snow Water Equivalent (in)': '1.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.8'}\n{'Date': '2021-08-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '72.5'}\nentry =   {'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '6.1'}\nentry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '10.9', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': ''}\n {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.8'}\nentry =  {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '41.2'}\nentry = {'Date': '2021-08-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.7'}{'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '35.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.7'} {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '37.8'}\n {'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry = entry = entry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '9.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '4.8'}\nentry =  {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '9.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}\nentry =  {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}\nentry = {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '5.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '22', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}\nentry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '5.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '20', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\nentry =  \nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '9.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}\n{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.1'}\nentry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-0.9'}\nentry =  entry = {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =   {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n \nentry =  {'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '7.7'}\nentry =  {'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '2.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '13.3'}\nentry =  {'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '2.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '15.8'} {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-5.4'}\n {'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '28.9', 'Change In Snow Water Equivalent (in)': '1.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '23.0'}\nentry =  {'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '29.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '25.2'}\nentry =  {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '46.9'}\nentry =  {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '56.8'}\n {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '19.4'}\nentry = entry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '10.1', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '21.9'}\nentry = \n{'Date': '2018-07-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '66.2'}\nentry =  {'Date': '2021-08-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '75.7'}\nentry =  {'Date': '2021-08-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '72.0'}entry =  {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '11.2', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '12.4', 'Change In Snow Water Equivalent (in)': '1.2', 'Snow Depth (in) Start of Day Values': '58', 'Change In Snow Depth (in)': '10', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '15.1', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '55', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '20.5'}\nentry =  {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}{'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =  \nentry =  {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '16.0', 'Change In Snow Water Equivalent (in)': '0.9', 'Snow Depth (in) Start of Day Values': '58', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '32.0'}\nentry =  {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '16.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '60', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '20.7'}\nentry =  {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '10.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '6.3'}\nentry =  {'Date': '2018-07-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '67.8'}\nentry = entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.6'} {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.0'} entry =  {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}\nentry =   {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \nentry =   {'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '29.5', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}\nentry =  {'Date': '2018-03-01', 'Snow Water Equivalent (in) Start of Day Values': '29.9', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}\nentry = \n {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '17.8'}\nentry = {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '5.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '22', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}\nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '11.1'}\n{'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  entry = {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '16.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '61', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '9.9'}\nentry =  {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '20.7'}\n  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '12.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '58', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '12.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '56', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '12.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '55', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '12.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '54', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '25', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '12.6'}\nentry = {'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '7.3'} {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '13.8'}\nentry =  {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '-1.7'}\n{'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '13.3'}\nentry = entry =  {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '30.2'}\nentry =   {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '37.0'}\nentry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '3.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '3.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \nentry =  {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '23.2'}\nentry = {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}\nentry =  {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '36.0'}\n {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-3.5'}\n{'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '20.5'}\nentry =  {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '19.9'}\nentry =  {'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '11.3'}\nentry =  entry =   {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.6'}\nentry = {'Date': '2018-03-02', 'Snow Water Equivalent (in) Start of Day Values': '29.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}\nentry =  {'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n {'Date': '2018-07-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '67.5'}\nentry =  {'Date': '2018-07-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '66.9'}\nentry =  {'Date': '2018-07-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '68.9'}\nentry =  {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry =  {'Date': '2018-03-03', 'Snow Water Equivalent (in) Start of Day Values': '30.1', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.3'}\nentry =  entry =  entry =  {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '12.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '53', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\n {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '25', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.3'}\nentry =  {'Date': '2018-03-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-03-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2021-08-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '72.5'}\nentry =  {'Date': '2021-08-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '66.9'}\nentry =  entry =  {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.9'}entry =  {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.6'}\nentry =  entry =  {'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '6.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '13.1'}\nentry =   {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '5.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '25.9'}\n{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.5'}\nentry =  entry = entry =  {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-3.3'}\nentry =  \nentry =  {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '9.3'}\nentry =  {'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}\nentry =  {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '51.1'}\n{'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '6.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}\nentry = entry = \nentry =  {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-03-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n {'Date': '2021-08-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.0'}\nentry =  {'Date': '2021-08-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '65.7'}\n{'Date': '2018-03-04', 'Snow Water Equivalent (in) Start of Day Values': '30.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\nentry =  entry =  {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '6.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry =  {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '6.4', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '31', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '12.6'}{'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}\nentry =  entry =  {'Date': '2021-08-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '65.7'}\nentry = {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '3.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '3.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '24.8'}\n {'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '5.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.4'}\nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =    {'Date': '2021-08-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '61.5'}\nentry =  {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '53', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '35.2', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.5'}\nentry =  {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '35.1', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\nentry = \nentry =  {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '6.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '12.6'}\nentry = entry =  {'Date': '2018-03-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-03-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \n{'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}\nentry = {'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}\n {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '49', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.1'}\nentry = {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '17.2'}\nentry = entry = {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '48.2'}\nentry =  {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}\nentry =  entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.3'}\nentry =  entry =  {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '6.0', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.5'} {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-11.0'} {'Date': '2018-03-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.4'}\nentry = entry =  {'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '26.4'}\nentry = {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.6'}\nentry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.2'}\n{'Date': '2018-07-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '63.7'}{'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.0'}\n {'Date': '2020-09-19', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '46.0'}\nentry =    {'Date': '2021-08-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '65.5'}\nentry =  {'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '9.9'}\n{'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '38.8'}\n {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '35.3', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.4'}{'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '16.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '59', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '14.4'}\nentry =  entry =  {'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '1.3', 'Snow Depth (in) Start of Day Values': '25', 'Change In Snow Depth (in)': '11', 'Air Temperature Observed (degF) Start of Day Values': '16.0'}\nentry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '29', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}\n {'Date': '2020-09-20', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.9'}\n{'Date': '2018-03-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =   {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.6'}\nentry = entry =   {'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}\nentry =  {'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '11.1'}{'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry = {'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.3'}\nentry =  {'Date': '2018-03-05', 'Snow Water Equivalent (in) Start of Day Values': '30.6', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\nentry =  {'Date': '2018-03-06', 'Snow Water Equivalent (in) Start of Day Values': '30.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.7'}\n {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '23.7'}\nentry = entry =  {'Date': '2018-03-01', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.2'}entry = \nentry =  {'Date': '2018-07-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '66.4'}\nentry =  entry =  {'Date': '2020-09-21', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '43.9'}\n{'Date': '2021-08-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '69.4'}entry =  {'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-5.1'}\nentry = \nentry =  {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '35.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '80', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}entry = {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '16.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '58', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '-2.0'}\n {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \nentry = entry =  entry =  {'Date': '2018-03-07', 'Snow Water Equivalent (in) Start of Day Values': '30.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}entry =  {'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '0.7'}\nentry =  {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '16.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '58', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.0'}\nentry = {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '1.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =   {'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-2.6'}\n{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '3.6', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  \n \nentry =  {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  entry =  {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '29', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}\n{'Date': '2018-03-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry =  entry =   entry =  entry =  {'Date': '2018-03-02', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}\n {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '35.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '81', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}\nentry =   {'Date': '2018-07-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '72.0'}entry =  {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '25.2'}\n{'Date': '2020-09-22', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '51.4'}\nentry =  {'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-0.2'}{'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.4'}{'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '14.0'}\nentry =  {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.7'}\nentry =  entry =  {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '35.7', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '18.3'}\nentry =  \nentry =  entry =  {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.3'}\nentry =  {'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '25.5'}\n{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '3.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '5.4'}\nentry = {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}\nentry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.0'}\nentry =  entry =  {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2018-03-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2020-09-23', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '47.1'}\nentry =  \nentry =  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}\n {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '16.5', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '57', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}\nentry =  {'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '26.6'}\nentry =  {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '37.9'}\n{'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '25', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}\nentry =  {'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '31.5'} entry =  entry = entry = \nentry = entry =   {'Date': '2018-03-03', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '31.8'}{'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}\nentry = entry =   {'Date': '2018-03-04', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.8'}{'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.3'}\nentry = entry =   {'Date': '2018-03-05', 'Snow Water Equivalent (in) Start of Day Values': '3.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '11.5'}{'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.1'}\nentry =  entry = {'Date': '2018-03-06', 'Snow Water Equivalent (in) Start of Day Values': '3.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '17.6'} \n{'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '6.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}entry =  \nentry = entry = {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '35.6', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '81', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '25.7'} \n {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '6.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}{'Date': '2018-03-07', 'Snow Water Equivalent (in) Start of Day Values': '3.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.8'}entry = {'Date': '2021-08-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '71.6'}entry = \nentry = entry =  \n {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '14.5'} {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.9'}entry =  entry = \n {'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '35.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}{'Date': '2018-03-08', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '35.4'} entry = \n{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.1'} \nentry = {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '31', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '17.2'}{'Date': '2018-07-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '70.5'}{'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = {'Date': '2021-08-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.9'}entry = \n \nentry =  entry = \n entry = entry = {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}  entry = {'Date': '2018-07-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '69.6'}entry =  {'Date': '2018-03-09', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.2'}\n{'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '13.8'}entry =  {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''} {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\n {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '19.2'}\n{'Date': '2021-08-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '65.1'}entry = {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '37.3', 'Change In Snow Water Equivalent (in)': '1.5', 'Snow Depth (in) Start of Day Values': '93', 'Change In Snow Depth (in)': '11', 'Air Temperature Observed (degF) Start of Day Values': '19.2'}\nentry = entry = \nentry = entry = \n entry =  \nentry =   {'Date': '2018-07-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '68.7'} {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '14.7'} {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.8'}entry = {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '19.2'} {'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '38.0', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '102', 'Change In Snow Depth (in)': '9', 'Air Temperature Observed (degF) Start of Day Values': '7.9'}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '21.4'}\n{'Date': '2018-03-10', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}\nentry =  \n  entry =  entry = \n{'Date': '2018-07-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '67.8'}entry =  entry =  entry = entry =   \n \nentry = entry =   entry =   \n{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '29', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}{'Date': '2018-07-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '63.5'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = \nentry = \n {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =   {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}entry = \n{'Date': '2018-07-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '68.5'}\n entry = \nentry = {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '23.7'} entry = \n{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}  entry = \n{'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}\n{'Date': '2018-07-31', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '72.3'} entry = {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '7.0', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '31', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}\n entry = {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  \n  {'Date': '2018-08-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '70.5'}\n{'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '1.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '17.2'}entry = {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry = entry =  entry =   {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '21.6'}\n{'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '13.5'}entry =  {'Date': '2018-03-08', 'Snow Water Equivalent (in) Start of Day Values': '30.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}\nentry = entry = {'Date': '2020-08-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '74.8'} {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '17.8'}\n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.5'}\n{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '7.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '31', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.1'}entry = \nentry =   entry = entry =  \n entry = {'Date': '2018-03-09', 'Snow Water Equivalent (in) Start of Day Values': '31.3', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}{'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '1.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '23.9'} \n \n{'Date': '2020-08-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '58.6'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '19.9'} \nentry = {'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = {'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '7.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '11.8'}{'Date': '2021-08-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.4'}entry = {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '7.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '30.7'}entry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}\nentry = {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '19.6'} entry =  entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '40.5'} \nentry = entry =  \n{'Date': '2018-03-10', 'Snow Water Equivalent (in) Start of Day Values': '31.5', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.5'}entry = \nentry = entry = {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.4'}{'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '1.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '15.4'}entry = {'Date': '2018-03-11', 'Snow Water Equivalent (in) Start of Day Values': '2.7', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.6'} {'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '38.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '99', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '12.6'} entry = {'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '23.5'}entry = \n{'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry = entry = entry =   {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '10.5', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '20.8'}\n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '54.1'}\n    {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '6.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.0'}\n{'Date': '2021-08-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.5'}entry = entry = entry = \n {'Date': '2020-08-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '67.8'}{'Date': '2018-08-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '71.6'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '7.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '31', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}     entry = entry = \n \n{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '13.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '52', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '19.4'}\n{'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = \n{'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '38.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '99', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '11.1'}{'Date': '2018-03-12', 'Snow Water Equivalent (in) Start of Day Values': '2.6', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.0'}\nentry = {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.1'} entry = \n  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}entry = entry =  \n {'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '1.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '14.4'}entry = {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.0'} \n{'Date': '2020-08-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '51.1'}entry = entry = {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '13.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '51', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.4'} entry = \n  entry = {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry =  {'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '1.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '14.4'} \n{'Date': '2020-08-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '57.6'} {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '34', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '12.9'}\n {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '14.5'}{'Date': '2021-08-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '71.2'}entry =  entry =  \nentry =  \nentry = \n{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '20.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '78', 'Change In Snow Depth (in)': '-5', 'Air Temperature Observed (degF) Start of Day Values': '15.4'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '38.3'}entry = {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  entry = entry = {'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '1.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.7'}entry =  entry =   \n entry =  \n{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.9'}  entry = entry =  entry = \n   entry =  entry = {'Date': '2021-08-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.0'}{'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '12.4'}entry = {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.6'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.9'}entry = entry =  {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '10.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '12.4'}\n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '17.4'}{'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '16.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '61', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '16.9'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}  \n{'Date': '2018-03-11', 'Snow Water Equivalent (in) Start of Day Values': '31.4', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '32.2'}{'Date': '2018-08-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '63.7'}entry = \n  entry = entry = \nentry = entry = entry = \n entry = entry = {'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-1.1'} {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.6'}  entry = \n entry =  {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '16.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '60', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '10.6'}{'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.5'} entry = {'Date': '2018-08-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '59.7'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.4'}\n {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '31.5'}\nentry =   {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.7'} {'Date': '2020-09-24', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '54.1'}\n \n{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.2'}\nentry = \nentry = entry = \n entry =  entry = entry =  entry = entry = entry =   entry =     \nentry =   {'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '16.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '55', 'Change In Snow Depth (in)': '-5', 'Air Temperature Observed (degF) Start of Day Values': '15.8'}{'Date': '2020-09-25', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.1'}{'Date': '2018-08-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '58.3'}{'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}{'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '18.9'} {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.1'}{'Date': '2021-08-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '67.8'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '20.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '75', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '14.0'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.5'}{'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '7.1', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '23', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.6'} {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '34.5'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}\n{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '43.7'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '13.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '50', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.4'} {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '22.5'}\n{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '56.5'}\nentry = \nentry = {'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '14.7'}entry = \n entry = entry = entry = {'Date': '2021-08-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '71.4'}entry = \n entry =   entry = \nentry = \nentry = \n entry = entry =   {'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '7.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '23', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.5'}  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.6'}{'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '17.6', 'Change In Snow Water Equivalent (in)': '1.0', 'Snow Depth (in) Start of Day Values': '61', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '23.0'}entry = \n{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '20.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '74', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '25.5'} entry = {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '53.4'}entry =  entry = \n {'Date': '2020-09-26', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}entry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.8'}\n{'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.4'}\nentry = \n \n   entry = \nentry = entry = \n  entry =   entry = \nentry =  entry =    entry = entry =  entry =    {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '1.1', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '14.0'}{'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '17.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '67', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '-10.1'}{'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '48.4'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}{'Date': '2021-08-29', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '69.6'}{'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '7.4', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '10.0'}{'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2020-08-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '65.5'}{'Date': '2018-08-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '59.5'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.7'}{'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '10.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '20.8'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '36.9'}{'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-6.2'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '38.3'}entry = {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '34', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.3'}{'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}{'Date': '2018-03-12', 'Snow Water Equivalent (in) Start of Day Values': '31.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '37.6'}\nentry = \nentry = \n \nentry = \n \nentry = entry = \n  entry = {'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '13.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = {'Date': '2018-03-13', 'Snow Water Equivalent (in) Start of Day Values': '2.5', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.0'} entry = \n entry = {'Date': '2020-08-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '72.1'}entry = {'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}  entry = \n{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}entry = {'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''} \n{'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '4.4', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = \nentry = entry = entry =  entry = entry = \n  {'Date': '2018-08-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '63.1'}{'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '12.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry =   {'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '1.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '10.2'}{'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '10.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.7'}entry = \n entry =  \n {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '8.1', 'Change In Snow Water Equivalent (in)': '0.8', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '15.4'}{'Date': '2021-08-30', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.0'}\n entry =  \nentry =  entry =  \n entry =   entry = \nentry = entry = entry = \nentry =  entry =     entry =      entry =  entry =  {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '11.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '10.8'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.9'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '8.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '18.1'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '13.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '50', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}{'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '7.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '20.3'}{'Date': '2020-08-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '65.7'}{'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '38.3', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '99', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.1'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}{'Date': '2018-03-14', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.4'} {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}{'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '1.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '20.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '72', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '23.4'}{'Date': '2020-09-27', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.4'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.4'}{'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '48.2'}\nentry = \nentry =  entry =  \n{'Date': '2018-03-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2020-08-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '58.3'}\n{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '43.3'}entry = \nentry = entry = entry = \n \nentry = {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.6'}\n  \nentry =  entry = entry = entry = entry = entry =   \nentry = entry = entry = entry = {'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '38.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '99', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '7.2'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.6'}entry = \n  {'Date': '2020-09-28', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}  {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '11.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '46', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '6.1'}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '35.1'}\n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}entry =     {'Date': '2018-03-01', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.9'}entry = {'Date': '2020-08-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '60.3'}entry = \n  entry =  entry = {'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '1.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.4'}\n \n entry = entry = entry =  \nentry =  entry = \n \n entry =   entry = entry = entry =       entry =  {'Date': '2018-03-02', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.1'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '7.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '-4', 'Air Temperature Observed (degF) Start of Day Values': '13.1'}{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '8.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}{'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '8.4'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.1'}{'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '20.5'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '13.3'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}{'Date': '2020-09-29', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '43.9'}{'Date': '2018-03-15', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.4'}{'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '13.1', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '50', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-08-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '66.7'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.7'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '3.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}{'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '38.8', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '98', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.7'}\n{'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '0.1', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry =  \n{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.9'}\nentry = \nentry = entry = \n  entry =  entry = \nentry = entry = entry = {'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '39.4', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '100', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '24.8'} entry = entry = entry =  entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '14.9'}{'Date': '2018-03-03', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}\nentry = \n{'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '13.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '49', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  \nentry =   {'Date': '2018-03-16', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '20.7'}  \n{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '2.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '30.0'}\n{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.8'} entry = entry = {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}  \n{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '3.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '40.1'}entry = \n{'Date': '2018-08-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '70.5'}\n   entry = \n{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '0.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.2'} entry = \nentry = \n entry = \n entry =  entry = entry =   \nentry =   entry =     {'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '40.7', 'Change In Snow Water Equivalent (in)': '1.3', 'Snow Depth (in) Start of Day Values': '105', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '16.3'}{'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '0.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '38.3'}{'Date': '2018-03-13', 'Snow Water Equivalent (in) Start of Day Values': '31.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '41.4'}{'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '10.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}{'Date': '2018-08-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '73.2'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '2.7', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '26.8'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '6.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.7'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.7', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}{'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '17.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '64', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '-17.7'}{'Date': '2018-03-04', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '-0.4', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.3'}{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}{'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '13.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '50', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '20.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '70', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '35.6'}{'Date': '2018-03-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-03-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '21.9'}\nentry = \nentry = \nentry = entry =  \n \nentry =  entry = entry = \n entry = entry = \nentry = entry = {'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '0.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '1', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.2'} \nentry =  {'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '17.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '62', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '1.2'}entry = {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '17.4'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '20.5', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '69', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}\n{'Date': '2018-03-14', 'Snow Water Equivalent (in) Start of Day Values': '32.0', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.4'} entry =  \n {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '17.2'} entry =  entry = \n   \n {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '2.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}entry = \n  {'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '13.5', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '55', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '16.0'}{'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '10.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.7'}entry = \n{'Date': '2018-08-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '76.6'}entry = entry = entry = {'Date': '2018-03-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''} entry = {'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '40.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '105', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.1'}entry = \n \nentry =  entry =   \n entry = entry =  \nentry = entry = entry =       {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '62.6'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '21.6'}{'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '-8.7'}{'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}{'Date': '2018-03-15', 'Snow Water Equivalent (in) Start of Day Values': '32.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}{'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '5.0', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-03-17', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}{'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '8.3', 'Change In Snow Water Equivalent (in)': '0.8', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}{'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '14.2'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.3'}{'Date': '2018-08-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '73.9'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '3.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.7'}{'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '17.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '62', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '8.4'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '30.4'}\nentry = \nentry = entry = \n \nentry = entry = entry = \n entry = entry = \n  entry =  entry = entry = entry =   \n \n{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '3.0', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '29.3'} {'Date': '2018-03-16', 'Snow Water Equivalent (in) Start of Day Values': '31.7', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}entry = \n {'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '6.6', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '12.6'} {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '26.6'}{'Date': '2018-03-18', 'Snow Water Equivalent (in) Start of Day Values': '2.1', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}entry = {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.9'}{'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '9.9', 'Change In Snow Water Equivalent (in)': '1.6', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '11', 'Air Temperature Observed (degF) Start of Day Values': '25.5'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '2.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}entry =  \n{'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '5.9'}entry = \n{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '3.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '37.0'}\n entry =  \nentry = {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '3.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.1'} \nentry = \nentry = \n{'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '5.4', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = entry = \n   entry = {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '55.9'}entry =      \nentry = \n entry =  entry = \n  entry = entry =   entry =  entry =  {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '11.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '46', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '17.8'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '3.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.0'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '6.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '35', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '11.7'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}{'Date': '2020-08-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '61.0'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '17.6'}{'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '10.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '14.7'}{'Date': '2018-03-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}{'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '6.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}{'Date': '2020-09-30', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '47.1'}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '17', 'Change In Snow Depth (in)': '8', 'Air Temperature Observed (degF) Start of Day Values': '14.9'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '3.0', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}{'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '17.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '62', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '6.8'}{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '8.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '2.8'}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '6.1', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '24.3'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '20.9', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '69', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}\nentry = \nentry = \nentry = entry = entry =  entry = \nentry =  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '3.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}  entry = \n{'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '17.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '61', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '7.5'} {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '10.2'}entry = entry = entry = \nentry = entry = \n{'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '8.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.8'} \nentry = {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}entry =  entry = \nentry = entry = entry = {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '11.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '44', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '17.2'}entry =  entry =  \n entry =   {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '3.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.1'} {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '8.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '35', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '19.6'}{'Date': '2020-10-01', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '40.6'} {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '3.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '24.1'} \nentry = entry = {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '20.8', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '68', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}\n  \n{'Date': '2018-03-03', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.5'} entry = entry =    \n entry =   entry = entry =    \nentry =  entry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '20.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '67', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.9'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '3.2', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}{'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '5.8', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '10.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.2'}{'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}{'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '17.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '64', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '11.3'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '6.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '10.9'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '17.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '62', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '10.0'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '20', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}{'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '10.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}{'Date': '2018-03-05', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '-0.8', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '15.1'}{'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '7.0', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.6'}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '18', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '18.1'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '59.0'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '20.5'}\nentry = \nentry = entry = \nentry = entry =  \nentry = entry = \nentry = entry =  entry = \n  {'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '17.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '59', 'Change In Snow Depth (in)': '-5', 'Air Temperature Observed (degF) Start of Day Values': '18.0'}entry = {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '3.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}{'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '11.1', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}entry = {'Date': '2018-03-01', 'Snow Water Equivalent (in) Start of Day Values': '10.7', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '27.5'} \nentry =  \n   entry = {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '6.8'}\n \nentry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '1.8', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '36.0'}\n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.7'}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.6'}entry = {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '54.1'} \nentry =   {'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '17.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '60', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '7.3'}entry = entry = \n \n entry = entry = \n {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '22.0', 'Change In Snow Water Equivalent (in)': '1.2', 'Snow Depth (in) Start of Day Values': '68', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '31.5'} entry = \n{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '7.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '18.1'}   \n \nentry =  \nentry = entry =  \nentry = entry = entry = \n  entry =   entry =   {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '20', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '44.6'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '11.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '44', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.5'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '7.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}{'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '13.7', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '54', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '39.0'}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '21', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '24.1'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.8'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '4.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '18', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.7'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '25', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '24.6'}{'Date': '2018-02-13', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '6.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.3'}{'Date': '2020-08-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '67.8'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '3.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.4'}{'Date': '2018-03-19', 'Snow Water Equivalent (in) Start of Day Values': '2.5', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '16.2'}\nentry = \nentry = entry =  \nentry =  \n \n{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '7.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}\nentry = entry = \n \n{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.3'} \nentry = {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '21', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '13.3'}entry =   {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '38.5'}\n {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '10.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.8'}\nentry = entry = entry =  {'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '19.2'} entry = entry = \n{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '17', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '20.5'}entry = entry = {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '3.7', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.2'}entry = \n entry =  entry = {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.0'}entry = {'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.5'} \n {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.7'} entry = entry =  \n {'Date': '2018-02-14', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''} \n{'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '8.6'}  \nentry = entry = entry = entry =   entry =  \nentry =  \n   entry = entry =  entry =    {'Date': '2018-03-02', 'Snow Water Equivalent (in) Start of Day Values': '11.2', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '46', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '19.6'}{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.0'}{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '8.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '34', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}{'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '11.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}{'Date': '2018-02-15', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '6.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-03-20', 'Snow Water Equivalent (in) Start of Day Values': '2.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.7'}{'Date': '2018-03-17', 'Snow Water Equivalent (in) Start of Day Values': '31.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '32.2'}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '49.5'}{'Date': '2018-03-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '7.9'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '37.4'}{'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '13.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '54', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-03-04', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.8'}\n{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '17.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '59', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '16.3'}{'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry =  entry = \n \nentry = \n{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '45.5'} \nentry = entry = entry = \nentry = entry =  \n{'Date': '2018-02-16', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry =  \n{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}\n{'Date': '2018-03-05', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.1'} {'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.4'}entry = \nentry =  entry = entry = entry =  {'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '8.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}\nentry = entry = entry =  {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '12.9'}entry = entry = \n     entry = {'Date': '2018-03-03', 'Snow Water Equivalent (in) Start of Day Values': '11.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '21.4'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '17.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '58', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '22.3'}{'Date': '2018-03-18', 'Snow Water Equivalent (in) Start of Day Values': '31.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '31.5'}\n {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '4.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}\nentry = entry =  entry =     entry = {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '6.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-03-06', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '14.7'}  \n entry =    \nentry = \n entry = entry =  \nentry = entry =    entry =  {'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '25', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.3'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '17.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '58', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.0'}{'Date': '2018-03-19', 'Snow Water Equivalent (in) Start of Day Values': '31.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}{'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '11.5', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}{'Date': '2020-10-02', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '50.4'}{'Date': '2018-03-06', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.2'}{'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '18.0'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '6.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '23', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '26.1'}{'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-4', 'Air Temperature Observed (degF) Start of Day Values': '10.9'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.6'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '10.6', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '24.4'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '4.1', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}{'Date': '2018-03-04', 'Snow Water Equivalent (in) Start of Day Values': '11.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '44', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '21.0'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '1.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.1'}\nentry = entry = \nentry = \n \n \n{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '25.7'}entry = \n \n entry = {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '0.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}entry = entry = {'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '6.1', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = \n \n entry = entry =  entry = \n {'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '13.3'}   {'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '11.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '44', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '24.1'}\n{'Date': '2018-03-05', 'Snow Water Equivalent (in) Start of Day Values': '11.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '4.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.9'}entry = entry = {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '20.3'}\n  \nentry = entry = \nentry = entry =  entry = \nentry = \n{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '17.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '57', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}entry = \n{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.6'} \n {'Date': '2018-03-07', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.8'}entry =  entry = entry =  entry =  \n{'Date': '2018-03-20', 'Snow Water Equivalent (in) Start of Day Values': '31.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '30.0'}    \nentry = entry = entry =   entry =   entry =   {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '22.4', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '74', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '23.4'}{'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '1.1', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.7'}{'Date': '2018-03-21', 'Snow Water Equivalent (in) Start of Day Values': '31.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '32.5'}{'Date': '2018-03-08', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}{'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '12.1', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '49', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '13.3'}{'Date': '2021-08-31', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '70.7'}{'Date': '2018-03-06', 'Snow Water Equivalent (in) Start of Day Values': '11.5', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '24.1'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '17.7', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '62', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '23.5'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '22', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.2'}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '20', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '7.9'}{'Date': '2018-03-07', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '19.2'}{'Date': '2020-10-03', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '42.3'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '3.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}{'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '41.0', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '104', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.4'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.0'}{'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry = \n entry =  entry = {'Date': '2018-03-22', 'Snow Water Equivalent (in) Start of Day Values': '32.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.6'} \nentry = \nentry = \n   {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.9', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '19.8'}\n{'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '17.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '61', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '19.0'}entry = entry = \nentry =  entry = entry = entry = {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.9'}\n entry = \n entry = {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '17.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '60', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.7'}entry =  {'Date': '2018-03-09', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '23.7', 'Change In Snow Water Equivalent (in)': '1.3', 'Snow Depth (in) Start of Day Values': '82', 'Change In Snow Depth (in)': '8', 'Air Temperature Observed (degF) Start of Day Values': '31.1'}  \nentry = {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '3.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}\n{'Date': '2018-03-23', 'Snow Water Equivalent (in) Start of Day Values': '32.3', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '26.1'}entry =  entry = {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '20', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '12.6'}  entry = \n \nentry = entry = entry = entry = {'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '19.6'} entry = entry = {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '24.2', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '83', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '30.7'} \n entry =     entry = entry = \n  entry =    \n entry =  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '4.4', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '31.5'}{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}{'Date': '2018-03-24', 'Snow Water Equivalent (in) Start of Day Values': '32.1', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.4'}{'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '16.3'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}{'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '17.8'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '3.0', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.1'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}{'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '12.2', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '19.9'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '45.7'}{'Date': '2018-03-08', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '48.6'}{'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '1.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '5.9', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '39.6'}\nentry = \nentry = entry =  entry = entry = \n \nentry = entry = \n   {'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.7'} \n{'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '8.8'}{'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '5.7', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-03-09', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '32.4'}\nentry = entry = entry = entry =  {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}\n \n \nentry = entry = entry = {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '43.3'}  {'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}\n{'Date': '2018-02-08', 'Snow Water Equivalent (in) Start of Day Values': '12.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '47', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.8'}entry = entry = \nentry =  entry =   entry =   {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '59.7'}entry =  {'Date': '2018-01-29', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}\n{'Date': '2018-03-10', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}\n{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '41.5'}entry = \nentry = \n{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '4.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '21.4'} entry = entry = \n  entry =   entry =   entry =   \n entry =  entry =  {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '25', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.4'}{'Date': '2018-02-18', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}{'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '5.6', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '7', 'Air Temperature Observed (degF) Start of Day Values': '22.5'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}{'Date': '2018-03-01', 'Snow Water Equivalent (in) Start of Day Values': '41.6', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '105', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '26.8'}{'Date': '2018-03-25', 'Snow Water Equivalent (in) Start of Day Values': '32.4', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '11.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '44', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.9'}{'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.1'}{'Date': '2018-01-21', 'Snow Water Equivalent (in) Start of Day Values': '8.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}{'Date': '2018-02-20', 'Snow Water Equivalent (in) Start of Day Values': '6.6', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '1.4'}{'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '19', 'Change In Snow Depth (in)': '8', 'Air Temperature Observed (degF) Start of Day Values': '17.4'}{'Date': '2018-03-11', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '30.7'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '10.5', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '2', 'Air Temperature Observed (degF) Start of Day Values': '22.1'}\n{'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '1.9', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry = entry = entry =  entry =  \nentry =  \n{'Date': '2018-01-22', 'Snow Water Equivalent (in) Start of Day Values': '8.5', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '40', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '4.8'}entry =  \nentry =  \nentry = \nentry =  entry = {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '28.6'}entry =  {'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '6.5', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '29', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '-0.9'} entry = \n {'Date': '2018-03-02', 'Snow Water Equivalent (in) Start of Day Values': '41.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '105', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.5'}\nentry = {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '11.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '19.0'}  {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '10.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '41', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '29.5'}\nentry =  {'Date': '2018-03-26', 'Snow Water Equivalent (in) Start of Day Values': '32.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}entry = {'Date': '2018-02-03', 'Snow Water Equivalent (in) Start of Day Values': '4.8', 'Change In Snow Water Equivalent (in)': '-0.8', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n  entry = entry = {'Date': '2018-02-19', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}  \n{'Date': '2018-01-23', 'Snow Water Equivalent (in) Start of Day Values': '8.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '8.2'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '11.1', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '42', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '31.3'}entry = \nentry = {'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '2.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = entry = {'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '9.7'}entry =  entry = entry =   \n  \n \n entry = entry =   \n  entry = entry =   entry =  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '7', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.2'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}{'Date': '2018-03-27', 'Snow Water Equivalent (in) Start of Day Values': '33.2', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '29.3'}{'Date': '2021-09-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '72.1'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '13.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '49', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '35.1'}{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.2'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '57.6'}{'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '17.6'}{'Date': '2018-03-10', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}{'Date': '2018-02-21', 'Snow Water Equivalent (in) Start of Day Values': '13.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '55', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2020-08-19', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '68.0'}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.1'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.4'}\n{'Date': '2018-03-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '37.6'}{'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '20.3'}\nentry = \n{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '20.1'}\nentry = \nentry = entry = \nentry =    entry = entry = {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '13.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '49', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.3'}\n entry = \nentry = \nentry =   {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '3.2', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '35.1'}\n{'Date': '2018-01-19', 'Snow Water Equivalent (in) Start of Day Values': '4.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '40.6'}entry = entry =   \n  {'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.7'}{'Date': '2018-01-06', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '3', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.1'}entry =  entry =  \n{'Date': '2018-01-20', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}\nentry = entry = entry =  entry =  {'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '24.8'} entry = {'Date': '2020-08-20', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '77.4'}\n{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '3.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.9'} \n{'Date': '2018-03-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '30.6'}entry = {'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '13.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '56', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.1'} \n \n \n{'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.1'}entry = entry =   \nentry = entry = entry =   \n entry =  entry = entry = \n entry = entry =     {'Date': '2018-03-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-01', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '22.5'}{'Date': '2018-08-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '60.6'}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '11.4', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '46', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '14.5'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}{'Date': '2020-10-04', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '43.0'}{'Date': '2018-03-07', 'Snow Water Equivalent (in) Start of Day Values': '11.4', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '32.9'}{'Date': '2018-03-28', 'Snow Water Equivalent (in) Start of Day Values': '33.7', 'Change In Snow Water Equivalent (in)': '0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '33.1'}{'Date': '2018-03-11', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.3'}{'Date': '2020-08-21', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '71.1'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '6.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '27', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.3'}{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '52.5'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.6'}{'Date': '2018-03-03', 'Snow Water Equivalent (in) Start of Day Values': '42.0', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '104', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.2'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '16', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.8'}{'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '13.8'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '23', 'Change In Snow Depth (in)': '7', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}\nentry = \nentry = \nentry = \n \nentry = entry = \n entry = entry = {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '22', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '24.6'}{'Date': '2018-03-29', 'Snow Water Equivalent (in) Start of Day Values': '33.2', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '32.7'}entry =  \n{'Date': '2020-08-22', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '64.0'}entry = \n entry =  \nentry =  \n  {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '6.5', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '32', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '12.9'}entry = \n{'Date': '2018-03-01', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '23.4'}entry = \n entry = entry =  {'Date': '2018-08-14', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '63.3'} {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '29.1'}\n{'Date': '2018-03-04', 'Snow Water Equivalent (in) Start of Day Values': '42.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '102', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '23.9'} {'Date': '2018-03-08', 'Snow Water Equivalent (in) Start of Day Values': '11.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.3'} entry = entry =  \n{'Date': '2018-01-02', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.0'} \n{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '12.3', 'Change In Snow Water Equivalent (in)': '0.9', 'Snow Depth (in) Start of Day Values': '55', 'Change In Snow Depth (in)': '9', 'Air Temperature Observed (degF) Start of Day Values': '25.7'}\n{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '56.3'}\nentry = \nentry =   entry =  \n{'Date': '2018-03-12', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.0'}entry = entry = entry = \nentry =  entry =   entry =   \n  \nentry = \n entry =  entry =  entry =   {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '25.7'}{'Date': '2018-01-30', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '41.0'}{'Date': '2018-03-30', 'Snow Water Equivalent (in) Start of Day Values': '33.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.6'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '11.5', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '43', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.9'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '6.6', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '31', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '17.6'}{'Date': '2018-01-03', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '18.0'}{'Date': '2018-03-21', 'Snow Water Equivalent (in) Start of Day Values': '2.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '8', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '37.0'}{'Date': '2018-08-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '66.0'}{'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '24', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '26.2'}{'Date': '2018-03-02', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '32.4'}{'Date': '2018-02-09', 'Snow Water Equivalent (in) Start of Day Values': '12.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '45', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '31.6'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '3.4', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '9', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '41.0'}{'Date': '2018-01-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '55.2'}{'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '13.2', 'Change In Snow Water Equivalent (in)': '0.9', 'Snow Depth (in) Start of Day Values': '59', 'Change In Snow Depth (in)': '4', 'Air Temperature Observed (degF) Start of Day Values': '23.4'}{'Date': '2018-03-05', 'Snow Water Equivalent (in) Start of Day Values': '42.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '103', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '22.6'}\nentry = entry = entry = entry = entry = \n \nentry = entry =  entry = \nentry =  \n \n  \nentry = {'Date': '2018-01-31', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '39.7'}\n{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '2.6', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '1', 'Air Temperature Observed (degF) Start of Day Values': '33.3'}{'Date': '2018-02-26', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}entry = \n \n  entry = entry =  entry = \nentry =   {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '2.9', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '38.1'}{'Date': '2018-03-06', 'Snow Water Equivalent (in) Start of Day Values': '42.0', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '101', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}entry = {'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '4.9', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '23', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '30.4'}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '7.2', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '5', 'Air Temperature Observed (degF) Start of Day Values': '17.6'}\n {'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '13.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '57', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '21.2'}{'Date': '2018-03-22', 'Snow Water Equivalent (in) Start of Day Values': '2.2', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '38.7'}entry =  {'Date': '2018-01-04', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '25.7'}\n{'Date': '2018-01-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '53.8'}\nentry = \n{'Date': '2018-03-31', 'Snow Water Equivalent (in) Start of Day Values': '33.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '35.4'} \nentry =  {'Date': '2018-08-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '66.4'}\nentry = entry = \nentry =   entry = \nentry =  entry =  entry =      \nentry = entry =  entry =    {'Date': '2018-02-01', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '37.9'}{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '35', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '20.8'}{'Date': '2018-03-23', 'Snow Water Equivalent (in) Start of Day Values': '1.7', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '4', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '37.0'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '1.0', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '6', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.3'}{'Date': '2018-01-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '27.9'}{'Date': '2018-01-24', 'Snow Water Equivalent (in) Start of Day Values': '8.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '38', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '9.3'}{'Date': '2018-02-04', 'Snow Water Equivalent (in) Start of Day Values': '4.3', 'Change In Snow Water Equivalent (in)': '-0.5', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '4.4', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '25.0'}{'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '14.2', 'Change In Snow Water Equivalent (in)': '0.3', 'Snow Depth (in) Start of Day Values': '59', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-10', 'Snow Water Equivalent (in) Start of Day Values': '12.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '48', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '23.9'}{'Date': '2018-04-01', 'Snow Water Equivalent (in) Start of Day Values': '33.0', 'Change In Snow Water Equivalent (in)': '-0.3', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': '34.5'}{'Date': '2018-01-07', 'Snow Water Equivalent (in) Start of Day Values': '6.6', 'Change In Snow Water Equivalent (in)': '0.7', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '27.3'}{'Date': '2018-01-05', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '30.4'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.2'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '26', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '34.2'}{'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '41.7'}{'Date': '2018-03-15', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry = \n entry = \nentry =  entry = {'Date': '2018-01-08', 'Snow Water Equivalent (in) Start of Day Values': '6.8', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '21.2'}\n{'Date': '2018-03-16', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry = entry = entry =  entry =  \n  \n \nentry =  {'Date': '2018-02-11', 'Snow Water Equivalent (in) Start of Day Values': '12.6', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '54', 'Change In Snow Depth (in)': '6', 'Air Temperature Observed (degF) Start of Day Values': '-4.5'}entry = \n{'Date': '2018-01-25', 'Snow Water Equivalent (in) Start of Day Values': '8.7', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '37', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.4'}\n   entry = {'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '6.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '27.5'}{'Date': '2018-01-09', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '15', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.4'}entry = entry =  \nentry = \n{'Date': '2018-02-02', 'Snow Water Equivalent (in) Start of Day Values': '1.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '5', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '36.0'}\nentry = entry = entry = {'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '7.3', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '33', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '23.2'}{'Date': '2018-03-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}  {'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '7.0', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '30', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '32.7'} entry = \n   entry = {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '0.4', 'Snow Depth (in) Start of Day Values': '13', 'Change In Snow Depth (in)': '7', 'Air Temperature Observed (degF) Start of Day Values': '16.0'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '5.5', 'Change In Snow Water Equivalent (in)': '1.1', 'Snow Depth (in) Start of Day Values': '25', 'Change In Snow Depth (in)': '11', 'Air Temperature Observed (degF) Start of Day Values': '28.0'} \n {'Date': '2018-02-12', 'Snow Water Equivalent (in) Start of Day Values': '12.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '51', 'Change In Snow Depth (in)': '-3', 'Air Temperature Observed (degF) Start of Day Values': '5.7'}\nentry =  entry = \n entry = \n entry = entry =   \nentry = \nentry = entry =   entry =    {'Date': '2018-02-27', 'Snow Water Equivalent (in) Start of Day Values': '2.3', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '17.9', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '59', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '31.1'}{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '3.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '20', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '16.2'}{'Date': '2018-02-22', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '29', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '7.5'}{'Date': '2018-01-10', 'Snow Water Equivalent (in) Start of Day Values': '4.0', 'Change In Snow Water Equivalent (in)': '0.2', 'Snow Depth (in) Start of Day Values': '14', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '34.2'}{'Date': '2018-02-24', 'Snow Water Equivalent (in) Start of Day Values': '14.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '58', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-15', 'Snow Water Equivalent (in) Start of Day Values': '13.2', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '55', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '22.3'}{'Date': '2018-03-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-02-05', 'Snow Water Equivalent (in) Start of Day Values': '4.1', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}{'Date': '2018-01-26', 'Snow Water Equivalent (in) Start of Day Values': '8.8', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '36', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '21.6'}{'Date': '2018-03-13', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '28.0'}{'Date': '2018-01-12', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '11', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '13.8'}{'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '10.9'}{'Date': '2020-10-05', 'Snow Water Equivalent (in) Start of Day Values': '0.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '43.2'}{'Date': '2018-02-17', 'Snow Water Equivalent (in) Start of Day Values': '0.5', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '35.8'}{'Date': '2018-08-17', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '64.2'}\n{'Date': '2018-03-07', 'Snow Water Equivalent (in) Start of Day Values': '42.0', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '101', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '23.2'}\nentry = entry =  \n {'Date': '2018-02-06', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '-0.2', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = entry = entry = {'Date': '2018-02-28', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\nentry = \nentry =  entry = entry = entry = \n{'Date': '2018-01-14', 'Snow Water Equivalent (in) Start of Day Values': '2.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '15.6'}   entry = \n {'Date': '2018-01-11', 'Snow Water Equivalent (in) Start of Day Values': '3.9', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '12', 'Change In Snow Depth (in)': '-2', 'Air Temperature Observed (degF) Start of Day Values': '32.2'}\n{'Date': '2018-02-25', 'Snow Water Equivalent (in) Start of Day Values': '14.8', 'Change In Snow Water Equivalent (in)': '0.6', 'Snow Depth (in) Start of Day Values': '65', 'Change In Snow Depth (in)': '7', 'Air Temperature Observed (degF) Start of Day Values': ''} entry = {'Date': '2018-01-27', 'Snow Water Equivalent (in) Start of Day Values': '8.8', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '3', 'Air Temperature Observed (degF) Start of Day Values': '3.6'}entry = {'Date': '2018-01-13', 'Snow Water Equivalent (in) Start of Day Values': '1.4', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '10', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '11.1'}entry = \n {'Date': '2018-02-23', 'Snow Water Equivalent (in) Start of Day Values': '6.7', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '28', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '5.0'}  \nentry = entry = {'Date': '2018-03-14', 'Snow Water Equivalent (in) Start of Day Values': '0.6', 'Change In Snow Water Equivalent (in)': '0.0', 'Snow Depth (in) Start of Day Values': '2', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '33.6'} entry = entry = {'Date': '2018-08-18', 'Snow Water Equivalent (in) Start of Day Values': '', 'Change In Snow Water Equivalent (in)': '', 'Snow Depth (in) Start of Day Values': '0', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '63.9'} \n \n{'Date': '2018-02-07', 'Snow Water Equivalent (in) Start of Day Values': '3.8', 'Change In Snow Water Equivalent (in)': '-0.1', 'Snow Depth (in) Start of Day Values': '', 'Change In Snow Depth (in)': '', 'Air Temperature Observed (degF) Start of Day Values': ''}\n{'Date': '2018-01-28', 'Snow Water Equivalent (in) Start of Day Values': '8.9', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '39', 'Change In Snow Depth (in)': '0', 'Air Temperature Observed (degF) Start of Day Values': '12.2'} entry = entry =    entry = entry =  {'Date': '2018-03-08', 'Snow Water Equivalent (in) Start of Day Values': '42.1', 'Change In Snow Water Equivalent (in)': '0.1', 'Snow Depth (in) Start of Day Values': '100', 'Change In Snow Depth (in)': '-1', 'Air Temperature Observed (degF) Start of Day Values': '33.6'}\n \nentry = \n  \nentry = entry = entry =     entry = entry =   \n\nStream closed",
  "history_begin_time" : 1703599866515,
  "history_end_time" : 1703599874897,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "cVbD3NvfQa7M",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nimport dask\nimport dask.dataframe as dd\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    # Create an empty Pandas DataFrame with the desired columns\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n\n    # Function to process each station\n    @dask.delayed\n    def process_station(station):\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n\n        entries = []\n        for entry in json_data:\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            entries.append(required_data)\n\n        return pd.DataFrame(entries)\n\n    # List of delayed computations for each station\n    delayed_results = [process_station(row) for _, row in new_base_df.iterrows()]\n\n    # Compute the delayed results\n    result_lists = dask.compute(*delayed_results)\n\n    # Concatenate the lists into a Pandas DataFrame\n    result_df = pd.concat(result_lists, ignore_index=True)\n\n    # Print the final Pandas DataFrame\n    print(result_df.head())\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/cVbD3NvfQa7M/data_snotel_station_only.py\", line 202, in <module>\n    get_swe_observations_from_snotel_cdec()\n  File \"/home/chetana/gw-workspace/cVbD3NvfQa7M/data_snotel_station_only.py\", line 188, in get_swe_observations_from_snotel_cdec\n    result_lists = dask.compute(*delayed_results)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/dask/base.py\", line 628, in compute\n    results = schedule(dsk, keys, **kwargs)\n  File \"/home/chetana/gw-workspace/cVbD3NvfQa7M/data_snotel_station_only.py\", line 176, in process_station\n    'date': entry['Date'], \nKeyError: 'Date'\n",
  "history_begin_time" : 1703599796347,
  "history_end_time" : 1703599817816,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "HE5MQrhBTuJJ",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nimport dask\nimport dask.dataframe as dd\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    # Create an empty Pandas DataFrame with the desired columns\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n\n    # Function to process each station\n    @dask.delayed\n    def process_station(station):\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n\n        entries = []\n        for entry in json_data:\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            entries.append(required_data)\n\n        return entries\n\n    # List of delayed computations for each station\n    delayed_results = [process_station(row) for _, row in new_base_df.iterrows()]\n\n    # Compute the delayed results\n    result_lists = dask.compute(*delayed_results)\n\n    # Concatenate the lists into a Pandas DataFrame\n    result_df = pd.concat(result_lists, ignore_index=True)\n\n    # Print the final Pandas DataFrame\n    print(result_df.head())\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/HE5MQrhBTuJJ/data_snotel_station_only.py\", line 202, in <module>\n    get_swe_observations_from_snotel_cdec()\n  File \"/home/chetana/gw-workspace/HE5MQrhBTuJJ/data_snotel_station_only.py\", line 191, in get_swe_observations_from_snotel_cdec\n    result_df = pd.concat(result_lists, ignore_index=True)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\", line 368, in concat\n    op = _Concatenator(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py\", line 458, in __init__\n    raise TypeError(msg)\nTypeError: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid\n",
  "history_begin_time" : 1703571252473,
  "history_end_time" : 1703571347769,
  "history_notes" : "using dask to parallelize the retrieval",
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "0jdDEGPjJ1Bt",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for index, station in new_base_df.iterrows():\n        print(f'station {station[\"name\"]} completed.')\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n        print(url)\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n        break\n    print(result_df.head())\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\nstation Abbey completed.\nhttps://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/ABY:CA:SNOW%7Cid%3D%22%22%7Cname/2018-01-01,2021-12-31%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\nEmpty DataFrame\nColumns: [station_name, date, lat, lon, swe_value]\nIndex: []\n",
  "history_begin_time" : 1703570923027,
  "history_end_time" : 1703570924956,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "xGLcVlpANOki",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for index, station in new_base_df.iterrows():\n        print(f'station {station[\"name\"]} completed.')\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n        break\n    print(result_df.head())\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\nstation Abbey completed.\nEmpty DataFrame\nColumns: [station_name, date, lat, lon, swe_value]\nIndex: []\n",
  "history_begin_time" : 1703570899560,
  "history_end_time" : 1703570900987,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "BFiKSZY8AhuP",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for index, station in new_base_df.iterrows():\n        print(f'station {station[\"name\"]} completed.')\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n  \t    break\n    print(result_df.head())\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/BFiKSZY8AhuP/data_snotel_station_only.py\", line 174\n    break\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1703570890785,
  "history_end_time" : 1703570890845,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "FM8qQxYA2F16",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for index, station in new_base_df.iterrows():\n        print(f'station {station[\"name\"]} completed.')\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t        result_df.loc[len(result_df.index)] = required_data\n  \t    break\n    print(result_df.head())\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/FM8qQxYA2F16/data_snotel_station_only.py\", line 173\n    result_df.loc[len(result_df.index)] = required_data\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1703570880158,
  "history_end_time" : 1703570880218,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lTqljolmiU53",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for index, station in new_base_df.iterrows():\n        print(f'station {station[\"name\"]} completed.')\n        location_name = station['name']\n  \t    location_triplet = station['stationTriplet']\n  \t    location_elevation = station['elevation']\n  \t    location_station_lat = station['latitude']\n  \t    location_station_long = station['longitude']\n\n  \t    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t    r = requests.get(url)\n  \t    text = remove_commented_lines(r.text)\n  \t    reader = csv.DictReader(io.StringIO(text))\n  \t    json_data = json.loads(json.dumps(list(reader)))\n  \t    for entry in json_data:\n  \t        required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t        result_df.loc[len(result_df.index)] = required_data\n  \t    break\n    print(result_df.head())\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/lTqljolmiU53/data_snotel_station_only.py\", line 156\n    location_triplet = station['stationTriplet']\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1703570845317,
  "history_end_time" : 1703570845378,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "9tJmRaYZ4GLj",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n    new_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n  \t\n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for index, station in new_base_df.iterrows():\n        print(f'station {station[\"name\"]} completed.')\n  \t    location_name = station['name']\n  \t    location_triplet = station['stationTriplet']\n  \t    location_elevation = station['elevation']\n  \t    location_station_lat = station['latitude']\n  \t    location_station_long = station['longitude']\n\n  \t    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t    r = requests.get(url)\n  \t    text = remove_commented_lines(r.text)\n  \t    reader = csv.DictReader(io.StringIO(text))\n  \t    json_data = json.loads(json.dumps(list(reader)))\n  \t    for entry in json_data:\n  \t        required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t        result_df.loc[len(result_df.index)] = required_data\n  \t    break\n    print(result_df.head())\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/9tJmRaYZ4GLj/data_snotel_station_only.py\", line 155\n    location_name = station['name']\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1703570830311,
  "history_end_time" : 1703570830382,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "R7EsrKA5UPqM",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n    start_date = train_start_date\n    end_date = train_end_date\n\t\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for index, station in new_base_df.iterrows():\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n  \t  \tbreak\n    print(result_df.head())\n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/R7EsrKA5UPqM/data_snotel_station_only.py\", line 149\n    start_date = train_start_date\n                                 ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570740897,
  "history_end_time" : 1703570740957,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ga8ng96QjERi",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor index, station in new_base_df.iterrows():\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n  \t  \tbreak\n    print(result_df.head())\n  \tresult_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/ga8ng96QjERi/data_snotel_station_only.py\", line 175\n    print(result_df.head())\n                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570723633,
  "history_end_time" : 1703570723697,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "6qw5XykXicNX",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor index, station in new_base_df.iterrows():\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n  \t  \tbreak\n  \tresult_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\nstation Abbey completed.\n",
  "history_begin_time" : 1703570661053,
  "history_end_time" : 1703570662683,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "KV78sDponSLg",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor index, station in new_base_df.iterrows():\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n  \t  \tbreak\n    \n    result_df.to_csv(csv_file, index=False)\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/KV78sDponSLg/data_snotel_station_only.py\", line 176\n    result_df.to_csv(csv_file, index=False)\n                                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570627653,
  "history_end_time" : 1703570627731,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "WEKFV1ubHBzP",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n  \t  \tbreak\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/WEKFV1ubHBzP/data_snotel_station_only.py\", line 179, in <module>\n    get_swe_observations_from_snotel_cdec()\n  File \"/home/chetana/gw-workspace/WEKFV1ubHBzP/data_snotel_station_only.py\", line 154, in get_swe_observations_from_snotel_cdec\n    print(f'station {station[\"name\"]} completed.')\nTypeError: string indices must be integers\n",
  "history_begin_time" : 1703570535934,
  "history_end_time" : 1703570537248,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ZZfLv06c9SwH",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n  \t  \tbreak\n    result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/ZZfLv06c9SwH/data_snotel_station_only.py\", line 175\n    result_df.to_csv(csv_file, index=False)\n                                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570469621,
  "history_end_time" : 1703570469698,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "wHIcrGkx9Lin",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n              \n  \t  \tbreak\n    result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/wHIcrGkx9Lin/data_snotel_station_only.py\", line 176\n    result_df.to_csv(csv_file, index=False)\n                                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570450608,
  "history_end_time" : 1703570450718,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "kFKPvgsF1nKp",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n              \n  \t  \tbreak\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/kFKPvgsF1nKp/data_snotel_station_only.py\", line 178\n    result_df.to_csv(csv_file, index=False)\n                                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570439911,
  "history_end_time" : 1703570440015,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "66uVk1f2rjcZ",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n              \n  \t  \tbreak\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/66uVk1f2rjcZ/data_snotel_station_only.py\", line 178\n    result_df.to_csv(csv_file, index=False)\n                                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570309385,
  "history_end_time" : 1703570309456,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "UzddQUsj0gYo",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n              \n  \t  \tbreak\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/UzddQUsj0gYo/data_snotel_station_only.py\", line 178\n    result_df.to_csv(csv_file, index=False)\n                                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570252208,
  "history_end_time" : 1703570252321,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "GuqKkrEsljTR",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n  \t  \turl = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n  \t  \tr = requests.get(url)\n  \t  \ttext = remove_commented_lines(r.text)\n  \t  \treader = csv.DictReader(io.StringIO(text))\n  \t  \tjson_data = json.loads(json.dumps(list(reader)))\n  \t  \tfor entry in json_data:\n  \t  \t    required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n  \t  \t    result_df.loc[len(result_df.index)] = required_data\n              \n  \t  \tbreak\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/GuqKkrEsljTR/data_snotel_station_only.py\", line 178\n    result_df.to_csv(csv_file, index=False)\n                                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703570241941,
  "history_end_time" : 1703570242007,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "NpvhaJrVWx2i",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n  \t  \tlocation_name = station['name']\n  \t  \tlocation_triplet = station['stationTriplet']\n  \t  \tlocation_elevation = station['elevation']\n  \t  \tlocation_station_lat = station['latitude']\n  \t  \tlocation_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n              \n        break\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/NpvhaJrVWx2i/data_snotel_station_only.py\", line 161\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1703570102682,
  "history_end_time" : 1703570102749,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "cJRIniDXnmR7",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon, train_start_date, train_end_date\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored_dask.csv'\n  \tstart_date = train_start_date\n  \tend_date = train_end_date\n\t\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in new_base_df:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n        location_name = station['name']\n        location_triplet = station['stationTriplet']\n        location_elevation = station['elevation']\n        location_station_lat = station['latitude']\n        location_station_long = station['longitude']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'station_name': location_name,\n                             'date': entry['Date'], \n                             'lat': location_station_lat, \n                             'lon': location_station_long,\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n              \n        break\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/cJRIniDXnmR7/data_snotel_station_only.py\", line 155\n    location_name = station['name']\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1703570087190,
  "history_end_time" : 1703570087286,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Qq8siNCsZKPB",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/all_snotel_cdec_stations_active_in_westus.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2021-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n        \n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n    stationTriplet stationId  ...              beginDate     endDate\n0      ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01\n1     0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01\n2     0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01\n3  08108010:NM:BOR  08108010  ...  1964-09-01 00:00:00.0  2100-01-01\n4    13E19:ID:SNOW     13E19  ...  1961-01-01 00:00:00.0  2100-01-01\n[5 rows x 16 columns]\nstation Adin Mtn completed.\nstation Agua Canyon completed.\nstation Albro Lake completed.\nstation Alexander Lake completed.\nstation Alpine Meadows completed.\nstation American Creek completed.\nstation Anchor River Divide completed.\nstation Anchorage Hillside completed.\nstation Aneroid Lake #2 completed.\nstation Aniak completed.\nstation Annie Springs completed.\nstation Apishapa completed.\nstation Arapaho Ridge completed.\nstation Arbuckle Mtn completed.\nstation Atigun Pass completed.\nstation Atlanta Summit completed.\nstation Atwater completed.\nstation Badger Pass completed.\nstation Baker Butte completed.\nstation Baker Butte Smt completed.\nstation Bald Mtn. completed.\nstation Baldy completed.\nstation Banfield Mountain completed.\nstation Banner Summit completed.\nstation Bar M completed.\nstation Barker Lakes completed.\nstation Base Camp completed.\nstation Basin Creek completed.\nstation Bassoo Peak completed.\nstation Bateman completed.\nstation Battle Mountain completed.\nstation Beagle Springs completed.\nstation Bear Basin completed.\nstation Bear Canyon completed.\nstation Bear Creek completed.\nstation Bear Grass completed.\nstation Bear Lake completed.\nstation Bear Mountain completed.\nstation Bear River completed.\nstation Bear River RS completed.\nstation Bear Saddle completed.\nstation Bear Trap Meadow completed.\nstation Beartooth Lake completed.\nstation Beartown completed.\nstation Beaver Ck Village completed.\nstation Beaver Creek completed.\nstation Beaver Dams completed.\nstation Beaver Divide completed.\nstation Beaver Head completed.\nstation Beaver Pass completed.\nstation Beaver Reservoir completed.\nstation Beaver Spring completed.\nstation Ben Lomond Peak completed.\nstation Ben Lomond Trail completed.\nstation Berry Creek completed.\nstation Berthoud Summit completed.\nstation Bettles Field completed.\nstation Bevans Cabin completed.\nstation Big Bend completed.\nstation Big Creek Sum completed.\nstation Big Creek Summit completed.\nstation Big Flat completed.\nstation Big Goose completed.\nstation Big Meadow completed.\nstation Big Red Mountain completed.\nstation Big Sandy Opening completed.\nstation Bigelow Camp completed.\nstation Billie Creek Divide completed.\nstation Bird Creek completed.\nstation Bison Lake completed.\nstation Bisson Creek completed.\nstation Black Bear completed.\nstation Black Flat-U.M. Ck completed.\nstation Black Mesa completed.\nstation Black Mountain completed.\nstation Black Pine completed.\nstation Blackhall Mtn completed.\nstation Blacks Fork Jct completed.\nstation Blacktail Mtn completed.\nstation Blackwater completed.\nstation Blazed Alder completed.\nstation Blewett Pass completed.\nstation Blind Bull Sum completed.\nstation Blind Park completed.\nstation Bloody Dick completed.\nstation Blue Lakes completed.\nstation Blue Mountain Spring completed.\nstation Bobs Hollow completed.\nstation Bogus Basin completed.\nstation Bone Springs Div completed.\nstation Bostetter R.S. completed.\nstation Boulder Mountain completed.\nstation Bourne completed.\nstation Bowman Springs completed.\nstation Box Canyon completed.\nstation Box Creek completed.\nstation Box Springs completed.\nstation Brackett Creek completed.\nstation Brian Head completed.\nstation Brighton completed.\nstation Bristlecone Trail completed.\nstation Brooklyn Lake completed.\nstation Brown Duck completed.\nstation Brown Top completed.\nstation Brumley completed.\nstation Brundage Reservoir completed.\nstation Buck Flat completed.\nstation Buck Pasture completed.\nstation Buckboard Flat completed.\nstation Buckinghorse completed.\nstation Buckskin Joe completed.\nstation Buckskin Lower completed.\nstation Buffalo Park completed.\nstation Bug Lake completed.\nstation Bumping Ridge completed.\nstation Bunchgrass Mdw completed.\nstation Burgess Junction completed.\nstation Burnside Lake completed.\nstation Burnt Mountain completed.\nstation Burnt Mtn completed.\nstation Burro Mountain completed.\nstation Burroughs Creek completed.\nstation Burts Miller Ranch completed.\nstation Butte completed.\nstation Calamity completed.\nstation Calvert Creek completed.\nstation Camas Creek Divide completed.\nstation Camp Jackson completed.\nstation Canyon completed.\nstation Carrot Basin completed.\nstation Carson Pass completed.\nstation Cascade #2 completed.\nstation Cascade Mountain completed.\nstation Cascade Summit completed.\nstation Casper Mtn. completed.\nstation Castle Creek completed.\nstation Castle Valley completed.\nstation Cave Mountain completed.\nstation Cayuse Pass completed.\nstation Cedar Pass completed.\nstation Chalender completed.\nstation Chalk Creek #1 completed.\nstation Chalk Creek #2 completed.\nstation Chamita completed.\nstation Chapman Tunnel completed.\nstation Chemult Alternate completed.\nstation Chena Lakes completed.\nstation Chepeta completed.\nstation Chicago Ridge completed.\nstation Chisana completed.\nstation Chocolate Gulch completed.\nstation Cinnabar Park completed.\nstation Clackamas Lake completed.\nstation Clayton Springs completed.\nstation Clear Creek #1 completed.\nstation Clear Creek #2 completed.\nstation Clear Lake completed.\nstation Cloud Peak Reservoir completed.\nstation Clover Meadow completed.\nstation Cochetopa Pass completed.\nstation Cold Springs completed.\nstation Cold Springs Camp completed.\nstation Coldfoot completed.\nstation Cole Canyon completed.\nstation Cole Creek completed.\nstation Columbia Basin completed.\nstation Columbine completed.\nstation Columbine Pass completed.\nstation Columbus Basin completed.\nstation Combination completed.\nstation Cool Creek completed.\nstation Cooper Lake completed.\nstation Copeland Lake completed.\nstation Copper Bottom completed.\nstation Copper Camp completed.\nstation Copper Mountain completed.\nstation Corduroy Flat completed.\nstation Coronado Trail completed.\nstation Corral completed.\nstation Corral Canyon completed.\nstation Corral Pass completed.\nstation Cottonwood Creek completed.\nstation Couch Summit completed.\nstation Cougar Mountain completed.\nstation County Line completed.\nstation Cozy Cove completed.\nstation Crab Creek completed.\nstation Crater Meadows completed.\nstation Crazyman Flat completed.\nstation Creamers Field completed.\nstation Crosho completed.\nstation Crow Creek completed.\nstation Crowder Flat completed.\nstation Crystal Lake completed.\nstation Css Lab completed.\nstation Culebra #2 completed.\nstation Cumbres Trestle completed.\nstation Currant Creek completed.\nstation Dahl Creek completed.\nstation Daisy Peak completed.\nstation Daly Creek completed.\nstation Daly Lake completed.\nstation Daniels-Strawberry completed.\nstation Darkhorse Lake completed.\nstation Deadman Creek completed.\nstation Deadman Hill completed.\nstation Deadwood Summit completed.\nstation Deer Park completed.\nstation Defiance Mines completed.\nstation Derr. completed.\nstation Diamond Lake completed.\nstation Diamond Peak completed.\nstation Dills Camp completed.\nstation Disaster Peak completed.\nstation Dismal Swamp completed.\nstation Divide completed.\nstation Divide Peak completed.\nstation Dollarhide Summit completed.\nstation Dome Lake completed.\nstation Donkey Reservoir completed.\nstation Dorsey Basin completed.\nstation Draw Creek completed.\nstation Dry Bread Pond completed.\nstation Dry Creek completed.\nstation Dry Fork completed.\nstation Dry Lake completed.\nstation Dungeness completed.\nstation Dupuyer Creek completed.\nstation Eagle Summit completed.\nstation East Boulder Mine completed.\nstation East Palmer completed.\nstation East Rim Divide completed.\nstation East Willow Creek completed.\nstation Easy Pass completed.\nstation Ebbetts Pass completed.\nstation Echo Lake completed.\nstation Echo Peak completed.\nstation EF Blacks Fork GS completed.\nstation Eilertson Meadows completed.\nstation El Diente Peak completed.\nstation Elbow Lake completed.\nstation Elk Butte completed.\nstation Elk Cabin completed.\nstation Elk Peak completed.\nstation Elk River completed.\nstation Elkhart Park G.S. completed.\nstation Elkhead Divide completed.\nstation Elliot Ridge completed.\nstation Emery Creek completed.\nstation Emigrant Springs completed.\nstation Emigrant Summit completed.\nstation Esther Island completed.\nstation Evening Star completed.\nstation Exit Glacier completed.\nstation Fallen Leaf completed.\nstation Farmington completed.\nstation Farmington Lower completed.\nstation Farnsworth Lake completed.\nstation Fawn Creek completed.\nstation Fielding Lake completed.\nstation Fifteenmile completed.\nstation Fish Ck completed.\nstation Fish Creek completed.\nstation Fish Lake completed.\nstation Fish Lake Utah completed.\nstation Fish Lk. completed.\nstation Fisher Creek completed.\nstation Five Points Lake completed.\nstation Flattop Mtn. completed.\nstation Flower Mountain completed.\nstation Fool Creek completed.\nstation Forestdale Creek completed.\nstation Fort Valley completed.\nstation Fort Yukon completed.\nstation Fourmile Lake completed.\nstation Franklin Basin completed.\nstation Fredonyer Peak completed.\nstation Fremont Pass completed.\nstation Frisco Divide completed.\nstation Frohner Meadow completed.\nstation Frostbite Bottom completed.\nstation Fry completed.\nstation Fry Canyon completed.\nstation Galena completed.\nstation Galena AK completed.\nstation Galena Summit completed.\nstation Gallegos Peak completed.\nstation Garden City Summit completed.\nstation Gardner Peak completed.\nstation Garfield R.S. completed.\nstation Garita Peak completed.\nstation Garver Creek completed.\nstation GBRC HQ completed.\nstation GBRC Meadows completed.\nstation George Creek completed.\nstation Gerber Reservoir completed.\nstation Giveout completed.\nstation Glen Cove completed.\nstation Gobblers Knob completed.\nstation Golconda completed.\nstation Gold Axe Camp completed.\nstation Gold Basin completed.\nstation Gold Center completed.\nstation Gold Mountain completed.\nstation Gooseberry RS completed.\nstation Gooseberry RS Up completed.\nstation Graham Guard Sta. completed.\nstation Grand Targhee completed.\nstation Grandview completed.\nstation Granite Creek completed.\nstation Granite Crk completed.\nstation Granite Peak completed.\nstation Grassy Lake completed.\nstation Grave Creek completed.\nstation Grave Springs completed.\nstation Grayback completed.\nstation Green Lake completed.\nstation Green Mountain completed.\nstation Greenpoint completed.\nstation Grizzly Peak completed.\nstation Gros Ventre Summit completed.\nstation Grouse Camp completed.\nstation Grouse Creek Divide completed.\nstation Gulkana River completed.\nstation Gunsight Pass completed.\nstation Gutz Peak completed.\nstation Hagans Meadow completed.\nstation Hams Fork completed.\nstation Hand Creek completed.\nstation Hannagan Meadows completed.\nstation Hansen Sawmill completed.\nstation Happy Jack completed.\nstation Hardscrabble completed.\nstation Harris Flat completed.\nstation Harts Pass completed.\nstation Hawkins Lake completed.\nstation Hawley Lake completed.\nstation Hayden Fork completed.\nstation Hayden Pass completed.\nstation Heavenly Valley completed.\nstation Heber completed.\nstation Heen Latinee completed.\nstation Hemlock Butte completed.\nstation Hewinta completed.\nstation Hickerson Park completed.\nstation Hidden Lake completed.\nstation High Lonesome completed.\nstation High Ridge completed.\nstation Hilts Creek completed.\nstation Hobble Creek completed.\nstation Hobbs Park completed.\nstation Hogg Pass completed.\nstation Hole-in-Mountain completed.\nstation Hole-in-Rock completed.\nstation Holland Meadows completed.\nstation Hoodoo Basin completed.\nstation Hoosier Pass completed.\nstation Hopewell completed.\nstation Horse Meadow completed.\nstation Horse Ridge completed.\nstation Hourglass Lake completed.\nstation Howard Prairie completed.\nstation Howell Canyon completed.\nstation Hozatka Lake completed.\nstation Hozomeen Camp completed.\nstation Huckleberry Creek completed.\nstation Humboldt Gulch completed.\nstation Huntington Horse completed.\nstation Hyndman completed.\nstation Idarado completed.\nstation Imnaviat Creek completed.\nstation Independence Camp completed.\nstation Independence Creek completed.\nstation Independence Lake completed.\nstation Independence Mine completed.\nstation Independence Pass completed.\nstation Indian Creek completed.\nstation Indian Pass completed.\nstation Indian Rock completed.\nstation Irish Taylor completed.\nstation Island Park completed.\nstation Ivanhoe completed.\nstation Jack Creek Upper completed.\nstation Jack Wade Jct completed.\nstation Jacks Peak completed.\nstation Jackson Peak completed.\nstation Jackwhacker Gulch completed.\nstation Jakes Creek completed.\nstation JL Meadow completed.\nstation Joe Wright completed.\nstation Johnsons Camp completed.\nstation Jones Corral completed.\nstation Jones Pass completed.\nstation Jump Off Joe completed.\nstation June Lake completed.\nstation Kalamazoo completed.\nstation Kantishna completed.\nstation Kelley R.S. completed.\nstation Kelly Station completed.\nstation Kenai Moose Pens completed.\nstation Kendall R.S. completed.\nstation Kilfoil Creek completed.\nstation Kiln completed.\nstation Kimberly Mine completed.\nstation King Mountain completed.\nstation Kings Cabin completed.\nstation Kirwin completed.\nstation Klondike Narrows completed.\nstation Kolob completed.\nstation Kraft Creek completed.\nstation Lake Creek R.S. completed.\nstation Lake Eldora completed.\nstation Lake Irene completed.\nstation Lakefork #1 completed.\nstation Lakefork #3 completed.\nstation Lakefork Basin completed.\nstation Lakeview Ridge completed.\nstation Lamance Creek completed.\nstation Lamoille #3 completed.\nstation Lamoille Upper completed.\nstation Laprele Creek completed.\nstation Larsen Creek completed.\nstation Lasal Mountain completed.\nstation Lasal Mountain-Lower completed.\nstation Laurel Draw completed.\nstation Leavitt Lake completed.\nstation Leavitt Meadows completed.\nstation Lee Canyon completed.\nstation Lemhi Ridge completed.\nstation Lewis Lake Divide completed.\nstation Lewis Peak completed.\nstation Lick Creek completed.\nstation Lightning Ridge completed.\nstation Lily Lake completed.\nstation Lily Pond completed.\nstation Little Bear completed.\nstation Little Chena Ridge completed.\nstation Little Goose completed.\nstation Little Grassy completed.\nstation Little Meadows completed.\nstation Little Snake River completed.\nstation Little Valley completed.\nstation Little Warm completed.\nstation Lizard Head Pass completed.\nstation Lobdell Lake completed.\nstation Lolo Pass completed.\nstation Lone Cone completed.\nstation Lone Mountain completed.\nstation Lone Pine completed.\nstation Lonesome Beaver completed.\nstation Long Draw Resv completed.\nstation Long Flat completed.\nstation Long Lake completed.\nstation Long Valley completed.\nstation Long Valley Jct completed.\nstation Lookout completed.\nstation Lookout Mountain completed.\nstation Lookout Peak completed.\nstation Loomis Park completed.\nstation Lost Creek Resv completed.\nstation Lost Dog completed.\nstation Lost Horse completed.\nstation Lost Lake completed.\nstation Lost-Wood Divide completed.\nstation Louis Meadow completed.\nstation Loveland Basin completed.\nstation Lower Kachemak Creek completed.\nstation Lower Twin completed.\nstation Lubrecht Flume completed.\nstation Lucky Strike completed.\nstation Lyman Lake completed.\nstation Lynn Lake completed.\nstation Lynx Pass completed.\nstation Madison Butte completed.\nstation Madison Plateau completed.\nstation Magic Mountain completed.\nstation Mammoth-Cottonwood completed.\nstation Mancos completed.\nstation Many Glacier completed.\nstation Marion Forks completed.\nstation Marlette Lake completed.\nstation Marquette completed.\nstation Marten Ridge completed.\nstation Maverick Fork completed.\nstation May Creek completed.\nstation Mc Clure Pass completed.\nstation Mccoy Park completed.\nstation McGrath completed.\nstation Mckenzie completed.\nstation Mcknight Cabin completed.\nstation Mcneil Canyon completed.\nstation Mcneil River SGS completed.\nstation Meadow Lake completed.\nstation Meadows Pass completed.\nstation Med Bow completed.\nstation Medano Pass completed.\nstation Merchant Valley completed.\nstation Merritt Mountain completed.\nstation Mesa Lakes completed.\nstation MF Nooksack completed.\nstation Mica Creek completed.\nstation Michigan Creek completed.\nstation Midas completed.\nstation Middle Creek completed.\nstation Middle Fork Bradley completed.\nstation Middle Fork Camp completed.\nstation Middle Powder completed.\nstation Midway Valley completed.\nstation Milk Shakes completed.\nstation Mill Creek Summit completed.\nstation Mill-D North completed.\nstation Miller Woods completed.\nstation Mineral Creek completed.\nstation Mining Fork completed.\nstation Molas Lake completed.\nstation Monahan Flat completed.\nstation Monitor Pass completed.\nstation Monte Cristo completed.\nstation Monument Creek completed.\nstation Monument Peak completed.\nstation Moon Pass completed.\nstation Moonshine completed.\nstation Moore Creek Bridge completed.\nstation Moose Creek completed.\nstation Moraine completed.\nstation Mores Creek Summit completed.\nstation Morgan Creek completed.\nstation Mormon Mountain completed.\nstation Mormon Mtn Summit completed.\nstation Morse Lake completed.\nstation Mosby Mtn. completed.\nstation Moscow Mountain completed.\nstation Moses Mtn completed.\nstation Mosquito Ridge completed.\nstation Moss Peak completed.\nstation Moss Springs completed.\nstation Mount Crag completed.\nstation Mount Gardner completed.\nstation Mount Lockhart completed.\nstation Mountain Meadows completed.\nstation Mowich completed.\nstation Mt Baldy completed.\nstation Mt Hood Test Site completed.\nstation Mt Pennell completed.\nstation Mt Rose Ski Area completed.\nstation Mt. Alyeska completed.\nstation Mt. Eyak completed.\nstation Mt. Howard completed.\nstation Mt. Ryan completed.\nstation Mt. Tebo completed.\nstation Muckamuck completed.\nstation Mud Flat completed.\nstation Mud Ridge completed.\nstation Mule Creek completed.\nstation Munson Ridge completed.\nstation Myrtle Creek completed.\nstation N Fk Elk Creek completed.\nstation Nast Lake completed.\nstation Navajo Whiskey Ck completed.\nstation Nenana completed.\nstation Nevada Ridge completed.\nstation Never Summer completed.\nstation New Crescent Lake completed.\nstation New Fork Lake completed.\nstation Nez Perce Camp completed.\nstation Niwot completed.\nstation Noisy Basin completed.\nstation North Costilla completed.\nstation North Fork completed.\nstation North Fork Jocko completed.\nstation North French Creek completed.\nstation North Lost Trail completed.\nstation North Rapid Creek completed.\nstation Northeast Entrance completed.\nstation Nuka Glacier completed.\nstation Nutrioso completed.\nstation Oak Creek completed.\nstation Ochoco Meadows completed.\nstation Olallie Meadows completed.\nstation ONeil Creek completed.\nstation Onion Park completed.\nstation Overland Res. completed.\nstation Owl Creek completed.\nstation Oxford Spring completed.\nstation Palisades Tahoe completed.\nstation Palo completed.\nstation Panguitch Lake RS completed.\nstation Paradise completed.\nstation Paradise Hill completed.\nstation Pargon Creek completed.\nstation Park Cone completed.\nstation Park Creek Ridge completed.\nstation Park Reservoir completed.\nstation Parker Peak completed.\nstation Parleys Summit completed.\nstation Parleys Upper completed.\nstation Parrish Creek completed.\nstation Payson R.S. completed.\nstation Peavine Ridge completed.\nstation Pebble Creek completed.\nstation Pepper Creek completed.\nstation Peterson Meadows completed.\nstation Phantom Valley completed.\nstation Phillips Bench completed.\nstation Pickfoot Creek completed.\nstation Pickle Keg completed.\nstation Pierce R.S. completed.\nstation Pigtail Peak completed.\nstation Pike Creek completed.\nstation Pine Creek completed.\nstation Pine Creek Pass completed.\nstation Pinto Rock completed.\nstation Placer Basin completed.\nstation Pocket Creek completed.\nstation Poison Flat completed.\nstation Pole Canyon completed.\nstation Pole Creek R.S. completed.\nstation Poorman Creek completed.\nstation Pope Ridge completed.\nstation Porcupine completed.\nstation Porphyry Creek completed.\nstation Port Graham completed.\nstation Porter Canyon completed.\nstation Potato Hill completed.\nstation Powder Mountain completed.\nstation Powder River Pass completed.\nstation Prairie completed.\nstation Promontory completed.\nstation Prudhoe Bay completed.\nstation Quartz Mountain completed.\nstation Quartz Peak completed.\nstation Quemazon completed.\nstation Rabbit Ears completed.\nstation Ragged Mountain completed.\nstation Railroad Overpass completed.\nstation Rainbow Canyon completed.\nstation Rainy Pass completed.\nstation Rawah completed.\nstation Red Hill completed.\nstation Red Mountain Pass completed.\nstation Red Pine Ridge completed.\nstation Red River Pass #2 completed.\nstation Redden Mine Lwr completed.\nstation Rees Flat completed.\nstation Reno Hill completed.\nstation Rex River completed.\nstation Reynolds Creek completed.\nstation Rice Park completed.\nstation Rio Santa Barbara completed.\nstation Ripple Creek completed.\nstation Roach completed.\nstation Roaring River completed.\nstation Rock Creek completed.\nstation Rock Springs completed.\nstation Rocker Peak completed.\nstation Rockwood GS completed.\nstation Rocky Basin-Settleme completed.\nstation Rocky Boy completed.\nstation Rocky Point completed.\nstation Rough And Tumble completed.\nstation Rubicon #2 completed.\nstation S Fork Shields completed.\nstation Sacajawea completed.\nstation Saddle Mountain completed.\nstation Saddle Mtn. completed.\nstation Sage Creek Basin completed.\nstation Sagwon completed.\nstation Saint Elmo completed.\nstation Salmon Meadows completed.\nstation Salt Creek Falls completed.\nstation Salt River Summit completed.\nstation San Antonio Sink completed.\nstation Sand Lake completed.\nstation Sandstone RS completed.\nstation Santa Fe completed.\nstation Santaquin Meadows completed.\nstation Santiam Jct. completed.\nstation Sargents Mesa completed.\nstation Sasse Ridge completed.\nstation Satus Pass completed.\nstation Savage Pass completed.\nstation Sawmill Ridge completed.\nstation Sawtooth completed.\nstation Schneider Meadows completed.\nstation Schofield Pass completed.\nstation Schwartz Lake completed.\nstation Schweitzer Basin completed.\nstation Scotch Creek completed.\nstation Secesh Summit completed.\nstation Sedgwick Peak completed.\nstation Seeley Creek completed.\nstation Seine Creek completed.\nstation Senorita Divide #2 completed.\nstation Sentinel Butte completed.\nstation Sevenmile Marsh completed.\nstation Seventysix Creek completed.\nstation Shanghi Summit completed.\nstation Sharkstooth completed.\nstation Sheep Canyon completed.\nstation Sheep Mtn. completed.\nstation Sheldon completed.\nstation Shell Creek completed.\nstation Sherwin completed.\nstation Short Creek completed.\nstation Shower Falls completed.\nstation Shuree completed.\nstation Sierra Blanca completed.\nstation Signal Peak completed.\nstation Silver Creek completed.\nstation Silver Creek Divide completed.\nstation Silver Creek Nv completed.\nstation Silvies completed.\nstation Skalkaho Summit completed.\nstation Skate Creek completed.\nstation Skookum Creek completed.\nstation Slagamelt Lakes completed.\nstation Sleeping Woman completed.\nstation Slug Creek Divide completed.\nstation Slumgullion completed.\nstation Smiley Mountain completed.\nstation Smith  Morehouse completed.\nstation Smith Ridge completed.\nstation Snake River Station completed.\nstation Snider Basin completed.\nstation Snow Mountain completed.\nstation Snowbird completed.\nstation Snowslide Canyon completed.\nstation Snowstorm Mtn completed.\nstation Soldier Park completed.\nstation Soldier R.S. completed.\nstation Somsen Ranch completed.\nstation Sonora Pass completed.\nstation Sourdough Gulch completed.\nstation South Brush Creek completed.\nstation South Colony completed.\nstation South Fork Bull Run completed.\nstation South Mtn. completed.\nstation South Pass completed.\nstation Spencer Meadow completed.\nstation Spirit Lake completed.\nstation Spirit Lk completed.\nstation Spratt Creek completed.\nstation Spring Creek completed.\nstation Spring Creek Divide completed.\nstation Spruce Springs completed.\nstation Spud Mountain completed.\nstation Spur Park completed.\nstation Squaw Flat completed.\nstation St. Lawrence Alt completed.\nstation Stag Mountain completed.\nstation Stahl Peak completed.\nstation Stampede Pass completed.\nstation Starr Ridge completed.\nstation State Line completed.\nstation Steel Creek Park completed.\nstation Stevens Pass completed.\nstation Stickney Mill completed.\nstation Stillwater Creek completed.\nstation Strawberry completed.\nstation Strawberry Divide completed.\nstation Stringer Creek completed.\nstation Stryker Basin completed.\nstation Stuart Mountain completed.\nstation Stump Lakes completed.\nstation Sucker Creek completed.\nstation Sugarloaf Mtn completed.\nstation Summer Rim completed.\nstation Summit Creek completed.\nstation Summit Lake completed.\nstation Summit Lk completed.\nstation Summit Meadow completed.\nstation Summit Ranch completed.\nstation Sun Pass completed.\nstation Sunflower Flat completed.\nstation Sunset completed.\nstation Surprise Lakes completed.\nstation Susitna Valley High completed.\nstation Suu Ranch completed.\nstation Swamp Creek completed.\nstation Swan Lake Mtn completed.\nstation Swede Peak completed.\nstation Swift Creek completed.\nstation Sylvan Lake completed.\nstation Sylvan Road completed.\nstation Tahoe City Cross completed.\nstation Takka Wiiya completed.\nstation Taos Powderhorn completed.\nstation Taos Pueblo completed.\nstation Taylor Butte completed.\nstation Taylor Canyon completed.\nstation Taylor Green completed.\nstation Telaquana Lake completed.\nstation Temple Fork completed.\nstation Tent Mtn Lower completed.\nstation Tepee Creek completed.\nstation Teuchet Creek completed.\nstation Thaynes Canyon completed.\nstation Thistle Flat completed.\nstation Three Creeks Meadow completed.\nstation Thumb Divide completed.\nstation Thunder Basin completed.\nstation Tie Creek completed.\nstation Timber Creek completed.\nstation Timberline completed.\nstation Timpanogos Divide completed.\nstation Tinkham Creek completed.\nstation Tipton completed.\nstation Tizer Basin completed.\nstation Toe Jam completed.\nstation Togwotee Pass completed.\nstation Tok completed.\nstation Toketee Airstrip completed.\nstation Tokositna Valley completed.\nstation Tolby completed.\nstation Tony Grove Lake completed.\nstation Tony Grove RS completed.\nstation Touchet completed.\nstation Tower completed.\nstation Townsend Creek completed.\nstation Trapper Lake completed.\nstation Tres Ritos completed.\nstation Trial Lake completed.\nstation Trinchera completed.\nstation Trinity completed.\nstation Trinity Mtn. completed.\nstation Triple Peak completed.\nstation Trough completed.\nstation Trout Creek completed.\nstation Truckee #2 completed.\nstation Turnagain Pass completed.\nstation Twelvemile Creek completed.\nstation Twin Lakes completed.\nstation Two Ocean Plateau completed.\nstation University Camp completed.\nstation Upper Chena completed.\nstation Upper Joes Valley completed.\nstation Upper Nome Creek completed.\nstation Upper Rio Grande completed.\nstation Upper San Juan completed.\nstation Upper Taylor completed.\nstation Upper Tsaina River completed.\nstation Upper Wheeler completed.\nstation Usu Doc Daniel completed.\nstation Ute Creek completed.\nstation Vacarro Springs completed.\nstation Vacas Locas completed.\nstation Vail Mountain completed.\nstation Vallecito completed.\nstation Van Wyck completed.\nstation Vernon Creek completed.\nstation Vienna Mine completed.\nstation Virginia Lakes Ridge completed.\nstation Wager Gulch completed.\nstation Waldron completed.\nstation Ward Creek #3 completed.\nstation Ward Mountain completed.\nstation Warm Springs completed.\nstation Waterhole completed.\nstation Webber Springs completed.\nstation Webster Flat completed.\nstation Wells Creek completed.\nstation Weminuche Creek completed.\nstation Wesner Springs completed.\nstation West Branch completed.\nstation West Yellowstone completed.\nstation Wheeler Peak completed.\nstation Whiskey Ck completed.\nstation Whiskey Creek completed.\nstation Whiskey Park completed.\nstation White Elephant completed.\nstation White Horse Lake completed.\nstation White Mill completed.\nstation White Pass E.S. completed.\nstation White River #1 completed.\nstation White River Nv completed.\nstation Widtsoe #3 completed.\nstation Wilbur Bench completed.\nstation Wild Basin completed.\nstation Wildcat completed.\nstation Wildhorse Divide completed.\nstation Willow Creek completed.\nstation Willow Creek Pass completed.\nstation Willow Park completed.\nstation Wilson Creek completed.\nstation Windy Peak completed.\nstation Wolf Creek completed.\nstation Wolf Creek Peak completed.\nstation Wolf Creek Summit completed.\nstation Wolverine completed.\nstation Wood Creek completed.\nstation Workman Creek completed.\nstation Wrigley Creek completed.\nstation Yankee Reservoir completed.\nstation Younts Peak completed.\nstation Zirkel completed.\n",
  "history_begin_time" : 1703569930378,
  "history_end_time" : 1703569932334,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "GeMduSd3XCA7",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2021-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n     station_name  elevation       lat        lon\n0        Adin Mtn       6190  41.23583 -120.79192\n1     Agua Canyon       8900  37.52217 -112.27118\n2      Albro Lake       8300  45.59723 -111.95902\n3  Alexander Lake        160  61.74967 -150.88967\n4  Alpine Meadows       3500  47.77957 -121.69847\nstation Adin Mtn completed.\nstation Agua Canyon completed.\nstation Albro Lake completed.\nstation Alexander Lake completed.\nstation Alpine Meadows completed.\nstation American Creek completed.\nstation Anchor River Divide completed.\nstation Anchorage Hillside completed.\nstation Aneroid Lake #2 completed.\nstation Aniak completed.\nstation Annie Springs completed.\nstation Apishapa completed.\nstation Arapaho Ridge completed.\nstation Arbuckle Mtn completed.\nstation Atigun Pass completed.\nstation Atlanta Summit completed.\nstation Atwater completed.\nstation Badger Pass completed.\nstation Baker Butte completed.\nstation Baker Butte Smt completed.\nstation Bald Mtn. completed.\nstation Baldy completed.\nstation Banfield Mountain completed.\nstation Banner Summit completed.\nstation Bar M completed.\nstation Barker Lakes completed.\nstation Base Camp completed.\nstation Basin Creek completed.\nstation Bassoo Peak completed.\nstation Bateman completed.\nstation Battle Mountain completed.\nstation Beagle Springs completed.\nstation Bear Basin completed.\nstation Bear Canyon completed.\nstation Bear Creek completed.\nstation Bear Grass completed.\nstation Bear Lake completed.\nstation Bear Mountain completed.\nstation Bear River completed.\nstation Bear River RS completed.\nstation Bear Saddle completed.\nstation Bear Trap Meadow completed.\nstation Beartooth Lake completed.\nstation Beartown completed.\nstation Beaver Ck Village completed.\nstation Beaver Creek completed.\nstation Beaver Dams completed.\nstation Beaver Divide completed.\nstation Beaver Head completed.\nstation Beaver Pass completed.\nstation Beaver Reservoir completed.\nstation Beaver Spring completed.\nstation Ben Lomond Peak completed.\nstation Ben Lomond Trail completed.\nstation Berry Creek completed.\nstation Berthoud Summit completed.\nstation Bettles Field completed.\nstation Bevans Cabin completed.\nstation Big Bend completed.\nstation Big Creek Sum completed.\nstation Big Creek Summit completed.\nstation Big Flat completed.\nstation Big Goose completed.\nstation Big Meadow completed.\nstation Big Red Mountain completed.\nstation Big Sandy Opening completed.\nstation Bigelow Camp completed.\nstation Billie Creek Divide completed.\nstation Bird Creek completed.\nstation Bison Lake completed.\nstation Bisson Creek completed.\nstation Black Bear completed.\nstation Black Flat-U.M. Ck completed.\nstation Black Mesa completed.\nstation Black Mountain completed.\nstation Black Pine completed.\nstation Blackhall Mtn completed.\nstation Blacks Fork Jct completed.\nstation Blacktail Mtn completed.\nstation Blackwater completed.\nstation Blazed Alder completed.\nstation Blewett Pass completed.\nstation Blind Bull Sum completed.\nstation Blind Park completed.\nstation Bloody Dick completed.\nstation Blue Lakes completed.\nstation Blue Mountain Spring completed.\nstation Bobs Hollow completed.\nstation Bogus Basin completed.\nstation Bone Springs Div completed.\nstation Bostetter R.S. completed.\nstation Boulder Mountain completed.\nstation Bourne completed.\nstation Bowman Springs completed.\nstation Box Canyon completed.\nstation Box Creek completed.\nstation Box Springs completed.\nstation Brackett Creek completed.\nstation Brian Head completed.\nstation Brighton completed.\nstation Bristlecone Trail completed.\nstation Brooklyn Lake completed.\nstation Brown Duck completed.\nstation Brown Top completed.\nstation Brumley completed.\nstation Brundage Reservoir completed.\nstation Buck Flat completed.\nstation Buck Pasture completed.\nstation Buckboard Flat completed.\nstation Buckinghorse completed.\nstation Buckskin Joe completed.\nstation Buckskin Lower completed.\nstation Buffalo Park completed.\nstation Bug Lake completed.\nstation Bumping Ridge completed.\nstation Bunchgrass Mdw completed.\nstation Burgess Junction completed.\nstation Burnside Lake completed.\nstation Burnt Mountain completed.\nstation Burnt Mtn completed.\nstation Burro Mountain completed.\nstation Burroughs Creek completed.\nstation Burts Miller Ranch completed.\nstation Butte completed.\nstation Calamity completed.\nstation Calvert Creek completed.\nstation Camas Creek Divide completed.\nstation Camp Jackson completed.\nstation Canyon completed.\nstation Carrot Basin completed.\nstation Carson Pass completed.\nstation Cascade #2 completed.\nstation Cascade Mountain completed.\nstation Cascade Summit completed.\nstation Casper Mtn. completed.\nstation Castle Creek completed.\nstation Castle Valley completed.\nstation Cave Mountain completed.\nstation Cayuse Pass completed.\nstation Cedar Pass completed.\nstation Chalender completed.\nstation Chalk Creek #1 completed.\nstation Chalk Creek #2 completed.\nstation Chamita completed.\nstation Chapman Tunnel completed.\nstation Chemult Alternate completed.\nstation Chena Lakes completed.\nstation Chepeta completed.\nstation Chicago Ridge completed.\nstation Chisana completed.\nstation Chocolate Gulch completed.\nstation Cinnabar Park completed.\nstation Clackamas Lake completed.\nstation Clayton Springs completed.\nstation Clear Creek #1 completed.\nstation Clear Creek #2 completed.\nstation Clear Lake completed.\nstation Cloud Peak Reservoir completed.\nstation Clover Meadow completed.\nstation Cochetopa Pass completed.\nstation Cold Springs completed.\nstation Cold Springs Camp completed.\nstation Coldfoot completed.\nstation Cole Canyon completed.\nstation Cole Creek completed.\nstation Columbia Basin completed.\nstation Columbine completed.\nstation Columbine Pass completed.\nstation Columbus Basin completed.\nstation Combination completed.\nstation Cool Creek completed.\nstation Cooper Lake completed.\nstation Copeland Lake completed.\nstation Copper Bottom completed.\nstation Copper Camp completed.\nstation Copper Mountain completed.\nstation Corduroy Flat completed.\nstation Coronado Trail completed.\nstation Corral completed.\nstation Corral Canyon completed.\nstation Corral Pass completed.\nstation Cottonwood Creek completed.\nstation Couch Summit completed.\nstation Cougar Mountain completed.\nstation County Line completed.\nstation Cozy Cove completed.\nstation Crab Creek completed.\nstation Crater Meadows completed.\nstation Crazyman Flat completed.\nstation Creamers Field completed.\nstation Crosho completed.\nstation Crow Creek completed.\nstation Crowder Flat completed.\nstation Crystal Lake completed.\nstation Css Lab completed.\nstation Culebra #2 completed.\nstation Cumbres Trestle completed.\nstation Currant Creek completed.\nstation Dahl Creek completed.\nstation Daisy Peak completed.\nstation Daly Creek completed.\nstation Daly Lake completed.\nstation Daniels-Strawberry completed.\nstation Darkhorse Lake completed.\nstation Deadman Creek completed.\nstation Deadman Hill completed.\nstation Deadwood Summit completed.\nstation Deer Park completed.\nstation Defiance Mines completed.\nstation Derr. completed.\nstation Diamond Lake completed.\nstation Diamond Peak completed.\nstation Dills Camp completed.\nstation Disaster Peak completed.\nstation Dismal Swamp completed.\nstation Divide completed.\nstation Divide Peak completed.\nstation Dollarhide Summit completed.\nstation Dome Lake completed.\nstation Donkey Reservoir completed.\nstation Dorsey Basin completed.\nstation Draw Creek completed.\nstation Dry Bread Pond completed.\nstation Dry Creek completed.\nstation Dry Fork completed.\nstation Dry Lake completed.\nstation Dungeness completed.\nstation Dupuyer Creek completed.\nstation Eagle Summit completed.\nstation East Boulder Mine completed.\nstation East Palmer completed.\nstation East Rim Divide completed.\nstation East Willow Creek completed.\nstation Easy Pass completed.\nstation Ebbetts Pass completed.\nstation Echo Lake completed.\nstation Echo Peak completed.\nstation EF Blacks Fork GS completed.\nstation Eilertson Meadows completed.\nstation El Diente Peak completed.\nstation Elbow Lake completed.\nstation Elk Butte completed.\nstation Elk Cabin completed.\nstation Elk Peak completed.\nstation Elk River completed.\nstation Elkhart Park G.S. completed.\nstation Elkhead Divide completed.\nstation Elliot Ridge completed.\nstation Emery Creek completed.\nstation Emigrant Springs completed.\nstation Emigrant Summit completed.\nstation Esther Island completed.\nstation Evening Star completed.\nstation Exit Glacier completed.\nstation Fallen Leaf completed.\nstation Farmington completed.\nstation Farmington Lower completed.\nstation Farnsworth Lake completed.\nstation Fawn Creek completed.\nstation Fielding Lake completed.\nstation Fifteenmile completed.\nstation Fish Ck completed.\nstation Fish Creek completed.\nstation Fish Lake completed.\nstation Fish Lake Utah completed.\nstation Fish Lk. completed.\nstation Fisher Creek completed.\nstation Five Points Lake completed.\nstation Flattop Mtn. completed.\nstation Flower Mountain completed.\nstation Fool Creek completed.\nstation Forestdale Creek completed.\nstation Fort Valley completed.\nstation Fort Yukon completed.\nstation Fourmile Lake completed.\nstation Franklin Basin completed.\nstation Fredonyer Peak completed.\nstation Fremont Pass completed.\nstation Frisco Divide completed.\nstation Frohner Meadow completed.\nstation Frostbite Bottom completed.\nstation Fry completed.\nstation Fry Canyon completed.\nstation Galena completed.\nstation Galena AK completed.\nstation Galena Summit completed.\nstation Gallegos Peak completed.\nstation Garden City Summit completed.\nstation Gardner Peak completed.\nstation Garfield R.S. completed.\nstation Garita Peak completed.\nstation Garver Creek completed.\nstation GBRC HQ completed.\nstation GBRC Meadows completed.\nstation George Creek completed.\nstation Gerber Reservoir completed.\nstation Giveout completed.\nstation Glen Cove completed.\nstation Gobblers Knob completed.\nstation Golconda completed.\nstation Gold Axe Camp completed.\nstation Gold Basin completed.\nstation Gold Center completed.\nstation Gold Mountain completed.\nstation Gooseberry RS completed.\nstation Gooseberry RS Up completed.\nstation Graham Guard Sta. completed.\nstation Grand Targhee completed.\nstation Grandview completed.\nstation Granite Creek completed.\nstation Granite Crk completed.\nstation Granite Peak completed.\nstation Grassy Lake completed.\nstation Grave Creek completed.\nstation Grave Springs completed.\nstation Grayback completed.\nstation Green Lake completed.\nstation Green Mountain completed.\nstation Greenpoint completed.\nstation Grizzly Peak completed.\nstation Gros Ventre Summit completed.\nstation Grouse Camp completed.\nstation Grouse Creek Divide completed.\nstation Gulkana River completed.\nstation Gunsight Pass completed.\nstation Gutz Peak completed.\nstation Hagans Meadow completed.\nstation Hams Fork completed.\nstation Hand Creek completed.\nstation Hannagan Meadows completed.\nstation Hansen Sawmill completed.\nstation Happy Jack completed.\nstation Hardscrabble completed.\nstation Harris Flat completed.\nstation Harts Pass completed.\nstation Hawkins Lake completed.\nstation Hawley Lake completed.\nstation Hayden Fork completed.\nstation Hayden Pass completed.\nstation Heavenly Valley completed.\nstation Heber completed.\nstation Heen Latinee completed.\nstation Hemlock Butte completed.\nstation Hewinta completed.\nstation Hickerson Park completed.\nstation Hidden Lake completed.\nstation High Lonesome completed.\nstation High Ridge completed.\nstation Hilts Creek completed.\nstation Hobble Creek completed.\nstation Hobbs Park completed.\nstation Hogg Pass completed.\nstation Hole-in-Mountain completed.\nstation Hole-in-Rock completed.\nstation Holland Meadows completed.\nstation Hoodoo Basin completed.\nstation Hoosier Pass completed.\nstation Hopewell completed.\nstation Horse Meadow completed.\nstation Horse Ridge completed.\nstation Hourglass Lake completed.\nstation Howard Prairie completed.\nstation Howell Canyon completed.\nstation Hozatka Lake completed.\nstation Hozomeen Camp completed.\nstation Huckleberry Creek completed.\nstation Humboldt Gulch completed.\nstation Huntington Horse completed.\nstation Hyndman completed.\nstation Idarado completed.\nstation Imnaviat Creek completed.\nstation Independence Camp completed.\nstation Independence Creek completed.\nstation Independence Lake completed.\nstation Independence Mine completed.\nstation Independence Pass completed.\nstation Indian Creek completed.\nstation Indian Pass completed.\nstation Indian Rock completed.\nstation Irish Taylor completed.\nstation Island Park completed.\nstation Ivanhoe completed.\nstation Jack Creek Upper completed.\nstation Jack Wade Jct completed.\nstation Jacks Peak completed.\nstation Jackson Peak completed.\nstation Jackwhacker Gulch completed.\nstation Jakes Creek completed.\nstation JL Meadow completed.\nstation Joe Wright completed.\nstation Johnsons Camp completed.\nstation Jones Corral completed.\nstation Jones Pass completed.\nstation Jump Off Joe completed.\nstation June Lake completed.\nstation Kalamazoo completed.\nstation Kantishna completed.\nstation Kelley R.S. completed.\nstation Kelly Station completed.\nstation Kenai Moose Pens completed.\nstation Kendall R.S. completed.\nstation Kilfoil Creek completed.\nstation Kiln completed.\nstation Kimberly Mine completed.\nstation King Mountain completed.\nstation Kings Cabin completed.\nstation Kirwin completed.\nstation Klondike Narrows completed.\nstation Kolob completed.\nstation Kraft Creek completed.\nstation Lake Creek R.S. completed.\nstation Lake Eldora completed.\nstation Lake Irene completed.\nstation Lakefork #1 completed.\nstation Lakefork #3 completed.\nstation Lakefork Basin completed.\nstation Lakeview Ridge completed.\nstation Lamance Creek completed.\nstation Lamoille #3 completed.\nstation Lamoille Upper completed.\nstation Laprele Creek completed.\nstation Larsen Creek completed.\nstation Lasal Mountain completed.\nstation Lasal Mountain-Lower completed.\nstation Laurel Draw completed.\nstation Leavitt Lake completed.\nstation Leavitt Meadows completed.\nstation Lee Canyon completed.\nstation Lemhi Ridge completed.\nstation Lewis Lake Divide completed.\nstation Lewis Peak completed.\nstation Lick Creek completed.\nstation Lightning Ridge completed.\nstation Lily Lake completed.\nstation Lily Pond completed.\nstation Little Bear completed.\nstation Little Chena Ridge completed.\nstation Little Goose completed.\nstation Little Grassy completed.\nstation Little Meadows completed.\nstation Little Snake River completed.\nstation Little Valley completed.\nstation Little Warm completed.\nstation Lizard Head Pass completed.\nstation Lobdell Lake completed.\nstation Lolo Pass completed.\nstation Lone Cone completed.\nstation Lone Mountain completed.\nstation Lone Pine completed.\nstation Lonesome Beaver completed.\nstation Long Draw Resv completed.\nstation Long Flat completed.\nstation Long Lake completed.\nstation Long Valley completed.\nstation Long Valley Jct completed.\nstation Lookout completed.\nstation Lookout Mountain completed.\nstation Lookout Peak completed.\nstation Loomis Park completed.\nstation Lost Creek Resv completed.\nstation Lost Dog completed.\nstation Lost Horse completed.\nstation Lost Lake completed.\nstation Lost-Wood Divide completed.\nstation Louis Meadow completed.\nstation Loveland Basin completed.\nstation Lower Kachemak Creek completed.\nstation Lower Twin completed.\nstation Lubrecht Flume completed.\nstation Lucky Strike completed.\nstation Lyman Lake completed.\nstation Lynn Lake completed.\nstation Lynx Pass completed.\nstation Madison Butte completed.\nstation Madison Plateau completed.\nstation Magic Mountain completed.\nstation Mammoth-Cottonwood completed.\nstation Mancos completed.\nstation Many Glacier completed.\nstation Marion Forks completed.\nstation Marlette Lake completed.\nstation Marquette completed.\nstation Marten Ridge completed.\nstation Maverick Fork completed.\nstation May Creek completed.\nstation Mc Clure Pass completed.\nstation Mccoy Park completed.\nstation McGrath completed.\nstation Mckenzie completed.\nstation Mcknight Cabin completed.\nstation Mcneil Canyon completed.\nstation Mcneil River SGS completed.\nstation Meadow Lake completed.\nstation Meadows Pass completed.\nstation Med Bow completed.\nstation Medano Pass completed.\nstation Merchant Valley completed.\nstation Merritt Mountain completed.\nstation Mesa Lakes completed.\nstation MF Nooksack completed.\nstation Mica Creek completed.\nstation Michigan Creek completed.\nstation Midas completed.\nstation Middle Creek completed.\nstation Middle Fork Bradley completed.\nstation Middle Fork Camp completed.\nstation Middle Powder completed.\nstation Midway Valley completed.\nstation Milk Shakes completed.\nstation Mill Creek Summit completed.\nstation Mill-D North completed.\nstation Miller Woods completed.\nstation Mineral Creek completed.\nstation Mining Fork completed.\nstation Molas Lake completed.\nstation Monahan Flat completed.\nstation Monitor Pass completed.\nstation Monte Cristo completed.\nstation Monument Creek completed.\nstation Monument Peak completed.\nstation Moon Pass completed.\nstation Moonshine completed.\nstation Moore Creek Bridge completed.\nstation Moose Creek completed.\nstation Moraine completed.\nstation Mores Creek Summit completed.\nstation Morgan Creek completed.\nstation Mormon Mountain completed.\nstation Mormon Mtn Summit completed.\nstation Morse Lake completed.\nstation Mosby Mtn. completed.\nstation Moscow Mountain completed.\nstation Moses Mtn completed.\nstation Mosquito Ridge completed.\nstation Moss Peak completed.\nstation Moss Springs completed.\nstation Mount Crag completed.\nstation Mount Gardner completed.\nstation Mount Lockhart completed.\nstation Mountain Meadows completed.\nstation Mowich completed.\nstation Mt Baldy completed.\nstation Mt Hood Test Site completed.\nstation Mt Pennell completed.\nstation Mt Rose Ski Area completed.\nstation Mt. Alyeska completed.\nstation Mt. Eyak completed.\nstation Mt. Howard completed.\nstation Mt. Ryan completed.\nstation Mt. Tebo completed.\nstation Muckamuck completed.\nstation Mud Flat completed.\nstation Mud Ridge completed.\nstation Mule Creek completed.\nstation Munson Ridge completed.\nstation Myrtle Creek completed.\nstation N Fk Elk Creek completed.\nstation Nast Lake completed.\nstation Navajo Whiskey Ck completed.\nstation Nenana completed.\nstation Nevada Ridge completed.\nstation Never Summer completed.\nstation New Crescent Lake completed.\nstation New Fork Lake completed.\nstation Nez Perce Camp completed.\nstation Niwot completed.\nstation Noisy Basin completed.\nstation North Costilla completed.\nstation North Fork completed.\nstation North Fork Jocko completed.\nstation North French Creek completed.\nstation North Lost Trail completed.\nstation North Rapid Creek completed.\nstation Northeast Entrance completed.\nstation Nuka Glacier completed.\nstation Nutrioso completed.\nstation Oak Creek completed.\nstation Ochoco Meadows completed.\nstation Olallie Meadows completed.\nstation ONeil Creek completed.\nstation Onion Park completed.\nstation Overland Res. completed.\nstation Owl Creek completed.\nstation Oxford Spring completed.\nstation Palisades Tahoe completed.\nstation Palo completed.\nstation Panguitch Lake RS completed.\nstation Paradise completed.\nstation Paradise Hill completed.\nstation Pargon Creek completed.\nstation Park Cone completed.\nstation Park Creek Ridge completed.\nstation Park Reservoir completed.\nstation Parker Peak completed.\nstation Parleys Summit completed.\nstation Parleys Upper completed.\nstation Parrish Creek completed.\nstation Payson R.S. completed.\nstation Peavine Ridge completed.\nstation Pebble Creek completed.\nstation Pepper Creek completed.\nstation Peterson Meadows completed.\nstation Phantom Valley completed.\nstation Phillips Bench completed.\nstation Pickfoot Creek completed.\nstation Pickle Keg completed.\nstation Pierce R.S. completed.\nstation Pigtail Peak completed.\nstation Pike Creek completed.\nstation Pine Creek completed.\nstation Pine Creek Pass completed.\nstation Pinto Rock completed.\nstation Placer Basin completed.\nstation Pocket Creek completed.\nstation Poison Flat completed.\nstation Pole Canyon completed.\nstation Pole Creek R.S. completed.\nstation Poorman Creek completed.\nstation Pope Ridge completed.\nstation Porcupine completed.\nstation Porphyry Creek completed.\nstation Port Graham completed.\nstation Porter Canyon completed.\nstation Potato Hill completed.\nstation Powder Mountain completed.\nstation Powder River Pass completed.\nstation Prairie completed.\nstation Promontory completed.\nstation Prudhoe Bay completed.\nstation Quartz Mountain completed.\nstation Quartz Peak completed.\nstation Quemazon completed.\nstation Rabbit Ears completed.\nstation Ragged Mountain completed.\nstation Railroad Overpass completed.\nstation Rainbow Canyon completed.\nstation Rainy Pass completed.\nstation Rawah completed.\nstation Red Hill completed.\nstation Red Mountain Pass completed.\nstation Red Pine Ridge completed.\nstation Red River Pass #2 completed.\nstation Redden Mine Lwr completed.\nstation Rees Flat completed.\nstation Reno Hill completed.\nstation Rex River completed.\nstation Reynolds Creek completed.\nstation Rice Park completed.\nstation Rio Santa Barbara completed.\nstation Ripple Creek completed.\nstation Roach completed.\nstation Roaring River completed.\nstation Rock Creek completed.\nstation Rock Springs completed.\nstation Rocker Peak completed.\nstation Rockwood GS completed.\nstation Rocky Basin-Settleme completed.\nstation Rocky Boy completed.\nstation Rocky Point completed.\nstation Rough And Tumble completed.\nstation Rubicon #2 completed.\nstation S Fork Shields completed.\nstation Sacajawea completed.\nstation Saddle Mountain completed.\nstation Saddle Mtn. completed.\nstation Sage Creek Basin completed.\nstation Sagwon completed.\nstation Saint Elmo completed.\nstation Salmon Meadows completed.\nstation Salt Creek Falls completed.\nstation Salt River Summit completed.\nstation San Antonio Sink completed.\nstation Sand Lake completed.\nstation Sandstone RS completed.\nstation Santa Fe completed.\nstation Santaquin Meadows completed.\nstation Santiam Jct. completed.\nstation Sargents Mesa completed.\nstation Sasse Ridge completed.\nstation Satus Pass completed.\nstation Savage Pass completed.\nstation Sawmill Ridge completed.\nstation Sawtooth completed.\nstation Schneider Meadows completed.\nstation Schofield Pass completed.\nstation Schwartz Lake completed.\nstation Schweitzer Basin completed.\nstation Scotch Creek completed.\nstation Secesh Summit completed.\nstation Sedgwick Peak completed.\nstation Seeley Creek completed.\nstation Seine Creek completed.\nstation Senorita Divide #2 completed.\nstation Sentinel Butte completed.\nstation Sevenmile Marsh completed.\nstation Seventysix Creek completed.\nstation Shanghi Summit completed.\nstation Sharkstooth completed.\nstation Sheep Canyon completed.\nstation Sheep Mtn. completed.\nstation Sheldon completed.\nstation Shell Creek completed.\nstation Sherwin completed.\nstation Short Creek completed.\nstation Shower Falls completed.\nstation Shuree completed.\nstation Sierra Blanca completed.\nstation Signal Peak completed.\nstation Silver Creek completed.\nstation Silver Creek Divide completed.\nstation Silver Creek Nv completed.\nstation Silvies completed.\nstation Skalkaho Summit completed.\nstation Skate Creek completed.\nstation Skookum Creek completed.\nstation Slagamelt Lakes completed.\nstation Sleeping Woman completed.\nstation Slug Creek Divide completed.\nstation Slumgullion completed.\nstation Smiley Mountain completed.\nstation Smith  Morehouse completed.\nstation Smith Ridge completed.\nstation Snake River Station completed.\nstation Snider Basin completed.\nstation Snow Mountain completed.\nstation Snowbird completed.\nstation Snowslide Canyon completed.\nstation Snowstorm Mtn completed.\nstation Soldier Park completed.\nstation Soldier R.S. completed.\nstation Somsen Ranch completed.\nstation Sonora Pass completed.\nstation Sourdough Gulch completed.\nstation South Brush Creek completed.\nstation South Colony completed.\nstation South Fork Bull Run completed.\nstation South Mtn. completed.\nstation South Pass completed.\nstation Spencer Meadow completed.\nstation Spirit Lake completed.\nstation Spirit Lk completed.\nstation Spratt Creek completed.\nstation Spring Creek completed.\nstation Spring Creek Divide completed.\nstation Spruce Springs completed.\nstation Spud Mountain completed.\nstation Spur Park completed.\nstation Squaw Flat completed.\nstation St. Lawrence Alt completed.\nstation Stag Mountain completed.\nstation Stahl Peak completed.\nstation Stampede Pass completed.\nstation Starr Ridge completed.\nstation State Line completed.\nstation Steel Creek Park completed.\nstation Stevens Pass completed.\nstation Stickney Mill completed.\nstation Stillwater Creek completed.\nstation Strawberry completed.\nstation Strawberry Divide completed.\nstation Stringer Creek completed.\nstation Stryker Basin completed.\nstation Stuart Mountain completed.\nstation Stump Lakes completed.\nstation Sucker Creek completed.\nstation Sugarloaf Mtn completed.\nstation Summer Rim completed.\nstation Summit Creek completed.\nstation Summit Lake completed.\nstation Summit Lk completed.\nstation Summit Meadow completed.\nstation Summit Ranch completed.\nstation Sun Pass completed.\nstation Sunflower Flat completed.\nstation Sunset completed.\nstation Surprise Lakes completed.\nstation Susitna Valley High completed.\nstation Suu Ranch completed.\nstation Swamp Creek completed.\nstation Swan Lake Mtn completed.\nstation Swede Peak completed.\nstation Swift Creek completed.\nstation Sylvan Lake completed.\nstation Sylvan Road completed.\nstation Tahoe City Cross completed.\nstation Takka Wiiya completed.\nstation Taos Powderhorn completed.\nstation Taos Pueblo completed.\nstation Taylor Butte completed.\nstation Taylor Canyon completed.\nstation Taylor Green completed.\nstation Telaquana Lake completed.\nstation Temple Fork completed.\nstation Tent Mtn Lower completed.\nstation Tepee Creek completed.\nstation Teuchet Creek completed.\nstation Thaynes Canyon completed.\nstation Thistle Flat completed.\nstation Three Creeks Meadow completed.\nstation Thumb Divide completed.\nstation Thunder Basin completed.\nstation Tie Creek completed.\nstation Timber Creek completed.\nstation Timberline completed.\nstation Timpanogos Divide completed.\nstation Tinkham Creek completed.\nstation Tipton completed.\nstation Tizer Basin completed.\nstation Toe Jam completed.\nstation Togwotee Pass completed.\nstation Tok completed.\nstation Toketee Airstrip completed.\nstation Tokositna Valley completed.\nstation Tolby completed.\nstation Tony Grove Lake completed.\nstation Tony Grove RS completed.\nstation Touchet completed.\nstation Tower completed.\nstation Townsend Creek completed.\nstation Trapper Lake completed.\nstation Tres Ritos completed.\nstation Trial Lake completed.\nstation Trinchera completed.\nstation Trinity completed.\nstation Trinity Mtn. completed.\nstation Triple Peak completed.\nstation Trough completed.\nstation Trout Creek completed.\nstation Truckee #2 completed.\nstation Turnagain Pass completed.\nstation Twelvemile Creek completed.\nstation Twin Lakes completed.\nstation Two Ocean Plateau completed.\nstation University Camp completed.\nstation Upper Chena completed.\nstation Upper Joes Valley completed.\nstation Upper Nome Creek completed.\nstation Upper Rio Grande completed.\nstation Upper San Juan completed.\nstation Upper Taylor completed.\nstation Upper Tsaina River completed.\nstation Upper Wheeler completed.\nstation Usu Doc Daniel completed.\nstation Ute Creek completed.\nstation Vacarro Springs completed.\nstation Vacas Locas completed.\nstation Vail Mountain completed.\nstation Vallecito completed.\nstation Van Wyck completed.\nstation Vernon Creek completed.\nstation Vienna Mine completed.\nstation Virginia Lakes Ridge completed.\nstation Wager Gulch completed.\nstation Waldron completed.\nstation Ward Creek #3 completed.\nstation Ward Mountain completed.\nstation Warm Springs completed.\nstation Waterhole completed.\nstation Webber Springs completed.\nstation Webster Flat completed.\nstation Wells Creek completed.\nstation Weminuche Creek completed.\nstation Wesner Springs completed.\nstation West Branch completed.\nstation West Yellowstone completed.\nstation Wheeler Peak completed.\nstation Whiskey Ck completed.\nstation Whiskey Creek completed.\nstation Whiskey Park completed.\nstation White Elephant completed.\nstation White Horse Lake completed.\nstation White Mill completed.\nstation White Pass E.S. completed.\nstation White River #1 completed.\nstation White River Nv completed.\nstation Widtsoe #3 completed.\nstation Wilbur Bench completed.\nstation Wild Basin completed.\nstation Wildcat completed.\nstation Wildhorse Divide completed.\nstation Willow Creek completed.\nstation Willow Creek Pass completed.\nstation Willow Park completed.\nstation Wilson Creek completed.\nstation Windy Peak completed.\nstation Wolf Creek completed.\nstation Wolf Creek Peak completed.\nstation Wolf Creek Summit completed.\nstation Wolverine completed.\nstation Wood Creek completed.\nstation Workman Creek completed.\nstation Wrigley Creek completed.\nstation Yankee Reservoir completed.\nstation Younts Peak completed.\nstation Zirkel completed.\n",
  "history_begin_time" : 1703569875538,
  "history_end_time" : 1703569877434,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "8BpqUd1iCvV1",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2021-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n",
  "history_begin_time" : 1703558623844,
  "history_end_time" : 1703558624895,
  "history_notes" : "get all the active in region snotel/cdec stations",
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "i1LLiwyS5lm0",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\nThe active csv already exists: /home/chetana/gridmet_test_run/all_snotel_cdec_stations_active_in_westus.csv\n",
  "history_begin_time" : 1703554754179,
  "history_end_time" : 1703554755002,
  "history_notes" : "get full set of snotel/cdec stations finally",
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "t322Q2Iqgc5D",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n        filtered_df.to_csv(active_csv_file_path, index=False)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\n  stationTriplet stationId  ...              beginDate                endDate\n0   2057:AL:SCAN      2057  ...  2002-02-23 00:00:00.0  2100-01-01 00:00:00.0\n1    ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01 00:00:00.0\n2   0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01 00:00:00.0\n3  1F01A:BC:SNOW     1F01A  ...  1939-04-01 00:00:00.0  2100-01-01 00:00:00.0\n4   0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01 00:00:00.0\n[5 rows x 16 columns]\n(4457, 16)\nFiltered DataFrame:\n(3759, 16)\n",
  "history_begin_time" : 1703554743268,
  "history_end_time" : 1703554744217,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "1LqKZKZ4qaDL",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n        \n        # Filter rows within the latitude and longitude ranges\n        filtered_df = filtered_df[\n            (filtered_df['latitude'] >= southwest_lat) & (filtered_df['latitude'] <= northeast_lat) &\n            (filtered_df['longitude'] >= southwest_lon) & (filtered_df['longitude'] <= northeast_lon)\n        ]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\n  stationTriplet stationId  ...              beginDate                endDate\n0   2057:AL:SCAN      2057  ...  2002-02-23 00:00:00.0  2100-01-01 00:00:00.0\n1    ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01 00:00:00.0\n2   0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01 00:00:00.0\n3  1F01A:BC:SNOW     1F01A  ...  1939-04-01 00:00:00.0  2100-01-01 00:00:00.0\n4   0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01 00:00:00.0\n[5 rows x 16 columns]\n(4457, 16)\nFiltered DataFrame:\n(3759, 16)\n",
  "history_begin_time" : 1703554672821,
  "history_end_time" : 1703554673737,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7RyxR0uIN1VC",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        print(all_df.shape)\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df.shape)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\n  stationTriplet stationId  ...              beginDate                endDate\n0   2057:AL:SCAN      2057  ...  2002-02-23 00:00:00.0  2100-01-01 00:00:00.0\n1    ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01 00:00:00.0\n2   0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01 00:00:00.0\n3  1F01A:BC:SNOW     1F01A  ...  1939-04-01 00:00:00.0  2100-01-01 00:00:00.0\n4   0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01 00:00:00.0\n[5 rows x 16 columns]\n(4457, 16)\nFiltered DataFrame:\n(4457, 16)\n",
  "history_begin_time" : 1703553560797,
  "history_end_time" : 1703553561709,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "tvxLexdQKQIT",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir, southwest_lat, southwest_lon, northeast_lat, northeast_lon\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n        all_df['endDate'] = pd.to_datetime(all_df['endDate'])\n        end_date = pd.to_datetime('2050-01-01')\n        filtered_df = all_df[all_df['endDate'] > end_date]\n\n        # Print the original and filtered DataFrames\n        print(\"Filtered DataFrame:\")\n        print(filtered_df)\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\n  stationTriplet stationId  ...              beginDate                endDate\n0   2057:AL:SCAN      2057  ...  2002-02-23 00:00:00.0  2100-01-01 00:00:00.0\n1    ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01 00:00:00.0\n2   0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01 00:00:00.0\n3  1F01A:BC:SNOW     1F01A  ...  1939-04-01 00:00:00.0  2100-01-01 00:00:00.0\n4   0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01 00:00:00.0\n[5 rows x 16 columns]\nFiltered DataFrame:\n        stationTriplet stationId  ...              beginDate    endDate\n0         2057:AL:SCAN      2057  ...  2002-02-23 00:00:00.0 2100-01-01\n1          ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0 2100-01-01\n2         0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0 2100-01-01\n3        1F01A:BC:SNOW     1F01A  ...  1939-04-01 00:00:00.0 2100-01-01\n4         0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0 2100-01-01\n...                ...       ...  ...                    ...        ...\n4452  1141800N:CA:USGS  1141800N  ...  1941-10-31 00:00:00.0 2100-01-01\n4453  15356000:AK:USGS  15356000  ...  1950-01-01 00:00:00.0 2100-01-01\n4454  15453500:AK:USGS  15453500  ...  1976-10-01 00:00:00.0 2100-01-01\n4455      1033:CO:SNTL      1033  ...  2002-08-14 00:00:00.0 2100-01-01\n4456  09386950:NM:USGS  09386950  ...  1969-10-01 00:00:00.0 2100-01-01\n[4457 rows x 16 columns]\n",
  "history_begin_time" : 1703553537415,
  "history_end_time" : 1703553538419,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "RTn9q3KBQp6W",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n    if not os.path.exists(csv_file_path):\n        # Read the JSON file\n        with open(output_json_file, 'r') as json_file:\n            json_content = json.load(json_file)\n\n        # Check the content (print or analyze as needed)\n        #print(\"JSON Content:\")\n        #print(json.dumps(json_content, indent=2))\n\n        # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n        data_list = json_content if isinstance(json_content, list) else [json_content]\n\n        # Get the header from the keys of the first dictionary (assuming consistent structure)\n        header = data_list[0].keys()\n        # Write to CSV file\n        with open(csv_file_path, 'w', newline='') as csv_file:\n            csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n            csv_writer.writeheader()\n            csv_writer.writerows(data_list)\n\n        print(f\"Data converted and saved to {csv_file_path}\")\n    \n    else:\n        print(f\"The csv all snotel/cdec stations exists.\")\n        \n        \n    active_csv_file_path = f'{working_dir}/all_snotel_cdec_stations_active_in_westus.csv'\n    if not os.path.exists(active_csv_file_path):\n        all_df = pd.read_csv(csv_file_path)\n        print(all_df.head())\n    else:\n        print(f\"The active csv already exists: {active_csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nThe csv all snotel/cdec stations exists.\n  stationTriplet stationId  ...              beginDate                endDate\n0   2057:AL:SCAN      2057  ...  2002-02-23 00:00:00.0  2100-01-01 00:00:00.0\n1    ABY:CA:SNOW       ABY  ...  1963-02-01 00:00:00.0  2100-01-01 00:00:00.0\n2   0010:ID:COOP      0010  ...  1914-01-01 00:00:00.0  2100-01-01 00:00:00.0\n3  1F01A:BC:SNOW     1F01A  ...  1939-04-01 00:00:00.0  2100-01-01 00:00:00.0\n4   0041:NM:COOP      0041  ...  1957-01-01 00:00:00.0  2100-01-01 00:00:00.0\n[5 rows x 16 columns]\n",
  "history_begin_time" : 1703552975763,
  "history_end_time" : 1703552976612,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "URwCuJ1VA2zP",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_json_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    # Read the JSON file\n    with open(output_json_file, 'r') as json_file:\n        json_content = json.load(json_file)\n\n    # Check the content (print or analyze as needed)\n    #print(\"JSON Content:\")\n    #print(json.dumps(json_content, indent=2))\n\n    # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n    data_list = json_content if isinstance(json_content, list) else [json_content]\n\n    # Get the header from the keys of the first dictionary (assuming consistent structure)\n    header = data_list[0].keys()\n    \n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n\n    # Write to CSV file\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n        csv_writer.writeheader()\n        csv_writer.writerows(data_list)\n\n    print(f\"Data converted and saved to {csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nData converted and saved to /home/chetana/gridmet_test_run/all_snotel_cdec_stations.csv\n",
  "history_begin_time" : 1703552264016,
  "history_end_time" : 1703552264881,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "JhHvSqbonFMd",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    # Read the JSON file\n    with open(output_json_file, 'r') as json_file:\n        json_content = json.load(json_file)\n\n    # Check the content (print or analyze as needed)\n    #print(\"JSON Content:\")\n    #print(json.dumps(json_content, indent=2))\n\n    # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n    data_list = json_content if isinstance(json_content, list) else [json_content]\n\n    # Get the header from the keys of the first dictionary (assuming consistent structure)\n    header = data_list[0].keys()\n    \n    csv_file_path = f'{working_dir}/all_snotel_cdec_stations.csv'\n\n    # Write to CSV file\n    with open(csv_file_path, 'w', newline='') as csv_file:\n        csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n        csv_writer.writeheader()\n        csv_writer.writerows(data_list)\n\n    print(f\"Data converted and saved to {csv_file_path}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/JhHvSqbonFMd/data_snotel_station_only.py\", line 161, in <module>\n    download_station_json()\n  File \"/home/chetana/gw-workspace/JhHvSqbonFMd/data_snotel_station_only.py\", line 30, in download_station_json\n    print(f\"Data downloaded and saved to {output_file}\")\nNameError: name 'output_file' is not defined\n",
  "history_begin_time" : 1703552244581,
  "history_end_time" : 1703552246643,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "dwQ8VTrBrFjV",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n    if not os.path.exists(output_json_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        \n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    # Read the JSON file\n    with open(output_json_file, 'r') as json_file:\n        json_content = json.load(json_file)\n\n    # Check the content (print or analyze as needed)\n    #print(\"JSON Content:\")\n    #print(json.dumps(json_content, indent=2))\n\n    # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n    data_list = json_content if isinstance(json_content, list) else [json_content]\n\n    # Get the header from the keys of the first dictionary (assuming consistent structure)\n    header = data_list[0].keys()\n    \n    csv_file = f'{working_dir}/all_snotel_cdec_stations.csv'\n\n    # Write to CSV file\n    with open(csv_file, 'w', newline='') as csv_file:\n        csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n        csv_writer.writeheader()\n        csv_writer.writerows(data_list)\n\n    print(f\"Data converted and saved to {csv_file}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nThe file /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json already exists.\nData converted and saved to <_io.TextIOWrapper name='/home/chetana/gridmet_test_run/all_snotel_cdec_stations.csv' mode='w' encoding='UTF-8'>\n",
  "history_begin_time" : 1703552209410,
  "history_end_time" : 1703552210257,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "YEz4HOh5eTVU",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    if not os.path.exists(output_file):\n        # Fetch data from the URL\n        response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n        output_json_file = f'{working_dir}/all_snotel_cdec_stations.json'\n\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            # Decode the JSON content\n            json_content = response.json()\n\n            # Save the JSON content to a file\n            with open(output_json_file, 'w') as json_file:\n                json.dump(json_content, json_file, indent=2)\n\n            print(f\"Data downloaded and saved to {output_file}\")\n        else:\n            print(f\"Failed to download data. Status code: {response.status_code}\")\n    else:\n        print(f\"The file {output_json_file} already exists.\")\n        \n    \n    # read the json file and convert it to csv\n    # Read the JSON file\n    with open(output_json_file, 'r') as json_file:\n        json_content = json.load(json_file)\n\n    # Check the content (print or analyze as needed)\n    #print(\"JSON Content:\")\n    #print(json.dumps(json_content, indent=2))\n\n    # Convert JSON data to a list of dictionaries (assuming JSON is a list of objects)\n    data_list = json_content if isinstance(json_content, list) else [json_content]\n\n    # Get the header from the keys of the first dictionary (assuming consistent structure)\n    header = data_list[0].keys()\n    \n    csv_file = f'{working_dir}/all_snotel_cdec_stations.csv'\n\n    # Write to CSV file\n    with open(csv_file, 'w', newline='') as csv_file:\n        csv_writer = csv.DictWriter(csv_file, fieldnames=header)\n        csv_writer.writeheader()\n        csv_writer.writerows(data_list)\n\n    print(f\"Data converted and saved to {csv_file}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/YEz4HOh5eTVU/data_snotel_station_only.py\", line 160, in <module>\n    download_station_json()\n  File \"/home/chetana/gw-workspace/YEz4HOh5eTVU/data_snotel_station_only.py\", line 15, in download_station_json\n    if not os.path.exists(output_file):\nNameError: name 'output_file' is not defined\n",
  "history_begin_time" : 1703552193330,
  "history_end_time" : 1703552194108,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "6dvmnYM7a5Ke",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef download_station_json():\n    # https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\n    # Fetch data from the URL\n    response = requests.get(\"https://wcc.sc.egov.usda.gov/awdbRestApi/services/v1/stations?activeOnly=true&returnForecastPointMetadata=false&returnReservoirMetadata=false&returnStationElements=false\")\n    output_file = f'{working_dir}/all_snotel_cdec_stations.json'\n\n    # Check if the request was successful (status code 200)\n    if response.status_code == 200:\n        # Decode the JSON content\n        json_content = response.json()\n\n        # Save the JSON content to a file\n        with open(output_file, 'w') as json_file:\n            json.dump(json_content, json_file, indent=2)\n        \n        print(f\"Data downloaded and saved to {output_file}\")\n    else:\n        print(f\"Failed to download data. Status code: {response.status_code}\")\n\t\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    download_station_json()\n    #get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-26\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nData downloaded and saved to /home/chetana/gridmet_test_run/all_snotel_cdec_stations.json\n",
  "history_begin_time" : 1703551864942,
  "history_end_time" : 1703551867027,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "CdzwJYOWL5qX",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n  \t\n  \told_messed_file = f\"{work_dir}/\"\n  \tcsv_file = f'{new_base_station_list_file}_swe_restored.csv'\n  \tstart_date = \"2018-01-01\"\n  \tend_date = \"2022-12-31\"\n\n  \tstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n  \t# print(station_locations)\n\n  \tresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n  \tfor station in station_locations:\n  \t  \tprint(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\n     station_name  elevation       lat        lon\n0        Adin Mtn       6190  41.23583 -120.79192\n1     Agua Canyon       8900  37.52217 -112.27118\n2      Albro Lake       8300  45.59723 -111.95902\n3  Alexander Lake        160  61.74967 -150.88967\n4  Alpine Meadows       3500  47.77957 -121.69847\nstation Adin Mtn completed.\nstation Agua Canyon completed.\nstation Albro Lake completed.\nstation Alexander Lake completed.\nstation Alpine Meadows completed.\nstation American Creek completed.\nstation Anchor River Divide completed.\nstation Anchorage Hillside completed.\nstation Aneroid Lake #2 completed.\nstation Aniak completed.\nstation Annie Springs completed.\nstation Apishapa completed.\nstation Arapaho Ridge completed.\nstation Arbuckle Mtn completed.\nstation Atigun Pass completed.\nstation Atlanta Summit completed.\nstation Atwater completed.\nstation Badger Pass completed.\nstation Baker Butte completed.\nstation Baker Butte Smt completed.\nstation Bald Mtn. completed.\nstation Baldy completed.\nstation Banfield Mountain completed.\nstation Banner Summit completed.\nstation Bar M completed.\nstation Barker Lakes completed.\nstation Base Camp completed.\nstation Basin Creek completed.\nstation Bassoo Peak completed.\nstation Bateman completed.\nstation Battle Mountain completed.\nstation Beagle Springs completed.\nstation Bear Basin completed.\nstation Bear Canyon completed.\nstation Bear Creek completed.\nstation Bear Grass completed.\nstation Bear Lake completed.\nstation Bear Mountain completed.\nstation Bear River completed.\nstation Bear River RS completed.\nstation Bear Saddle completed.\nstation Bear Trap Meadow completed.\nstation Beartooth Lake completed.\nstation Beartown completed.\nstation Beaver Ck Village completed.\nstation Beaver Creek completed.\nstation Beaver Dams completed.\nstation Beaver Divide completed.\nstation Beaver Head completed.\nstation Beaver Pass completed.\nstation Beaver Reservoir completed.\nstation Beaver Spring completed.\nstation Ben Lomond Peak completed.\nstation Ben Lomond Trail completed.\nstation Berry Creek completed.\nstation Berthoud Summit completed.\nstation Bettles Field completed.\nstation Bevans Cabin completed.\nstation Big Bend completed.\nstation Big Creek Sum completed.\nstation Big Creek Summit completed.\nstation Big Flat completed.\nstation Big Goose completed.\nstation Big Meadow completed.\nstation Big Red Mountain completed.\nstation Big Sandy Opening completed.\nstation Bigelow Camp completed.\nstation Billie Creek Divide completed.\nstation Bird Creek completed.\nstation Bison Lake completed.\nstation Bisson Creek completed.\nstation Black Bear completed.\nstation Black Flat-U.M. Ck completed.\nstation Black Mesa completed.\nstation Black Mountain completed.\nstation Black Pine completed.\nstation Blackhall Mtn completed.\nstation Blacks Fork Jct completed.\nstation Blacktail Mtn completed.\nstation Blackwater completed.\nstation Blazed Alder completed.\nstation Blewett Pass completed.\nstation Blind Bull Sum completed.\nstation Blind Park completed.\nstation Bloody Dick completed.\nstation Blue Lakes completed.\nstation Blue Mountain Spring completed.\nstation Bobs Hollow completed.\nstation Bogus Basin completed.\nstation Bone Springs Div completed.\nstation Bostetter R.S. completed.\nstation Boulder Mountain completed.\nstation Bourne completed.\nstation Bowman Springs completed.\nstation Box Canyon completed.\nstation Box Creek completed.\nstation Box Springs completed.\nstation Brackett Creek completed.\nstation Brian Head completed.\nstation Brighton completed.\nstation Bristlecone Trail completed.\nstation Brooklyn Lake completed.\nstation Brown Duck completed.\nstation Brown Top completed.\nstation Brumley completed.\nstation Brundage Reservoir completed.\nstation Buck Flat completed.\nstation Buck Pasture completed.\nstation Buckboard Flat completed.\nstation Buckinghorse completed.\nstation Buckskin Joe completed.\nstation Buckskin Lower completed.\nstation Buffalo Park completed.\nstation Bug Lake completed.\nstation Bumping Ridge completed.\nstation Bunchgrass Mdw completed.\nstation Burgess Junction completed.\nstation Burnside Lake completed.\nstation Burnt Mountain completed.\nstation Burnt Mtn completed.\nstation Burro Mountain completed.\nstation Burroughs Creek completed.\nstation Burts Miller Ranch completed.\nstation Butte completed.\nstation Calamity completed.\nstation Calvert Creek completed.\nstation Camas Creek Divide completed.\nstation Camp Jackson completed.\nstation Canyon completed.\nstation Carrot Basin completed.\nstation Carson Pass completed.\nstation Cascade #2 completed.\nstation Cascade Mountain completed.\nstation Cascade Summit completed.\nstation Casper Mtn. completed.\nstation Castle Creek completed.\nstation Castle Valley completed.\nstation Cave Mountain completed.\nstation Cayuse Pass completed.\nstation Cedar Pass completed.\nstation Chalender completed.\nstation Chalk Creek #1 completed.\nstation Chalk Creek #2 completed.\nstation Chamita completed.\nstation Chapman Tunnel completed.\nstation Chemult Alternate completed.\nstation Chena Lakes completed.\nstation Chepeta completed.\nstation Chicago Ridge completed.\nstation Chisana completed.\nstation Chocolate Gulch completed.\nstation Cinnabar Park completed.\nstation Clackamas Lake completed.\nstation Clayton Springs completed.\nstation Clear Creek #1 completed.\nstation Clear Creek #2 completed.\nstation Clear Lake completed.\nstation Cloud Peak Reservoir completed.\nstation Clover Meadow completed.\nstation Cochetopa Pass completed.\nstation Cold Springs completed.\nstation Cold Springs Camp completed.\nstation Coldfoot completed.\nstation Cole Canyon completed.\nstation Cole Creek completed.\nstation Columbia Basin completed.\nstation Columbine completed.\nstation Columbine Pass completed.\nstation Columbus Basin completed.\nstation Combination completed.\nstation Cool Creek completed.\nstation Cooper Lake completed.\nstation Copeland Lake completed.\nstation Copper Bottom completed.\nstation Copper Camp completed.\nstation Copper Mountain completed.\nstation Corduroy Flat completed.\nstation Coronado Trail completed.\nstation Corral completed.\nstation Corral Canyon completed.\nstation Corral Pass completed.\nstation Cottonwood Creek completed.\nstation Couch Summit completed.\nstation Cougar Mountain completed.\nstation County Line completed.\nstation Cozy Cove completed.\nstation Crab Creek completed.\nstation Crater Meadows completed.\nstation Crazyman Flat completed.\nstation Creamers Field completed.\nstation Crosho completed.\nstation Crow Creek completed.\nstation Crowder Flat completed.\nstation Crystal Lake completed.\nstation Css Lab completed.\nstation Culebra #2 completed.\nstation Cumbres Trestle completed.\nstation Currant Creek completed.\nstation Dahl Creek completed.\nstation Daisy Peak completed.\nstation Daly Creek completed.\nstation Daly Lake completed.\nstation Daniels-Strawberry completed.\nstation Darkhorse Lake completed.\nstation Deadman Creek completed.\nstation Deadman Hill completed.\nstation Deadwood Summit completed.\nstation Deer Park completed.\nstation Defiance Mines completed.\nstation Derr. completed.\nstation Diamond Lake completed.\nstation Diamond Peak completed.\nstation Dills Camp completed.\nstation Disaster Peak completed.\nstation Dismal Swamp completed.\nstation Divide completed.\nstation Divide Peak completed.\nstation Dollarhide Summit completed.\nstation Dome Lake completed.\nstation Donkey Reservoir completed.\nstation Dorsey Basin completed.\nstation Draw Creek completed.\nstation Dry Bread Pond completed.\nstation Dry Creek completed.\nstation Dry Fork completed.\nstation Dry Lake completed.\nstation Dungeness completed.\nstation Dupuyer Creek completed.\nstation Eagle Summit completed.\nstation East Boulder Mine completed.\nstation East Palmer completed.\nstation East Rim Divide completed.\nstation East Willow Creek completed.\nstation Easy Pass completed.\nstation Ebbetts Pass completed.\nstation Echo Lake completed.\nstation Echo Peak completed.\nstation EF Blacks Fork GS completed.\nstation Eilertson Meadows completed.\nstation El Diente Peak completed.\nstation Elbow Lake completed.\nstation Elk Butte completed.\nstation Elk Cabin completed.\nstation Elk Peak completed.\nstation Elk River completed.\nstation Elkhart Park G.S. completed.\nstation Elkhead Divide completed.\nstation Elliot Ridge completed.\nstation Emery Creek completed.\nstation Emigrant Springs completed.\nstation Emigrant Summit completed.\nstation Esther Island completed.\nstation Evening Star completed.\nstation Exit Glacier completed.\nstation Fallen Leaf completed.\nstation Farmington completed.\nstation Farmington Lower completed.\nstation Farnsworth Lake completed.\nstation Fawn Creek completed.\nstation Fielding Lake completed.\nstation Fifteenmile completed.\nstation Fish Ck completed.\nstation Fish Creek completed.\nstation Fish Lake completed.\nstation Fish Lake Utah completed.\nstation Fish Lk. completed.\nstation Fisher Creek completed.\nstation Five Points Lake completed.\nstation Flattop Mtn. completed.\nstation Flower Mountain completed.\nstation Fool Creek completed.\nstation Forestdale Creek completed.\nstation Fort Valley completed.\nstation Fort Yukon completed.\nstation Fourmile Lake completed.\nstation Franklin Basin completed.\nstation Fredonyer Peak completed.\nstation Fremont Pass completed.\nstation Frisco Divide completed.\nstation Frohner Meadow completed.\nstation Frostbite Bottom completed.\nstation Fry completed.\nstation Fry Canyon completed.\nstation Galena completed.\nstation Galena AK completed.\nstation Galena Summit completed.\nstation Gallegos Peak completed.\nstation Garden City Summit completed.\nstation Gardner Peak completed.\nstation Garfield R.S. completed.\nstation Garita Peak completed.\nstation Garver Creek completed.\nstation GBRC HQ completed.\nstation GBRC Meadows completed.\nstation George Creek completed.\nstation Gerber Reservoir completed.\nstation Giveout completed.\nstation Glen Cove completed.\nstation Gobblers Knob completed.\nstation Golconda completed.\nstation Gold Axe Camp completed.\nstation Gold Basin completed.\nstation Gold Center completed.\nstation Gold Mountain completed.\nstation Gooseberry RS completed.\nstation Gooseberry RS Up completed.\nstation Graham Guard Sta. completed.\nstation Grand Targhee completed.\nstation Grandview completed.\nstation Granite Creek completed.\nstation Granite Crk completed.\nstation Granite Peak completed.\nstation Grassy Lake completed.\nstation Grave Creek completed.\nstation Grave Springs completed.\nstation Grayback completed.\nstation Green Lake completed.\nstation Green Mountain completed.\nstation Greenpoint completed.\nstation Grizzly Peak completed.\nstation Gros Ventre Summit completed.\nstation Grouse Camp completed.\nstation Grouse Creek Divide completed.\nstation Gulkana River completed.\nstation Gunsight Pass completed.\nstation Gutz Peak completed.\nstation Hagans Meadow completed.\nstation Hams Fork completed.\nstation Hand Creek completed.\nstation Hannagan Meadows completed.\nstation Hansen Sawmill completed.\nstation Happy Jack completed.\nstation Hardscrabble completed.\nstation Harris Flat completed.\nstation Harts Pass completed.\nstation Hawkins Lake completed.\nstation Hawley Lake completed.\nstation Hayden Fork completed.\nstation Hayden Pass completed.\nstation Heavenly Valley completed.\nstation Heber completed.\nstation Heen Latinee completed.\nstation Hemlock Butte completed.\nstation Hewinta completed.\nstation Hickerson Park completed.\nstation Hidden Lake completed.\nstation High Lonesome completed.\nstation High Ridge completed.\nstation Hilts Creek completed.\nstation Hobble Creek completed.\nstation Hobbs Park completed.\nstation Hogg Pass completed.\nstation Hole-in-Mountain completed.\nstation Hole-in-Rock completed.\nstation Holland Meadows completed.\nstation Hoodoo Basin completed.\nstation Hoosier Pass completed.\nstation Hopewell completed.\nstation Horse Meadow completed.\nstation Horse Ridge completed.\nstation Hourglass Lake completed.\nstation Howard Prairie completed.\nstation Howell Canyon completed.\nstation Hozatka Lake completed.\nstation Hozomeen Camp completed.\nstation Huckleberry Creek completed.\nstation Humboldt Gulch completed.\nstation Huntington Horse completed.\nstation Hyndman completed.\nstation Idarado completed.\nstation Imnaviat Creek completed.\nstation Independence Camp completed.\nstation Independence Creek completed.\nstation Independence Lake completed.\nstation Independence Mine completed.\nstation Independence Pass completed.\nstation Indian Creek completed.\nstation Indian Pass completed.\nstation Indian Rock completed.\nstation Irish Taylor completed.\nstation Island Park completed.\nstation Ivanhoe completed.\nstation Jack Creek Upper completed.\nstation Jack Wade Jct completed.\nstation Jacks Peak completed.\nstation Jackson Peak completed.\nstation Jackwhacker Gulch completed.\nstation Jakes Creek completed.\nstation JL Meadow completed.\nstation Joe Wright completed.\nstation Johnsons Camp completed.\nstation Jones Corral completed.\nstation Jones Pass completed.\nstation Jump Off Joe completed.\nstation June Lake completed.\nstation Kalamazoo completed.\nstation Kantishna completed.\nstation Kelley R.S. completed.\nstation Kelly Station completed.\nstation Kenai Moose Pens completed.\nstation Kendall R.S. completed.\nstation Kilfoil Creek completed.\nstation Kiln completed.\nstation Kimberly Mine completed.\nstation King Mountain completed.\nstation Kings Cabin completed.\nstation Kirwin completed.\nstation Klondike Narrows completed.\nstation Kolob completed.\nstation Kraft Creek completed.\nstation Lake Creek R.S. completed.\nstation Lake Eldora completed.\nstation Lake Irene completed.\nstation Lakefork #1 completed.\nstation Lakefork #3 completed.\nstation Lakefork Basin completed.\nstation Lakeview Ridge completed.\nstation Lamance Creek completed.\nstation Lamoille #3 completed.\nstation Lamoille Upper completed.\nstation Laprele Creek completed.\nstation Larsen Creek completed.\nstation Lasal Mountain completed.\nstation Lasal Mountain-Lower completed.\nstation Laurel Draw completed.\nstation Leavitt Lake completed.\nstation Leavitt Meadows completed.\nstation Lee Canyon completed.\nstation Lemhi Ridge completed.\nstation Lewis Lake Divide completed.\nstation Lewis Peak completed.\nstation Lick Creek completed.\nstation Lightning Ridge completed.\nstation Lily Lake completed.\nstation Lily Pond completed.\nstation Little Bear completed.\nstation Little Chena Ridge completed.\nstation Little Goose completed.\nstation Little Grassy completed.\nstation Little Meadows completed.\nstation Little Snake River completed.\nstation Little Valley completed.\nstation Little Warm completed.\nstation Lizard Head Pass completed.\nstation Lobdell Lake completed.\nstation Lolo Pass completed.\nstation Lone Cone completed.\nstation Lone Mountain completed.\nstation Lone Pine completed.\nstation Lonesome Beaver completed.\nstation Long Draw Resv completed.\nstation Long Flat completed.\nstation Long Lake completed.\nstation Long Valley completed.\nstation Long Valley Jct completed.\nstation Lookout completed.\nstation Lookout Mountain completed.\nstation Lookout Peak completed.\nstation Loomis Park completed.\nstation Lost Creek Resv completed.\nstation Lost Dog completed.\nstation Lost Horse completed.\nstation Lost Lake completed.\nstation Lost-Wood Divide completed.\nstation Louis Meadow completed.\nstation Loveland Basin completed.\nstation Lower Kachemak Creek completed.\nstation Lower Twin completed.\nstation Lubrecht Flume completed.\nstation Lucky Strike completed.\nstation Lyman Lake completed.\nstation Lynn Lake completed.\nstation Lynx Pass completed.\nstation Madison Butte completed.\nstation Madison Plateau completed.\nstation Magic Mountain completed.\nstation Mammoth-Cottonwood completed.\nstation Mancos completed.\nstation Many Glacier completed.\nstation Marion Forks completed.\nstation Marlette Lake completed.\nstation Marquette completed.\nstation Marten Ridge completed.\nstation Maverick Fork completed.\nstation May Creek completed.\nstation Mc Clure Pass completed.\nstation Mccoy Park completed.\nstation McGrath completed.\nstation Mckenzie completed.\nstation Mcknight Cabin completed.\nstation Mcneil Canyon completed.\nstation Mcneil River SGS completed.\nstation Meadow Lake completed.\nstation Meadows Pass completed.\nstation Med Bow completed.\nstation Medano Pass completed.\nstation Merchant Valley completed.\nstation Merritt Mountain completed.\nstation Mesa Lakes completed.\nstation MF Nooksack completed.\nstation Mica Creek completed.\nstation Michigan Creek completed.\nstation Midas completed.\nstation Middle Creek completed.\nstation Middle Fork Bradley completed.\nstation Middle Fork Camp completed.\nstation Middle Powder completed.\nstation Midway Valley completed.\nstation Milk Shakes completed.\nstation Mill Creek Summit completed.\nstation Mill-D North completed.\nstation Miller Woods completed.\nstation Mineral Creek completed.\nstation Mining Fork completed.\nstation Molas Lake completed.\nstation Monahan Flat completed.\nstation Monitor Pass completed.\nstation Monte Cristo completed.\nstation Monument Creek completed.\nstation Monument Peak completed.\nstation Moon Pass completed.\nstation Moonshine completed.\nstation Moore Creek Bridge completed.\nstation Moose Creek completed.\nstation Moraine completed.\nstation Mores Creek Summit completed.\nstation Morgan Creek completed.\nstation Mormon Mountain completed.\nstation Mormon Mtn Summit completed.\nstation Morse Lake completed.\nstation Mosby Mtn. completed.\nstation Moscow Mountain completed.\nstation Moses Mtn completed.\nstation Mosquito Ridge completed.\nstation Moss Peak completed.\nstation Moss Springs completed.\nstation Mount Crag completed.\nstation Mount Gardner completed.\nstation Mount Lockhart completed.\nstation Mountain Meadows completed.\nstation Mowich completed.\nstation Mt Baldy completed.\nstation Mt Hood Test Site completed.\nstation Mt Pennell completed.\nstation Mt Rose Ski Area completed.\nstation Mt. Alyeska completed.\nstation Mt. Eyak completed.\nstation Mt. Howard completed.\nstation Mt. Ryan completed.\nstation Mt. Tebo completed.\nstation Muckamuck completed.\nstation Mud Flat completed.\nstation Mud Ridge completed.\nstation Mule Creek completed.\nstation Munson Ridge completed.\nstation Myrtle Creek completed.\nstation N Fk Elk Creek completed.\nstation Nast Lake completed.\nstation Navajo Whiskey Ck completed.\nstation Nenana completed.\nstation Nevada Ridge completed.\nstation Never Summer completed.\nstation New Crescent Lake completed.\nstation New Fork Lake completed.\nstation Nez Perce Camp completed.\nstation Niwot completed.\nstation Noisy Basin completed.\nstation North Costilla completed.\nstation North Fork completed.\nstation North Fork Jocko completed.\nstation North French Creek completed.\nstation North Lost Trail completed.\nstation North Rapid Creek completed.\nstation Northeast Entrance completed.\nstation Nuka Glacier completed.\nstation Nutrioso completed.\nstation Oak Creek completed.\nstation Ochoco Meadows completed.\nstation Olallie Meadows completed.\nstation ONeil Creek completed.\nstation Onion Park completed.\nstation Overland Res. completed.\nstation Owl Creek completed.\nstation Oxford Spring completed.\nstation Palisades Tahoe completed.\nstation Palo completed.\nstation Panguitch Lake RS completed.\nstation Paradise completed.\nstation Paradise Hill completed.\nstation Pargon Creek completed.\nstation Park Cone completed.\nstation Park Creek Ridge completed.\nstation Park Reservoir completed.\nstation Parker Peak completed.\nstation Parleys Summit completed.\nstation Parleys Upper completed.\nstation Parrish Creek completed.\nstation Payson R.S. completed.\nstation Peavine Ridge completed.\nstation Pebble Creek completed.\nstation Pepper Creek completed.\nstation Peterson Meadows completed.\nstation Phantom Valley completed.\nstation Phillips Bench completed.\nstation Pickfoot Creek completed.\nstation Pickle Keg completed.\nstation Pierce R.S. completed.\nstation Pigtail Peak completed.\nstation Pike Creek completed.\nstation Pine Creek completed.\nstation Pine Creek Pass completed.\nstation Pinto Rock completed.\nstation Placer Basin completed.\nstation Pocket Creek completed.\nstation Poison Flat completed.\nstation Pole Canyon completed.\nstation Pole Creek R.S. completed.\nstation Poorman Creek completed.\nstation Pope Ridge completed.\nstation Porcupine completed.\nstation Porphyry Creek completed.\nstation Port Graham completed.\nstation Porter Canyon completed.\nstation Potato Hill completed.\nstation Powder Mountain completed.\nstation Powder River Pass completed.\nstation Prairie completed.\nstation Promontory completed.\nstation Prudhoe Bay completed.\nstation Quartz Mountain completed.\nstation Quartz Peak completed.\nstation Quemazon completed.\nstation Rabbit Ears completed.\nstation Ragged Mountain completed.\nstation Railroad Overpass completed.\nstation Rainbow Canyon completed.\nstation Rainy Pass completed.\nstation Rawah completed.\nstation Red Hill completed.\nstation Red Mountain Pass completed.\nstation Red Pine Ridge completed.\nstation Red River Pass #2 completed.\nstation Redden Mine Lwr completed.\nstation Rees Flat completed.\nstation Reno Hill completed.\nstation Rex River completed.\nstation Reynolds Creek completed.\nstation Rice Park completed.\nstation Rio Santa Barbara completed.\nstation Ripple Creek completed.\nstation Roach completed.\nstation Roaring River completed.\nstation Rock Creek completed.\nstation Rock Springs completed.\nstation Rocker Peak completed.\nstation Rockwood GS completed.\nstation Rocky Basin-Settleme completed.\nstation Rocky Boy completed.\nstation Rocky Point completed.\nstation Rough And Tumble completed.\nstation Rubicon #2 completed.\nstation S Fork Shields completed.\nstation Sacajawea completed.\nstation Saddle Mountain completed.\nstation Saddle Mtn. completed.\nstation Sage Creek Basin completed.\nstation Sagwon completed.\nstation Saint Elmo completed.\nstation Salmon Meadows completed.\nstation Salt Creek Falls completed.\nstation Salt River Summit completed.\nstation San Antonio Sink completed.\nstation Sand Lake completed.\nstation Sandstone RS completed.\nstation Santa Fe completed.\nstation Santaquin Meadows completed.\nstation Santiam Jct. completed.\nstation Sargents Mesa completed.\nstation Sasse Ridge completed.\nstation Satus Pass completed.\nstation Savage Pass completed.\nstation Sawmill Ridge completed.\nstation Sawtooth completed.\nstation Schneider Meadows completed.\nstation Schofield Pass completed.\nstation Schwartz Lake completed.\nstation Schweitzer Basin completed.\nstation Scotch Creek completed.\nstation Secesh Summit completed.\nstation Sedgwick Peak completed.\nstation Seeley Creek completed.\nstation Seine Creek completed.\nstation Senorita Divide #2 completed.\nstation Sentinel Butte completed.\nstation Sevenmile Marsh completed.\nstation Seventysix Creek completed.\nstation Shanghi Summit completed.\nstation Sharkstooth completed.\nstation Sheep Canyon completed.\nstation Sheep Mtn. completed.\nstation Sheldon completed.\nstation Shell Creek completed.\nstation Sherwin completed.\nstation Short Creek completed.\nstation Shower Falls completed.\nstation Shuree completed.\nstation Sierra Blanca completed.\nstation Signal Peak completed.\nstation Silver Creek completed.\nstation Silver Creek Divide completed.\nstation Silver Creek Nv completed.\nstation Silvies completed.\nstation Skalkaho Summit completed.\nstation Skate Creek completed.\nstation Skookum Creek completed.\nstation Slagamelt Lakes completed.\nstation Sleeping Woman completed.\nstation Slug Creek Divide completed.\nstation Slumgullion completed.\nstation Smiley Mountain completed.\nstation Smith  Morehouse completed.\nstation Smith Ridge completed.\nstation Snake River Station completed.\nstation Snider Basin completed.\nstation Snow Mountain completed.\nstation Snowbird completed.\nstation Snowslide Canyon completed.\nstation Snowstorm Mtn completed.\nstation Soldier Park completed.\nstation Soldier R.S. completed.\nstation Somsen Ranch completed.\nstation Sonora Pass completed.\nstation Sourdough Gulch completed.\nstation South Brush Creek completed.\nstation South Colony completed.\nstation South Fork Bull Run completed.\nstation South Mtn. completed.\nstation South Pass completed.\nstation Spencer Meadow completed.\nstation Spirit Lake completed.\nstation Spirit Lk completed.\nstation Spratt Creek completed.\nstation Spring Creek completed.\nstation Spring Creek Divide completed.\nstation Spruce Springs completed.\nstation Spud Mountain completed.\nstation Spur Park completed.\nstation Squaw Flat completed.\nstation St. Lawrence Alt completed.\nstation Stag Mountain completed.\nstation Stahl Peak completed.\nstation Stampede Pass completed.\nstation Starr Ridge completed.\nstation State Line completed.\nstation Steel Creek Park completed.\nstation Stevens Pass completed.\nstation Stickney Mill completed.\nstation Stillwater Creek completed.\nstation Strawberry completed.\nstation Strawberry Divide completed.\nstation Stringer Creek completed.\nstation Stryker Basin completed.\nstation Stuart Mountain completed.\nstation Stump Lakes completed.\nstation Sucker Creek completed.\nstation Sugarloaf Mtn completed.\nstation Summer Rim completed.\nstation Summit Creek completed.\nstation Summit Lake completed.\nstation Summit Lk completed.\nstation Summit Meadow completed.\nstation Summit Ranch completed.\nstation Sun Pass completed.\nstation Sunflower Flat completed.\nstation Sunset completed.\nstation Surprise Lakes completed.\nstation Susitna Valley High completed.\nstation Suu Ranch completed.\nstation Swamp Creek completed.\nstation Swan Lake Mtn completed.\nstation Swede Peak completed.\nstation Swift Creek completed.\nstation Sylvan Lake completed.\nstation Sylvan Road completed.\nstation Tahoe City Cross completed.\nstation Takka Wiiya completed.\nstation Taos Powderhorn completed.\nstation Taos Pueblo completed.\nstation Taylor Butte completed.\nstation Taylor Canyon completed.\nstation Taylor Green completed.\nstation Telaquana Lake completed.\nstation Temple Fork completed.\nstation Tent Mtn Lower completed.\nstation Tepee Creek completed.\nstation Teuchet Creek completed.\nstation Thaynes Canyon completed.\nstation Thistle Flat completed.\nstation Three Creeks Meadow completed.\nstation Thumb Divide completed.\nstation Thunder Basin completed.\nstation Tie Creek completed.\nstation Timber Creek completed.\nstation Timberline completed.\nstation Timpanogos Divide completed.\nstation Tinkham Creek completed.\nstation Tipton completed.\nstation Tizer Basin completed.\nstation Toe Jam completed.\nstation Togwotee Pass completed.\nstation Tok completed.\nstation Toketee Airstrip completed.\nstation Tokositna Valley completed.\nstation Tolby completed.\nstation Tony Grove Lake completed.\nstation Tony Grove RS completed.\nstation Touchet completed.\nstation Tower completed.\nstation Townsend Creek completed.\nstation Trapper Lake completed.\nstation Tres Ritos completed.\nstation Trial Lake completed.\nstation Trinchera completed.\nstation Trinity completed.\nstation Trinity Mtn. completed.\nstation Triple Peak completed.\nstation Trough completed.\nstation Trout Creek completed.\nstation Truckee #2 completed.\nstation Turnagain Pass completed.\nstation Twelvemile Creek completed.\nstation Twin Lakes completed.\nstation Two Ocean Plateau completed.\nstation University Camp completed.\nstation Upper Chena completed.\nstation Upper Joes Valley completed.\nstation Upper Nome Creek completed.\nstation Upper Rio Grande completed.\nstation Upper San Juan completed.\nstation Upper Taylor completed.\nstation Upper Tsaina River completed.\nstation Upper Wheeler completed.\nstation Usu Doc Daniel completed.\nstation Ute Creek completed.\nstation Vacarro Springs completed.\nstation Vacas Locas completed.\nstation Vail Mountain completed.\nstation Vallecito completed.\nstation Van Wyck completed.\nstation Vernon Creek completed.\nstation Vienna Mine completed.\nstation Virginia Lakes Ridge completed.\nstation Wager Gulch completed.\nstation Waldron completed.\nstation Ward Creek #3 completed.\nstation Ward Mountain completed.\nstation Warm Springs completed.\nstation Waterhole completed.\nstation Webber Springs completed.\nstation Webster Flat completed.\nstation Wells Creek completed.\nstation Weminuche Creek completed.\nstation Wesner Springs completed.\nstation West Branch completed.\nstation West Yellowstone completed.\nstation Wheeler Peak completed.\nstation Whiskey Ck completed.\nstation Whiskey Creek completed.\nstation Whiskey Park completed.\nstation White Elephant completed.\nstation White Horse Lake completed.\nstation White Mill completed.\nstation White Pass E.S. completed.\nstation White River #1 completed.\nstation White River Nv completed.\nstation Widtsoe #3 completed.\nstation Wilbur Bench completed.\nstation Wild Basin completed.\nstation Wildcat completed.\nstation Wildhorse Divide completed.\nstation Willow Creek completed.\nstation Willow Creek Pass completed.\nstation Willow Park completed.\nstation Wilson Creek completed.\nstation Windy Peak completed.\nstation Wolf Creek completed.\nstation Wolf Creek Peak completed.\nstation Wolf Creek Summit completed.\nstation Wolverine completed.\nstation Wood Creek completed.\nstation Workman Creek completed.\nstation Wrigley Creek completed.\nstation Yankee Reservoir completed.\nstation Younts Peak completed.\nstation Zirkel completed.\n",
  "history_begin_time" : 1703547415927,
  "history_end_time" : 1703547417202,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "zAOv9foyGpgz",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n  \tnew_base_df = pd.read_csv(new_base_station_list_file)\n  \tprint(new_base_df.head())\n    \n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored.csv'\n    start_date = \"2018-01-01\"\n    end_date = \"2022-12-31\"\n\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    # print(station_locations)\n\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for station in station_locations:\n        print(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/zAOv9foyGpgz/data_snotel_station_only.py\", line 72\n    old_messed_file = f\"{work_dir}/\"\n                                    ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703547389871,
  "history_end_time" : 1703547389926,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "mtbAFNCTprYt",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n  \ndef get_swe_observations_from_snotel_cdec():\n  \tnew_base_station_list_file = f\"{work_dir}/training_snotel_station_list_elevation.csv\"\n    new_base_df = pd.read_csv(new_base_station_list_file)\n    print(new_base_df.head())\n    \n    old_messed_file = f\"{work_dir}/\"\n    csv_file = f'{new_base_station_list_file}_swe_restored.csv'\n    start_date = \"2018-01-01\"\n    end_date = \"2022-12-31\"\n\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    # print(station_locations)\n\n    result_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\n    for station in station_locations:\n        print(f'station {station[\"name\"]} completed.')\n\n#         location_name = station['name']\n#         location_triplet = station['triplet']\n#         location_elevation = station['elevation']\n#         location_station_lat = station['location']['lat']\n#         location_station_long = station['location']['lng']\n\n#         url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n#         r = requests.get(url)\n#         text = remove_commented_lines(r.text)\n#         reader = csv.DictReader(io.StringIO(text))\n#         json_data = json.loads(json.dumps(list(reader)))\n#         for entry in json_data:\n#             required_data = {'station_name': location_name,\n#                              'date': entry['Date'], \n#                              'lat': location_station_lat, \n#                              'lon': location_station_long,\n#                              'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n#             result_df.loc[len(result_df.index)] = required_data\n\n#         #print(result_df.head())\n#         #break\n\n#     # Save the DataFrame to a CSV file\n#     result_df.to_csv(csv_file, index=False)\n\nif __name__ == \"__main__\":\n    get_swe_observations_from_snotel_cdec()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/mtbAFNCTprYt/data_snotel_station_only.py\", line 69\n    new_base_df = pd.read_csv(new_base_station_list_file)\n                                                         ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703547340435,
  "history_end_time" : 1703547340489,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "GbxgpgqPQOsR",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_corrected.csv'\nstart_date = \"2018-01-01\"\nend_date = \"2022-12-31\"\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n# print(station_locations)\n\nresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\nfor station in station_locations:\n    print(f'station {station[\"name\"]} completed.')\n    \n    location_name = station['name']\n    location_triplet = station['triplet']\n    location_elevation = station['elevation']\n    location_station_lat = station['location']['lat']\n    location_station_long = station['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'station_name': location_name,\n                         'date': entry['Date'], \n                         'lat': location_station_lat, \n                         'lon': location_station_long,\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n          \n    #print(result_df.head())\n    #break\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nstation Adin Mtn completed.\nstation Agua Canyon completed.\nstation Albro Lake completed.\nstation Alexander Lake completed.\nstation Alpine Meadows completed.\nstation American Creek completed.\nstation Anchor River Divide completed.\nstation Anchorage Hillside completed.\nstation Aneroid Lake #2 completed.\nstation Aniak completed.\nstation Annie Springs completed.\nstation Apishapa completed.\nstation Arapaho Ridge completed.\nstation Arbuckle Mtn completed.\nstation Atigun Pass completed.\nstation Atlanta Summit completed.\nstation Atwater completed.\nstation Badger Pass completed.\nstation Baker Butte completed.\nstation Baker Butte Smt completed.\nstation Bald Mtn. completed.\nstation Baldy completed.\nstation Banfield Mountain completed.\nstation Banner Summit completed.\nstation Bar M completed.\nstation Barker Lakes completed.\nstation Base Camp completed.\nstation Basin Creek completed.\nstation Bassoo Peak completed.\nstation Bateman completed.\nstation Battle Mountain completed.\nstation Beagle Springs completed.\nstation Bear Basin completed.\nstation Bear Canyon completed.\nstation Bear Creek completed.\nstation Bear Grass completed.\nstation Bear Lake completed.\nstation Bear Mountain completed.\nstation Bear River completed.\nstation Bear River RS completed.\nstation Bear Saddle completed.\nstation Bear Trap Meadow completed.\nstation Beartooth Lake completed.\nstation Beartown completed.\nstation Beaver Ck Village completed.\nstation Beaver Creek completed.\nstation Beaver Dams completed.\nstation Beaver Divide completed.\nstation Beaver Head completed.\nstation Beaver Pass completed.\nstation Beaver Reservoir completed.\nstation Beaver Spring completed.\nstation Ben Lomond Peak completed.\nstation Ben Lomond Trail completed.\nstation Berry Creek completed.\nstation Berthoud Summit completed.\nstation Bettles Field completed.\nstation Bevans Cabin completed.\nstation Big Bend completed.\nstation Big Creek Sum completed.\nstation Big Creek Summit completed.\nstation Big Flat completed.\nstation Big Goose completed.\nstation Big Meadow completed.\nstation Big Red Mountain completed.\nstation Big Sandy Opening completed.\nstation Bigelow Camp completed.\nstation Billie Creek Divide completed.\nstation Bird Creek completed.\nstation Bison Lake completed.\nstation Bisson Creek completed.\nstation Black Bear completed.\nstation Black Flat-U.M. Ck completed.\nstation Black Mesa completed.\nstation Black Mountain completed.\nstation Black Pine completed.\nstation Blackhall Mtn completed.\nstation Blacks Fork Jct completed.\nstation Blacktail Mtn completed.\nstation Blackwater completed.\nstation Blazed Alder completed.\nstation Blewett Pass completed.\nstation Blind Bull Sum completed.\nstation Blind Park completed.\nstation Bloody Dick completed.\nstation Blue Lakes completed.\nstation Blue Mountain Spring completed.\nstation Bobs Hollow completed.\nstation Bogus Basin completed.\nstation Bone Springs Div completed.\nstation Bostetter R.S. completed.\nstation Boulder Mountain completed.\nstation Bourne completed.\nstation Bowman Springs completed.\nstation Box Canyon completed.\nstation Box Creek completed.\nstation Box Springs completed.\nstation Brackett Creek completed.\nstation Brian Head completed.\nstation Brighton completed.\nstation Bristlecone Trail completed.\nstation Brooklyn Lake completed.\nstation Brown Duck completed.\nstation Brown Top completed.\nstation Brumley completed.\nstation Brundage Reservoir completed.\nstation Buck Flat completed.\nstation Buck Pasture completed.\nstation Buckboard Flat completed.\nstation Buckinghorse completed.\nstation Buckskin Joe completed.\nstation Buckskin Lower completed.\nstation Buffalo Park completed.\nstation Bug Lake completed.\nstation Bumping Ridge completed.\nstation Bunchgrass Mdw completed.\nstation Burgess Junction completed.\nstation Burnside Lake completed.\nstation Burnt Mountain completed.\nstation Burnt Mtn completed.\nstation Burro Mountain completed.\nstation Burroughs Creek completed.\nstation Burts Miller Ranch completed.\nstation Butte completed.\nstation Calamity completed.\nstation Calvert Creek completed.\nstation Camas Creek Divide completed.\nstation Camp Jackson completed.\nstation Canyon completed.\nstation Carrot Basin completed.\nstation Carson Pass completed.\nstation Cascade #2 completed.\nstation Cascade Mountain completed.\nstation Cascade Summit completed.\nstation Casper Mtn. completed.\nstation Castle Creek completed.\nstation Castle Valley completed.\nstation Cave Mountain completed.\nstation Cayuse Pass completed.\nstation Cedar Pass completed.\nstation Chalender completed.\nstation Chalk Creek #1 completed.\nstation Chalk Creek #2 completed.\nstation Chamita completed.\nstation Chapman Tunnel completed.\nstation Chemult Alternate completed.\nstation Chena Lakes completed.\nstation Chepeta completed.\nstation Chicago Ridge completed.\nstation Chisana completed.\nstation Chocolate Gulch completed.\nstation Cinnabar Park completed.\nstation Clackamas Lake completed.\nstation Clayton Springs completed.\nstation Clear Creek #1 completed.\nstation Clear Creek #2 completed.\nstation Clear Lake completed.\nstation Cloud Peak Reservoir completed.\nstation Clover Meadow completed.\nstation Cochetopa Pass completed.\nstation Cold Springs completed.\nstation Cold Springs Camp completed.\nstation Coldfoot completed.\nstation Cole Canyon completed.\nstation Cole Creek completed.\nstation Columbia Basin completed.\nstation Columbine completed.\nstation Columbine Pass completed.\nstation Columbus Basin completed.\nstation Combination completed.\nstation Cool Creek completed.\nstation Cooper Lake completed.\nstation Copeland Lake completed.\nstation Copper Bottom completed.\nstation Copper Camp completed.\nstation Copper Mountain completed.\nstation Corduroy Flat completed.\nstation Coronado Trail completed.\nstation Corral completed.\nstation Corral Canyon completed.\nstation Corral Pass completed.\nstation Cottonwood Creek completed.\nstation Couch Summit completed.\nstation Cougar Mountain completed.\nstation County Line completed.\nstation Cozy Cove completed.\nstation Crab Creek completed.\nstation Crater Meadows completed.\nstation Crazyman Flat completed.\nstation Creamers Field completed.\nstation Crosho completed.\nstation Crow Creek completed.\nstation Crowder Flat completed.\nstation Crystal Lake completed.\nstation Css Lab completed.\nstation Culebra #2 completed.\nstation Cumbres Trestle completed.\nstation Currant Creek completed.\nstation Dahl Creek completed.\nstation Daisy Peak completed.\nstation Daly Creek completed.\nstation Daly Lake completed.\nstation Daniels-Strawberry completed.\nstation Darkhorse Lake completed.\nstation Deadman Creek completed.\nstation Deadman Hill completed.\nstation Deadwood Summit completed.\nstation Deer Park completed.\nstation Defiance Mines completed.\nstation Derr. completed.\nstation Diamond Lake completed.\nstation Diamond Peak completed.\nstation Dills Camp completed.\nstation Disaster Peak completed.\nstation Dismal Swamp completed.\nstation Divide completed.\nstation Divide Peak completed.\nstation Dollarhide Summit completed.\nstation Dome Lake completed.\nstation Donkey Reservoir completed.\nstation Dorsey Basin completed.\nstation Draw Creek completed.\nstation Dry Bread Pond completed.\nstation Dry Creek completed.\nstation Dry Fork completed.\nstation Dry Lake completed.\nstation Dungeness completed.\nstation Dupuyer Creek completed.\nstation Eagle Summit completed.\nstation East Boulder Mine completed.\nstation East Palmer completed.\nstation East Rim Divide completed.\nstation East Willow Creek completed.\nstation Easy Pass completed.\nstation Ebbetts Pass completed.\nstation Echo Lake completed.\nstation Echo Peak completed.\nstation EF Blacks Fork GS completed.\nstation Eilertson Meadows completed.\nstation El Diente Peak completed.\nstation Elbow Lake completed.\nstation Elk Butte completed.\nstation Elk Cabin completed.\nstation Elk Peak completed.\nstation Elk River completed.\nstation Elkhart Park G.S. completed.\nstation Elkhead Divide completed.\nstation Elliot Ridge completed.\nstation Emery Creek completed.\nstation Emigrant Springs completed.\nstation Emigrant Summit completed.\nstation Esther Island completed.\nstation Evening Star completed.\nstation Exit Glacier completed.\nstation Fallen Leaf completed.\nstation Farmington completed.\nstation Farmington Lower completed.\nstation Farnsworth Lake completed.\nstation Fawn Creek completed.\nstation Fielding Lake completed.\nstation Fifteenmile completed.\nstation Fish Ck completed.\nstation Fish Creek completed.\nstation Fish Lake completed.\nstation Fish Lake Utah completed.\nstation Fish Lk. completed.\nstation Fisher Creek completed.\nstation Five Points Lake completed.\nstation Flattop Mtn. completed.\nstation Flower Mountain completed.\nstation Fool Creek completed.\nstation Forestdale Creek completed.\nstation Fort Valley completed.\nstation Fort Yukon completed.\nstation Fourmile Lake completed.\nstation Franklin Basin completed.\nstation Fredonyer Peak completed.\nstation Fremont Pass completed.\nstation Frisco Divide completed.\nstation Frohner Meadow completed.\nstation Frostbite Bottom completed.\nstation Fry completed.\nstation Fry Canyon completed.\nstation Galena completed.\nstation Galena AK completed.\nstation Galena Summit completed.\nstation Gallegos Peak completed.\nstation Garden City Summit completed.\nstation Gardner Peak completed.\nstation Garfield R.S. completed.\nstation Garita Peak completed.\nstation Garver Creek completed.\nstation GBRC HQ completed.\nstation GBRC Meadows completed.\nstation George Creek completed.\nstation Gerber Reservoir completed.\nstation Giveout completed.\nstation Glen Cove completed.\nstation Gobblers Knob completed.\nstation Golconda completed.\nstation Gold Axe Camp completed.\nstation Gold Basin completed.\nstation Gold Center completed.\nstation Gold Mountain completed.\nstation Gooseberry RS completed.\nstation Gooseberry RS Up completed.\nstation Graham Guard Sta. completed.\nstation Grand Targhee completed.\nstation Grandview completed.\nstation Granite Creek completed.\nstation Granite Crk completed.\nstation Granite Peak completed.\nstation Grassy Lake completed.\nstation Grave Creek completed.\nstation Grave Springs completed.\nstation Grayback completed.\nstation Green Lake completed.\nstation Green Mountain completed.\nstation Greenpoint completed.\nstation Grizzly Peak completed.\nstation Gros Ventre Summit completed.\nstation Grouse Camp completed.\nstation Grouse Creek Divide completed.\nstation Gulkana River completed.\nstation Gunsight Pass completed.\nstation Gutz Peak completed.\nstation Hagans Meadow completed.\nstation Hams Fork completed.\nstation Hand Creek completed.\nstation Hannagan Meadows completed.\nstation Hansen Sawmill completed.\nstation Happy Jack completed.\nstation Hardscrabble completed.\nstation Harris Flat completed.\nstation Harts Pass completed.\nstation Hawkins Lake completed.\nstation Hawley Lake completed.\nstation Hayden Fork completed.\nstation Hayden Pass completed.\nstation Heavenly Valley completed.\nstation Heber completed.\nstation Heen Latinee completed.\nstation Hemlock Butte completed.\nstation Hewinta completed.\nstation Hickerson Park completed.\nstation Hidden Lake completed.\nstation High Lonesome completed.\nstation High Ridge completed.\nstation Hilts Creek completed.\nstation Hobble Creek completed.\nstation Hobbs Park completed.\nstation Hogg Pass completed.\nstation Hole-in-Mountain completed.\nstation Hole-in-Rock completed.\nstation Holland Meadows completed.\nstation Hoodoo Basin completed.\nstation Hoosier Pass completed.\nstation Hopewell completed.\nstation Horse Meadow completed.\nstation Horse Ridge completed.\nstation Hourglass Lake completed.\nstation Howard Prairie completed.\nstation Howell Canyon completed.\nstation Hozatka Lake completed.\nstation Hozomeen Camp completed.\nstation Huckleberry Creek completed.\nstation Humboldt Gulch completed.\nstation Huntington Horse completed.\nstation Hyndman completed.\nstation Idarado completed.\nstation Imnaviat Creek completed.\nstation Independence Camp completed.\nstation Independence Creek completed.\nstation Independence Lake completed.\nstation Independence Mine completed.\nstation Independence Pass completed.\nstation Indian Creek completed.\nstation Indian Pass completed.\nstation Indian Rock completed.\nstation Irish Taylor completed.\nstation Island Park completed.\nstation Ivanhoe completed.\nstation Jack Creek Upper completed.\nstation Jack Wade Jct completed.\nstation Jacks Peak completed.\nstation Jackson Peak completed.\nstation Jackwhacker Gulch completed.\nstation Jakes Creek completed.\nstation JL Meadow completed.\nstation Joe Wright completed.\nstation Johnsons Camp completed.\nstation Jones Corral completed.\nstation Jones Pass completed.\nstation Jump Off Joe completed.\nstation June Lake completed.\nstation Kalamazoo completed.\nstation Kantishna completed.\nstation Kelley R.S. completed.\nstation Kelly Station completed.\nstation Kenai Moose Pens completed.\nstation Kendall R.S. completed.\nstation Kilfoil Creek completed.\nstation Kiln completed.\nstation Kimberly Mine completed.\nstation King Mountain completed.\nstation Kings Cabin completed.\nstation Kirwin completed.\nstation Klondike Narrows completed.\nstation Kolob completed.\nstation Kraft Creek completed.\nstation Lake Creek R.S. completed.\nstation Lake Eldora completed.\nstation Lake Irene completed.\nstation Lakefork #1 completed.\nstation Lakefork #3 completed.\nstation Lakefork Basin completed.\nstation Lakeview Ridge completed.\nstation Lamance Creek completed.\nstation Lamoille #3 completed.\nstation Lamoille Upper completed.\nstation Laprele Creek completed.\nstation Larsen Creek completed.\nstation Lasal Mountain completed.\nstation Lasal Mountain-Lower completed.\nstation Laurel Draw completed.\nstation Leavitt Lake completed.\nstation Leavitt Meadows completed.\nstation Lee Canyon completed.\nstation Lemhi Ridge completed.\nstation Lewis Lake Divide completed.\nstation Lewis Peak completed.\nstation Lick Creek completed.\nstation Lightning Ridge completed.\nstation Lily Lake completed.\nstation Lily Pond completed.\nstation Little Bear completed.\nstation Little Chena Ridge completed.\nstation Little Goose completed.\nstation Little Grassy completed.\nstation Little Meadows completed.\nstation Little Snake River completed.\nstation Little Valley completed.\nstation Little Warm completed.\nstation Lizard Head Pass completed.\nstation Lobdell Lake completed.\nstation Lolo Pass completed.\nstation Lone Cone completed.\nstation Lone Mountain completed.\nstation Lone Pine completed.\nstation Lonesome Beaver completed.\nstation Long Draw Resv completed.\nstation Long Flat completed.\nstation Long Lake completed.\nstation Long Valley completed.\nstation Long Valley Jct completed.\nstation Lookout completed.\nstation Lookout Mountain completed.\nstation Lookout Peak completed.\nstation Loomis Park completed.\nstation Lost Creek Resv completed.\nstation Lost Dog completed.\nstation Lost Horse completed.\nstation Lost Lake completed.\nstation Lost-Wood Divide completed.\nstation Louis Meadow completed.\nstation Loveland Basin completed.\nstation Lower Kachemak Creek completed.\nstation Lower Twin completed.\nstation Lubrecht Flume completed.\nstation Lucky Strike completed.\nstation Lyman Lake completed.\nstation Lynn Lake completed.\nstation Lynx Pass completed.\nstation Madison Butte completed.\nstation Madison Plateau completed.\nstation Magic Mountain completed.\nstation Mammoth-Cottonwood completed.\nstation Mancos completed.\nstation Many Glacier completed.\nstation Marion Forks completed.\nstation Marlette Lake completed.\nstation Marquette completed.\nstation Marten Ridge completed.\nstation Maverick Fork completed.\nstation May Creek completed.\nstation Mc Clure Pass completed.\nstation Mccoy Park completed.\nstation McGrath completed.\nstation Mckenzie completed.\nstation Mcknight Cabin completed.\nstation Mcneil Canyon completed.\nstation Mcneil River SGS completed.\nstation Meadow Lake completed.\nstation Meadows Pass completed.\nstation Med Bow completed.\nstation Medano Pass completed.\nstation Merchant Valley completed.\nstation Merritt Mountain completed.\nstation Mesa Lakes completed.\nstation MF Nooksack completed.\nstation Mica Creek completed.\nstation Michigan Creek completed.\nstation Midas completed.\nstation Middle Creek completed.\nstation Middle Fork Bradley completed.\nstation Middle Fork Camp completed.\nstation Middle Powder completed.\nstation Midway Valley completed.\nstation Milk Shakes completed.\nstation Mill Creek Summit completed.\nstation Mill-D North completed.\nstation Miller Woods completed.\nstation Mineral Creek completed.\nstation Mining Fork completed.\nstation Molas Lake completed.\nstation Monahan Flat completed.\nstation Monitor Pass completed.\nstation Monte Cristo completed.\nstation Monument Creek completed.\nstation Monument Peak completed.\nstation Moon Pass completed.\nstation Moonshine completed.\nstation Moore Creek Bridge completed.\nstation Moose Creek completed.\nstation Moraine completed.\nstation Mores Creek Summit completed.\nstation Morgan Creek completed.\nstation Mormon Mountain completed.\nstation Mormon Mtn Summit completed.\nstation Morse Lake completed.\nstation Mosby Mtn. completed.\nstation Moscow Mountain completed.\nstation Moses Mtn completed.\nstation Mosquito Ridge completed.\nstation Moss Peak completed.\nstation Moss Springs completed.\nstation Mount Crag completed.\nstation Mount Gardner completed.\nstation Mount Lockhart completed.\nstation Mountain Meadows completed.\nstation Mowich completed.\nstation Mt Baldy completed.\nstation Mt Hood Test Site completed.\nstation Mt Pennell completed.\nstation Mt Rose Ski Area completed.\nstation Mt. Alyeska completed.\nstation Mt. Eyak completed.\nstation Mt. Howard completed.\nstation Mt. Ryan completed.\nstation Mt. Tebo completed.\nstation Muckamuck completed.\nstation Mud Flat completed.\nstation Mud Ridge completed.\nstation Mule Creek completed.\nstation Munson Ridge completed.\nstation Myrtle Creek completed.\nstation N Fk Elk Creek completed.\nstation Nast Lake completed.\nstation Navajo Whiskey Ck completed.\nstation Nenana completed.\nstation Nevada Ridge completed.\nstation Never Summer completed.\nstation New Crescent Lake completed.\nstation New Fork Lake completed.\nstation Nez Perce Camp completed.\nstation Niwot completed.\nstation Noisy Basin completed.\nstation North Costilla completed.\nstation North Fork completed.\nstation North Fork Jocko completed.\nstation North French Creek completed.\nstation North Lost Trail completed.\nstation North Rapid Creek completed.\nstation Northeast Entrance completed.\nstation Nuka Glacier completed.\nstation Nutrioso completed.\nstation Oak Creek completed.\nstation Ochoco Meadows completed.\nstation Olallie Meadows completed.\nstation ONeil Creek completed.\nstation Onion Park completed.\nstation Overland Res. completed.\nstation Owl Creek completed.\nstation Oxford Spring completed.\nstation Palisades Tahoe completed.\nstation Palo completed.\nstation Panguitch Lake RS completed.\nstation Paradise completed.\nstation Paradise Hill completed.\nstation Pargon Creek completed.\nstation Park Cone completed.\nstation Park Creek Ridge completed.\nstation Park Reservoir completed.\nstation Parker Peak completed.\nstation Parleys Summit completed.\nstation Parleys Upper completed.\nstation Parrish Creek completed.\nstation Payson R.S. completed.\nstation Peavine Ridge completed.\nstation Pebble Creek completed.\nstation Pepper Creek completed.\nstation Peterson Meadows completed.\nstation Phantom Valley completed.\nstation Phillips Bench completed.\nstation Pickfoot Creek completed.\nstation Pickle Keg completed.\nstation Pierce R.S. completed.\nstation Pigtail Peak completed.\nstation Pike Creek completed.\nstation Pine Creek completed.\nstation Pine Creek Pass completed.\nstation Pinto Rock completed.\nstation Placer Basin completed.\nstation Pocket Creek completed.\nstation Poison Flat completed.\nstation Pole Canyon completed.\nstation Pole Creek R.S. completed.\nstation Poorman Creek completed.\nstation Pope Ridge completed.\nstation Porcupine completed.\nstation Porphyry Creek completed.\nstation Port Graham completed.\nstation Porter Canyon completed.\nstation Potato Hill completed.\nstation Powder Mountain completed.\nstation Powder River Pass completed.\nstation Prairie completed.\nstation Promontory completed.\nstation Prudhoe Bay completed.\nstation Quartz Mountain completed.\nstation Quartz Peak completed.\nstation Quemazon completed.\nstation Rabbit Ears completed.\nstation Ragged Mountain completed.\nstation Railroad Overpass completed.\nstation Rainbow Canyon completed.\nstation Rainy Pass completed.\nstation Rawah completed.\nstation Red Hill completed.\nstation Red Mountain Pass completed.\nstation Red Pine Ridge completed.\nstation Red River Pass #2 completed.\nstation Redden Mine Lwr completed.\nstation Rees Flat completed.\nstation Reno Hill completed.\nstation Rex River completed.\nstation Reynolds Creek completed.\nstation Rice Park completed.\nstation Rio Santa Barbara completed.\nstation Ripple Creek completed.\nstation Roach completed.\nstation Roaring River completed.\nstation Rock Creek completed.\nstation Rock Springs completed.\nstation Rocker Peak completed.\nstation Rockwood GS completed.\nstation Rocky Basin-Settleme completed.\nstation Rocky Boy completed.\nstation Rocky Point completed.\nstation Rough And Tumble completed.\nstation Rubicon #2 completed.\nstation S Fork Shields completed.\nstation Sacajawea completed.\nstation Saddle Mountain completed.\nstation Saddle Mtn. completed.\nstation Sage Creek Basin completed.\nstation Sagwon completed.\nstation Saint Elmo completed.\nstation Salmon Meadows completed.\nstation Salt Creek Falls completed.\nstation Salt River Summit completed.\nstation San Antonio Sink completed.\nstation Sand Lake completed.\nstation Sandstone RS completed.\nstation Santa Fe completed.\nstation Santaquin Meadows completed.\nstation Santiam Jct. completed.\nstation Sargents Mesa completed.\nstation Sasse Ridge completed.\nstation Satus Pass completed.\nstation Savage Pass completed.\nstation Sawmill Ridge completed.\nstation Sawtooth completed.\nstation Schneider Meadows completed.\nstation Schofield Pass completed.\nstation Schwartz Lake completed.\nstation Schweitzer Basin completed.\nstation Scotch Creek completed.\nstation Secesh Summit completed.\nstation Sedgwick Peak completed.\nstation Seeley Creek completed.\nstation Seine Creek completed.\nstation Senorita Divide #2 completed.\nstation Sentinel Butte completed.\nstation Sevenmile Marsh completed.\nstation Seventysix Creek completed.\nstation Shanghi Summit completed.\nstation Sharkstooth completed.\nstation Sheep Canyon completed.\nstation Sheep Mtn. completed.\nstation Sheldon completed.\nstation Shell Creek completed.\nstation Sherwin completed.\nstation Short Creek completed.\nstation Shower Falls completed.\nstation Shuree completed.\nstation Sierra Blanca completed.\nstation Signal Peak completed.\nstation Silver Creek completed.\nstation Silver Creek Divide completed.\nstation Silver Creek Nv completed.\nstation Silvies completed.\nstation Skalkaho Summit completed.\nstation Skate Creek completed.\nstation Skookum Creek completed.\nstation Slagamelt Lakes completed.\nstation Sleeping Woman completed.\nstation Slug Creek Divide completed.\nstation Slumgullion completed.\nstation Smiley Mountain completed.\nstation Smith  Morehouse completed.\nstation Smith Ridge completed.\nstation Snake River Station completed.\nstation Snider Basin completed.\nstation Snow Mountain completed.\nstation Snowbird completed.\nstation Snowslide Canyon completed.\nstation Snowstorm Mtn completed.\nstation Soldier Park completed.\nstation Soldier R.S. completed.\nstation Somsen Ranch completed.\nstation Sonora Pass completed.\nstation Sourdough Gulch completed.\nstation South Brush Creek completed.\nstation South Colony completed.\nstation South Fork Bull Run completed.\nstation South Mtn. completed.\nstation South Pass completed.\nstation Spencer Meadow completed.\nstation Spirit Lake completed.\nstation Spirit Lk completed.\nstation Spratt Creek completed.\nstation Spring Creek completed.\nstation Spring Creek Divide completed.\nstation Spruce Springs completed.\nstation Spud Mountain completed.\nstation Spur Park completed.\nstation Squaw Flat completed.\nstation St. Lawrence Alt completed.\nstation Stag Mountain completed.\nstation Stahl Peak completed.\nstation Stampede Pass completed.\nstation Starr Ridge completed.\nstation State Line completed.\nstation Steel Creek Park completed.\nstation Stevens Pass completed.\nstation Stickney Mill completed.\nstation Stillwater Creek completed.\nstation Strawberry completed.\nstation Strawberry Divide completed.\nstation Stringer Creek completed.\nstation Stryker Basin completed.\nstation Stuart Mountain completed.\nstation Stump Lakes completed.\nstation Sucker Creek completed.\nstation Sugarloaf Mtn completed.\nstation Summer Rim completed.\nstation Summit Creek completed.\nstation Summit Lake completed.\nstation Summit Lk completed.\nstation Summit Meadow completed.\nstation Summit Ranch completed.\nstation Sun Pass completed.\nstation Sunflower Flat completed.\nstation Sunset completed.\nstation Surprise Lakes completed.\nstation Susitna Valley High completed.\nstation Suu Ranch completed.\nstation Swamp Creek completed.\nstation Swan Lake Mtn completed.\nstation Swede Peak completed.\nstation Swift Creek completed.\nstation Sylvan Lake completed.\nstation Sylvan Road completed.\nstation Tahoe City Cross completed.\nstation Takka Wiiya completed.\nstation Taos Powderhorn completed.\nstation Taos Pueblo completed.\nstation Taylor Butte completed.\nstation Taylor Canyon completed.\nstation Taylor Green completed.\nstation Telaquana Lake completed.\nstation Temple Fork completed.\nstation Tent Mtn Lower completed.\nstation Tepee Creek completed.\nstation Teuchet Creek completed.\nstation Thaynes Canyon completed.\nstation Thistle Flat completed.\nstation Three Creeks Meadow completed.\nstation Thumb Divide completed.\nstation Thunder Basin completed.\nstation Tie Creek completed.\nstation Timber Creek completed.\nstation Timberline completed.\nstation Timpanogos Divide completed.\nstation Tinkham Creek completed.\nstation Tipton completed.\nstation Tizer Basin completed.\nstation Toe Jam completed.\nstation Togwotee Pass completed.\nstation Tok completed.\nstation Toketee Airstrip completed.\nstation Tokositna Valley completed.\nstation Tolby completed.\nstation Tony Grove Lake completed.\nstation Tony Grove RS completed.\nstation Touchet completed.\nstation Tower completed.\nstation Townsend Creek completed.\nstation Trapper Lake completed.\nstation Tres Ritos completed.\nstation Trial Lake completed.\nstation Trinchera completed.\nstation Trinity completed.\nstation Trinity Mtn. completed.\nstation Triple Peak completed.\nstation Trough completed.\nstation Trout Creek completed.\nstation Truckee #2 completed.\nstation Turnagain Pass completed.\nstation Twelvemile Creek completed.\nstation Twin Lakes completed.\nstation Two Ocean Plateau completed.\nstation University Camp completed.\nstation Upper Chena completed.\nstation Upper Joes Valley completed.\nstation Upper Nome Creek completed.\nstation Upper Rio Grande completed.\nstation Upper San Juan completed.\nstation Upper Taylor completed.\nstation Upper Tsaina River completed.\nstation Upper Wheeler completed.\nstation Usu Doc Daniel completed.\nstation Ute Creek completed.\nstation Vacarro Springs completed.\nstation Vacas Locas completed.\nstation Vail Mountain completed.\nstation Vallecito completed.\nstation Van Wyck completed.\nstation Vernon Creek completed.\nstation Vienna Mine completed.\nstation Virginia Lakes Ridge completed.\nstation Wager Gulch completed.\nstation Waldron completed.\nstation Ward Creek #3 completed.\nstation Ward Mountain completed.\nstation Warm Springs completed.\nstation Waterhole completed.\nstation Webber Springs completed.\nstation Webster Flat completed.\nstation Wells Creek completed.\nstation Weminuche Creek completed.\nstation Wesner Springs completed.\nstation West Branch completed.\nstation West Yellowstone completed.\nstation Wheeler Peak completed.\nstation Whiskey Ck completed.\nstation Whiskey Creek completed.\nstation Whiskey Park completed.\nstation White Elephant completed.\nstation White Horse Lake completed.\nstation White Mill completed.\nstation White Pass E.S. completed.\nstation White River #1 completed.\nstation White River Nv completed.\nstation Widtsoe #3 completed.\nstation Wilbur Bench completed.\nstation Wild Basin completed.\nstation Wildcat completed.\nstation Wildhorse Divide completed.\nstation Willow Creek completed.\nstation Willow Creek Pass completed.\nstation Willow Park completed.\nstation Wilson Creek completed.\nstation Windy Peak completed.\nstation Wolf Creek completed.\nstation Wolf Creek Peak completed.\nstation Wolf Creek Summit completed.\nstation Wolverine completed.\nstation Wood Creek completed.\nstation Workman Creek completed.\nstation Wrigley Creek completed.\nstation Yankee Reservoir completed.\nstation Younts Peak completed.\nstation Zirkel completed.\n",
  "history_begin_time" : 1703489044095,
  "history_end_time" : 1703617782353,
  "history_notes" : "directly got all data from snotel website, this takes almost a day. Very very slow.",
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "8UKh002hHyoh",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_corrected.csv'\nstart_date = \"2018-01-01\"\nend_date = \"2022-12-31\"\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n# print(station_locations)\n\nresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\nfor station in station_locations:\n    print(f'station {station[\"name\"]} completed.')\n    \n    location_name = station['name']\n    location_triplet = station['triplet']\n    location_elevation = station['elevation']\n    location_station_lat = station['location']['lat']\n    location_station_long = station['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'station_name': location_name,\n                         'date': entry['Date'], \n                         'lat': location_station_lat, \n                         'lon': location_station_long,\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n          \n    print(result_df.head())\n    break\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nstation Adin Mtn completed.\n  station_name        date       lat        lon swe_value\n0     Adin Mtn  2018-01-01  41.23583 -120.79192       1.2\n1     Adin Mtn  2018-01-02  41.23583 -120.79192       1.3\n2     Adin Mtn  2018-01-03  41.23583 -120.79192       1.3\n3     Adin Mtn  2018-01-04  41.23583 -120.79192       1.4\n4     Adin Mtn  2018-01-05  41.23583 -120.79192       1.3\n",
  "history_begin_time" : 1703488996124,
  "history_end_time" : 1703489000476,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "encjBDVoebjj",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_corrected.csv'\nstart_date = \"2018-01-01\"\nend_date = \"2022-12-31\"\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n# print(station_locations)\n\nresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\nfor station in station_locations:\n    print(f'station {station[\"name\"]} completed.')\n    \n    location_name = station['name']\n    location_triplet = station['triplet']\n    location_elevation = station['elevation']\n    location_station_lat = station['location']['lat']\n    location_station_long = station['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': location_station_lat, 'lon': location_station_long,\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n          \n    print(result_df.head())\n    break\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nstation Adin Mtn completed.\n   station_name        date       lat        lon swe_value\n0           NaN  2018-01-01  41.23583 -120.79192       1.2\n1           NaN  2018-01-02  41.23583 -120.79192       1.3\n2           NaN  2018-01-03  41.23583 -120.79192       1.3\n3           NaN  2018-01-04  41.23583 -120.79192       1.4\n4           NaN  2018-01-05  41.23583 -120.79192       1.3\n",
  "history_begin_time" : 1703488763111,
  "history_end_time" : 1703488767843,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "3jJqG7DITIY4",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_corrected.csv'\nstart_date = \"2018-01-01\"\nend_date = \"2022-12-31\"\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n# print(station_locations)\n\nresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\nfor station in station_locations:\n    print(f'station {station[\"name\"]} completed.')\n    \n    location_name = station['name']\n    location_triplet = station['triplet']\n    location_elevation = station['elevation']\n    location_station_lat = station['location']['lat']\n    location_station_long = station['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': location_station_lat, 'lon': location_station_long,\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n          \n     print(result_df.head())\n     break\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/3jJqG7DITIY4/data_snotel_station_only.py\", line 95\n    print(result_df.head())\n                           ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1703488753879,
  "history_end_time" : 1703488753935,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "uLttyinYRQoy",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_corrected.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n# print(station_locations)\n\nresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\nfor station in station_locations:\n    print(f'station {station[\"name\"]} completed.')\n    \n    location_name = station['name']\n    location_triplet = station['triplet']\n    location_elevation = station['elevation']\n    location_station_lat = station['location']['lat']\n    location_station_long = station['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': location_station_lat, 'lon': location_station_long,\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nstation Adin Mtn completed.\nstation Agua Canyon completed.\nstation Albro Lake completed.\nstation Alexander Lake completed.\nstation Alpine Meadows completed.\nstation American Creek completed.\nstation Anchor River Divide completed.\nstation Anchorage Hillside completed.\nstation Aneroid Lake #2 completed.\nstation Aniak completed.\nstation Annie Springs completed.\nstation Apishapa completed.\nstation Arapaho Ridge completed.\nstation Arbuckle Mtn completed.\nstation Atigun Pass completed.\nstation Atlanta Summit completed.\nstation Atwater completed.\nstation Badger Pass completed.\nstation Baker Butte completed.\nstation Baker Butte Smt completed.\nstation Bald Mtn. completed.\nstation Baldy completed.\nstation Banfield Mountain completed.\nstation Banner Summit completed.\nstation Bar M completed.\nstation Barker Lakes completed.\nstation Base Camp completed.\nstation Basin Creek completed.\nstation Bassoo Peak completed.\nstation Bateman completed.\nstation Battle Mountain completed.\nstation Beagle Springs completed.\nstation Bear Basin completed.\nstation Bear Canyon completed.\nstation Bear Creek completed.\nstation Bear Grass completed.\nstation Bear Lake completed.\nstation Bear Mountain completed.\nstation Bear River completed.\nstation Bear River RS completed.\nstation Bear Saddle completed.\nstation Bear Trap Meadow completed.\nstation Beartooth Lake completed.\nstation Beartown completed.\nstation Beaver Ck Village completed.\nstation Beaver Creek completed.\nstation Beaver Dams completed.\nstation Beaver Divide completed.\nstation Beaver Head completed.\nstation Beaver Pass completed.\nstation Beaver Reservoir completed.\nstation Beaver Spring completed.\nstation Ben Lomond Peak completed.\nstation Ben Lomond Trail completed.\nstation Berry Creek completed.\nstation Berthoud Summit completed.\nstation Bettles Field completed.\nstation Bevans Cabin completed.\nstation Big Bend completed.\nstation Big Creek Sum completed.\nstation Big Creek Summit completed.\nstation Big Flat completed.\nstation Big Goose completed.\nstation Big Meadow completed.\nstation Big Red Mountain completed.\nstation Big Sandy Opening completed.\nstation Bigelow Camp completed.\nstation Billie Creek Divide completed.\nstation Bird Creek completed.\nstation Bison Lake completed.\nstation Bisson Creek completed.\nstation Black Bear completed.\nstation Black Flat-U.M. Ck completed.\nstation Black Mesa completed.\nstation Black Mountain completed.\nstation Black Pine completed.\nstation Blackhall Mtn completed.\nstation Blacks Fork Jct completed.\nstation Blacktail Mtn completed.\nstation Blackwater completed.\nstation Blazed Alder completed.\nstation Blewett Pass completed.\nstation Blind Bull Sum completed.\nstation Blind Park completed.\nstation Bloody Dick completed.\nstation Blue Lakes completed.\nstation Blue Mountain Spring completed.\nstation Bobs Hollow completed.\nstation Bogus Basin completed.\nstation Bone Springs Div completed.\nstation Bostetter R.S. completed.\nstation Boulder Mountain completed.\nstation Bourne completed.\nstation Bowman Springs completed.\nstation Box Canyon completed.\nstation Box Creek completed.\nstation Box Springs completed.\nstation Brackett Creek completed.\nstation Brian Head completed.\nstation Brighton completed.\nstation Bristlecone Trail completed.\nstation Brooklyn Lake completed.\nstation Brown Duck completed.\nstation Brown Top completed.\nstation Brumley completed.\nstation Brundage Reservoir completed.\nstation Buck Flat completed.\nstation Buck Pasture completed.\nstation Buckboard Flat completed.\nstation Buckinghorse completed.\nstation Buckskin Joe completed.\nstation Buckskin Lower completed.\nstation Buffalo Park completed.\nstation Bug Lake completed.\nstation Bumping Ridge completed.\nstation Bunchgrass Mdw completed.\nstation Burgess Junction completed.\nstation Burnside Lake completed.\nstation Burnt Mountain completed.\nstation Burnt Mtn completed.\nstation Burro Mountain completed.\nstation Burroughs Creek completed.\nstation Burts Miller Ranch completed.\nstation Butte completed.\nstation Calamity completed.\nstation Calvert Creek completed.\nstation Camas Creek Divide completed.\n",
  "history_begin_time" : 1703487011012,
  "history_end_time" : 1703488696855,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "T5ZK3mjycyNQ",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_corrected.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\n# print(station_locations)\n\nresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\nfor station in station_locations:\n    print(f'station {station[name]} completed.')\n    \n    location_name = station['name']\n    location_triplet = station['triplet']\n    location_elevation = station['elevation']\n    location_station_lat = station['location']['lat']\n    location_station_long = station['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': location_station_lat, 'lon': location_station_long,\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/T5ZK3mjycyNQ/data_snotel_station_only.py\", line 76, in <module>\n    print(f'station {station[name]} completed.')\nNameError: name 'name' is not defined\n",
  "history_begin_time" : 1703486451154,
  "history_end_time" : 1703486452035,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "UjXdGJBpSFKE",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_corrected.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\nprint(station_locations)\n\nresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\nfor station in station_locations.items():\n    print(f'station {station[name]} completed.')\n    \n    location_name = station['name']\n    location_triplet = station['triplet']\n    location_elevation = station['elevation']\n    location_station_lat = station['location']['lat']\n    location_station_long = station['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': location_station_lat, 'lon': location_station_long,\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\n[{'name': 'Adin Mtn', 'triplet': '301:CA:SNTL', 'elevation': 6190, 'location': {'lat': 41.23583, 'lng': -120.79192}}, {'name': 'Agua Canyon', 'triplet': '907:UT:SNTL', 'elevation': 8900, 'location': {'lat': 37.52217, 'lng': -112.27118}}, {'name': 'Albro Lake', 'triplet': '916:MT:SNTL', 'elevation': 8300, 'location': {'lat': 45.59723, 'lng': -111.95902}}, {'name': 'Alexander Lake', 'triplet': '1267:AK:SNTL', 'elevation': 160, 'location': {'lat': 61.74967, 'lng': -150.88967}}, {'name': 'Alpine Meadows', 'triplet': '908:WA:SNTL', 'elevation': 3500, 'location': {'lat': 47.77957, 'lng': -121.69847}}, {'name': 'American Creek', 'triplet': '1189:AK:SNTL', 'elevation': 1050, 'location': {'lat': 64.78969, 'lng': -141.23376}}, {'name': 'Anchor River Divide', 'triplet': '1062:AK:SNTL', 'elevation': 1653, 'location': {'lat': 59.85972, 'lng': -151.315}}, {'name': 'Anchorage Hillside', 'triplet': '1070:AK:SNTL', 'elevation': 2080, 'location': {'lat': 61.11483, 'lng': -149.66683}}, {'name': 'Aneroid Lake #2', 'triplet': '302:OR:SNTL', 'elevation': 7400, 'location': {'lat': 45.21328, 'lng': -117.19258}}, {'name': 'Aniak', 'triplet': '2065:AK:SNTL', 'elevation': 80, 'location': {'lat': 61.58337, 'lng': -159.57708}}, {'name': 'Annie Springs', 'triplet': '1000:OR:SNTL', 'elevation': 6010, 'location': {'lat': 42.87007, 'lng': -122.16518}}, {'name': 'Apishapa', 'triplet': '303:CO:SNTL', 'elevation': 10027, 'location': {'lat': 37.33067, 'lng': -105.06766}}, {'name': 'Arapaho Ridge', 'triplet': '1030:CO:SNTL', 'elevation': 10976, 'location': {'lat': 40.35098, 'lng': -106.38141}}, {'name': 'Arbuckle Mtn', 'triplet': '304:OR:SNTL', 'elevation': 5770, 'location': {'lat': 45.19085, 'lng': -119.25392}}, {'name': 'Atigun Pass', 'triplet': '957:AK:SNTL', 'elevation': 4800, 'location': {'lat': 68.12983, 'lng': -149.47817}}, {'name': 'Atlanta Summit', 'triplet': '306:ID:SNTL', 'elevation': 7580, 'location': {'lat': 43.7569, 'lng': -115.23907}}, {'name': 'Atwater', 'triplet': '1308:UT:SNTL', 'elevation': 8753, 'location': {'lat': 40.59124, 'lng': -111.63775}}, {'name': 'Badger Pass', 'triplet': '307:MT:SNTL', 'elevation': 6900, 'location': {'lat': 48.13088, 'lng': -113.02317}}, {'name': 'Baker Butte', 'triplet': '308:AZ:SNTL', 'elevation': 7363, 'location': {'lat': 34.45654, 'lng': -111.40651}}, {'name': 'Baker Butte Smt', 'triplet': '1140:AZ:SNTL', 'elevation': 7752, 'location': {'lat': 34.45552, 'lng': -111.38262}}, {'name': 'Bald Mtn.', 'triplet': '309:WY:SNTL', 'elevation': 9380, 'location': {'lat': 44.8007, 'lng': -107.84442}}, {'name': 'Baldy', 'triplet': '310:AZ:SNTL', 'elevation': 9221, 'location': {'lat': 33.97845, 'lng': -109.50357}}, {'name': 'Banfield Mountain', 'triplet': '311:MT:SNTL', 'elevation': 5600, 'location': {'lat': 48.5712, 'lng': -115.44573}}, {'name': 'Banner Summit', 'triplet': '312:ID:SNTL', 'elevation': 7040, 'location': {'lat': 44.30342, 'lng': -115.23447}}, {'name': 'Bar M', 'triplet': '1212:AZ:SNTL', 'elevation': 6397, 'location': {'lat': 34.86142, 'lng': -111.60497}}, {'name': 'Barker Lakes', 'triplet': '313:MT:SNTL', 'elevation': 8250, 'location': {'lat': 46.09713, 'lng': -113.13038}}, {'name': 'Base Camp', 'triplet': '314:WY:SNTL', 'elevation': 7060, 'location': {'lat': 43.94019, 'lng': -110.44544}}, {'name': 'Basin Creek', 'triplet': '315:MT:SNTL', 'elevation': 7180, 'location': {'lat': 45.79737, 'lng': -112.52047}}, {'name': 'Bassoo Peak', 'triplet': '1190:MT:SNTL', 'elevation': 5150, 'location': {'lat': 47.85562, 'lng': -114.75841}}, {'name': 'Bateman', 'triplet': '316:NM:SNTL', 'elevation': 9249, 'location': {'lat': 36.51174, 'lng': -106.31543}}, {'name': 'Battle Mountain', 'triplet': '317:WY:SNTL', 'elevation': 7498, 'location': {'lat': 41.05402, 'lng': -107.26674}}, {'name': 'Beagle Springs', 'triplet': '318:MT:SNTL', 'elevation': 8850, 'location': {'lat': 44.47147, 'lng': -112.98191}}, {'name': 'Bear Basin', 'triplet': '319:ID:SNTL', 'elevation': 5350, 'location': {'lat': 44.95222, 'lng': -116.14293}}, {'name': 'Bear Canyon', 'triplet': '320:ID:SNTL', 'elevation': 7900, 'location': {'lat': 43.74367, 'lng': -113.93797}}, {'name': 'Bear Creek', 'triplet': '321:NV:SNTL', 'elevation': 8040, 'location': {'lat': 41.83384, 'lng': -115.45278}}, {'name': 'Bear Grass', 'triplet': '1166:OR:SNTL', 'elevation': 4720, 'location': {'lat': 44.3253, 'lng': -122.0938}}, {'name': 'Bear Lake', 'triplet': '322:CO:SNTL', 'elevation': 9522, 'location': {'lat': 40.31176, 'lng': -105.6467}}, {'name': 'Bear Mountain', 'triplet': '323:ID:SNTL', 'elevation': 5400, 'location': {'lat': 48.30577, 'lng': -116.07448}}, {'name': 'Bear River', 'triplet': '1061:CO:SNTL', 'elevation': 9112, 'location': {'lat': 40.06152, 'lng': -107.00948}}, {'name': 'Bear River RS', 'triplet': '992:UT:SNTL', 'elevation': 8777, 'location': {'lat': 40.8852, 'lng': -110.8277}}, {'name': 'Bear Saddle', 'triplet': '324:ID:SNTL', 'elevation': 6180, 'location': {'lat': 44.60533, 'lng': -116.98097}}, {'name': 'Bear Trap Meadow', 'triplet': '325:WY:SNTL', 'elevation': 8200, 'location': {'lat': 43.88743, 'lng': -107.06135}}, {'name': 'Beartooth Lake', 'triplet': '326:WY:SNTL', 'elevation': 9360, 'location': {'lat': 44.94307, 'lng': -109.56743}}, {'name': 'Beartown', 'triplet': '327:CO:SNTL', 'elevation': 11600, 'location': {'lat': 37.71433, 'lng': -107.5124}}, {'name': 'Beaver Ck Village', 'triplet': '1041:CO:SNTL', 'elevation': 8565, 'location': {'lat': 39.59871, 'lng': -106.51113}}, {'name': 'Beaver Creek', 'triplet': '328:MT:SNTL', 'elevation': 7850, 'location': {'lat': 44.94966, 'lng': -111.35852}}, {'name': 'Beaver Dams', 'triplet': '329:UT:SNTL', 'elevation': 7990, 'location': {'lat': 39.13683, 'lng': -111.55813}}, {'name': 'Beaver Divide', 'triplet': '330:UT:SNTL', 'elevation': 8280, 'location': {'lat': 40.61233, 'lng': -111.09782}}, {'name': 'Beaver Head', 'triplet': '902:AZ:SNTL', 'elevation': 8076, 'location': {'lat': 33.69115, 'lng': -109.21685}}, {'name': 'Beaver Pass', 'triplet': '990:WA:SNTL', 'elevation': 3630, 'location': {'lat': 48.8793, 'lng': -121.2555}}, {'name': 'Beaver Reservoir', 'triplet': '331:OR:SNTL', 'elevation': 5150, 'location': {'lat': 45.14532, 'lng': -118.219}}, {'name': 'Beaver Spring', 'triplet': '1143:AZ:SNTL', 'elevation': 9255, 'location': {'lat': 36.32671, 'lng': -109.05702}}, {'name': 'Ben Lomond Peak', 'triplet': '332:UT:SNTL', 'elevation': 7689, 'location': {'lat': 41.37603, 'lng': -111.94405}}, {'name': 'Ben Lomond Trail', 'triplet': '333:UT:SNTL', 'elevation': 5972, 'location': {'lat': 41.38291, 'lng': -111.92103}}, {'name': 'Berry Creek', 'triplet': '334:NV:SNTL', 'elevation': 9377, 'location': {'lat': 39.31917, 'lng': -114.62278}}, {'name': 'Berthoud Summit', 'triplet': '335:CO:SNTL', 'elevation': 11314, 'location': {'lat': 39.80364, 'lng': -105.77786}}, {'name': 'Bettles Field', 'triplet': '1182:AK:SNTL', 'elevation': 640, 'location': {'lat': 66.91667, 'lng': -151.53333}}, {'name': 'Bevans Cabin', 'triplet': '1214:UT:SNTL', 'elevation': 6520, 'location': {'lat': 40.46182, 'lng': -112.25233}}, {'name': 'Big Bend', 'triplet': '336:NV:SNTL', 'elevation': 6898, 'location': {'lat': 41.76168, 'lng': -115.6931}}, {'name': 'Big Creek Sum', 'triplet': '337:NV:SNTL', 'elevation': 8685, 'location': {'lat': 39.29148, 'lng': -117.11506}}, {'name': 'Big Creek Summit', 'triplet': '338:ID:SNTL', 'elevation': 6560, 'location': {'lat': 44.62621, 'lng': -115.79561}}, {'name': 'Big Flat', 'triplet': '339:UT:SNTL', 'elevation': 10349, 'location': {'lat': 38.30183, 'lng': -112.35672}}, {'name': 'Big Goose', 'triplet': '931:WY:SNTL', 'elevation': 7990, 'location': {'lat': 44.57924, 'lng': -107.20068}}, {'name': 'Big Meadow', 'triplet': '340:NV:SNTL', 'elevation': 8235, 'location': {'lat': 39.455, 'lng': -119.9422}}, {'name': 'Big Red Mountain', 'triplet': '341:OR:SNTL', 'elevation': 6050, 'location': {'lat': 42.05257, 'lng': -122.85487}}, {'name': 'Big Sandy Opening', 'triplet': '342:WY:SNTL', 'elevation': 9080, 'location': {'lat': 42.6458, 'lng': -109.25965}}, {'name': 'Bigelow Camp', 'triplet': '343:OR:SNTL', 'elevation': 5130, 'location': {'lat': 42.07875, 'lng': -123.34393}}, {'name': 'Billie Creek Divide', 'triplet': '344:OR:SNTL', 'elevation': 5280, 'location': {'lat': 42.40717, 'lng': -122.26617}}, {'name': 'Bird Creek', 'triplet': '1155:NV:SNTL', 'elevation': 7537, 'location': {'lat': 39.46138, 'lng': -114.64863}}, {'name': 'Bison Lake', 'triplet': '345:CO:SNTL', 'elevation': 10964, 'location': {'lat': 39.76458, 'lng': -107.35628}}, {'name': 'Bisson Creek', 'triplet': '346:MT:SNTL', 'elevation': 4920, 'location': {'lat': 47.68389, 'lng': -113.99901}}, {'name': 'Black Bear', 'triplet': '347:MT:SNTL', 'elevation': 8170, 'location': {'lat': 44.50832, 'lng': -111.12803}}, {'name': 'Black Flat-U.M. Ck', 'triplet': '348:UT:SNTL', 'elevation': 9414, 'location': {'lat': 38.6799, 'lng': -111.59765}}, {'name': 'Black Mesa', 'triplet': '1185:CO:SNTL', 'elevation': 11564, 'location': {'lat': 37.78968, 'lng': -108.18376}}, {'name': 'Black Mountain', 'triplet': '1161:CO:SNTL', 'elevation': 8980, 'location': {'lat': 40.8879, 'lng': -105.66404}}, {'name': 'Black Pine', 'triplet': '349:MT:SNTL', 'elevation': 7210, 'location': {'lat': 46.414, 'lng': -113.43095}}, {'name': 'Blackhall Mtn', 'triplet': '1119:WY:SNTL', 'elevation': 9839, 'location': {'lat': 41.05623, 'lng': -106.714}}, {'name': 'Blacks Fork Jct', 'triplet': '1162:UT:SNTL', 'elevation': 8869, 'location': {'lat': 40.95814, 'lng': -110.5828}}, {'name': 'Blacktail Mtn', 'triplet': '1144:MT:SNTL', 'elevation': 5650, 'location': {'lat': 47.98288, 'lng': -114.3543}}, {'name': 'Blackwater', 'triplet': '350:WY:SNTL', 'elevation': 9780, 'location': {'lat': 44.37667, 'lng': -109.79333}}, {'name': 'Blazed Alder', 'triplet': '351:OR:SNTL', 'elevation': 3650, 'location': {'lat': 45.4287, 'lng': -121.85605}}, {'name': 'Blewett Pass', 'triplet': '352:WA:SNTL', 'elevation': 4240, 'location': {'lat': 47.35037, 'lng': -120.6796}}, {'name': 'Blind Bull Sum', 'triplet': '353:WY:SNTL', 'elevation': 8650, 'location': {'lat': 42.964, 'lng': -110.60973}}, {'name': 'Blind Park', 'triplet': '354:SD:SNTL', 'elevation': 6890, 'location': {'lat': 44.10772, 'lng': -103.97688}}, {'name': 'Bloody Dick', 'triplet': '355:MT:SNTL', 'elevation': 7600, 'location': {'lat': 45.16507, 'lng': -113.50099}}, {'name': 'Blue Lakes', 'triplet': '356:CA:SNTL', 'elevation': 8067, 'location': {'lat': 38.608, 'lng': -119.92437}}, {'name': 'Blue Mountain Spring', 'triplet': '357:OR:SNTL', 'elevation': 5870, 'location': {'lat': 44.24767, 'lng': -118.51722}}, {'name': 'Bobs Hollow', 'triplet': '1278:UT:SNTL', 'elevation': 9319, 'location': {'lat': 38.94569, 'lng': -112.15349}}, {'name': 'Bogus Basin', 'triplet': '978:ID:SNTL', 'elevation': 6340, 'location': {'lat': 43.76377, 'lng': -116.09685}}, {'name': 'Bone Springs Div', 'triplet': '358:WY:SNTL', 'elevation': 9350, 'location': {'lat': 44.67888, 'lng': -107.5811}}, {'name': 'Bostetter R.S.', 'triplet': '359:ID:SNTL', 'elevation': 7500, 'location': {'lat': 42.16442, 'lng': -114.19272}}, {'name': 'Boulder Mountain', 'triplet': '360:MT:SNTL', 'elevation': 7950, 'location': {'lat': 46.5596, 'lng': -111.28973}}, {'name': 'Bourne', 'triplet': '361:OR:SNTL', 'elevation': 5850, 'location': {'lat': 44.83052, 'lng': -118.18787}}, {'name': 'Bowman Springs', 'triplet': '362:OR:SNTL', 'elevation': 4530, 'location': {'lat': 45.36428, 'lng': -118.46715}}, {'name': 'Box Canyon', 'triplet': '363:MT:SNTL', 'elevation': 6670, 'location': {'lat': 45.2719, 'lng': -110.24903}}, {'name': 'Box Creek', 'triplet': '364:UT:SNTL', 'elevation': 9853, 'location': {'lat': 38.50809, 'lng': -112.01856}}, {'name': 'Box Springs', 'triplet': '1156:UT:SNTL', 'elevation': 9228, 'location': {'lat': 38.49746, 'lng': -112.00779}}, {'name': 'Brackett Creek', 'triplet': '365:MT:SNTL', 'elevation': 7320, 'location': {'lat': 45.89107, 'lng': -110.93851}}, {'name': 'Brian Head', 'triplet': '1154:UT:SNTL', 'elevation': 10039, 'location': {'lat': 37.67994, 'lng': -112.85674}}, {'name': 'Brighton', 'triplet': '366:UT:SNTL', 'elevation': 8766, 'location': {'lat': 40.59936, 'lng': -111.58167}}, {'name': 'Bristlecone Trail', 'triplet': '1111:NV:SNTL', 'elevation': 8890, 'location': {'lat': 36.31575, 'lng': -115.69543}}, {'name': 'Brooklyn Lake', 'triplet': '367:WY:SNTL', 'elevation': 10250, 'location': {'lat': 41.36038, 'lng': -106.23038}}, {'name': 'Brown Duck', 'triplet': '368:UT:SNTL', 'elevation': 10574, 'location': {'lat': 40.58102, 'lng': -110.58587}}, {'name': 'Brown Top', 'triplet': '1080:WA:SNTL', 'elevation': 5830, 'location': {'lat': 48.92755, 'lng': -121.19713}}, {'name': 'Brumley', 'triplet': '369:CO:SNTL', 'elevation': 10594, 'location': {'lat': 39.08758, 'lng': -106.54231}}, {'name': 'Brundage Reservoir', 'triplet': '370:ID:SNTL', 'elevation': 6250, 'location': {'lat': 45.04315, 'lng': -116.13253}}, {'name': 'Buck Flat', 'triplet': '371:UT:SNTL', 'elevation': 9409, 'location': {'lat': 39.134, 'lng': -111.43722}}, {'name': 'Buck Pasture', 'triplet': '1192:UT:SNTL', 'elevation': 9632, 'location': {'lat': 40.84456, 'lng': -110.66068}}, {'name': 'Buckboard Flat', 'triplet': '1153:UT:SNTL', 'elevation': 8924, 'location': {'lat': 37.86943, 'lng': -109.44717}}, {'name': 'Buckinghorse', 'triplet': '1107:WA:SNTL', 'elevation': 4870, 'location': {'lat': 47.7086, 'lng': -123.45747}}, {'name': 'Buckskin Joe', 'triplet': '938:CO:SNTL', 'elevation': 11166, 'location': {'lat': 39.30378, 'lng': -106.11316}}, {'name': 'Buckskin Lower', 'triplet': '373:NV:SNTL', 'elevation': 6930, 'location': {'lat': 41.75067, 'lng': -117.53182}}, {'name': 'Buffalo Park', 'triplet': '913:CO:SNTL', 'elevation': 9249, 'location': {'lat': 40.22838, 'lng': -106.5962}}, {'name': 'Bug Lake', 'triplet': '374:UT:SNTL', 'elevation': 7987, 'location': {'lat': 41.68541, 'lng': -111.41987}}, {'name': 'Bumping Ridge', 'triplet': '375:WA:SNTL', 'elevation': 4610, 'location': {'lat': 46.81003, 'lng': -121.33058}}, {'name': 'Bunchgrass Mdw', 'triplet': '376:WA:SNTL', 'elevation': 5000, 'location': {'lat': 48.68688, 'lng': -117.17633}}, {'name': 'Burgess Junction', 'triplet': '377:WY:SNTL', 'elevation': 7880, 'location': {'lat': 44.78765, 'lng': -107.52917}}, {'name': 'Burnside Lake', 'triplet': '1051:CA:SNTL', 'elevation': 8129, 'location': {'lat': 38.71943, 'lng': -119.8942}}, {'name': 'Burnt Mountain', 'triplet': '942:WA:SNTL', 'elevation': 4170, 'location': {'lat': 47.0444, 'lng': -121.94032}}, {'name': 'Burnt Mtn', 'triplet': '981:MT:SNTL', 'elevation': 5880, 'location': {'lat': 45.2401, 'lng': -109.45961}}, {'name': 'Burro Mountain', 'triplet': '378:CO:SNTL', 'elevation': 9317, 'location': {'lat': 39.87504, 'lng': -107.59902}}, {'name': 'Burroughs Creek', 'triplet': '379:WY:SNTL', 'elevation': 8750, 'location': {'lat': 43.69733, 'lng': -109.67021}}, {'name': 'Burts Miller Ranch', 'triplet': '1135:UT:SNTL', 'elevation': 8000, 'location': {'lat': 40.98492, 'lng': -110.85075}}, {'name': 'Butte', 'triplet': '380:CO:SNTL', 'elevation': 10200, 'location': {'lat': 38.89435, 'lng': -106.95327}}, {'name': 'Calamity', 'triplet': '1109:WA:SNTL', 'elevation': 2500, 'location': {'lat': 45.90362, 'lng': -122.21633}}, {'name': 'Calvert Creek', 'triplet': '381:MT:SNTL', 'elevation': 6430, 'location': {'lat': 45.8838, 'lng': -113.32553}}, {'name': 'Camas Creek Divide', 'triplet': '382:ID:SNTL', 'elevation': 5710, 'location': {'lat': 43.26548, 'lng': -115.3453}}, {'name': 'Camp Jackson', 'triplet': '383:UT:SNTL', 'elevation': 8858, 'location': {'lat': 37.81333, 'lng': -109.48723}}, {'name': 'Canyon', 'triplet': '384:WY:SNTL', 'elevation': 7870, 'location': {'lat': 44.71961, 'lng': -110.51084}}, {'name': 'Carrot Basin', 'triplet': '385:MT:SNTL', 'elevation': 9000, 'location': {'lat': 44.96192, 'lng': -111.29403}}, {'name': 'Carson Pass', 'triplet': '1067:CA:SNTL', 'elevation': 8360, 'location': {'lat': 38.6927, 'lng': -120.0022}}, {'name': 'Cascade #2', 'triplet': '387:CO:SNTL', 'elevation': 9012, 'location': {'lat': 37.65751, 'lng': -107.80287}}, {'name': 'Cascade Mountain', 'triplet': '1039:UT:SNTL', 'elevation': 7774, 'location': {'lat': 40.283, 'lng': -111.60992}}, {'name': 'Cascade Summit', 'triplet': '388:OR:SNTL', 'elevation': 5100, 'location': {'lat': 43.59042, 'lng': -122.0601}}, {'name': 'Casper Mtn.', 'triplet': '389:WY:SNTL', 'elevation': 7920, 'location': {'lat': 42.73362, 'lng': -106.31789}}, {'name': 'Castle Creek', 'triplet': '1130:WY:SNTL', 'elevation': 8400, 'location': {'lat': 43.6748, 'lng': -109.3774}}, {'name': 'Castle Valley', 'triplet': '390:UT:SNTL', 'elevation': 9607, 'location': {'lat': 37.66098, 'lng': -112.74093}}, {'name': 'Cave Mountain', 'triplet': '1152:NV:SNTL', 'elevation': 10578, 'location': {'lat': 39.16337, 'lng': -114.6133}}, {'name': 'Cayuse Pass', 'triplet': '1085:WA:SNTL', 'elevation': 5240, 'location': {'lat': 46.86954, 'lng': -121.5343}}, {'name': 'Cedar Pass', 'triplet': '391:CA:SNTL', 'elevation': 7030, 'location': {'lat': 41.58233, 'lng': -120.3025}}, {'name': 'Chalender', 'triplet': '1139:AZ:SNTL', 'elevation': 7035, 'location': {'lat': 35.26238, 'lng': -112.06221}}, {'name': 'Chalk Creek #1', 'triplet': '392:UT:SNTL', 'elevation': 9171, 'location': {'lat': 40.85464, 'lng': -111.04765}}, {'name': 'Chalk Creek #2', 'triplet': '393:UT:SNTL', 'elevation': 8208, 'location': {'lat': 40.88529, 'lng': -111.06954}}, {'name': 'Chamita', 'triplet': '394:NM:SNTL', 'elevation': 8383, 'location': {'lat': 36.95606, 'lng': -106.65723}}, {'name': 'Chapman Tunnel', 'triplet': '1101:CO:SNTL', 'elevation': 10100, 'location': {'lat': 39.2621, 'lng': -106.62944}}, {'name': 'Chemult Alternate', 'triplet': '395:OR:SNTL', 'elevation': 4850, 'location': {'lat': 43.22625, 'lng': -121.80662}}, {'name': 'Chena Lakes', 'triplet': '1260:AK:SNTL', 'elevation': 500, 'location': {'lat': 64.75793, 'lng': -147.21823}}, {'name': 'Chepeta', 'triplet': '396:UT:SNTL', 'elevation': 10499, 'location': {'lat': 40.77458, 'lng': -110.0105}}, {'name': 'Chicago Ridge', 'triplet': '1312:MT:SNTL', 'elevation': 5800, 'location': {'lat': 48.062, 'lng': -115.698}}, {'name': 'Chisana', 'triplet': '1093:AK:SNTL', 'elevation': 3320, 'location': {'lat': 62.069, 'lng': -142.049}}, {'name': 'Chocolate Gulch', 'triplet': '895:ID:SNTL', 'elevation': 6310, 'location': {'lat': 43.7685, 'lng': -114.41812}}, {'name': 'Cinnabar Park', 'triplet': '1046:WY:SNTL', 'elevation': 9707, 'location': {'lat': 41.23843, 'lng': -106.23101}}, {'name': 'Clackamas Lake', 'triplet': '398:OR:SNTL', 'elevation': 3400, 'location': {'lat': 45.09658, 'lng': -121.75443}}, {'name': 'Clayton Springs', 'triplet': '983:UT:SNTL', 'elevation': 10049, 'location': {'lat': 37.9725, 'lng': -111.83355}}, {'name': 'Clear Creek #1', 'triplet': '399:UT:SNTL', 'elevation': 8975, 'location': {'lat': 39.86671, 'lng': -111.28363}}, {'name': 'Clear Creek #2', 'triplet': '400:UT:SNTL', 'elevation': 7837, 'location': {'lat': 39.89275, 'lng': -111.25154}}, {'name': 'Clear Lake', 'triplet': '401:OR:SNTL', 'elevation': 3810, 'location': {'lat': 45.18832, 'lng': -121.6916}}, {'name': 'Cloud Peak Reservoir', 'triplet': '402:WY:SNTL', 'elevation': 9860, 'location': {'lat': 44.40343, 'lng': -107.06057}}, {'name': 'Clover Meadow', 'triplet': '403:MT:SNTL', 'elevation': 8600, 'location': {'lat': 45.01788, 'lng': -111.8456}}, {'name': 'Cochetopa Pass', 'triplet': '1059:CO:SNTL', 'elevation': 10061, 'location': {'lat': 38.16273, 'lng': -106.5988}}, {'name': 'Cold Springs', 'triplet': '405:WY:SNTL', 'elevation': 9630, 'location': {'lat': 43.27676, 'lng': -109.44585}}, {'name': 'Cold Springs Camp', 'triplet': '406:OR:SNTL', 'elevation': 5940, 'location': {'lat': 42.53305, 'lng': -122.17683}}, {'name': 'Coldfoot', 'triplet': '958:AK:SNTL', 'elevation': 1040, 'location': {'lat': 67.25333, 'lng': -150.183}}, {'name': 'Cole Canyon', 'triplet': '982:WY:SNTL', 'elevation': 5910, 'location': {'lat': 44.48632, 'lng': -104.41057}}, {'name': 'Cole Creek', 'triplet': '407:MT:SNTL', 'elevation': 7850, 'location': {'lat': 45.19405, 'lng': -109.34548}}, {'name': 'Columbia Basin', 'triplet': '1204:NV:SNTL', 'elevation': 6483, 'location': {'lat': 41.67167, 'lng': -116.07033}}, {'name': 'Columbine', 'triplet': '408:CO:SNTL', 'elevation': 9167, 'location': {'lat': 40.39591, 'lng': -106.60437}}, {'name': 'Columbine Pass', 'triplet': '409:CO:SNTL', 'elevation': 9171, 'location': {'lat': 38.41819, 'lng': -108.38313}}, {'name': 'Columbus Basin', 'triplet': '904:CO:SNTL', 'elevation': 10781, 'location': {'lat': 37.44146, 'lng': -108.02468}}, {'name': 'Combination', 'triplet': '410:MT:SNTL', 'elevation': 5600, 'location': {'lat': 46.46523, 'lng': -113.39358}}, {'name': 'Cool Creek', 'triplet': '411:ID:SNTL', 'elevation': 6280, 'location': {'lat': 46.76361, 'lng': -115.29528}}, {'name': 'Cooper Lake', 'triplet': '959:AK:SNTL', 'elevation': 1200, 'location': {'lat': 60.39027, 'lng': -149.6936}}, {'name': 'Copeland Lake', 'triplet': '412:CO:SNTL', 'elevation': 8555, 'location': {'lat': 40.20733, 'lng': -105.5695}}, {'name': 'Copper Bottom', 'triplet': '413:MT:SNTL', 'elevation': 5200, 'location': {'lat': 47.05678, 'lng': -112.595}}, {'name': 'Copper Camp', 'triplet': '414:MT:SNTL', 'elevation': 6950, 'location': {'lat': 47.08158, 'lng': -112.72955}}, {'name': 'Copper Mountain', 'triplet': '415:CO:SNTL', 'elevation': 10523, 'location': {'lat': 39.48917, 'lng': -106.17154}}, {'name': 'Corduroy Flat', 'triplet': '1209:NV:SNTL', 'elevation': 8640, 'location': {'lat': 38.99651, 'lng': -115.42478}}, {'name': 'Coronado Trail', 'triplet': '416:AZ:SNTL', 'elevation': 8418, 'location': {'lat': 33.80418, 'lng': -109.15352}}, {'name': 'Corral', 'triplet': '1236:UT:SNTL', 'elevation': 8207, 'location': {'lat': 39.65795, 'lng': -110.37906}}, {'name': 'Corral Canyon', 'triplet': '417:NV:SNTL', 'elevation': 8445, 'location': {'lat': 40.27551, 'lng': -115.54017}}, {'name': 'Corral Pass', 'triplet': '418:WA:SNTL', 'elevation': 5800, 'location': {'lat': 47.01872, 'lng': -121.46464}}, {'name': 'Cottonwood Creek', 'triplet': '419:WY:SNTL', 'elevation': 7670, 'location': {'lat': 42.6459, 'lng': -110.81482}}, {'name': 'Couch Summit', 'triplet': '1306:ID:SNTL', 'elevation': 6800, 'location': {'lat': 43.51768, 'lng': -114.8022}}, {'name': 'Cougar Mountain', 'triplet': '420:WA:SNTL', 'elevation': 3200, 'location': {'lat': 47.27666, 'lng': -121.67138}}, {'name': 'County Line', 'triplet': '422:OR:SNTL', 'elevation': 4830, 'location': {'lat': 45.19107, 'lng': -118.55015}}, {'name': 'Cozy Cove', 'triplet': '423:ID:SNTL', 'elevation': 5400, 'location': {'lat': 44.28846, 'lng': -115.65508}}, {'name': 'Crab Creek', 'triplet': '424:ID:SNTL', 'elevation': 6900, 'location': {'lat': 44.437, 'lng': -111.99384}}, {'name': 'Crater Meadows', 'triplet': '425:ID:SNTL', 'elevation': 5960, 'location': {'lat': 46.56394, 'lng': -115.28903}}, {'name': 'Crazyman Flat', 'triplet': '1010:OR:SNTL', 'elevation': 6180, 'location': {'lat': 42.6381, 'lng': -120.94917}}, {'name': 'Creamers Field', 'triplet': '1302:AK:SNTL', 'elevation': 440, 'location': {'lat': 64.86534, 'lng': -147.73617}}, {'name': 'Crosho', 'triplet': '426:CO:SNTL', 'elevation': 8973, 'location': {'lat': 40.16749, 'lng': -107.05769}}, {'name': 'Crow Creek', 'triplet': '1045:WY:SNTL', 'elevation': 8335, 'location': {'lat': 41.22824, 'lng': -105.38571}}, {'name': 'Crowder Flat', 'triplet': '977:CA:SNTL', 'elevation': 5170, 'location': {'lat': 41.89318, 'lng': -120.75202}}, {'name': 'Crystal Lake', 'triplet': '427:MT:SNTL', 'elevation': 6050, 'location': {'lat': 46.78942, 'lng': -109.51205}}, {'name': 'Css Lab', 'triplet': '428:CA:SNTL', 'elevation': 6894, 'location': {'lat': 39.32565, 'lng': -120.36807}}, {'name': 'Culebra #2', 'triplet': '430:CO:SNTL', 'elevation': 10562, 'location': {'lat': 37.20939, 'lng': -105.19988}}, {'name': 'Cumbres Trestle', 'triplet': '431:CO:SNTL', 'elevation': 10035, 'location': {'lat': 37.01877, 'lng': -106.45275}}, {'name': 'Currant Creek', 'triplet': '432:UT:SNTL', 'elevation': 7915, 'location': {'lat': 40.35747, 'lng': -111.08993}}, {'name': 'Dahl Creek', 'triplet': '1303:AK:SNTL', 'elevation': 260, 'location': {'lat': 66.94517, 'lng': -156.90318}}, {'name': 'Daisy Peak', 'triplet': '919:MT:SNTL', 'elevation': 7600, 'location': {'lat': 46.66858, 'lng': -110.33022}}, {'name': 'Daly Creek', 'triplet': '433:MT:SNTL', 'elevation': 5780, 'location': {'lat': 46.18367, 'lng': -113.8533}}, {'name': 'Daly Lake', 'triplet': '434:OR:SNTL', 'elevation': 3690, 'location': {'lat': 44.52147, 'lng': -122.08718}}, {'name': 'Daniels-Strawberry', 'triplet': '435:UT:SNTL', 'elevation': 8008, 'location': {'lat': 40.2953, 'lng': -111.25677}}, {'name': 'Darkhorse Lake', 'triplet': '436:MT:SNTL', 'elevation': 8945, 'location': {'lat': 45.17367, 'lng': -113.58448}}, {'name': 'Deadman Creek', 'triplet': '437:MT:SNTL', 'elevation': 6450, 'location': {'lat': 46.79279, 'lng': -110.67545}}, {'name': 'Deadman Hill', 'triplet': '438:CO:SNTL', 'elevation': 10239, 'location': {'lat': 40.80572, 'lng': -105.77018}}, {'name': 'Deadwood Summit', 'triplet': '439:ID:SNTL', 'elevation': 6860, 'location': {'lat': 44.54514, 'lng': -115.5638}}, {'name': 'Deer Park', 'triplet': '923:WY:SNTL', 'elevation': 9700, 'location': {'lat': 42.59076, 'lng': -108.90273}}, {'name': 'Defiance Mines', 'triplet': '1210:NV:SNTL', 'elevation': 9302, 'location': {'lat': 39.08527, 'lng': -114.89977}}, {'name': 'Derr.', 'triplet': '440:OR:SNTL', 'elevation': 5850, 'location': {'lat': 44.4465, 'lng': -119.93012}}, {'name': 'Diamond Lake', 'triplet': '442:OR:SNTL', 'elevation': 5280, 'location': {'lat': 43.18787, 'lng': -122.14003}}, {'name': 'Diamond Peak', 'triplet': '443:NV:SNTL', 'elevation': 8017, 'location': {'lat': 39.56361, 'lng': -115.84421}}, {'name': 'Dills Camp', 'triplet': '444:UT:SNTL', 'elevation': 9228, 'location': {'lat': 39.04554, 'lng': -111.46875}}, {'name': 'Disaster Peak', 'triplet': '445:NV:SNTL', 'elevation': 6260, 'location': {'lat': 41.96737, 'lng': -118.18934}}, {'name': 'Dismal Swamp', 'triplet': '446:CA:SNTL', 'elevation': 7360, 'location': {'lat': 41.99127, 'lng': -120.18033}}, {'name': 'Divide', 'triplet': '448:MT:SNTL', 'elevation': 7800, 'location': {'lat': 44.79317, 'lng': -112.05645}}, {'name': 'Divide Peak', 'triplet': '449:WY:SNTL', 'elevation': 8730, 'location': {'lat': 41.30399, 'lng': -107.15255}}, {'name': 'Dollarhide Summit', 'triplet': '450:ID:SNTL', 'elevation': 8420, 'location': {'lat': 43.6025, 'lng': -114.67417}}, {'name': 'Dome Lake', 'triplet': '451:WY:SNTL', 'elevation': 8880, 'location': {'lat': 44.57462, 'lng': -107.29537}}, {'name': 'Donkey Reservoir', 'triplet': '452:UT:SNTL', 'elevation': 9799, 'location': {'lat': 38.2084, 'lng': -111.47412}}, {'name': 'Dorsey Basin', 'triplet': '453:NV:SNTL', 'elevation': 7903, 'location': {'lat': 40.89343, 'lng': -115.21104}}, {'name': 'Draw Creek', 'triplet': '454:NV:SNTL', 'elevation': 7332, 'location': {'lat': 41.661, 'lng': -115.3234}}, {'name': 'Dry Bread Pond', 'triplet': '455:UT:SNTL', 'elevation': 8302, 'location': {'lat': 41.41289, 'lng': -111.5377}}, {'name': 'Dry Creek', 'triplet': '1243:NV:SNTL', 'elevation': 6555, 'location': {'lat': 40.8638, 'lng': -115.22014}}, {'name': 'Dry Fork', 'triplet': '906:UT:SNTL', 'elevation': 7093, 'location': {'lat': 40.56533, 'lng': -112.17343}}, {'name': 'Dry Lake', 'triplet': '457:CO:SNTL', 'elevation': 8271, 'location': {'lat': 40.5337, 'lng': -106.7814}}, {'name': 'Dungeness', 'triplet': '943:WA:SNTL', 'elevation': 4010, 'location': {'lat': 47.87224, 'lng': -123.0788}}, {'name': 'Dupuyer Creek', 'triplet': '458:MT:SNTL', 'elevation': 5750, 'location': {'lat': 48.06341, 'lng': -112.7573}}, {'name': 'Eagle Summit', 'triplet': '960:AK:SNTL', 'elevation': 3650, 'location': {'lat': 65.48588, 'lng': -145.41212}}, {'name': 'East Boulder Mine', 'triplet': '1105:MT:SNTL', 'elevation': 6335, 'location': {'lat': 45.50381, 'lng': -110.08019}}, {'name': 'East Palmer', 'triplet': '953:AK:SNTL', 'elevation': 230, 'location': {'lat': 61.59858, 'lng': -149.09637}}, {'name': 'East Rim Divide', 'triplet': '460:WY:SNTL', 'elevation': 7930, 'location': {'lat': 43.13097, 'lng': -110.2023}}, {'name': 'East Willow Creek', 'triplet': '461:UT:SNTL', 'elevation': 8302, 'location': {'lat': 39.31213, 'lng': -109.53179}}, {'name': 'Easy Pass', 'triplet': '998:WA:SNTL', 'elevation': 5270, 'location': {'lat': 48.85933, 'lng': -121.43895}}, {'name': 'Ebbetts Pass', 'triplet': '462:CA:SNTL', 'elevation': 8661, 'location': {'lat': 38.5497, 'lng': -119.80468}}, {'name': 'Echo Lake', 'triplet': '936:CO:SNTL', 'elevation': 10694, 'location': {'lat': 39.65539, 'lng': -105.59358}}, {'name': 'Echo Peak', 'triplet': '463:CA:SNTL', 'elevation': 7653, 'location': {'lat': 38.849, 'lng': -120.0795}}, {'name': 'EF Blacks Fork GS', 'triplet': '1163:UT:SNTL', 'elevation': 9360, 'location': {'lat': 40.88472, 'lng': -110.54056}}, {'name': 'Eilertson Meadows', 'triplet': '464:OR:SNTL', 'elevation': 5510, 'location': {'lat': 44.86887, 'lng': -118.11387}}, {'name': 'El Diente Peak', 'triplet': '465:CO:SNTL', 'elevation': 10217, 'location': {'lat': 37.78607, 'lng': -108.02235}}, {'name': 'Elbow Lake', 'triplet': '910:WA:SNTL', 'elevation': 3040, 'location': {'lat': 48.69092, 'lng': -121.90893}}, {'name': 'Elk Butte', 'triplet': '466:ID:SNTL', 'elevation': 5690, 'location': {'lat': 46.83998, 'lng': -116.12233}}, {'name': 'Elk Cabin', 'triplet': '921:NM:SNTL', 'elevation': 8239, 'location': {'lat': 35.7073, 'lng': -105.80584}}, {'name': 'Elk Peak', 'triplet': '1106:MT:SNTL', 'elevation': 7600, 'location': {'lat': 46.4845, 'lng': -110.7125}}, {'name': 'Elk River', 'triplet': '467:CO:SNTL', 'elevation': 8739, 'location': {'lat': 40.84758, 'lng': -106.96861}}, {'name': 'Elkhart Park G.S.', 'triplet': '468:WY:SNTL', 'elevation': 9400, 'location': {'lat': 43.00657, 'lng': -109.75893}}, {'name': 'Elkhead Divide', 'triplet': '1252:CO:SNTL', 'elevation': 8800, 'location': {'lat': 40.79637, 'lng': -107.10113}}, {'name': 'Elliot Ridge', 'triplet': '1120:CO:SNTL', 'elevation': 10549, 'location': {'lat': 39.8638, 'lng': -106.42473}}, {'name': 'Emery Creek', 'triplet': '469:MT:SNTL', 'elevation': 4350, 'location': {'lat': 48.43412, 'lng': -113.93725}}, {'name': 'Emigrant Springs', 'triplet': '470:OR:SNTL', 'elevation': 3800, 'location': {'lat': 45.55808, 'lng': -118.45383}}, {'name': 'Emigrant Summit', 'triplet': '471:ID:SNTL', 'elevation': 7390, 'location': {'lat': 42.36055, 'lng': -111.56085}}, {'name': 'Esther Island', 'triplet': '1071:AK:SNTL', 'elevation': 50, 'location': {'lat': 60.798, 'lng': -148.0857}}, {'name': 'Evening Star', 'triplet': '472:WY:SNTL', 'elevation': 9200, 'location': {'lat': 44.65258, 'lng': -109.78422}}, {'name': 'Exit Glacier', 'triplet': '1092:AK:SNTL', 'elevation': 400, 'location': {'lat': 60.19033, 'lng': -149.62117}}, {'name': 'Fallen Leaf', 'triplet': '473:CA:SNTL', 'elevation': 6242, 'location': {'lat': 38.93403, 'lng': -120.0545}}, {'name': 'Farmington', 'triplet': '474:UT:SNTL', 'elevation': 7902, 'location': {'lat': 40.97462, 'lng': -111.80975}}, {'name': 'Farmington Lower', 'triplet': '1054:UT:SNTL', 'elevation': 6779, 'location': {'lat': 40.992, 'lng': -111.81702}}, {'name': 'Farnsworth Lake', 'triplet': '475:UT:SNTL', 'elevation': 9623, 'location': {'lat': 38.77246, 'lng': -111.67662}}, {'name': 'Fawn Creek', 'triplet': '476:NV:SNTL', 'elevation': 7031, 'location': {'lat': 41.82098, 'lng': -116.10153}}, {'name': 'Fielding Lake', 'triplet': '1268:AK:SNTL', 'elevation': 3000, 'location': {'lat': 63.20267, 'lng': -145.6305}}, {'name': 'Fifteenmile', 'triplet': '1314:OR:SNTL', 'elevation': 5970, 'location': {'lat': 45.35265, 'lng': -121.53}}, {'name': 'Fish Ck', 'triplet': '1305:ID:SNTL', 'elevation': 6330, 'location': {'lat': 43.55542, 'lng': -113.71924}}, {'name': 'Fish Creek', 'triplet': '477:OR:SNTL', 'elevation': 7660, 'location': {'lat': 42.70992, 'lng': -118.6321}}, {'name': 'Fish Lake', 'triplet': '478:WA:SNTL', 'elevation': 3430, 'location': {'lat': 47.53565, 'lng': -121.08553}}, {'name': 'Fish Lake Utah', 'triplet': '1149:UT:SNTL', 'elevation': 8798, 'location': {'lat': 38.50455, 'lng': -111.76693}}, {'name': 'Fish Lk.', 'triplet': '479:OR:SNTL', 'elevation': 4660, 'location': {'lat': 42.3801, 'lng': -122.34943}}, {'name': 'Fisher Creek', 'triplet': '480:MT:SNTL', 'elevation': 9100, 'location': {'lat': 45.06235, 'lng': -109.94488}}, {'name': 'Five Points Lake', 'triplet': '481:UT:SNTL', 'elevation': 10943, 'location': {'lat': 40.71785, 'lng': -110.46721}}, {'name': 'Flattop Mtn.', 'triplet': '482:MT:SNTL', 'elevation': 6300, 'location': {'lat': 48.80225, 'lng': -113.85713}}, {'name': 'Flower Mountain', 'triplet': '1285:AK:SNTL', 'elevation': 2510, 'location': {'lat': 59.39617, 'lng': -136.28123}}, {'name': 'Fool Creek', 'triplet': '1186:CO:SNTL', 'elevation': 11156, 'location': {'lat': 39.86866, 'lng': -105.86765}}, {'name': 'Forestdale Creek', 'triplet': '1049:CA:SNTL', 'elevation': 8017, 'location': {'lat': 38.68245, 'lng': -119.9597}}, {'name': 'Fort Valley', 'triplet': '1121:AZ:SNTL', 'elevation': 7371, 'location': {'lat': 35.26773, 'lng': -111.74479}}, {'name': 'Fort Yukon', 'triplet': '961:AK:SNTL', 'elevation': 430, 'location': {'lat': 66.5705, 'lng': -145.24553}}, {'name': 'Fourmile Lake', 'triplet': '483:OR:SNTL', 'elevation': 5970, 'location': {'lat': 42.43933, 'lng': -122.2288}}, {'name': 'Franklin Basin', 'triplet': '484:ID:SNTL', 'elevation': 8140, 'location': {'lat': 42.0505, 'lng': -111.6012}}, {'name': 'Fredonyer Peak', 'triplet': '1277:CA:SNTL', 'elevation': 7208, 'location': {'lat': 40.68799, 'lng': -120.60805}}, {'name': 'Fremont Pass', 'triplet': '485:CO:SNTL', 'elevation': 11326, 'location': {'lat': 39.38014, 'lng': -106.19784}}, {'name': 'Frisco Divide', 'triplet': '486:NM:SNTL', 'elevation': 8013, 'location': {'lat': 33.73687, 'lng': -108.94327}}, {'name': 'Frohner Meadow', 'triplet': '487:MT:SNTL', 'elevation': 6480, 'location': {'lat': 46.43545, 'lng': -112.19277}}, {'name': 'Frostbite Bottom', 'triplet': '641:AK:SNTL', 'elevation': 2700, 'location': {'lat': 61.74722, 'lng': -149.2688}}, {'name': 'Fry', 'triplet': '488:AZ:SNTL', 'elevation': 7236, 'location': {'lat': 35.07356, 'lng': -111.84477}}, {'name': 'Fry Canyon', 'triplet': '1262:NV:SNTL', 'elevation': 6798, 'location': {'lat': 41.57022, 'lng': -115.93645}}, {'name': 'Galena', 'triplet': '489:ID:SNTL', 'elevation': 7470, 'location': {'lat': 43.87722, 'lng': -114.6725}}, {'name': 'Galena AK', 'triplet': '429:AK:SNTL', 'elevation': 410, 'location': {'lat': 64.69662, 'lng': -156.71497}}, {'name': 'Galena Summit', 'triplet': '490:ID:SNTL', 'elevation': 8780, 'location': {'lat': 43.87497, 'lng': -114.71363}}, {'name': 'Gallegos Peak', 'triplet': '491:NM:SNTL', 'elevation': 9480, 'location': {'lat': 36.19418, 'lng': -105.55742}}, {'name': 'Garden City Summit', 'triplet': '1114:UT:SNTL', 'elevation': 7705, 'location': {'lat': 41.9215, 'lng': -111.4693}}, {'name': 'Gardner Peak', 'triplet': '1066:UT:SNTL', 'elevation': 8322, 'location': {'lat': 37.40083, 'lng': -113.45988}}, {'name': 'Garfield R.S.', 'triplet': '492:ID:SNTL', 'elevation': 6560, 'location': {'lat': 43.6104, 'lng': -113.9308}}, {'name': 'Garita Peak', 'triplet': '1173:NM:SNTL', 'elevation': 10115, 'location': {'lat': 36.00469, 'lng': -106.54805}}, {'name': 'Garver Creek', 'triplet': '918:MT:SNTL', 'elevation': 4250, 'location': {'lat': 48.97523, 'lng': -115.81915}}, {'name': 'GBRC HQ', 'triplet': '1221:UT:SNTL', 'elevation': 8801, 'location': {'lat': 39.32019, 'lng': -111.48827}}, {'name': 'GBRC Meadows', 'triplet': '1222:UT:SNTL', 'elevation': 9858, 'location': {'lat': 39.30229, 'lng': -111.45383}}, {'name': 'George Creek', 'triplet': '1151:UT:SNTL', 'elevation': 8964, 'location': {'lat': 41.91562, 'lng': -113.41154}}, {'name': 'Gerber Reservoir', 'triplet': '945:OR:SNTL', 'elevation': 4890, 'location': {'lat': 42.2062, 'lng': -121.1334}}, {'name': 'Giveout', 'triplet': '493:ID:SNTL', 'elevation': 6930, 'location': {'lat': 42.4132, 'lng': -111.1663}}, {'name': 'Glen Cove', 'triplet': '1057:CO:SNTL', 'elevation': 11391, 'location': {'lat': 38.87602, 'lng': -105.07605}}, {'name': 'Gobblers Knob', 'triplet': '962:AK:SNTL', 'elevation': 2030, 'location': {'lat': 66.745, 'lng': -150.6675}}, {'name': 'Golconda', 'triplet': '1195:NV:SNTL', 'elevation': 6616, 'location': {'lat': 40.88358, 'lng': -117.58812}}, {'name': 'Gold Axe Camp', 'triplet': '1159:WA:SNTL', 'elevation': 5360, 'location': {'lat': 48.9516, 'lng': -118.9864}}, {'name': 'Gold Basin', 'triplet': '1304:UT:SNTL', 'elevation': 10076, 'location': {'lat': 38.46516, 'lng': -109.26332}}, {'name': 'Gold Center', 'triplet': '494:OR:SNTL', 'elevation': 5410, 'location': {'lat': 44.7638, 'lng': -118.3117}}, {'name': 'Gold Mountain', 'triplet': '1256:WA:SNTL', 'elevation': 4390, 'location': {'lat': 48.18934, 'lng': -118.4559}}, {'name': 'Gooseberry RS', 'triplet': '495:UT:SNTL', 'elevation': 7944, 'location': {'lat': 38.80034, 'lng': -111.68333}}, {'name': 'Gooseberry RS Up', 'triplet': '1184:UT:SNTL', 'elevation': 8396, 'location': {'lat': 38.7882, 'lng': -111.68892}}, {'name': 'Graham Guard Sta.', 'triplet': '496:ID:SNTL', 'elevation': 5690, 'location': {'lat': 43.9538, 'lng': -115.27387}}, {'name': 'Grand Targhee', 'triplet': '1082:WY:SNTL', 'elevation': 9260, 'location': {'lat': 43.77933, 'lng': -110.92783}}, {'name': 'Grandview', 'triplet': '956:AK:SNTL', 'elevation': 1100, 'location': {'lat': 60.60832, 'lng': -149.06313}}, {'name': 'Granite Creek', 'triplet': '497:WY:SNTL', 'elevation': 6770, 'location': {'lat': 43.34298, 'lng': -110.43495}}, {'name': 'Granite Crk', 'triplet': '963:AK:SNTL', 'elevation': 1240, 'location': {'lat': 63.94382, 'lng': -145.39993}}, {'name': 'Granite Peak', 'triplet': '498:NV:SNTL', 'elevation': 8503, 'location': {'lat': 41.67032, 'lng': -117.56668}}, {'name': 'Grassy Lake', 'triplet': '499:WY:SNTL', 'elevation': 7265, 'location': {'lat': 44.12612, 'lng': -110.83435}}, {'name': 'Grave Creek', 'triplet': '500:MT:SNTL', 'elevation': 4300, 'location': {'lat': 48.91453, 'lng': -114.76663}}, {'name': 'Grave Springs', 'triplet': '501:WY:SNTL', 'elevation': 8550, 'location': {'lat': 43.46643, 'lng': -107.23977}}, {'name': 'Grayback', 'triplet': '1058:CO:SNTL', 'elevation': 11626, 'location': {'lat': 37.47051, 'lng': -106.5379}}, {'name': 'Green Lake', 'triplet': '502:WA:SNTL', 'elevation': 5920, 'location': {'lat': 46.54741, 'lng': -121.17093}}, {'name': 'Green Mountain', 'triplet': '503:NV:SNTL', 'elevation': 8185, 'location': {'lat': 40.3848, 'lng': -115.52757}}, {'name': 'Greenpoint', 'triplet': '504:OR:SNTL', 'elevation': 3310, 'location': {'lat': 45.62237, 'lng': -121.70415}}, {'name': 'Grizzly Peak', 'triplet': '505:CO:SNTL', 'elevation': 11139, 'location': {'lat': 39.64646, 'lng': -105.8694}}, {'name': 'Gros Ventre Summit', 'triplet': '506:WY:SNTL', 'elevation': 8750, 'location': {'lat': 43.38939, 'lng': -110.12943}}, {'name': 'Grouse Camp', 'triplet': '507:WA:SNTL', 'elevation': 5390, 'location': {'lat': 47.28107, 'lng': -120.48771}}, {'name': 'Grouse Creek Divide', 'triplet': '964:AK:SNTL', 'elevation': 700, 'location': {'lat': 60.25965, 'lng': -149.34228}}, {'name': 'Gulkana River', 'triplet': '2222:AK:SNTL', 'elevation': 1830, 'location': {'lat': 62.40962, 'lng': -145.37513}}, {'name': 'Gunsight Pass', 'triplet': '944:WY:SNTL', 'elevation': 9820, 'location': {'lat': 43.38332, 'lng': -109.87815}}, {'name': 'Gutz Peak', 'triplet': '1065:UT:SNTL', 'elevation': 6763, 'location': {'lat': 37.49617, 'lng': -113.94235}}, {'name': 'Hagans Meadow', 'triplet': '508:CA:SNTL', 'elevation': 7742, 'location': {'lat': 38.8519, 'lng': -119.9374}}, {'name': 'Hams Fork', 'triplet': '509:WY:SNTL', 'elevation': 7840, 'location': {'lat': 42.146, 'lng': -110.67833}}, {'name': 'Hand Creek', 'triplet': '510:MT:SNTL', 'elevation': 5035, 'location': {'lat': 48.30754, 'lng': -114.84075}}, {'name': 'Hannagan Meadows', 'triplet': '511:AZ:SNTL', 'elevation': 9027, 'location': {'lat': 33.65352, 'lng': -109.30877}}, {'name': 'Hansen Sawmill', 'triplet': '512:WY:SNTL', 'elevation': 8360, 'location': {'lat': 44.25602, 'lng': -106.97983}}, {'name': 'Happy Jack', 'triplet': '969:AZ:SNTL', 'elevation': 7539, 'location': {'lat': 34.74594, 'lng': -111.41219}}, {'name': 'Hardscrabble', 'triplet': '896:UT:SNTL', 'elevation': 7250, 'location': {'lat': 40.86833, 'lng': -111.71865}}, {'name': 'Harris Flat', 'triplet': '514:UT:SNTL', 'elevation': 7792, 'location': {'lat': 37.48997, 'lng': -112.57602}}, {'name': 'Harts Pass', 'triplet': '515:WA:SNTL', 'elevation': 6490, 'location': {'lat': 48.72047, 'lng': -120.6586}}, {'name': 'Hawkins Lake', 'triplet': '516:MT:SNTL', 'elevation': 6450, 'location': {'lat': 48.9723, 'lng': -115.95337}}, {'name': 'Hawley Lake', 'triplet': '1271:AZ:SNTL', 'elevation': 8314, 'location': {'lat': 33.97121, 'lng': -109.76531}}, {'name': 'Hayden Fork', 'triplet': '517:UT:SNTL', 'elevation': 9130, 'location': {'lat': 40.79669, 'lng': -110.88472}}, {'name': 'Hayden Pass', 'triplet': '1102:CO:SNTL', 'elevation': 10699, 'location': {'lat': 38.29303, 'lng': -105.85027}}, {'name': 'Heavenly Valley', 'triplet': '518:CA:SNTL', 'elevation': 8534, 'location': {'lat': 38.92431, 'lng': -119.91641}}, {'name': 'Heber', 'triplet': '519:AZ:SNTL', 'elevation': 7654, 'location': {'lat': 34.31254, 'lng': -110.75433}}, {'name': 'Heen Latinee', 'triplet': '1270:AK:SNTL', 'elevation': 2065, 'location': {'lat': 58.69652, 'lng': -134.86448}}, {'name': 'Hemlock Butte', 'triplet': '520:ID:SNTL', 'elevation': 5810, 'location': {'lat': 46.48111, 'lng': -115.63361}}, {'name': 'Hewinta', 'triplet': '521:UT:SNTL', 'elevation': 9500, 'location': {'lat': 40.95009, 'lng': -110.48419}}, {'name': 'Hickerson Park', 'triplet': '522:UT:SNTL', 'elevation': 9122, 'location': {'lat': 40.90663, 'lng': -109.96287}}, {'name': 'Hidden Lake', 'triplet': '988:ID:SNTL', 'elevation': 5040, 'location': {'lat': 48.8937, 'lng': -116.75748}}, {'name': 'High Lonesome', 'triplet': '1187:CO:SNTL', 'elevation': 10638, 'location': {'lat': 40.0359, 'lng': -105.75472}}, {'name': 'High Ridge', 'triplet': '523:OR:SNTL', 'elevation': 4920, 'location': {'lat': 45.69682, 'lng': -118.10657}}, {'name': 'Hilts Creek', 'triplet': '524:ID:SNTL', 'elevation': 8000, 'location': {'lat': 44.01897, 'lng': -113.4723}}, {'name': 'Hobble Creek', 'triplet': '1223:UT:SNTL', 'elevation': 7377, 'location': {'lat': 40.18538, 'lng': -111.35971}}, {'name': 'Hobbs Park', 'triplet': '525:WY:SNTL', 'elevation': 10100, 'location': {'lat': 42.86984, 'lng': -109.09455}}, {'name': 'Hogg Pass', 'triplet': '526:OR:SNTL', 'elevation': 4790, 'location': {'lat': 44.42042, 'lng': -121.85655}}, {'name': 'Hole-in-Mountain', 'triplet': '527:NV:SNTL', 'elevation': 8163, 'location': {'lat': 40.94168, 'lng': -115.0954}}, {'name': 'Hole-in-Rock', 'triplet': '528:UT:SNTL', 'elevation': 9168, 'location': {'lat': 40.92167, 'lng': -110.18623}}, {'name': 'Holland Meadows', 'triplet': '529:OR:SNTL', 'elevation': 4930, 'location': {'lat': 43.66917, 'lng': -122.56877}}, {'name': 'Hoodoo Basin', 'triplet': '530:MT:SNTL', 'elevation': 6050, 'location': {'lat': 46.9751, 'lng': -115.0349}}, {'name': 'Hoosier Pass', 'triplet': '531:CO:SNTL', 'elevation': 11611, 'location': {'lat': 39.36092, 'lng': -106.05999}}, {'name': 'Hopewell', 'triplet': '532:NM:SNTL', 'elevation': 10095, 'location': {'lat': 36.71632, 'lng': -106.2637}}, {'name': 'Horse Meadow', 'triplet': '1050:CA:SNTL', 'elevation': 8557, 'location': {'lat': 38.83652, 'lng': -119.88732}}, {'name': 'Horse Ridge', 'triplet': '533:UT:SNTL', 'elevation': 8199, 'location': {'lat': 41.31372, 'lng': -111.44624}}, {'name': 'Hourglass Lake', 'triplet': '1122:CO:SNTL', 'elevation': 9417, 'location': {'lat': 40.57717, 'lng': -105.62584}}, {'name': 'Howard Prairie', 'triplet': '1158:OR:SNTL', 'elevation': 4580, 'location': {'lat': 42.215, 'lng': -122.3713}}, {'name': 'Howell Canyon', 'triplet': '534:ID:SNTL', 'elevation': 7980, 'location': {'lat': 42.32029, 'lng': -113.61587}}, {'name': 'Hozatka Lake', 'triplet': '2210:AK:SNTL', 'elevation': 206, 'location': {'lat': 65.198, 'lng': -156.635}}, {'name': 'Hozomeen Camp', 'triplet': '991:WA:SNTL', 'elevation': 1690, 'location': {'lat': 48.98075, 'lng': -121.07976}}, {'name': 'Huckleberry Creek', 'triplet': '928:WA:SNTL', 'elevation': 2250, 'location': {'lat': 47.06565, 'lng': -121.58778}}, {'name': 'Humboldt Gulch', 'triplet': '535:ID:SNTL', 'elevation': 4250, 'location': {'lat': 47.53178, 'lng': -115.77643}}, {'name': 'Huntington Horse', 'triplet': '1216:UT:SNTL', 'elevation': 9652, 'location': {'lat': 39.61774, 'lng': -111.30576}}, {'name': 'Hyndman', 'triplet': '537:ID:SNTL', 'elevation': 7620, 'location': {'lat': 43.71077, 'lng': -114.15894}}, {'name': 'Idarado', 'triplet': '538:CO:SNTL', 'elevation': 9812, 'location': {'lat': 37.93389, 'lng': -107.6762}}, {'name': 'Imnaviat Creek', 'triplet': '968:AK:SNTL', 'elevation': 3050, 'location': {'lat': 68.61683, 'lng': -149.30017}}, {'name': 'Independence Camp', 'triplet': '539:CA:SNTL', 'elevation': 6980, 'location': {'lat': 39.45269, 'lng': -120.29367}}, {'name': 'Independence Creek', 'triplet': '540:CA:SNTL', 'elevation': 6436, 'location': {'lat': 39.49001, 'lng': -120.28226}}, {'name': 'Independence Lake', 'triplet': '541:CA:SNTL', 'elevation': 8338, 'location': {'lat': 39.42752, 'lng': -120.31342}}, {'name': 'Independence Mine', 'triplet': '1091:AK:SNTL', 'elevation': 3550, 'location': {'lat': 61.79001, 'lng': -149.2839}}, {'name': 'Independence Pass', 'triplet': '542:CO:SNTL', 'elevation': 10598, 'location': {'lat': 39.07543, 'lng': -106.61154}}, {'name': 'Indian Creek', 'triplet': '544:WY:SNTL', 'elevation': 9425, 'location': {'lat': 42.30023, 'lng': -110.67753}}, {'name': 'Indian Pass', 'triplet': '946:AK:SNTL', 'elevation': 2350, 'location': {'lat': 61.06767, 'lng': -149.4795}}, {'name': 'Indian Rock', 'triplet': '1129:WA:SNTL', 'elevation': 5360, 'location': {'lat': 45.99077, 'lng': -120.80767}}, {'name': 'Irish Taylor', 'triplet': '545:OR:SNTL', 'elevation': 5540, 'location': {'lat': 43.80368, 'lng': -121.94793}}, {'name': 'Island Park', 'triplet': '546:ID:SNTL', 'elevation': 6290, 'location': {'lat': 44.4203, 'lng': -111.38512}}, {'name': 'Ivanhoe', 'triplet': '547:CO:SNTL', 'elevation': 10541, 'location': {'lat': 39.29228, 'lng': -106.54907}}, {'name': 'Jack Creek Upper', 'triplet': '548:NV:SNTL', 'elevation': 7377, 'location': {'lat': 41.54675, 'lng': -116.00517}}, {'name': 'Jack Wade Jct', 'triplet': '1275:AK:SNTL', 'elevation': 3585, 'location': {'lat': 64.1529, 'lng': -141.32693}}, {'name': 'Jacks Peak', 'triplet': '549:NV:SNTL', 'elevation': 8424, 'location': {'lat': 41.5136, 'lng': -116.0117}}, {'name': 'Jackson Peak', 'triplet': '550:ID:SNTL', 'elevation': 7070, 'location': {'lat': 44.05092, 'lng': -115.44322}}, {'name': 'Jackwhacker Gulch', 'triplet': '935:CO:SNTL', 'elevation': 11054, 'location': {'lat': 39.57096, 'lng': -105.80355}}, {'name': 'Jakes Creek', 'triplet': '1211:NV:SNTL', 'elevation': 7380, 'location': {'lat': 41.5687, 'lng': -115.03243}}, {'name': 'JL Meadow', 'triplet': '1287:MT:SNTL', 'elevation': 8800, 'location': {'lat': 44.77665, 'lng': -113.12217}}, {'name': 'Joe Wright', 'triplet': '551:CO:SNTL', 'elevation': 10158, 'location': {'lat': 40.53285, 'lng': -105.88747}}, {'name': 'Johnsons Camp', 'triplet': '1036:AK:SNTL', 'elevation': 25, 'location': {'lat': 64.5646, 'lng': -164.29257}}, {'name': 'Jones Corral', 'triplet': '1099:UT:SNTL', 'elevation': 9749, 'location': {'lat': 38.07125, 'lng': -112.16788}}, {'name': 'Jones Pass', 'triplet': '970:CO:SNTL', 'elevation': 10426, 'location': {'lat': 39.7645, 'lng': -105.90655}}, {'name': 'Jump Off Joe', 'triplet': '552:OR:SNTL', 'elevation': 3520, 'location': {'lat': 44.38605, 'lng': -122.16683}}, {'name': 'June Lake', 'triplet': '553:WA:SNTL', 'elevation': 3440, 'location': {'lat': 46.14778, 'lng': -122.15413}}, {'name': 'Kalamazoo', 'triplet': '1150:NV:SNTL', 'elevation': 7775, 'location': {'lat': 39.5579, 'lng': -114.62762}}, {'name': 'Kantishna', 'triplet': '1072:AK:SNTL', 'elevation': 1550, 'location': {'lat': 63.54167, 'lng': -150.994}}, {'name': 'Kelley R.S.', 'triplet': '554:WY:SNTL', 'elevation': 8180, 'location': {'lat': 42.26554, 'lng': -110.80177}}, {'name': 'Kelly Station', 'triplet': '1175:AK:SNTL', 'elevation': 310, 'location': {'lat': 67.93333, 'lng': -162.28333}}, {'name': 'Kenai Moose Pens', 'triplet': '966:AK:SNTL', 'elevation': 300, 'location': {'lat': 60.727, 'lng': -150.47517}}, {'name': 'Kendall R.S.', 'triplet': '555:WY:SNTL', 'elevation': 7740, 'location': {'lat': 43.2493, 'lng': -110.01662}}, {'name': 'Kilfoil Creek', 'triplet': '1145:UT:SNTL', 'elevation': 7220, 'location': {'lat': 41.24764, 'lng': -111.41249}}, {'name': 'Kiln', 'triplet': '556:CO:SNTL', 'elevation': 9624, 'location': {'lat': 39.3172, 'lng': -106.61501}}, {'name': 'Kimberly Mine', 'triplet': '557:UT:SNTL', 'elevation': 9101, 'location': {'lat': 38.48383, 'lng': -112.39273}}, {'name': 'King Mountain', 'triplet': '558:OR:SNTL', 'elevation': 4340, 'location': {'lat': 42.72395, 'lng': -123.20037}}, {'name': 'Kings Cabin', 'triplet': '559:UT:SNTL', 'elevation': 8728, 'location': {'lat': 40.71632, 'lng': -109.54401}}, {'name': 'Kirwin', 'triplet': '560:WY:SNTL', 'elevation': 9550, 'location': {'lat': 43.86067, 'lng': -109.32163}}, {'name': 'Klondike Narrows', 'triplet': '1115:UT:SNTL', 'elevation': 7250, 'location': {'lat': 41.96769, 'lng': -111.59713}}, {'name': 'Kolob', 'triplet': '561:UT:SNTL', 'elevation': 9263, 'location': {'lat': 37.52664, 'lng': -113.05386}}, {'name': 'Kraft Creek', 'triplet': '562:MT:SNTL', 'elevation': 4750, 'location': {'lat': 47.42749, 'lng': -113.77515}}, {'name': 'Lake Creek R.S.', 'triplet': '563:OR:SNTL', 'elevation': 5240, 'location': {'lat': 44.21007, 'lng': -118.63752}}, {'name': 'Lake Eldora', 'triplet': '564:CO:SNTL', 'elevation': 9728, 'location': {'lat': 39.93659, 'lng': -105.59031}}, {'name': 'Lake Irene', 'triplet': '565:CO:SNTL', 'elevation': 10682, 'location': {'lat': 40.41446, 'lng': -105.81941}}, {'name': 'Lakefork #1', 'triplet': '566:UT:SNTL', 'elevation': 10128, 'location': {'lat': 40.59709, 'lng': -110.43316}}, {'name': 'Lakefork #3', 'triplet': '1116:UT:SNTL', 'elevation': 8464, 'location': {'lat': 40.5502, 'lng': -110.3529}}, {'name': 'Lakefork Basin', 'triplet': '513:UT:SNTL', 'elevation': 10885, 'location': {'lat': 40.73785, 'lng': -110.62121}}, {'name': 'Lakeview Ridge', 'triplet': '568:MT:SNTL', 'elevation': 7400, 'location': {'lat': 44.58907, 'lng': -111.82498}}, {'name': 'Lamance Creek', 'triplet': '569:NV:SNTL', 'elevation': 6395, 'location': {'lat': 41.51542, 'lng': -117.63197}}, {'name': 'Lamoille #3', 'triplet': '570:NV:SNTL', 'elevation': 8051, 'location': {'lat': 40.6448, 'lng': -115.3812}}, {'name': 'Lamoille Upper', 'triplet': '1310:NV:SNTL', 'elevation': 8993, 'location': {'lat': 40.59965, 'lng': -115.37902}}, {'name': 'Laprele Creek', 'triplet': '571:WY:SNTL', 'elevation': 8390, 'location': {'lat': 42.43566, 'lng': -105.86051}}, {'name': 'Larsen Creek', 'triplet': '1134:WY:SNTL', 'elevation': 9000, 'location': {'lat': 42.5801, 'lng': -109.0883}}, {'name': 'Lasal Mountain', 'triplet': '572:UT:SNTL', 'elevation': 9578, 'location': {'lat': 38.48226, 'lng': -109.27198}}, {'name': 'Lasal Mountain-Lower', 'triplet': '1215:UT:SNTL', 'elevation': 8783, 'location': {'lat': 38.48167, 'lng': -109.29164}}, {'name': 'Laurel Draw', 'triplet': '573:NV:SNTL', 'elevation': 6682, 'location': {'lat': 41.77637, 'lng': -116.02957}}, {'name': 'Leavitt Lake', 'triplet': '574:CA:SNTL', 'elevation': 9604, 'location': {'lat': 38.27594, 'lng': -119.61281}}, {'name': 'Leavitt Meadows', 'triplet': '575:CA:SNTL', 'elevation': 7198, 'location': {'lat': 38.30367, 'lng': -119.55111}}, {'name': 'Lee Canyon', 'triplet': '1112:NV:SNTL', 'elevation': 8626, 'location': {'lat': 36.30537, 'lng': -115.67508}}, {'name': 'Lemhi Ridge', 'triplet': '576:MT:SNTL', 'elevation': 8100, 'location': {'lat': 44.9938, 'lng': -113.44399}}, {'name': 'Lewis Lake Divide', 'triplet': '577:WY:SNTL', 'elevation': 7850, 'location': {'lat': 44.20862, 'lng': -110.66628}}, {'name': 'Lewis Peak', 'triplet': '1006:NV:SNTL', 'elevation': 7370, 'location': {'lat': 40.3572, 'lng': -116.8647}}, {'name': 'Lick Creek', 'triplet': '578:MT:SNTL', 'elevation': 6860, 'location': {'lat': 45.5041, 'lng': -110.96625}}, {'name': 'Lightning Ridge', 'triplet': '1056:UT:SNTL', 'elevation': 8215, 'location': {'lat': 41.35891, 'lng': -111.48749}}, {'name': 'Lily Lake', 'triplet': '579:UT:SNTL', 'elevation': 9133, 'location': {'lat': 40.86493, 'lng': -110.79813}}, {'name': 'Lily Pond', 'triplet': '580:CO:SNTL', 'elevation': 11069, 'location': {'lat': 37.38028, 'lng': -106.54823}}, {'name': 'Little Bear', 'triplet': '582:UT:SNTL', 'elevation': 6548, 'location': {'lat': 41.40562, 'lng': -111.82607}}, {'name': 'Little Chena Ridge', 'triplet': '947:AK:SNTL', 'elevation': 2000, 'location': {'lat': 65.12422, 'lng': -146.7339}}, {'name': 'Little Goose', 'triplet': '1131:WY:SNTL', 'elevation': 8870, 'location': {'lat': 44.54315, 'lng': -107.17865}}, {'name': 'Little Grassy', 'triplet': '583:UT:SNTL', 'elevation': 6065, 'location': {'lat': 37.48631, 'lng': -113.84582}}, {'name': 'Little Meadows', 'triplet': '584:OR:SNTL', 'elevation': 4020, 'location': {'lat': 44.61297, 'lng': -122.22565}}, {'name': 'Little Snake River', 'triplet': '1047:WY:SNTL', 'elevation': 8928, 'location': {'lat': 41.07051, 'lng': -106.94284}}, {'name': 'Little Valley', 'triplet': '1242:NV:SNTL', 'elevation': 6493, 'location': {'lat': 39.25259, 'lng': -119.8771}}, {'name': 'Little Warm', 'triplet': '585:WY:SNTL', 'elevation': 9370, 'location': {'lat': 43.50278, 'lng': -109.752}}, {'name': 'Lizard Head Pass', 'triplet': '586:CO:SNTL', 'elevation': 10193, 'location': {'lat': 37.79895, 'lng': -107.92475}}, {'name': 'Lobdell Lake', 'triplet': '587:CA:SNTL', 'elevation': 9249, 'location': {'lat': 38.43745, 'lng': -119.36572}}, {'name': 'Lolo Pass', 'triplet': '588:ID:SNTL', 'elevation': 5240, 'location': {'lat': 46.63448, 'lng': -114.58072}}, {'name': 'Lone Cone', 'triplet': '589:CO:SNTL', 'elevation': 9755, 'location': {'lat': 37.89169, 'lng': -108.19636}}, {'name': 'Lone Mountain', 'triplet': '590:MT:SNTL', 'elevation': 8880, 'location': {'lat': 45.27412, 'lng': -111.42692}}, {'name': 'Lone Pine', 'triplet': '591:WA:SNTL', 'elevation': 3930, 'location': {'lat': 46.27143, 'lng': -121.96288}}, {'name': 'Lonesome Beaver', 'triplet': '1261:UT:SNTL', 'elevation': 9410, 'location': {'lat': 38.07, 'lng': -110.77241}}, {'name': 'Long Draw Resv', 'triplet': '1123:CO:SNTL', 'elevation': 10008, 'location': {'lat': 40.51154, 'lng': -105.7654}}, {'name': 'Long Flat', 'triplet': '592:UT:SNTL', 'elevation': 7982, 'location': {'lat': 37.51255, 'lng': -113.39661}}, {'name': 'Long Lake', 'triplet': '1001:AK:SNTL', 'elevation': 850, 'location': {'lat': 58.186, 'lng': -133.83217}}, {'name': 'Long Valley', 'triplet': '1016:ID:SNTL', 'elevation': 4890, 'location': {'lat': 44.78835, 'lng': -116.08878}}, {'name': 'Long Valley Jct', 'triplet': '593:UT:SNTL', 'elevation': 7465, 'location': {'lat': 37.48756, 'lng': -112.51458}}, {'name': 'Lookout', 'triplet': '594:ID:SNTL', 'elevation': 5190, 'location': {'lat': 47.45749, 'lng': -115.70457}}, {'name': 'Lookout Mountain', 'triplet': '595:NM:SNTL', 'elevation': 8509, 'location': {'lat': 33.36089, 'lng': -107.83203}}, {'name': 'Lookout Peak', 'triplet': '596:UT:SNTL', 'elevation': 8161, 'location': {'lat': 40.83731, 'lng': -111.70965}}, {'name': 'Loomis Park', 'triplet': '597:WY:SNTL', 'elevation': 8240, 'location': {'lat': 43.17387, 'lng': -110.14007}}, {'name': 'Lost Creek Resv', 'triplet': '1118:UT:SNTL', 'elevation': 6082, 'location': {'lat': 41.22155, 'lng': -111.35947}}, {'name': 'Lost Dog', 'triplet': '940:CO:SNTL', 'elevation': 9327, 'location': {'lat': 40.81557, 'lng': -106.74833}}, {'name': 'Lost Horse', 'triplet': '599:WA:SNTL', 'elevation': 5120, 'location': {'lat': 46.3575, 'lng': -121.08095}}, {'name': 'Lost Lake', 'triplet': '600:ID:SNTL', 'elevation': 6110, 'location': {'lat': 47.0809, 'lng': -115.9604}}, {'name': 'Lost-Wood Divide', 'triplet': '601:ID:SNTL', 'elevation': 7900, 'location': {'lat': 43.82432, 'lng': -114.26402}}, {'name': 'Louis Meadow', 'triplet': '972:UT:SNTL', 'elevation': 6700, 'location': {'lat': 40.83033, 'lng': -111.76457}}, {'name': 'Loveland Basin', 'triplet': '602:CO:SNTL', 'elevation': 11427, 'location': {'lat': 39.67428, 'lng': -105.90264}}, {'name': 'Lower Kachemak Creek', 'triplet': '1265:AK:SNTL', 'elevation': 1915, 'location': {'lat': 59.73507, 'lng': -150.69327}}, {'name': 'Lower Twin', 'triplet': '603:MT:SNTL', 'elevation': 7900, 'location': {'lat': 45.50871, 'lng': -111.92288}}, {'name': 'Lubrecht Flume', 'triplet': '604:MT:SNTL', 'elevation': 4680, 'location': {'lat': 46.88293, 'lng': -113.32228}}, {'name': 'Lucky Strike', 'triplet': '605:OR:SNTL', 'elevation': 4970, 'location': {'lat': 45.27478, 'lng': -118.8479}}, {'name': 'Lyman Lake', 'triplet': '606:WA:SNTL', 'elevation': 5980, 'location': {'lat': 48.19798, 'lng': -120.91678}}, {'name': 'Lynn Lake', 'triplet': '1069:WA:SNTL', 'elevation': 3900, 'location': {'lat': 47.20172, 'lng': -121.77972}}, {'name': 'Lynx Pass', 'triplet': '607:CO:SNTL', 'elevation': 8919, 'location': {'lat': 40.07832, 'lng': -106.67095}}, {'name': 'Madison Butte', 'triplet': '608:OR:SNTL', 'elevation': 5150, 'location': {'lat': 45.10513, 'lng': -119.49585}}, {'name': 'Madison Plateau', 'triplet': '609:MT:SNTL', 'elevation': 7750, 'location': {'lat': 44.58623, 'lng': -111.11627}}, {'name': 'Magic Mountain', 'triplet': '610:ID:SNTL', 'elevation': 6880, 'location': {'lat': 42.18072, 'lng': -114.28662}}, {'name': 'Mammoth-Cottonwood', 'triplet': '612:UT:SNTL', 'elevation': 8709, 'location': {'lat': 39.68338, 'lng': -111.31818}}, {'name': 'Mancos', 'triplet': '905:CO:SNTL', 'elevation': 10044, 'location': {'lat': 37.43109, 'lng': -108.17005}}, {'name': 'Many Glacier', 'triplet': '613:MT:SNTL', 'elevation': 4900, 'location': {'lat': 48.79698, 'lng': -113.6705}}, {'name': 'Marion Forks', 'triplet': '614:OR:SNTL', 'elevation': 2590, 'location': {'lat': 44.59397, 'lng': -121.97365}}, {'name': 'Marlette Lake', 'triplet': '615:NV:SNTL', 'elevation': 7884, 'location': {'lat': 39.16395, 'lng': -119.89672}}, {'name': 'Marquette', 'triplet': '616:WY:SNTL', 'elevation': 8760, 'location': {'lat': 44.3016, 'lng': -109.24019}}, {'name': 'Marten Ridge', 'triplet': '999:WA:SNTL', 'elevation': 3520, 'location': {'lat': 48.76292, 'lng': -121.69823}}, {'name': 'Maverick Fork', 'triplet': '617:AZ:SNTL', 'elevation': 9220, 'location': {'lat': 33.92123, 'lng': -109.45872}}, {'name': 'May Creek', 'triplet': '1096:AK:SNTL', 'elevation': 1610, 'location': {'lat': 61.34783, 'lng': -142.70967}}, {'name': 'Mc Clure Pass', 'triplet': '618:CO:SNTL', 'elevation': 8774, 'location': {'lat': 39.12899, 'lng': -107.28834}}, {'name': 'Mccoy Park', 'triplet': '1040:CO:SNTL', 'elevation': 9516, 'location': {'lat': 39.60231, 'lng': -106.544}}, {'name': 'McGrath', 'triplet': '785:AK:SNTL', 'elevation': 340, 'location': {'lat': 62.94652, 'lng': -155.6102}}, {'name': 'Mckenzie', 'triplet': '619:OR:SNTL', 'elevation': 4770, 'location': {'lat': 44.2103, 'lng': -121.87292}}, {'name': 'Mcknight Cabin', 'triplet': '1048:NM:SNTL', 'elevation': 9242, 'location': {'lat': 33.00796, 'lng': -107.86982}}, {'name': 'Mcneil Canyon', 'triplet': '1003:AK:SNTL', 'elevation': 1320, 'location': {'lat': 59.74433, 'lng': -151.25133}}, {'name': 'Mcneil River SGS', 'triplet': '1191:AK:SNTL', 'elevation': 140, 'location': {'lat': 59.08332, 'lng': -154.27543}}, {'name': 'Meadow Lake', 'triplet': '620:ID:SNTL', 'elevation': 9150, 'location': {'lat': 44.43655, 'lng': -113.31815}}, {'name': 'Meadows Pass', 'triplet': '897:WA:SNTL', 'elevation': 3230, 'location': {'lat': 47.28312, 'lng': -121.47197}}, {'name': 'Med Bow', 'triplet': '1196:WY:SNTL', 'elevation': 10512, 'location': {'lat': 41.37833, 'lng': -106.34697}}, {'name': 'Medano Pass', 'triplet': '914:CO:SNTL', 'elevation': 9668, 'location': {'lat': 37.85192, 'lng': -105.43666}}, {'name': 'Merchant Valley', 'triplet': '621:UT:SNTL', 'elevation': 8705, 'location': {'lat': 38.30285, 'lng': -112.43637}}, {'name': 'Merritt Mountain', 'triplet': '1207:NV:SNTL', 'elevation': 6915, 'location': {'lat': 41.8927, 'lng': -115.858}}, {'name': 'Mesa Lakes', 'triplet': '622:CO:SNTL', 'elevation': 10168, 'location': {'lat': 39.05738, 'lng': -108.05756}}, {'name': 'MF Nooksack', 'triplet': '1011:WA:SNTL', 'elevation': 4970, 'location': {'lat': 48.82453, 'lng': -121.92951}}, {'name': 'Mica Creek', 'triplet': '623:ID:SNTL', 'elevation': 4510, 'location': {'lat': 47.15045, 'lng': -116.26643}}, {'name': 'Michigan Creek', 'triplet': '937:CO:SNTL', 'elevation': 10702, 'location': {'lat': 39.43579, 'lng': -105.91072}}, {'name': 'Midas', 'triplet': '1206:NV:SNTL', 'elevation': 6630, 'location': {'lat': 41.26873, 'lng': -116.80332}}, {'name': 'Middle Creek', 'triplet': '624:CO:SNTL', 'elevation': 11269, 'location': {'lat': 37.61779, 'lng': -107.03932}}, {'name': 'Middle Fork Bradley', 'triplet': '1064:AK:SNTL', 'elevation': 2300, 'location': {'lat': 59.77683, 'lng': -150.75733}}, {'name': 'Middle Fork Camp', 'triplet': '1014:CO:SNTL', 'elevation': 8969, 'location': {'lat': 39.79565, 'lng': -106.02802}}, {'name': 'Middle Powder', 'triplet': '625:WY:SNTL', 'elevation': 7760, 'location': {'lat': 43.62728, 'lng': -107.18138}}, {'name': 'Midway Valley', 'triplet': '626:UT:SNTL', 'elevation': 9827, 'location': {'lat': 37.56933, 'lng': -112.83849}}, {'name': 'Milk Shakes', 'triplet': '1079:OR:SNTL', 'elevation': 5580, 'location': {'lat': 45.9821, 'lng': -117.94883}}, {'name': 'Mill Creek Summit', 'triplet': '627:ID:SNTL', 'elevation': 8800, 'location': {'lat': 44.47212, 'lng': -114.48992}}, {'name': 'Mill-D North', 'triplet': '628:UT:SNTL', 'elevation': 8963, 'location': {'lat': 40.65883, 'lng': -111.63683}}, {'name': 'Miller Woods', 'triplet': '1084:OR:SNTL', 'elevation': 420, 'location': {'lat': 45.24755, 'lng': -123.27563}}, {'name': 'Mineral Creek', 'triplet': '629:CO:SNTL', 'elevation': 10046, 'location': {'lat': 37.84737, 'lng': -107.72657}}, {'name': 'Mining Fork', 'triplet': '631:UT:SNTL', 'elevation': 8295, 'location': {'lat': 40.49384, 'lng': -112.61141}}, {'name': 'Molas Lake', 'triplet': '632:CO:SNTL', 'elevation': 10631, 'location': {'lat': 37.74929, 'lng': -107.68933}}, {'name': 'Monahan Flat', 'triplet': '1094:AK:SNTL', 'elevation': 2710, 'location': {'lat': 63.30533, 'lng': -147.64633}}, {'name': 'Monitor Pass', 'triplet': '633:CA:SNTL', 'elevation': 8306, 'location': {'lat': 38.6683, 'lng': -119.6087}}, {'name': 'Monte Cristo', 'triplet': '634:UT:SNTL', 'elevation': 8932, 'location': {'lat': 41.46547, 'lng': -111.49688}}, {'name': 'Monument Creek', 'triplet': '949:AK:SNTL', 'elevation': 1850, 'location': {'lat': 65.07833, 'lng': -145.87067}}, {'name': 'Monument Peak', 'triplet': '635:MT:SNTL', 'elevation': 8850, 'location': {'lat': 45.21759, 'lng': -110.237}}, {'name': 'Moon Pass', 'triplet': '1124:CO:SNTL', 'elevation': 11128, 'location': {'lat': 37.96627, 'lng': -106.55857}}, {'name': 'Moonshine', 'triplet': '636:ID:SNTL', 'elevation': 7440, 'location': {'lat': 44.4147, 'lng': -113.39812}}, {'name': 'Moore Creek Bridge', 'triplet': '1176:AK:SNTL', 'elevation': 2250, 'location': {'lat': 59.58783, 'lng': -135.2105}}, {'name': 'Moose Creek', 'triplet': '638:ID:SNTL', 'elevation': 6200, 'location': {'lat': 45.67008, 'lng': -113.95315}}, {'name': 'Moraine', 'triplet': '1035:AK:SNTL', 'elevation': 2100, 'location': {'lat': 61.37727, 'lng': -148.99917}}, {'name': 'Mores Creek Summit', 'triplet': '637:ID:SNTL', 'elevation': 6100, 'location': {'lat': 43.932, 'lng': -115.66588}}, {'name': 'Morgan Creek', 'triplet': '639:ID:SNTL', 'elevation': 7600, 'location': {'lat': 44.84237, 'lng': -114.26871}}, {'name': 'Mormon Mountain', 'triplet': '640:AZ:SNTL', 'elevation': 7500, 'location': {'lat': 34.94141, 'lng': -111.51864}}, {'name': 'Mormon Mtn Summit', 'triplet': '1125:AZ:SNTL', 'elevation': 8462, 'location': {'lat': 34.96942, 'lng': -111.50868}}, {'name': 'Morse Lake', 'triplet': '642:WA:SNTL', 'elevation': 5410, 'location': {'lat': 46.90585, 'lng': -121.4827}}, {'name': 'Mosby Mtn.', 'triplet': '643:UT:SNTL', 'elevation': 9553, 'location': {'lat': 40.60798, 'lng': -109.8881}}, {'name': 'Moscow Mountain', 'triplet': '989:ID:SNTL', 'elevation': 4700, 'location': {'lat': 46.805, 'lng': -116.8535}}, {'name': 'Moses Mtn', 'triplet': '644:WA:SNTL', 'elevation': 5010, 'location': {'lat': 48.36163, 'lng': -119.08159}}, {'name': 'Mosquito Ridge', 'triplet': '645:ID:SNTL', 'elevation': 5260, 'location': {'lat': 48.05726, 'lng': -116.23055}}, {'name': 'Moss Peak', 'triplet': '646:MT:SNTL', 'elevation': 6780, 'location': {'lat': 47.68493, 'lng': -113.9623}}, {'name': 'Moss Springs', 'triplet': '647:OR:SNTL', 'elevation': 5760, 'location': {'lat': 45.27173, 'lng': -117.68747}}, {'name': 'Mount Crag', 'triplet': '648:WA:SNTL', 'elevation': 3960, 'location': {'lat': 47.7637, 'lng': -123.026}}, {'name': 'Mount Gardner', 'triplet': '898:WA:SNTL', 'elevation': 2920, 'location': {'lat': 47.35768, 'lng': -121.56812}}, {'name': 'Mount Lockhart', 'triplet': '649:MT:SNTL', 'elevation': 6400, 'location': {'lat': 47.91727, 'lng': -112.8238}}, {'name': 'Mountain Meadows', 'triplet': '650:ID:SNTL', 'elevation': 6320, 'location': {'lat': 45.69694, 'lng': -115.22972}}, {'name': 'Mowich', 'triplet': '941:WA:SNTL', 'elevation': 3160, 'location': {'lat': 46.92833, 'lng': -121.95232}}, {'name': 'Mt Baldy', 'triplet': '1224:UT:SNTL', 'elevation': 9524, 'location': {'lat': 39.13648, 'lng': -111.50527}}, {'name': 'Mt Hood Test Site', 'triplet': '651:OR:SNTL', 'elevation': 5370, 'location': {'lat': 45.32097, 'lng': -121.7158}}, {'name': 'Mt Pennell', 'triplet': '1269:UT:SNTL', 'elevation': 9209, 'location': {'lat': 37.97793, 'lng': -110.7933}}, {'name': 'Mt Rose Ski Area', 'triplet': '652:NV:SNTL', 'elevation': 8801, 'location': {'lat': 39.31573, 'lng': -119.89473}}, {'name': 'Mt. Alyeska', 'triplet': '1103:AK:SNTL', 'elevation': 1540, 'location': {'lat': 60.95983, 'lng': -149.08617}}, {'name': 'Mt. Eyak', 'triplet': '1073:AK:SNTL', 'elevation': 1405, 'location': {'lat': 60.55, 'lng': -145.745}}, {'name': 'Mt. Howard', 'triplet': '653:OR:SNTL', 'elevation': 7910, 'location': {'lat': 45.26522, 'lng': -117.17373}}, {'name': 'Mt. Ryan', 'triplet': '948:AK:SNTL', 'elevation': 2800, 'location': {'lat': 65.25113, 'lng': -146.15133}}, {'name': 'Mt. Tebo', 'triplet': '1126:WA:SNTL', 'elevation': 3384, 'location': {'lat': 47.46061, 'lng': -123.41219}}, {'name': 'Muckamuck', 'triplet': '1259:WA:SNTL', 'elevation': 4470, 'location': {'lat': 48.58526, 'lng': -119.86624}}, {'name': 'Mud Flat', 'triplet': '654:ID:SNTL', 'elevation': 5730, 'location': {'lat': 42.6004, 'lng': -116.55925}}, {'name': 'Mud Ridge', 'triplet': '655:OR:SNTL', 'elevation': 4070, 'location': {'lat': 45.25362, 'lng': -121.73673}}, {'name': 'Mule Creek', 'triplet': '656:MT:SNTL', 'elevation': 8300, 'location': {'lat': 45.40957, 'lng': -112.95927}}, {'name': 'Munson Ridge', 'triplet': '950:AK:SNTL', 'elevation': 3100, 'location': {'lat': 64.85033, 'lng': -146.20945}}, {'name': 'Myrtle Creek', 'triplet': '1053:ID:SNTL', 'elevation': 3520, 'location': {'lat': 48.72263, 'lng': -116.46312}}, {'name': 'N Fk Elk Creek', 'triplet': '657:MT:SNTL', 'elevation': 6250, 'location': {'lat': 46.8716, 'lng': -113.27725}}, {'name': 'Nast Lake', 'triplet': '658:CO:SNTL', 'elevation': 8731, 'location': {'lat': 39.29695, 'lng': -106.60786}}, {'name': 'Navajo Whiskey Ck', 'triplet': '1138:NM:SNTL', 'elevation': 9064, 'location': {'lat': 36.17716, 'lng': -108.94556}}, {'name': 'Nenana', 'triplet': '2081:AK:SNTL', 'elevation': 415, 'location': {'lat': 64.68582, 'lng': -148.9113}}, {'name': 'Nevada Ridge', 'triplet': '903:MT:SNTL', 'elevation': 7020, 'location': {'lat': 46.84234, 'lng': -112.50787}}, {'name': 'Never Summer', 'triplet': '1031:CO:SNTL', 'elevation': 10323, 'location': {'lat': 40.40392, 'lng': -105.95567}}, {'name': 'New Crescent Lake', 'triplet': '660:OR:SNTL', 'elevation': 4910, 'location': {'lat': 43.51185, 'lng': -121.97982}}, {'name': 'New Fork Lake', 'triplet': '661:WY:SNTL', 'elevation': 8340, 'location': {'lat': 43.11265, 'lng': -109.94947}}, {'name': 'Nez Perce Camp', 'triplet': '662:MT:SNTL', 'elevation': 5650, 'location': {'lat': 45.73107, 'lng': -114.48075}}, {'name': 'Niwot', 'triplet': '663:CO:SNTL', 'elevation': 9979, 'location': {'lat': 40.03581, 'lng': -105.5452}}, {'name': 'Noisy Basin', 'triplet': '664:MT:SNTL', 'elevation': 6040, 'location': {'lat': 48.15678, 'lng': -113.94637}}, {'name': 'North Costilla', 'triplet': '665:NM:SNTL', 'elevation': 10598, 'location': {'lat': 36.99396, 'lng': -105.25988}}, {'name': 'North Fork', 'triplet': '666:OR:SNTL', 'elevation': 3060, 'location': {'lat': 45.5505, 'lng': -122.00283}}, {'name': 'North Fork Jocko', 'triplet': '667:MT:SNTL', 'elevation': 6330, 'location': {'lat': 47.2726, 'lng': -113.75617}}, {'name': 'North French Creek', 'triplet': '668:WY:SNTL', 'elevation': 10153, 'location': {'lat': 41.33087, 'lng': -106.37558}}, {'name': 'North Lost Trail', 'triplet': '669:CO:SNTL', 'elevation': 9219, 'location': {'lat': 39.07818, 'lng': -107.14388}}, {'name': 'North Rapid Creek', 'triplet': '920:SD:SNTL', 'elevation': 6130, 'location': {'lat': 44.20617, 'lng': -103.78758}}, {'name': 'Northeast Entrance', 'triplet': '670:MT:SNTL', 'elevation': 7350, 'location': {'lat': 45.00565, 'lng': -110.01406}}, {'name': 'Nuka Glacier', 'triplet': '1037:AK:SNTL', 'elevation': 1250, 'location': {'lat': 59.69867, 'lng': -150.70967}}, {'name': 'Nutrioso', 'triplet': '1127:AZ:SNTL', 'elevation': 8571, 'location': {'lat': 33.89791, 'lng': -109.15465}}, {'name': 'Oak Creek', 'triplet': '1146:UT:SNTL', 'elevation': 7850, 'location': {'lat': 39.3485, 'lng': -112.32639}}, {'name': 'Ochoco Meadows', 'triplet': '671:OR:SNTL', 'elevation': 5430, 'location': {'lat': 44.42917, 'lng': -120.3311}}, {'name': 'Olallie Meadows', 'triplet': '672:WA:SNTL', 'elevation': 4030, 'location': {'lat': 47.37406, 'lng': -121.44213}}, {'name': 'ONeil Creek', 'triplet': '1272:NV:SNTL', 'elevation': 6520, 'location': {'lat': 41.8642, 'lng': -115.08316}}, {'name': 'Onion Park', 'triplet': '1008:MT:SNTL', 'elevation': 7410, 'location': {'lat': 46.91348, 'lng': -110.8536}}, {'name': 'Overland Res.', 'triplet': '675:CO:SNTL', 'elevation': 9893, 'location': {'lat': 39.09035, 'lng': -107.63583}}, {'name': 'Owl Creek', 'triplet': '676:WY:SNTL', 'elevation': 8975, 'location': {'lat': 43.65868, 'lng': -109.00988}}, {'name': 'Oxford Spring', 'triplet': '677:ID:SNTL', 'elevation': 6740, 'location': {'lat': 42.26015, 'lng': -112.12515}}, {'name': 'Palisades Tahoe', 'triplet': '784:CA:SNTL', 'elevation': 8013, 'location': {'lat': 39.18986, 'lng': -120.26576}}, {'name': 'Palo', 'triplet': '1170:NM:SNTL', 'elevation': 9343, 'location': {'lat': 36.40869, 'lng': -105.33038}}, {'name': 'Panguitch Lake RS', 'triplet': '1148:UT:SNTL', 'elevation': 8350, 'location': {'lat': 37.70463, 'lng': -112.65037}}, {'name': 'Paradise', 'triplet': '679:WA:SNTL', 'elevation': 5130, 'location': {'lat': 46.78265, 'lng': -121.74765}}, {'name': 'Paradise Hill', 'triplet': '1301:AK:SNTL', 'elevation': 2010, 'location': {'lat': 62.83329, 'lng': -141.40918}}, {'name': 'Pargon Creek', 'triplet': '986:AK:SNTL', 'elevation': 100, 'location': {'lat': 64.9935, 'lng': -163.10317}}, {'name': 'Park Cone', 'triplet': '680:CO:SNTL', 'elevation': 9621, 'location': {'lat': 38.81982, 'lng': -106.58962}}, {'name': 'Park Creek Ridge', 'triplet': '681:WA:SNTL', 'elevation': 4600, 'location': {'lat': 48.44488, 'lng': -120.91551}}, {'name': 'Park Reservoir', 'triplet': '682:CO:SNTL', 'elevation': 9987, 'location': {'lat': 39.04433, 'lng': -107.87951}}, {'name': 'Parker Peak', 'triplet': '683:WY:SNTL', 'elevation': 9400, 'location': {'lat': 44.73396, 'lng': -109.91484}}, {'name': 'Parleys Summit', 'triplet': '684:UT:SNTL', 'elevation': 7585, 'location': {'lat': 40.76184, 'lng': -111.62917}}, {'name': 'Parleys Upper', 'triplet': '856:UT:SNTL', 'elevation': 8353, 'location': {'lat': 40.70194, 'lng': -111.60619}}, {'name': 'Parrish Creek', 'triplet': '971:UT:SNTL', 'elevation': 7740, 'location': {'lat': 40.93417, 'lng': -111.81372}}, {'name': 'Payson R.S.', 'triplet': '686:UT:SNTL', 'elevation': 8044, 'location': {'lat': 39.92976, 'lng': -111.63109}}, {'name': 'Peavine Ridge', 'triplet': '687:OR:SNTL', 'elevation': 3420, 'location': {'lat': 45.04148, 'lng': -121.93252}}, {'name': 'Pebble Creek', 'triplet': '1299:ID:SNTL', 'elevation': 6513, 'location': {'lat': 42.7674, 'lng': -112.10648}}, {'name': 'Pepper Creek', 'triplet': '1104:WA:SNTL', 'elevation': 2140, 'location': {'lat': 46.10242, 'lng': -121.95555}}, {'name': 'Peterson Meadows', 'triplet': '930:MT:SNTL', 'elevation': 7200, 'location': {'lat': 46.12588, 'lng': -113.30792}}, {'name': 'Phantom Valley', 'triplet': '688:CO:SNTL', 'elevation': 9045, 'location': {'lat': 40.39803, 'lng': -105.84606}}, {'name': 'Phillips Bench', 'triplet': '689:WY:SNTL', 'elevation': 8200, 'location': {'lat': 43.51687, 'lng': -110.91258}}, {'name': 'Pickfoot Creek', 'triplet': '690:MT:SNTL', 'elevation': 6650, 'location': {'lat': 46.57978, 'lng': -111.26832}}, {'name': 'Pickle Keg', 'triplet': '691:UT:SNTL', 'elevation': 9020, 'location': {'lat': 39.01219, 'lng': -111.58259}}, {'name': 'Pierce R.S.', 'triplet': '1142:ID:SNTL', 'elevation': 3080, 'location': {'lat': 46.49597, 'lng': -115.7957}}, {'name': 'Pigtail Peak', 'triplet': '692:WA:SNTL', 'elevation': 5800, 'location': {'lat': 46.62153, 'lng': -121.38643}}, {'name': 'Pike Creek', 'triplet': '693:MT:SNTL', 'elevation': 5930, 'location': {'lat': 48.30305, 'lng': -113.32868}}, {'name': 'Pine Creek', 'triplet': '694:UT:SNTL', 'elevation': 8734, 'location': {'lat': 38.88185, 'lng': -112.24915}}, {'name': 'Pine Creek Pass', 'triplet': '695:ID:SNTL', 'elevation': 6720, 'location': {'lat': 43.56998, 'lng': -111.21157}}, {'name': 'Pinto Rock', 'triplet': '1263:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.32318, 'lng': -121.94219}}, {'name': 'Placer Basin', 'triplet': '696:MT:SNTL', 'elevation': 8830, 'location': {'lat': 45.41905, 'lng': -110.08844}}, {'name': 'Pocket Creek', 'triplet': '1133:WY:SNTL', 'elevation': 9360, 'location': {'lat': 42.7121, 'lng': -109.4112}}, {'name': 'Poison Flat', 'triplet': '697:CA:SNTL', 'elevation': 7736, 'location': {'lat': 38.50576, 'lng': -119.62624}}, {'name': 'Pole Canyon', 'triplet': '1244:NV:SNTL', 'elevation': 7760, 'location': {'lat': 40.86293, 'lng': -115.12067}}, {'name': 'Pole Creek R.S.', 'triplet': '698:NV:SNTL', 'elevation': 8360, 'location': {'lat': 41.87255, 'lng': -115.24713}}, {'name': 'Poorman Creek', 'triplet': '932:MT:SNTL', 'elevation': 5100, 'location': {'lat': 48.12672, 'lng': -115.62333}}, {'name': 'Pope Ridge', 'triplet': '699:WA:SNTL', 'elevation': 3590, 'location': {'lat': 47.9909, 'lng': -120.56622}}, {'name': 'Porcupine', 'triplet': '700:MT:SNTL', 'elevation': 6500, 'location': {'lat': 46.11192, 'lng': -110.4696}}, {'name': 'Porphyry Creek', 'triplet': '701:CO:SNTL', 'elevation': 10788, 'location': {'lat': 38.48864, 'lng': -106.33967}}, {'name': 'Port Graham', 'triplet': '987:AK:SNTL', 'elevation': 300, 'location': {'lat': 59.35065, 'lng': -151.84768}}, {'name': 'Porter Canyon', 'triplet': '2170:NV:SNTL', 'elevation': 7187, 'location': {'lat': 39.46544, 'lng': -117.62069}}, {'name': 'Potato Hill', 'triplet': '702:WA:SNTL', 'elevation': 4510, 'location': {'lat': 46.34963, 'lng': -121.51435}}, {'name': 'Powder Mountain', 'triplet': '1300:UT:SNTL', 'elevation': 8505, 'location': {'lat': 41.37428, 'lng': -111.76673}}, {'name': 'Powder River Pass', 'triplet': '703:WY:SNTL', 'elevation': 9480, 'location': {'lat': 44.16188, 'lng': -107.12622}}, {'name': 'Prairie', 'triplet': '704:ID:SNTL', 'elevation': 4800, 'location': {'lat': 43.50513, 'lng': -115.573}}, {'name': 'Promontory', 'triplet': '705:AZ:SNTL', 'elevation': 7942, 'location': {'lat': 34.36848, 'lng': -111.01088}}, {'name': 'Prudhoe Bay', 'triplet': '1177:AK:SNTL', 'elevation': 30, 'location': {'lat': 70.26666, 'lng': -148.56666}}, {'name': 'Quartz Mountain', 'triplet': '706:OR:SNTL', 'elevation': 5720, 'location': {'lat': 42.31923, 'lng': -120.82533}}, {'name': 'Quartz Peak', 'triplet': '707:WA:SNTL', 'elevation': 4700, 'location': {'lat': 47.87927, 'lng': -117.08938}}, {'name': 'Quemazon', 'triplet': '708:NM:SNTL', 'elevation': 9507, 'location': {'lat': 35.92195, 'lng': -106.39179}}, {'name': 'Rabbit Ears', 'triplet': '709:CO:SNTL', 'elevation': 9411, 'location': {'lat': 40.36735, 'lng': -106.74118}}, {'name': 'Ragged Mountain', 'triplet': '1081:ID:SNTL', 'elevation': 4210, 'location': {'lat': 47.85583, 'lng': -117.03667}}, {'name': 'Railroad Overpass', 'triplet': '710:OR:SNTL', 'elevation': 2680, 'location': {'lat': 43.65887, 'lng': -122.21272}}, {'name': 'Rainbow Canyon', 'triplet': '1110:NV:SNTL', 'elevation': 7860, 'location': {'lat': 36.2493, 'lng': -115.62972}}, {'name': 'Rainy Pass', 'triplet': '711:WA:SNTL', 'elevation': 4890, 'location': {'lat': 48.51865, 'lng': -120.7358}}, {'name': 'Rawah', 'triplet': '1032:CO:SNTL', 'elevation': 9069, 'location': {'lat': 40.70794, 'lng': -106.00727}}, {'name': 'Red Hill', 'triplet': '712:OR:SNTL', 'elevation': 4410, 'location': {'lat': 45.4643, 'lng': -121.70428}}, {'name': 'Red Mountain Pass', 'triplet': '713:CO:SNTL', 'elevation': 11080, 'location': {'lat': 37.89168, 'lng': -107.71389}}, {'name': 'Red Pine Ridge', 'triplet': '714:UT:SNTL', 'elevation': 8988, 'location': {'lat': 39.45197, 'lng': -111.27221}}, {'name': 'Red River Pass #2', 'triplet': '715:NM:SNTL', 'elevation': 9855, 'location': {'lat': 36.69935, 'lng': -105.34145}}, {'name': 'Redden Mine Lwr', 'triplet': '1225:UT:SNTL', 'elevation': 8532, 'location': {'lat': 40.67505, 'lng': -111.21765}}, {'name': 'Rees Flat', 'triplet': '1217:UT:SNTL', 'elevation': 7206, 'location': {'lat': 39.49667, 'lng': -111.72508}}, {'name': 'Reno Hill', 'triplet': '716:WY:SNTL', 'elevation': 8430, 'location': {'lat': 42.57089, 'lng': -106.08969}}, {'name': 'Rex River', 'triplet': '911:WA:SNTL', 'elevation': 3810, 'location': {'lat': 47.30218, 'lng': -121.60475}}, {'name': 'Reynolds Creek', 'triplet': '2029:ID:SNTL', 'elevation': 5600, 'location': {'lat': 43.28863, 'lng': -116.8431}}, {'name': 'Rice Park', 'triplet': '933:NM:SNTL', 'elevation': 8497, 'location': {'lat': 35.23658, 'lng': -108.27404}}, {'name': 'Rio Santa Barbara', 'triplet': '1254:NM:SNTL', 'elevation': 10664, 'location': {'lat': 36.07196, 'lng': -105.62949}}, {'name': 'Ripple Creek', 'triplet': '717:CO:SNTL', 'elevation': 10350, 'location': {'lat': 40.10844, 'lng': -107.29383}}, {'name': 'Roach', 'triplet': '718:CO:SNTL', 'elevation': 9740, 'location': {'lat': 40.87498, 'lng': -106.04675}}, {'name': 'Roaring River', 'triplet': '719:OR:SNTL', 'elevation': 4950, 'location': {'lat': 43.90098, 'lng': -122.03063}}, {'name': 'Rock Creek', 'triplet': '720:UT:SNTL', 'elevation': 7886, 'location': {'lat': 40.54875, 'lng': -110.69292}}, {'name': 'Rock Springs', 'triplet': '721:OR:SNTL', 'elevation': 5290, 'location': {'lat': 44.00883, 'lng': -118.83842}}, {'name': 'Rocker Peak', 'triplet': '722:MT:SNTL', 'elevation': 8000, 'location': {'lat': 46.35613, 'lng': -112.26176}}, {'name': 'Rockwood GS', 'triplet': '1309:UT:SNTL', 'elevation': 8593, 'location': {'lat': 38.67101, 'lng': -112.3305}}, {'name': 'Rocky Basin-Settleme', 'triplet': '723:UT:SNTL', 'elevation': 8704, 'location': {'lat': 40.44293, 'lng': -112.22377}}, {'name': 'Rocky Boy', 'triplet': '917:MT:SNTL', 'elevation': 4700, 'location': {'lat': 48.17478, 'lng': -109.64728}}, {'name': 'Rocky Point', 'triplet': '973:AK:SNTL', 'elevation': 250, 'location': {'lat': 64.53482, 'lng': -163.4214}}, {'name': 'Rough And Tumble', 'triplet': '939:CO:SNTL', 'elevation': 10432, 'location': {'lat': 39.02611, 'lng': -106.08063}}, {'name': 'Rubicon #2', 'triplet': '724:CA:SNTL', 'elevation': 7619, 'location': {'lat': 38.99927, 'lng': -120.13139}}, {'name': 'S Fork Shields', 'triplet': '725:MT:SNTL', 'elevation': 8100, 'location': {'lat': 46.0896, 'lng': -110.43363}}, {'name': 'Sacajawea', 'triplet': '929:MT:SNTL', 'elevation': 6550, 'location': {'lat': 45.87395, 'lng': -110.92783}}, {'name': 'Saddle Mountain', 'triplet': '726:OR:SNTL', 'elevation': 3110, 'location': {'lat': 45.54477, 'lng': -123.37315}}, {'name': 'Saddle Mtn.', 'triplet': '727:MT:SNTL', 'elevation': 7940, 'location': {'lat': 45.69259, 'lng': -113.96828}}, {'name': 'Sage Creek Basin', 'triplet': '1015:WY:SNTL', 'elevation': 7850, 'location': {'lat': 41.40107, 'lng': -107.2574}}, {'name': 'Sagwon', 'triplet': '1183:AK:SNTL', 'elevation': 1000, 'location': {'lat': 69.42417, 'lng': -148.6925}}, {'name': 'Saint Elmo', 'triplet': '1100:CO:SNTL', 'elevation': 10450, 'location': {'lat': 38.69985, 'lng': -106.36805}}, {'name': 'Salmon Meadows', 'triplet': '728:WA:SNTL', 'elevation': 4460, 'location': {'lat': 48.65518, 'lng': -119.8383}}, {'name': 'Salt Creek Falls', 'triplet': '729:OR:SNTL', 'elevation': 4220, 'location': {'lat': 43.61193, 'lng': -122.11758}}, {'name': 'Salt River Summit', 'triplet': '730:WY:SNTL', 'elevation': 7640, 'location': {'lat': 42.5075, 'lng': -110.9099}}, {'name': 'San Antonio Sink', 'triplet': '1172:NM:SNTL', 'elevation': 9143, 'location': {'lat': 36.85967, 'lng': -106.22657}}, {'name': 'Sand Lake', 'triplet': '731:WY:SNTL', 'elevation': 10098, 'location': {'lat': 41.4625, 'lng': -106.281}}, {'name': 'Sandstone RS', 'triplet': '732:WY:SNTL', 'elevation': 8152, 'location': {'lat': 41.11179, 'lng': -107.17043}}, {'name': 'Santa Fe', 'triplet': '922:NM:SNTL', 'elevation': 11465, 'location': {'lat': 35.77154, 'lng': -105.78487}}, {'name': 'Santaquin Meadows', 'triplet': '1280:UT:SNTL', 'elevation': 7835, 'location': {'lat': 39.92076, 'lng': -111.71802}}, {'name': 'Santiam Jct.', 'triplet': '733:OR:SNTL', 'elevation': 3740, 'location': {'lat': 44.43503, 'lng': -121.94502}}, {'name': 'Sargents Mesa', 'triplet': '1128:CO:SNTL', 'elevation': 11499, 'location': {'lat': 38.2856, 'lng': -106.37085}}, {'name': 'Sasse Ridge', 'triplet': '734:WA:SNTL', 'elevation': 4340, 'location': {'lat': 47.38485, 'lng': -121.06323}}, {'name': 'Satus Pass', 'triplet': '1231:WA:SNTL', 'elevation': 3960, 'location': {'lat': 45.98797, 'lng': -120.67734}}, {'name': 'Savage Pass', 'triplet': '735:ID:SNTL', 'elevation': 6190, 'location': {'lat': 46.46633, 'lng': -114.63333}}, {'name': 'Sawmill Ridge', 'triplet': '1068:WA:SNTL', 'elevation': 4640, 'location': {'lat': 47.15992, 'lng': -121.42172}}, {'name': 'Sawtooth', 'triplet': '1251:CO:SNTL', 'elevation': 9676, 'location': {'lat': 40.13632, 'lng': -105.58486}}, {'name': 'Schneider Meadows', 'triplet': '736:OR:SNTL', 'elevation': 5400, 'location': {'lat': 45.00107, 'lng': -117.16522}}, {'name': 'Schofield Pass', 'triplet': '737:CO:SNTL', 'elevation': 10653, 'location': {'lat': 39.01467, 'lng': -107.04933}}, {'name': 'Schwartz Lake', 'triplet': '915:ID:SNTL', 'elevation': 8630, 'location': {'lat': 44.84618, 'lng': -113.83732}}, {'name': 'Schweitzer Basin', 'triplet': '738:ID:SNTL', 'elevation': 6090, 'location': {'lat': 48.37428, 'lng': -116.63917}}, {'name': 'Scotch Creek', 'triplet': '739:CO:SNTL', 'elevation': 9195, 'location': {'lat': 37.64562, 'lng': -108.00833}}, {'name': 'Secesh Summit', 'triplet': '740:ID:SNTL', 'elevation': 6540, 'location': {'lat': 45.18848, 'lng': -115.97152}}, {'name': 'Sedgwick Peak', 'triplet': '741:ID:SNTL', 'elevation': 7850, 'location': {'lat': 42.52497, 'lng': -111.95635}}, {'name': 'Seeley Creek', 'triplet': '742:UT:SNTL', 'elevation': 9904, 'location': {'lat': 39.31042, 'lng': -111.43297}}, {'name': 'Seine Creek', 'triplet': '743:OR:SNTL', 'elevation': 2060, 'location': {'lat': 45.52688, 'lng': -123.29857}}, {'name': 'Senorita Divide #2', 'triplet': '744:NM:SNTL', 'elevation': 8569, 'location': {'lat': 36.00152, 'lng': -106.83408}}, {'name': 'Sentinel Butte', 'triplet': '1043:WA:SNTL', 'elevation': 4680, 'location': {'lat': 48.86133, 'lng': -118.39843}}, {'name': 'Sevenmile Marsh', 'triplet': '745:OR:SNTL', 'elevation': 5700, 'location': {'lat': 42.69825, 'lng': -122.14165}}, {'name': 'Seventysix Creek', 'triplet': '746:NV:SNTL', 'elevation': 7350, 'location': {'lat': 41.73732, 'lng': -115.47215}}, {'name': 'Shanghi Summit', 'triplet': '747:ID:SNTL', 'elevation': 4600, 'location': {'lat': 46.56603, 'lng': -115.74216}}, {'name': 'Sharkstooth', 'triplet': '1060:CO:SNTL', 'elevation': 10747, 'location': {'lat': 37.50356, 'lng': -108.11405}}, {'name': 'Sheep Canyon', 'triplet': '748:WA:SNTL', 'elevation': 3990, 'location': {'lat': 46.19325, 'lng': -122.25393}}, {'name': 'Sheep Mtn.', 'triplet': '749:ID:SNTL', 'elevation': 6650, 'location': {'lat': 43.2103, 'lng': -111.68792}}, {'name': 'Sheldon', 'triplet': '750:NV:SNTL', 'elevation': 5865, 'location': {'lat': 41.90435, 'lng': -119.44464}}, {'name': 'Shell Creek', 'triplet': '751:WY:SNTL', 'elevation': 9580, 'location': {'lat': 44.50012, 'lng': -107.42947}}, {'name': 'Sherwin', 'triplet': '752:ID:SNTL', 'elevation': 3200, 'location': {'lat': 46.95028, 'lng': -116.33972}}, {'name': 'Short Creek', 'triplet': '753:MT:SNTL', 'elevation': 7000, 'location': {'lat': 44.97572, 'lng': -111.95215}}, {'name': 'Shower Falls', 'triplet': '754:MT:SNTL', 'elevation': 8100, 'location': {'lat': 45.40125, 'lng': -110.95758}}, {'name': 'Shuree', 'triplet': '1169:NM:SNTL', 'elevation': 10092, 'location': {'lat': 36.78765, 'lng': -105.2392}}, {'name': 'Sierra Blanca', 'triplet': '1034:NM:SNTL', 'elevation': 10268, 'location': {'lat': 33.40682, 'lng': -105.79467}}, {'name': 'Signal Peak', 'triplet': '755:NM:SNTL', 'elevation': 8405, 'location': {'lat': 32.92342, 'lng': -108.14546}}, {'name': 'Silver Creek', 'triplet': '756:OR:SNTL', 'elevation': 5740, 'location': {'lat': 42.95615, 'lng': -121.18123}}, {'name': 'Silver Creek Divide', 'triplet': '757:NM:SNTL', 'elevation': 9096, 'location': {'lat': 33.3696, 'lng': -108.70711}}, {'name': 'Silver Creek Nv', 'triplet': '1205:NV:SNTL', 'elevation': 8200, 'location': {'lat': 39.23305, 'lng': -114.2429}}, {'name': 'Silvies', 'triplet': '759:OR:SNTL', 'elevation': 6990, 'location': {'lat': 42.75333, 'lng': -118.68785}}, {'name': 'Skalkaho Summit', 'triplet': '760:MT:SNTL', 'elevation': 7250, 'location': {'lat': 46.24212, 'lng': -113.7725}}, {'name': 'Skate Creek', 'triplet': '1257:WA:SNTL', 'elevation': 3770, 'location': {'lat': 46.64336, 'lng': -121.83044}}, {'name': 'Skookum Creek', 'triplet': '912:WA:SNTL', 'elevation': 3310, 'location': {'lat': 47.68433, 'lng': -121.61007}}, {'name': 'Slagamelt Lakes', 'triplet': '1286:MT:SNTL', 'elevation': 8620, 'location': {'lat': 45.36526, 'lng': -113.71834}}, {'name': 'Sleeping Woman', 'triplet': '783:MT:SNTL', 'elevation': 6150, 'location': {'lat': 47.17902, 'lng': -114.33368}}, {'name': 'Slug Creek Divide', 'triplet': '761:ID:SNTL', 'elevation': 7225, 'location': {'lat': 42.56248, 'lng': -111.29797}}, {'name': 'Slumgullion', 'triplet': '762:CO:SNTL', 'elevation': 11560, 'location': {'lat': 37.99076, 'lng': -107.20392}}, {'name': 'Smiley Mountain', 'triplet': '926:ID:SNTL', 'elevation': 9520, 'location': {'lat': 43.72718, 'lng': -113.83402}}, {'name': 'Smith  Morehouse', 'triplet': '763:UT:SNTL', 'elevation': 7631, 'location': {'lat': 40.78931, 'lng': -111.09192}}, {'name': 'Smith Ridge', 'triplet': '1167:OR:SNTL', 'elevation': 3270, 'location': {'lat': 44.30325, 'lng': -122.04053}}, {'name': 'Snake River Station', 'triplet': '764:WY:SNTL', 'elevation': 6920, 'location': {'lat': 44.13361, 'lng': -110.66917}}, {'name': 'Snider Basin', 'triplet': '765:WY:SNTL', 'elevation': 8060, 'location': {'lat': 42.4949, 'lng': -110.53203}}, {'name': 'Snow Mountain', 'triplet': '767:OR:SNTL', 'elevation': 6230, 'location': {'lat': 43.94885, 'lng': -119.54013}}, {'name': 'Snowbird', 'triplet': '766:UT:SNTL', 'elevation': 9177, 'location': {'lat': 40.56914, 'lng': -111.65852}}, {'name': 'Snowslide Canyon', 'triplet': '927:AZ:SNTL', 'elevation': 9744, 'location': {'lat': 35.34179, 'lng': -111.65084}}, {'name': 'Snowstorm Mtn', 'triplet': '1208:NV:SNTL', 'elevation': 7403, 'location': {'lat': 41.33981, 'lng': -116.98044}}, {'name': 'Soldier Park', 'triplet': '1132:WY:SNTL', 'elevation': 8720, 'location': {'lat': 44.34847, 'lng': -107.0136}}, {'name': 'Soldier R.S.', 'triplet': '769:ID:SNTL', 'elevation': 5740, 'location': {'lat': 43.48407, 'lng': -114.82692}}, {'name': 'Somsen Ranch', 'triplet': '770:ID:SNTL', 'elevation': 6800, 'location': {'lat': 42.95275, 'lng': -111.35933}}, {'name': 'Sonora Pass', 'triplet': '771:CA:SNTL', 'elevation': 8770, 'location': {'lat': 38.31021, 'lng': -119.6003}}, {'name': 'Sourdough Gulch', 'triplet': '985:WA:SNTL', 'elevation': 4000, 'location': {'lat': 46.23718, 'lng': -117.39438}}, {'name': 'South Brush Creek', 'triplet': '772:WY:SNTL', 'elevation': 8495, 'location': {'lat': 41.3295, 'lng': -106.5025}}, {'name': 'South Colony', 'triplet': '773:CO:SNTL', 'elevation': 10868, 'location': {'lat': 37.96647, 'lng': -105.53671}}, {'name': 'South Fork Bull Run', 'triplet': '925:OR:SNTL', 'elevation': 2690, 'location': {'lat': 45.44575, 'lng': -122.03125}}, {'name': 'South Mtn.', 'triplet': '774:ID:SNTL', 'elevation': 6500, 'location': {'lat': 42.76478, 'lng': -116.90037}}, {'name': 'South Pass', 'triplet': '775:WY:SNTL', 'elevation': 9040, 'location': {'lat': 42.57317, 'lng': -108.84325}}, {'name': 'Spencer Meadow', 'triplet': '776:WA:SNTL', 'elevation': 3400, 'location': {'lat': 46.1795, 'lng': -121.92661}}, {'name': 'Spirit Lake', 'triplet': '777:WA:SNTL', 'elevation': 3520, 'location': {'lat': 46.26113, 'lng': -122.1772}}, {'name': 'Spirit Lk', 'triplet': '1117:UT:SNTL', 'elevation': 10235, 'location': {'lat': 40.83868, 'lng': -110.00527}}, {'name': 'Spratt Creek', 'triplet': '778:CA:SNTL', 'elevation': 6063, 'location': {'lat': 38.66627, 'lng': -119.81741}}, {'name': 'Spring Creek', 'triplet': '2044:AK:SNTL', 'elevation': 580, 'location': {'lat': 61.65722, 'lng': -149.12853}}, {'name': 'Spring Creek Divide', 'triplet': '779:WY:SNTL', 'elevation': 9000, 'location': {'lat': 42.52516, 'lng': -110.66148}}, {'name': 'Spruce Springs', 'triplet': '984:WA:SNTL', 'elevation': 5700, 'location': {'lat': 46.18287, 'lng': -117.54155}}, {'name': 'Spud Mountain', 'triplet': '780:CO:SNTL', 'elevation': 10674, 'location': {'lat': 37.69883, 'lng': -107.77841}}, {'name': 'Spur Park', 'triplet': '781:MT:SNTL', 'elevation': 8100, 'location': {'lat': 46.77962, 'lng': -110.62165}}, {'name': 'Squaw Flat', 'triplet': '782:ID:SNTL', 'elevation': 6240, 'location': {'lat': 44.77091, 'lng': -116.24805}}, {'name': 'St. Lawrence Alt', 'triplet': '786:WY:SNTL', 'elevation': 8620, 'location': {'lat': 43.03313, 'lng': -109.17025}}, {'name': 'Stag Mountain', 'triplet': '1203:NV:SNTL', 'elevation': 7640, 'location': {'lat': 41.408, 'lng': -115.4464}}, {'name': 'Stahl Peak', 'triplet': '787:MT:SNTL', 'elevation': 6030, 'location': {'lat': 48.90902, 'lng': -114.86298}}, {'name': 'Stampede Pass', 'triplet': '788:WA:SNTL', 'elevation': 3850, 'location': {'lat': 47.27427, 'lng': -121.34162}}, {'name': 'Starr Ridge', 'triplet': '789:OR:SNTL', 'elevation': 5250, 'location': {'lat': 44.26423, 'lng': -119.02162}}, {'name': 'State Line', 'triplet': '1258:CA:SNTL', 'elevation': 5680, 'location': {'lat': 41.98609, 'lng': -120.71574}}, {'name': 'Steel Creek Park', 'triplet': '790:UT:SNTL', 'elevation': 10158, 'location': {'lat': 40.90862, 'lng': -110.50462}}, {'name': 'Stevens Pass', 'triplet': '791:WA:SNTL', 'elevation': 3950, 'location': {'lat': 47.74607, 'lng': -121.09288}}, {'name': 'Stickney Mill', 'triplet': '792:ID:SNTL', 'elevation': 7430, 'location': {'lat': 43.86117, 'lng': -114.20902}}, {'name': 'Stillwater Creek', 'triplet': '793:CO:SNTL', 'elevation': 8880, 'location': {'lat': 40.22532, 'lng': -105.9198}}, {'name': 'Strawberry', 'triplet': '794:OR:SNTL', 'elevation': 5770, 'location': {'lat': 42.12587, 'lng': -120.8361}}, {'name': 'Strawberry Divide', 'triplet': '795:UT:SNTL', 'elevation': 8123, 'location': {'lat': 40.16483, 'lng': -111.20665}}, {'name': 'Stringer Creek', 'triplet': '1009:MT:SNTL', 'elevation': 6550, 'location': {'lat': 46.9269, 'lng': -110.90198}}, {'name': 'Stryker Basin', 'triplet': '1311:MT:SNTL', 'elevation': 6155, 'location': {'lat': 48.6802, 'lng': -114.664}}, {'name': 'Stuart Mountain', 'triplet': '901:MT:SNTL', 'elevation': 7400, 'location': {'lat': 46.99523, 'lng': -113.92664}}, {'name': 'Stump Lakes', 'triplet': '797:CO:SNTL', 'elevation': 11248, 'location': {'lat': 37.47647, 'lng': -107.63348}}, {'name': 'Sucker Creek', 'triplet': '798:WY:SNTL', 'elevation': 8880, 'location': {'lat': 44.7225, 'lng': -107.40033}}, {'name': 'Sugarloaf Mtn', 'triplet': '1095:AK:SNTL', 'elevation': 550, 'location': {'lat': 61.081, 'lng': -146.2995}}, {'name': 'Summer Rim', 'triplet': '800:OR:SNTL', 'elevation': 7080, 'location': {'lat': 42.6957, 'lng': -120.80158}}, {'name': 'Summit Creek', 'triplet': '955:AK:SNTL', 'elevation': 1400, 'location': {'lat': 60.61713, 'lng': -149.53128}}, {'name': 'Summit Lake', 'triplet': '801:OR:SNTL', 'elevation': 5610, 'location': {'lat': 43.44907, 'lng': -122.13808}}, {'name': 'Summit Lk', 'triplet': '1194:NV:SNTL', 'elevation': 7615, 'location': {'lat': 41.48953, 'lng': -118.99663}}, {'name': 'Summit Meadow', 'triplet': '1052:CA:SNTL', 'elevation': 9313, 'location': {'lat': 38.39747, 'lng': -119.53522}}, {'name': 'Summit Ranch', 'triplet': '802:CO:SNTL', 'elevation': 9371, 'location': {'lat': 39.71803, 'lng': -106.1577}}, {'name': 'Sun Pass', 'triplet': '1078:OR:SNTL', 'elevation': 5400, 'location': {'lat': 42.78637, 'lng': -121.97715}}, {'name': 'Sunflower Flat', 'triplet': '1249:UT:SNTL', 'elevation': 10018, 'location': {'lat': 38.048, 'lng': -111.33981}}, {'name': 'Sunset', 'triplet': '803:ID:SNTL', 'elevation': 5540, 'location': {'lat': 47.55545, 'lng': -115.82422}}, {'name': 'Surprise Lakes', 'triplet': '804:WA:SNTL', 'elevation': 4290, 'location': {'lat': 46.09497, 'lng': -121.76345}}, {'name': 'Susitna Valley High', 'triplet': '967:AK:SNTL', 'elevation': 375, 'location': {'lat': 62.13333, 'lng': -150.04167}}, {'name': 'Suu Ranch', 'triplet': '1248:UT:SNTL', 'elevation': 8050, 'location': {'lat': 37.59711, 'lng': -112.92949}}, {'name': 'Swamp Creek', 'triplet': '975:WA:SNTL', 'elevation': 3930, 'location': {'lat': 48.57142, 'lng': -120.78267}}, {'name': 'Swan Lake Mtn', 'triplet': '1077:OR:SNTL', 'elevation': 6830, 'location': {'lat': 42.41323, 'lng': -121.68002}}, {'name': 'Swede Peak', 'triplet': '805:ID:SNTL', 'elevation': 7640, 'location': {'lat': 43.626, 'lng': -113.96887}}, {'name': 'Swift Creek', 'triplet': '1012:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.1638, 'lng': -122.18402}}, {'name': 'Sylvan Lake', 'triplet': '806:WY:SNTL', 'elevation': 8420, 'location': {'lat': 44.47764, 'lng': -110.15651}}, {'name': 'Sylvan Road', 'triplet': '807:WY:SNTL', 'elevation': 7120, 'location': {'lat': 44.47825, 'lng': -110.03808}}, {'name': 'Tahoe City Cross', 'triplet': '809:CA:SNTL', 'elevation': 6797, 'location': {'lat': 39.17162, 'lng': -120.15362}}, {'name': 'Takka Wiiya', 'triplet': '1247:UT:SNTL', 'elevation': 9122, 'location': {'lat': 39.74104, 'lng': -113.98262}}, {'name': 'Taos Powderhorn', 'triplet': '1168:NM:SNTL', 'elevation': 11045, 'location': {'lat': 36.58195, 'lng': -105.45617}}, {'name': 'Taos Pueblo', 'triplet': '1307:NM:SNTL', 'elevation': 11020, 'location': {'lat': 36.54099, 'lng': -105.35944}}, {'name': 'Taylor Butte', 'triplet': '810:OR:SNTL', 'elevation': 5030, 'location': {'lat': 42.69108, 'lng': -121.42592}}, {'name': 'Taylor Canyon', 'triplet': '811:NV:SNTL', 'elevation': 6325, 'location': {'lat': 41.2287, 'lng': -116.0293}}, {'name': 'Taylor Green', 'triplet': '812:OR:SNTL', 'elevation': 5740, 'location': {'lat': 45.07707, 'lng': -117.55067}}, {'name': 'Telaquana Lake', 'triplet': '1266:AK:SNTL', 'elevation': 1275, 'location': {'lat': 60.98243, 'lng': -153.91772}}, {'name': 'Temple Fork', 'triplet': '1013:UT:SNTL', 'elevation': 7406, 'location': {'lat': 41.793, 'lng': -111.54605}}, {'name': 'Tent Mtn Lower', 'triplet': '1202:NV:SNTL', 'elevation': 7100, 'location': {'lat': 40.97852, 'lng': -115.17215}}, {'name': 'Tepee Creek', 'triplet': '813:MT:SNTL', 'elevation': 8000, 'location': {'lat': 44.78562, 'lng': -111.71}}, {'name': 'Teuchet Creek', 'triplet': '951:AK:SNTL', 'elevation': 1640, 'location': {'lat': 64.94583, 'lng': -145.51667}}, {'name': 'Thaynes Canyon', 'triplet': '814:UT:SNTL', 'elevation': 9230, 'location': {'lat': 40.6235, 'lng': -111.53322}}, {'name': 'Thistle Flat', 'triplet': '1226:UT:SNTL', 'elevation': 8787, 'location': {'lat': 39.23803, 'lng': -111.51998}}, {'name': 'Three Creeks Meadow', 'triplet': '815:OR:SNTL', 'elevation': 5690, 'location': {'lat': 44.14425, 'lng': -121.64095}}, {'name': 'Thumb Divide', 'triplet': '816:WY:SNTL', 'elevation': 7980, 'location': {'lat': 44.36917, 'lng': -110.57717}}, {'name': 'Thunder Basin', 'triplet': '817:WA:SNTL', 'elevation': 4320, 'location': {'lat': 48.52753, 'lng': -120.9895}}, {'name': 'Tie Creek', 'triplet': '818:WY:SNTL', 'elevation': 6870, 'location': {'lat': 44.81243, 'lng': -107.41017}}, {'name': 'Timber Creek', 'triplet': '819:WY:SNTL', 'elevation': 7950, 'location': {'lat': 44.0274, 'lng': -109.17879}}, {'name': 'Timberline', 'triplet': '1097:UT:SNTL', 'elevation': 8736, 'location': {'lat': 39.67712, 'lng': -110.43395}}, {'name': 'Timpanogos Divide', 'triplet': '820:UT:SNTL', 'elevation': 8140, 'location': {'lat': 40.42817, 'lng': -111.61633}}, {'name': 'Tinkham Creek', 'triplet': '899:WA:SNTL', 'elevation': 2990, 'location': {'lat': 47.33198, 'lng': -121.46975}}, {'name': 'Tipton', 'triplet': '821:OR:SNTL', 'elevation': 5150, 'location': {'lat': 44.65567, 'lng': -118.42617}}, {'name': 'Tizer Basin', 'triplet': '893:MT:SNTL', 'elevation': 6880, 'location': {'lat': 46.34937, 'lng': -111.85308}}, {'name': 'Toe Jam', 'triplet': '1136:NV:SNTL', 'elevation': 7690, 'location': {'lat': 41.3187, 'lng': -116.3408}}, {'name': 'Togwotee Pass', 'triplet': '822:WY:SNTL', 'elevation': 9580, 'location': {'lat': 43.74902, 'lng': -110.0578}}, {'name': 'Tok', 'triplet': '2080:AK:SNTL', 'elevation': 1630, 'location': {'lat': 63.3532, 'lng': -142.98164}}, {'name': 'Toketee Airstrip', 'triplet': '1044:OR:SNTL', 'elevation': 3240, 'location': {'lat': 43.22718, 'lng': -122.42537}}, {'name': 'Tokositna Valley', 'triplet': '1089:AK:SNTL', 'elevation': 850, 'location': {'lat': 62.63, 'lng': -150.77617}}, {'name': 'Tolby', 'triplet': '934:NM:SNTL', 'elevation': 10220, 'location': {'lat': 36.47498, 'lng': -105.19534}}, {'name': 'Tony Grove Lake', 'triplet': '823:UT:SNTL', 'elevation': 8474, 'location': {'lat': 41.89833, 'lng': -111.62957}}, {'name': 'Tony Grove RS', 'triplet': '1113:UT:SNTL', 'elevation': 6332, 'location': {'lat': 41.88573, 'lng': -111.56918}}, {'name': 'Touchet', 'triplet': '824:WA:SNTL', 'elevation': 5530, 'location': {'lat': 46.11868, 'lng': -117.8505}}, {'name': 'Tower', 'triplet': '825:CO:SNTL', 'elevation': 10620, 'location': {'lat': 40.5374, 'lng': -106.67655}}, {'name': 'Townsend Creek', 'triplet': '826:WY:SNTL', 'elevation': 8700, 'location': {'lat': 42.69525, 'lng': -108.89572}}, {'name': 'Trapper Lake', 'triplet': '827:CO:SNTL', 'elevation': 9759, 'location': {'lat': 39.99881, 'lng': -107.23618}}, {'name': 'Tres Ritos', 'triplet': '1083:NM:SNTL', 'elevation': 8755, 'location': {'lat': 36.1279, 'lng': -105.52706}}, {'name': 'Trial Lake', 'triplet': '828:UT:SNTL', 'elevation': 9992, 'location': {'lat': 40.678, 'lng': -110.94873}}, {'name': 'Trinchera', 'triplet': '829:CO:SNTL', 'elevation': 10922, 'location': {'lat': 37.35296, 'lng': -105.23259}}, {'name': 'Trinity', 'triplet': '1171:WA:SNTL', 'elevation': 2930, 'location': {'lat': 48.0747, 'lng': -120.8493}}, {'name': 'Trinity Mtn.', 'triplet': '830:ID:SNTL', 'elevation': 7770, 'location': {'lat': 43.62903, 'lng': -115.43818}}, {'name': 'Triple Peak', 'triplet': '831:WY:SNTL', 'elevation': 8500, 'location': {'lat': 42.76393, 'lng': -110.5914}}, {'name': 'Trough', 'triplet': '832:WA:SNTL', 'elevation': 5480, 'location': {'lat': 47.23328, 'lng': -120.29412}}, {'name': 'Trout Creek', 'triplet': '833:UT:SNTL', 'elevation': 9518, 'location': {'lat': 40.739, 'lng': -109.6728}}, {'name': 'Truckee #2', 'triplet': '834:CA:SNTL', 'elevation': 6509, 'location': {'lat': 39.30087, 'lng': -120.18407}}, {'name': 'Turnagain Pass', 'triplet': '954:AK:SNTL', 'elevation': 1880, 'location': {'lat': 60.78043, 'lng': -149.18325}}, {'name': 'Twelvemile Creek', 'triplet': '835:MT:SNTL', 'elevation': 5600, 'location': {'lat': 46.14287, 'lng': -114.44755}}, {'name': 'Twin Lakes', 'triplet': '836:MT:SNTL', 'elevation': 6400, 'location': {'lat': 46.1438, 'lng': -114.5056}}, {'name': 'Two Ocean Plateau', 'triplet': '837:WY:SNTL', 'elevation': 9240, 'location': {'lat': 44.15178, 'lng': -110.22122}}, {'name': 'University Camp', 'triplet': '838:CO:SNTL', 'elevation': 10360, 'location': {'lat': 40.03307, 'lng': -105.57562}}, {'name': 'Upper Chena', 'triplet': '952:AK:SNTL', 'elevation': 2850, 'location': {'lat': 65.1, 'lng': -144.93317}}, {'name': 'Upper Joes Valley', 'triplet': '1227:UT:SNTL', 'elevation': 8596, 'location': {'lat': 39.4155, 'lng': -111.2491}}, {'name': 'Upper Nome Creek', 'triplet': '1090:AK:SNTL', 'elevation': 2520, 'location': {'lat': 65.3671, 'lng': -146.592}}, {'name': 'Upper Rio Grande', 'triplet': '839:CO:SNTL', 'elevation': 9379, 'location': {'lat': 37.72172, 'lng': -107.25971}}, {'name': 'Upper San Juan', 'triplet': '840:CO:SNTL', 'elevation': 10140, 'location': {'lat': 37.48563, 'lng': -106.83528}}, {'name': 'Upper Taylor', 'triplet': '1141:CO:SNTL', 'elevation': 10717, 'location': {'lat': 38.99071, 'lng': -106.74504}}, {'name': 'Upper Tsaina River', 'triplet': '1055:AK:SNTL', 'elevation': 1750, 'location': {'lat': 61.19112, 'lng': -145.64807}}, {'name': 'Upper Wheeler', 'triplet': '841:WA:SNTL', 'elevation': 4330, 'location': {'lat': 47.28734, 'lng': -120.37015}}, {'name': 'Usu Doc Daniel', 'triplet': '1098:UT:SNTL', 'elevation': 8270, 'location': {'lat': 41.86425, 'lng': -111.50603}}, {'name': 'Ute Creek', 'triplet': '1005:CO:SNTL', 'elevation': 10734, 'location': {'lat': 37.6148, 'lng': -105.37322}}, {'name': 'Vacarro Springs', 'triplet': '1137:NV:SNTL', 'elevation': 7890, 'location': {'lat': 39.4495, 'lng': -115.9834}}, {'name': 'Vacas Locas', 'triplet': '1017:NM:SNTL', 'elevation': 9364, 'location': {'lat': 36.02653, 'lng': -106.81361}}, {'name': 'Vail Mountain', 'triplet': '842:CO:SNTL', 'elevation': 10310, 'location': {'lat': 39.61765, 'lng': -106.38019}}, {'name': 'Vallecito', 'triplet': '843:CO:SNTL', 'elevation': 10782, 'location': {'lat': 37.48524, 'lng': -107.50748}}, {'name': 'Van Wyck', 'triplet': '979:ID:SNTL', 'elevation': 4920, 'location': {'lat': 44.37665, 'lng': -116.3366}}, {'name': 'Vernon Creek', 'triplet': '844:UT:SNTL', 'elevation': 7401, 'location': {'lat': 39.93667, 'lng': -112.41478}}, {'name': 'Vienna Mine', 'triplet': '845:ID:SNTL', 'elevation': 8960, 'location': {'lat': 43.79942, 'lng': -114.85273}}, {'name': 'Virginia Lakes Ridge', 'triplet': '846:CA:SNTL', 'elevation': 9400, 'location': {'lat': 38.07298, 'lng': -119.23433}}, {'name': 'Wager Gulch', 'triplet': '1188:CO:SNTL', 'elevation': 11132, 'location': {'lat': 37.88248, 'lng': -107.36428}}, {'name': 'Waldron', 'triplet': '847:MT:SNTL', 'elevation': 5600, 'location': {'lat': 47.91998, 'lng': -112.79087}}, {'name': 'Ward Creek #3', 'triplet': '848:CA:SNTL', 'elevation': 6745, 'location': {'lat': 39.13545, 'lng': -120.21865}}, {'name': 'Ward Mountain', 'triplet': '849:NV:SNTL', 'elevation': 9163, 'location': {'lat': 39.13242, 'lng': -114.95575}}, {'name': 'Warm Springs', 'triplet': '850:MT:SNTL', 'elevation': 7800, 'location': {'lat': 46.27368, 'lng': -113.164}}, {'name': 'Waterhole', 'triplet': '974:WA:SNTL', 'elevation': 5010, 'location': {'lat': 47.94485, 'lng': -123.42594}}, {'name': 'Webber Springs', 'triplet': '852:WY:SNTL', 'elevation': 9260, 'location': {'lat': 41.1591, 'lng': -106.92809}}, {'name': 'Webster Flat', 'triplet': '853:UT:SNTL', 'elevation': 9203, 'location': {'lat': 37.575, 'lng': -112.90155}}, {'name': 'Wells Creek', 'triplet': '909:WA:SNTL', 'elevation': 4030, 'location': {'lat': 48.8661, 'lng': -121.78976}}, {'name': 'Weminuche Creek', 'triplet': '1160:CO:SNTL', 'elevation': 10749, 'location': {'lat': 37.51968, 'lng': -107.32139}}, {'name': 'Wesner Springs', 'triplet': '854:NM:SNTL', 'elevation': 11151, 'location': {'lat': 35.77584, 'lng': -105.54337}}, {'name': 'West Branch', 'triplet': '855:ID:SNTL', 'elevation': 5560, 'location': {'lat': 45.0722, 'lng': -116.45413}}, {'name': 'West Yellowstone', 'triplet': '924:MT:SNTL', 'elevation': 6700, 'location': {'lat': 44.65866, 'lng': -111.09199}}, {'name': 'Wheeler Peak', 'triplet': '1147:NV:SNTL', 'elevation': 10060, 'location': {'lat': 39.00995, 'lng': -114.31021}}, {'name': 'Whiskey Ck', 'triplet': '857:CO:SNTL', 'elevation': 10290, 'location': {'lat': 37.21423, 'lng': -105.12262}}, {'name': 'Whiskey Creek', 'triplet': '858:MT:SNTL', 'elevation': 6800, 'location': {'lat': 44.61088, 'lng': -111.14998}}, {'name': 'Whiskey Park', 'triplet': '859:WY:SNTL', 'elevation': 9020, 'location': {'lat': 41.00368, 'lng': -106.90795}}, {'name': 'White Elephant', 'triplet': '860:ID:SNTL', 'elevation': 7710, 'location': {'lat': 44.53267, 'lng': -111.41085}}, {'name': 'White Horse Lake', 'triplet': '861:AZ:SNTL', 'elevation': 7203, 'location': {'lat': 35.14189, 'lng': -112.14966}}, {'name': 'White Mill', 'triplet': '862:MT:SNTL', 'elevation': 8700, 'location': {'lat': 45.04575, 'lng': -109.90987}}, {'name': 'White Pass E.S.', 'triplet': '863:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.64142, 'lng': -121.38153}}, {'name': 'White River #1', 'triplet': '864:UT:SNTL', 'elevation': 8641, 'location': {'lat': 39.9645, 'lng': -110.98845}}, {'name': 'White River Nv', 'triplet': '1213:NV:SNTL', 'elevation': 7367, 'location': {'lat': 38.94557, 'lng': -115.37922}}, {'name': 'Widtsoe #3', 'triplet': '865:UT:SNTL', 'elevation': 9640, 'location': {'lat': 37.83633, 'lng': -111.88163}}, {'name': 'Wilbur Bench', 'triplet': '543:UT:SNTL', 'elevation': 9171, 'location': {'lat': 39.89166, 'lng': -110.74604}}, {'name': 'Wild Basin', 'triplet': '1042:CO:SNTL', 'elevation': 9439, 'location': {'lat': 40.201, 'lng': -105.6025}}, {'name': 'Wildcat', 'triplet': '866:AZ:SNTL', 'elevation': 7868, 'location': {'lat': 33.74347, 'lng': -109.48078}}, {'name': 'Wildhorse Divide', 'triplet': '867:ID:SNTL', 'elevation': 6490, 'location': {'lat': 42.75743, 'lng': -112.47783}}, {'name': 'Willow Creek', 'triplet': '868:WY:SNTL', 'elevation': 8080, 'location': {'lat': 42.81513, 'lng': -110.83515}}, {'name': 'Willow Creek Pass', 'triplet': '869:CO:SNTL', 'elevation': 9523, 'location': {'lat': 40.34734, 'lng': -106.0952}}, {'name': 'Willow Park', 'triplet': '870:CO:SNTL', 'elevation': 10732, 'location': {'lat': 40.43397, 'lng': -105.73588}}, {'name': 'Wilson Creek', 'triplet': '871:ID:SNTL', 'elevation': 7120, 'location': {'lat': 42.01257, 'lng': -115.00278}}, {'name': 'Windy Peak', 'triplet': '872:WY:SNTL', 'elevation': 7915, 'location': {'lat': 42.27991, 'lng': -105.57782}}, {'name': 'Wolf Creek', 'triplet': '873:OR:SNTL', 'elevation': 5630, 'location': {'lat': 45.06703, 'lng': -118.15192}}, {'name': 'Wolf Creek Peak', 'triplet': '1164:UT:SNTL', 'elevation': 9796, 'location': {'lat': 40.47733, 'lng': -111.04469}}, {'name': 'Wolf Creek Summit', 'triplet': '874:CO:SNTL', 'elevation': 10957, 'location': {'lat': 37.47903, 'lng': -106.80234}}, {'name': 'Wolverine', 'triplet': '875:WY:SNTL', 'elevation': 7650, 'location': {'lat': 44.80417, 'lng': -109.657}}, {'name': 'Wood Creek', 'triplet': '876:MT:SNTL', 'elevation': 5960, 'location': {'lat': 47.44847, 'lng': -112.81428}}, {'name': 'Workman Creek', 'triplet': '877:AZ:SNTL', 'elevation': 7032, 'location': {'lat': 33.81259, 'lng': -110.91852}}, {'name': 'Wrigley Creek', 'triplet': '1228:UT:SNTL', 'elevation': 9327, 'location': {'lat': 39.13233, 'lng': -111.35685}}, {'name': 'Yankee Reservoir', 'triplet': '1197:UT:SNTL', 'elevation': 8692, 'location': {'lat': 37.74797, 'lng': -112.77495}}, {'name': 'Younts Peak', 'triplet': '878:WY:SNTL', 'elevation': 8350, 'location': {'lat': 43.93225, 'lng': -109.81775}}, {'name': 'Zirkel', 'triplet': '1033:CO:SNTL', 'elevation': 9338, 'location': {'lat': 40.79492, 'lng': -106.59544}}]\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/UjXdGJBpSFKE/data_snotel_station_only.py\", line 75, in <module>\n    for station in station_locations.items():\nAttributeError: 'list' object has no attribute 'items'\n",
  "history_begin_time" : 1703486433898,
  "history_end_time" : 1703486434817,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "bBiB8GKwgT3o",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_corrected.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\nprint(station_locations)\n\nresult_df = pd.DataFrame(columns=['station_name', 'date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_locations.iterrows():\n    print(f'station {row[name]} completed.')\n    \n    location_name = row['name']\n    location_triplet = row['triplet']\n    location_elevation = row['elevation']\n    location_station_lat = row['location']['lat']\n    location_station_long = row['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\n[{'name': 'Adin Mtn', 'triplet': '301:CA:SNTL', 'elevation': 6190, 'location': {'lat': 41.23583, 'lng': -120.79192}}, {'name': 'Agua Canyon', 'triplet': '907:UT:SNTL', 'elevation': 8900, 'location': {'lat': 37.52217, 'lng': -112.27118}}, {'name': 'Albro Lake', 'triplet': '916:MT:SNTL', 'elevation': 8300, 'location': {'lat': 45.59723, 'lng': -111.95902}}, {'name': 'Alexander Lake', 'triplet': '1267:AK:SNTL', 'elevation': 160, 'location': {'lat': 61.74967, 'lng': -150.88967}}, {'name': 'Alpine Meadows', 'triplet': '908:WA:SNTL', 'elevation': 3500, 'location': {'lat': 47.77957, 'lng': -121.69847}}, {'name': 'American Creek', 'triplet': '1189:AK:SNTL', 'elevation': 1050, 'location': {'lat': 64.78969, 'lng': -141.23376}}, {'name': 'Anchor River Divide', 'triplet': '1062:AK:SNTL', 'elevation': 1653, 'location': {'lat': 59.85972, 'lng': -151.315}}, {'name': 'Anchorage Hillside', 'triplet': '1070:AK:SNTL', 'elevation': 2080, 'location': {'lat': 61.11483, 'lng': -149.66683}}, {'name': 'Aneroid Lake #2', 'triplet': '302:OR:SNTL', 'elevation': 7400, 'location': {'lat': 45.21328, 'lng': -117.19258}}, {'name': 'Aniak', 'triplet': '2065:AK:SNTL', 'elevation': 80, 'location': {'lat': 61.58337, 'lng': -159.57708}}, {'name': 'Annie Springs', 'triplet': '1000:OR:SNTL', 'elevation': 6010, 'location': {'lat': 42.87007, 'lng': -122.16518}}, {'name': 'Apishapa', 'triplet': '303:CO:SNTL', 'elevation': 10027, 'location': {'lat': 37.33067, 'lng': -105.06766}}, {'name': 'Arapaho Ridge', 'triplet': '1030:CO:SNTL', 'elevation': 10976, 'location': {'lat': 40.35098, 'lng': -106.38141}}, {'name': 'Arbuckle Mtn', 'triplet': '304:OR:SNTL', 'elevation': 5770, 'location': {'lat': 45.19085, 'lng': -119.25392}}, {'name': 'Atigun Pass', 'triplet': '957:AK:SNTL', 'elevation': 4800, 'location': {'lat': 68.12983, 'lng': -149.47817}}, {'name': 'Atlanta Summit', 'triplet': '306:ID:SNTL', 'elevation': 7580, 'location': {'lat': 43.7569, 'lng': -115.23907}}, {'name': 'Atwater', 'triplet': '1308:UT:SNTL', 'elevation': 8753, 'location': {'lat': 40.59124, 'lng': -111.63775}}, {'name': 'Badger Pass', 'triplet': '307:MT:SNTL', 'elevation': 6900, 'location': {'lat': 48.13088, 'lng': -113.02317}}, {'name': 'Baker Butte', 'triplet': '308:AZ:SNTL', 'elevation': 7363, 'location': {'lat': 34.45654, 'lng': -111.40651}}, {'name': 'Baker Butte Smt', 'triplet': '1140:AZ:SNTL', 'elevation': 7752, 'location': {'lat': 34.45552, 'lng': -111.38262}}, {'name': 'Bald Mtn.', 'triplet': '309:WY:SNTL', 'elevation': 9380, 'location': {'lat': 44.8007, 'lng': -107.84442}}, {'name': 'Baldy', 'triplet': '310:AZ:SNTL', 'elevation': 9221, 'location': {'lat': 33.97845, 'lng': -109.50357}}, {'name': 'Banfield Mountain', 'triplet': '311:MT:SNTL', 'elevation': 5600, 'location': {'lat': 48.5712, 'lng': -115.44573}}, {'name': 'Banner Summit', 'triplet': '312:ID:SNTL', 'elevation': 7040, 'location': {'lat': 44.30342, 'lng': -115.23447}}, {'name': 'Bar M', 'triplet': '1212:AZ:SNTL', 'elevation': 6397, 'location': {'lat': 34.86142, 'lng': -111.60497}}, {'name': 'Barker Lakes', 'triplet': '313:MT:SNTL', 'elevation': 8250, 'location': {'lat': 46.09713, 'lng': -113.13038}}, {'name': 'Base Camp', 'triplet': '314:WY:SNTL', 'elevation': 7060, 'location': {'lat': 43.94019, 'lng': -110.44544}}, {'name': 'Basin Creek', 'triplet': '315:MT:SNTL', 'elevation': 7180, 'location': {'lat': 45.79737, 'lng': -112.52047}}, {'name': 'Bassoo Peak', 'triplet': '1190:MT:SNTL', 'elevation': 5150, 'location': {'lat': 47.85562, 'lng': -114.75841}}, {'name': 'Bateman', 'triplet': '316:NM:SNTL', 'elevation': 9249, 'location': {'lat': 36.51174, 'lng': -106.31543}}, {'name': 'Battle Mountain', 'triplet': '317:WY:SNTL', 'elevation': 7498, 'location': {'lat': 41.05402, 'lng': -107.26674}}, {'name': 'Beagle Springs', 'triplet': '318:MT:SNTL', 'elevation': 8850, 'location': {'lat': 44.47147, 'lng': -112.98191}}, {'name': 'Bear Basin', 'triplet': '319:ID:SNTL', 'elevation': 5350, 'location': {'lat': 44.95222, 'lng': -116.14293}}, {'name': 'Bear Canyon', 'triplet': '320:ID:SNTL', 'elevation': 7900, 'location': {'lat': 43.74367, 'lng': -113.93797}}, {'name': 'Bear Creek', 'triplet': '321:NV:SNTL', 'elevation': 8040, 'location': {'lat': 41.83384, 'lng': -115.45278}}, {'name': 'Bear Grass', 'triplet': '1166:OR:SNTL', 'elevation': 4720, 'location': {'lat': 44.3253, 'lng': -122.0938}}, {'name': 'Bear Lake', 'triplet': '322:CO:SNTL', 'elevation': 9522, 'location': {'lat': 40.31176, 'lng': -105.6467}}, {'name': 'Bear Mountain', 'triplet': '323:ID:SNTL', 'elevation': 5400, 'location': {'lat': 48.30577, 'lng': -116.07448}}, {'name': 'Bear River', 'triplet': '1061:CO:SNTL', 'elevation': 9112, 'location': {'lat': 40.06152, 'lng': -107.00948}}, {'name': 'Bear River RS', 'triplet': '992:UT:SNTL', 'elevation': 8777, 'location': {'lat': 40.8852, 'lng': -110.8277}}, {'name': 'Bear Saddle', 'triplet': '324:ID:SNTL', 'elevation': 6180, 'location': {'lat': 44.60533, 'lng': -116.98097}}, {'name': 'Bear Trap Meadow', 'triplet': '325:WY:SNTL', 'elevation': 8200, 'location': {'lat': 43.88743, 'lng': -107.06135}}, {'name': 'Beartooth Lake', 'triplet': '326:WY:SNTL', 'elevation': 9360, 'location': {'lat': 44.94307, 'lng': -109.56743}}, {'name': 'Beartown', 'triplet': '327:CO:SNTL', 'elevation': 11600, 'location': {'lat': 37.71433, 'lng': -107.5124}}, {'name': 'Beaver Ck Village', 'triplet': '1041:CO:SNTL', 'elevation': 8565, 'location': {'lat': 39.59871, 'lng': -106.51113}}, {'name': 'Beaver Creek', 'triplet': '328:MT:SNTL', 'elevation': 7850, 'location': {'lat': 44.94966, 'lng': -111.35852}}, {'name': 'Beaver Dams', 'triplet': '329:UT:SNTL', 'elevation': 7990, 'location': {'lat': 39.13683, 'lng': -111.55813}}, {'name': 'Beaver Divide', 'triplet': '330:UT:SNTL', 'elevation': 8280, 'location': {'lat': 40.61233, 'lng': -111.09782}}, {'name': 'Beaver Head', 'triplet': '902:AZ:SNTL', 'elevation': 8076, 'location': {'lat': 33.69115, 'lng': -109.21685}}, {'name': 'Beaver Pass', 'triplet': '990:WA:SNTL', 'elevation': 3630, 'location': {'lat': 48.8793, 'lng': -121.2555}}, {'name': 'Beaver Reservoir', 'triplet': '331:OR:SNTL', 'elevation': 5150, 'location': {'lat': 45.14532, 'lng': -118.219}}, {'name': 'Beaver Spring', 'triplet': '1143:AZ:SNTL', 'elevation': 9255, 'location': {'lat': 36.32671, 'lng': -109.05702}}, {'name': 'Ben Lomond Peak', 'triplet': '332:UT:SNTL', 'elevation': 7689, 'location': {'lat': 41.37603, 'lng': -111.94405}}, {'name': 'Ben Lomond Trail', 'triplet': '333:UT:SNTL', 'elevation': 5972, 'location': {'lat': 41.38291, 'lng': -111.92103}}, {'name': 'Berry Creek', 'triplet': '334:NV:SNTL', 'elevation': 9377, 'location': {'lat': 39.31917, 'lng': -114.62278}}, {'name': 'Berthoud Summit', 'triplet': '335:CO:SNTL', 'elevation': 11314, 'location': {'lat': 39.80364, 'lng': -105.77786}}, {'name': 'Bettles Field', 'triplet': '1182:AK:SNTL', 'elevation': 640, 'location': {'lat': 66.91667, 'lng': -151.53333}}, {'name': 'Bevans Cabin', 'triplet': '1214:UT:SNTL', 'elevation': 6520, 'location': {'lat': 40.46182, 'lng': -112.25233}}, {'name': 'Big Bend', 'triplet': '336:NV:SNTL', 'elevation': 6898, 'location': {'lat': 41.76168, 'lng': -115.6931}}, {'name': 'Big Creek Sum', 'triplet': '337:NV:SNTL', 'elevation': 8685, 'location': {'lat': 39.29148, 'lng': -117.11506}}, {'name': 'Big Creek Summit', 'triplet': '338:ID:SNTL', 'elevation': 6560, 'location': {'lat': 44.62621, 'lng': -115.79561}}, {'name': 'Big Flat', 'triplet': '339:UT:SNTL', 'elevation': 10349, 'location': {'lat': 38.30183, 'lng': -112.35672}}, {'name': 'Big Goose', 'triplet': '931:WY:SNTL', 'elevation': 7990, 'location': {'lat': 44.57924, 'lng': -107.20068}}, {'name': 'Big Meadow', 'triplet': '340:NV:SNTL', 'elevation': 8235, 'location': {'lat': 39.455, 'lng': -119.9422}}, {'name': 'Big Red Mountain', 'triplet': '341:OR:SNTL', 'elevation': 6050, 'location': {'lat': 42.05257, 'lng': -122.85487}}, {'name': 'Big Sandy Opening', 'triplet': '342:WY:SNTL', 'elevation': 9080, 'location': {'lat': 42.6458, 'lng': -109.25965}}, {'name': 'Bigelow Camp', 'triplet': '343:OR:SNTL', 'elevation': 5130, 'location': {'lat': 42.07875, 'lng': -123.34393}}, {'name': 'Billie Creek Divide', 'triplet': '344:OR:SNTL', 'elevation': 5280, 'location': {'lat': 42.40717, 'lng': -122.26617}}, {'name': 'Bird Creek', 'triplet': '1155:NV:SNTL', 'elevation': 7537, 'location': {'lat': 39.46138, 'lng': -114.64863}}, {'name': 'Bison Lake', 'triplet': '345:CO:SNTL', 'elevation': 10964, 'location': {'lat': 39.76458, 'lng': -107.35628}}, {'name': 'Bisson Creek', 'triplet': '346:MT:SNTL', 'elevation': 4920, 'location': {'lat': 47.68389, 'lng': -113.99901}}, {'name': 'Black Bear', 'triplet': '347:MT:SNTL', 'elevation': 8170, 'location': {'lat': 44.50832, 'lng': -111.12803}}, {'name': 'Black Flat-U.M. Ck', 'triplet': '348:UT:SNTL', 'elevation': 9414, 'location': {'lat': 38.6799, 'lng': -111.59765}}, {'name': 'Black Mesa', 'triplet': '1185:CO:SNTL', 'elevation': 11564, 'location': {'lat': 37.78968, 'lng': -108.18376}}, {'name': 'Black Mountain', 'triplet': '1161:CO:SNTL', 'elevation': 8980, 'location': {'lat': 40.8879, 'lng': -105.66404}}, {'name': 'Black Pine', 'triplet': '349:MT:SNTL', 'elevation': 7210, 'location': {'lat': 46.414, 'lng': -113.43095}}, {'name': 'Blackhall Mtn', 'triplet': '1119:WY:SNTL', 'elevation': 9839, 'location': {'lat': 41.05623, 'lng': -106.714}}, {'name': 'Blacks Fork Jct', 'triplet': '1162:UT:SNTL', 'elevation': 8869, 'location': {'lat': 40.95814, 'lng': -110.5828}}, {'name': 'Blacktail Mtn', 'triplet': '1144:MT:SNTL', 'elevation': 5650, 'location': {'lat': 47.98288, 'lng': -114.3543}}, {'name': 'Blackwater', 'triplet': '350:WY:SNTL', 'elevation': 9780, 'location': {'lat': 44.37667, 'lng': -109.79333}}, {'name': 'Blazed Alder', 'triplet': '351:OR:SNTL', 'elevation': 3650, 'location': {'lat': 45.4287, 'lng': -121.85605}}, {'name': 'Blewett Pass', 'triplet': '352:WA:SNTL', 'elevation': 4240, 'location': {'lat': 47.35037, 'lng': -120.6796}}, {'name': 'Blind Bull Sum', 'triplet': '353:WY:SNTL', 'elevation': 8650, 'location': {'lat': 42.964, 'lng': -110.60973}}, {'name': 'Blind Park', 'triplet': '354:SD:SNTL', 'elevation': 6890, 'location': {'lat': 44.10772, 'lng': -103.97688}}, {'name': 'Bloody Dick', 'triplet': '355:MT:SNTL', 'elevation': 7600, 'location': {'lat': 45.16507, 'lng': -113.50099}}, {'name': 'Blue Lakes', 'triplet': '356:CA:SNTL', 'elevation': 8067, 'location': {'lat': 38.608, 'lng': -119.92437}}, {'name': 'Blue Mountain Spring', 'triplet': '357:OR:SNTL', 'elevation': 5870, 'location': {'lat': 44.24767, 'lng': -118.51722}}, {'name': 'Bobs Hollow', 'triplet': '1278:UT:SNTL', 'elevation': 9319, 'location': {'lat': 38.94569, 'lng': -112.15349}}, {'name': 'Bogus Basin', 'triplet': '978:ID:SNTL', 'elevation': 6340, 'location': {'lat': 43.76377, 'lng': -116.09685}}, {'name': 'Bone Springs Div', 'triplet': '358:WY:SNTL', 'elevation': 9350, 'location': {'lat': 44.67888, 'lng': -107.5811}}, {'name': 'Bostetter R.S.', 'triplet': '359:ID:SNTL', 'elevation': 7500, 'location': {'lat': 42.16442, 'lng': -114.19272}}, {'name': 'Boulder Mountain', 'triplet': '360:MT:SNTL', 'elevation': 7950, 'location': {'lat': 46.5596, 'lng': -111.28973}}, {'name': 'Bourne', 'triplet': '361:OR:SNTL', 'elevation': 5850, 'location': {'lat': 44.83052, 'lng': -118.18787}}, {'name': 'Bowman Springs', 'triplet': '362:OR:SNTL', 'elevation': 4530, 'location': {'lat': 45.36428, 'lng': -118.46715}}, {'name': 'Box Canyon', 'triplet': '363:MT:SNTL', 'elevation': 6670, 'location': {'lat': 45.2719, 'lng': -110.24903}}, {'name': 'Box Creek', 'triplet': '364:UT:SNTL', 'elevation': 9853, 'location': {'lat': 38.50809, 'lng': -112.01856}}, {'name': 'Box Springs', 'triplet': '1156:UT:SNTL', 'elevation': 9228, 'location': {'lat': 38.49746, 'lng': -112.00779}}, {'name': 'Brackett Creek', 'triplet': '365:MT:SNTL', 'elevation': 7320, 'location': {'lat': 45.89107, 'lng': -110.93851}}, {'name': 'Brian Head', 'triplet': '1154:UT:SNTL', 'elevation': 10039, 'location': {'lat': 37.67994, 'lng': -112.85674}}, {'name': 'Brighton', 'triplet': '366:UT:SNTL', 'elevation': 8766, 'location': {'lat': 40.59936, 'lng': -111.58167}}, {'name': 'Bristlecone Trail', 'triplet': '1111:NV:SNTL', 'elevation': 8890, 'location': {'lat': 36.31575, 'lng': -115.69543}}, {'name': 'Brooklyn Lake', 'triplet': '367:WY:SNTL', 'elevation': 10250, 'location': {'lat': 41.36038, 'lng': -106.23038}}, {'name': 'Brown Duck', 'triplet': '368:UT:SNTL', 'elevation': 10574, 'location': {'lat': 40.58102, 'lng': -110.58587}}, {'name': 'Brown Top', 'triplet': '1080:WA:SNTL', 'elevation': 5830, 'location': {'lat': 48.92755, 'lng': -121.19713}}, {'name': 'Brumley', 'triplet': '369:CO:SNTL', 'elevation': 10594, 'location': {'lat': 39.08758, 'lng': -106.54231}}, {'name': 'Brundage Reservoir', 'triplet': '370:ID:SNTL', 'elevation': 6250, 'location': {'lat': 45.04315, 'lng': -116.13253}}, {'name': 'Buck Flat', 'triplet': '371:UT:SNTL', 'elevation': 9409, 'location': {'lat': 39.134, 'lng': -111.43722}}, {'name': 'Buck Pasture', 'triplet': '1192:UT:SNTL', 'elevation': 9632, 'location': {'lat': 40.84456, 'lng': -110.66068}}, {'name': 'Buckboard Flat', 'triplet': '1153:UT:SNTL', 'elevation': 8924, 'location': {'lat': 37.86943, 'lng': -109.44717}}, {'name': 'Buckinghorse', 'triplet': '1107:WA:SNTL', 'elevation': 4870, 'location': {'lat': 47.7086, 'lng': -123.45747}}, {'name': 'Buckskin Joe', 'triplet': '938:CO:SNTL', 'elevation': 11166, 'location': {'lat': 39.30378, 'lng': -106.11316}}, {'name': 'Buckskin Lower', 'triplet': '373:NV:SNTL', 'elevation': 6930, 'location': {'lat': 41.75067, 'lng': -117.53182}}, {'name': 'Buffalo Park', 'triplet': '913:CO:SNTL', 'elevation': 9249, 'location': {'lat': 40.22838, 'lng': -106.5962}}, {'name': 'Bug Lake', 'triplet': '374:UT:SNTL', 'elevation': 7987, 'location': {'lat': 41.68541, 'lng': -111.41987}}, {'name': 'Bumping Ridge', 'triplet': '375:WA:SNTL', 'elevation': 4610, 'location': {'lat': 46.81003, 'lng': -121.33058}}, {'name': 'Bunchgrass Mdw', 'triplet': '376:WA:SNTL', 'elevation': 5000, 'location': {'lat': 48.68688, 'lng': -117.17633}}, {'name': 'Burgess Junction', 'triplet': '377:WY:SNTL', 'elevation': 7880, 'location': {'lat': 44.78765, 'lng': -107.52917}}, {'name': 'Burnside Lake', 'triplet': '1051:CA:SNTL', 'elevation': 8129, 'location': {'lat': 38.71943, 'lng': -119.8942}}, {'name': 'Burnt Mountain', 'triplet': '942:WA:SNTL', 'elevation': 4170, 'location': {'lat': 47.0444, 'lng': -121.94032}}, {'name': 'Burnt Mtn', 'triplet': '981:MT:SNTL', 'elevation': 5880, 'location': {'lat': 45.2401, 'lng': -109.45961}}, {'name': 'Burro Mountain', 'triplet': '378:CO:SNTL', 'elevation': 9317, 'location': {'lat': 39.87504, 'lng': -107.59902}}, {'name': 'Burroughs Creek', 'triplet': '379:WY:SNTL', 'elevation': 8750, 'location': {'lat': 43.69733, 'lng': -109.67021}}, {'name': 'Burts Miller Ranch', 'triplet': '1135:UT:SNTL', 'elevation': 8000, 'location': {'lat': 40.98492, 'lng': -110.85075}}, {'name': 'Butte', 'triplet': '380:CO:SNTL', 'elevation': 10200, 'location': {'lat': 38.89435, 'lng': -106.95327}}, {'name': 'Calamity', 'triplet': '1109:WA:SNTL', 'elevation': 2500, 'location': {'lat': 45.90362, 'lng': -122.21633}}, {'name': 'Calvert Creek', 'triplet': '381:MT:SNTL', 'elevation': 6430, 'location': {'lat': 45.8838, 'lng': -113.32553}}, {'name': 'Camas Creek Divide', 'triplet': '382:ID:SNTL', 'elevation': 5710, 'location': {'lat': 43.26548, 'lng': -115.3453}}, {'name': 'Camp Jackson', 'triplet': '383:UT:SNTL', 'elevation': 8858, 'location': {'lat': 37.81333, 'lng': -109.48723}}, {'name': 'Canyon', 'triplet': '384:WY:SNTL', 'elevation': 7870, 'location': {'lat': 44.71961, 'lng': -110.51084}}, {'name': 'Carrot Basin', 'triplet': '385:MT:SNTL', 'elevation': 9000, 'location': {'lat': 44.96192, 'lng': -111.29403}}, {'name': 'Carson Pass', 'triplet': '1067:CA:SNTL', 'elevation': 8360, 'location': {'lat': 38.6927, 'lng': -120.0022}}, {'name': 'Cascade #2', 'triplet': '387:CO:SNTL', 'elevation': 9012, 'location': {'lat': 37.65751, 'lng': -107.80287}}, {'name': 'Cascade Mountain', 'triplet': '1039:UT:SNTL', 'elevation': 7774, 'location': {'lat': 40.283, 'lng': -111.60992}}, {'name': 'Cascade Summit', 'triplet': '388:OR:SNTL', 'elevation': 5100, 'location': {'lat': 43.59042, 'lng': -122.0601}}, {'name': 'Casper Mtn.', 'triplet': '389:WY:SNTL', 'elevation': 7920, 'location': {'lat': 42.73362, 'lng': -106.31789}}, {'name': 'Castle Creek', 'triplet': '1130:WY:SNTL', 'elevation': 8400, 'location': {'lat': 43.6748, 'lng': -109.3774}}, {'name': 'Castle Valley', 'triplet': '390:UT:SNTL', 'elevation': 9607, 'location': {'lat': 37.66098, 'lng': -112.74093}}, {'name': 'Cave Mountain', 'triplet': '1152:NV:SNTL', 'elevation': 10578, 'location': {'lat': 39.16337, 'lng': -114.6133}}, {'name': 'Cayuse Pass', 'triplet': '1085:WA:SNTL', 'elevation': 5240, 'location': {'lat': 46.86954, 'lng': -121.5343}}, {'name': 'Cedar Pass', 'triplet': '391:CA:SNTL', 'elevation': 7030, 'location': {'lat': 41.58233, 'lng': -120.3025}}, {'name': 'Chalender', 'triplet': '1139:AZ:SNTL', 'elevation': 7035, 'location': {'lat': 35.26238, 'lng': -112.06221}}, {'name': 'Chalk Creek #1', 'triplet': '392:UT:SNTL', 'elevation': 9171, 'location': {'lat': 40.85464, 'lng': -111.04765}}, {'name': 'Chalk Creek #2', 'triplet': '393:UT:SNTL', 'elevation': 8208, 'location': {'lat': 40.88529, 'lng': -111.06954}}, {'name': 'Chamita', 'triplet': '394:NM:SNTL', 'elevation': 8383, 'location': {'lat': 36.95606, 'lng': -106.65723}}, {'name': 'Chapman Tunnel', 'triplet': '1101:CO:SNTL', 'elevation': 10100, 'location': {'lat': 39.2621, 'lng': -106.62944}}, {'name': 'Chemult Alternate', 'triplet': '395:OR:SNTL', 'elevation': 4850, 'location': {'lat': 43.22625, 'lng': -121.80662}}, {'name': 'Chena Lakes', 'triplet': '1260:AK:SNTL', 'elevation': 500, 'location': {'lat': 64.75793, 'lng': -147.21823}}, {'name': 'Chepeta', 'triplet': '396:UT:SNTL', 'elevation': 10499, 'location': {'lat': 40.77458, 'lng': -110.0105}}, {'name': 'Chicago Ridge', 'triplet': '1312:MT:SNTL', 'elevation': 5800, 'location': {'lat': 48.062, 'lng': -115.698}}, {'name': 'Chisana', 'triplet': '1093:AK:SNTL', 'elevation': 3320, 'location': {'lat': 62.069, 'lng': -142.049}}, {'name': 'Chocolate Gulch', 'triplet': '895:ID:SNTL', 'elevation': 6310, 'location': {'lat': 43.7685, 'lng': -114.41812}}, {'name': 'Cinnabar Park', 'triplet': '1046:WY:SNTL', 'elevation': 9707, 'location': {'lat': 41.23843, 'lng': -106.23101}}, {'name': 'Clackamas Lake', 'triplet': '398:OR:SNTL', 'elevation': 3400, 'location': {'lat': 45.09658, 'lng': -121.75443}}, {'name': 'Clayton Springs', 'triplet': '983:UT:SNTL', 'elevation': 10049, 'location': {'lat': 37.9725, 'lng': -111.83355}}, {'name': 'Clear Creek #1', 'triplet': '399:UT:SNTL', 'elevation': 8975, 'location': {'lat': 39.86671, 'lng': -111.28363}}, {'name': 'Clear Creek #2', 'triplet': '400:UT:SNTL', 'elevation': 7837, 'location': {'lat': 39.89275, 'lng': -111.25154}}, {'name': 'Clear Lake', 'triplet': '401:OR:SNTL', 'elevation': 3810, 'location': {'lat': 45.18832, 'lng': -121.6916}}, {'name': 'Cloud Peak Reservoir', 'triplet': '402:WY:SNTL', 'elevation': 9860, 'location': {'lat': 44.40343, 'lng': -107.06057}}, {'name': 'Clover Meadow', 'triplet': '403:MT:SNTL', 'elevation': 8600, 'location': {'lat': 45.01788, 'lng': -111.8456}}, {'name': 'Cochetopa Pass', 'triplet': '1059:CO:SNTL', 'elevation': 10061, 'location': {'lat': 38.16273, 'lng': -106.5988}}, {'name': 'Cold Springs', 'triplet': '405:WY:SNTL', 'elevation': 9630, 'location': {'lat': 43.27676, 'lng': -109.44585}}, {'name': 'Cold Springs Camp', 'triplet': '406:OR:SNTL', 'elevation': 5940, 'location': {'lat': 42.53305, 'lng': -122.17683}}, {'name': 'Coldfoot', 'triplet': '958:AK:SNTL', 'elevation': 1040, 'location': {'lat': 67.25333, 'lng': -150.183}}, {'name': 'Cole Canyon', 'triplet': '982:WY:SNTL', 'elevation': 5910, 'location': {'lat': 44.48632, 'lng': -104.41057}}, {'name': 'Cole Creek', 'triplet': '407:MT:SNTL', 'elevation': 7850, 'location': {'lat': 45.19405, 'lng': -109.34548}}, {'name': 'Columbia Basin', 'triplet': '1204:NV:SNTL', 'elevation': 6483, 'location': {'lat': 41.67167, 'lng': -116.07033}}, {'name': 'Columbine', 'triplet': '408:CO:SNTL', 'elevation': 9167, 'location': {'lat': 40.39591, 'lng': -106.60437}}, {'name': 'Columbine Pass', 'triplet': '409:CO:SNTL', 'elevation': 9171, 'location': {'lat': 38.41819, 'lng': -108.38313}}, {'name': 'Columbus Basin', 'triplet': '904:CO:SNTL', 'elevation': 10781, 'location': {'lat': 37.44146, 'lng': -108.02468}}, {'name': 'Combination', 'triplet': '410:MT:SNTL', 'elevation': 5600, 'location': {'lat': 46.46523, 'lng': -113.39358}}, {'name': 'Cool Creek', 'triplet': '411:ID:SNTL', 'elevation': 6280, 'location': {'lat': 46.76361, 'lng': -115.29528}}, {'name': 'Cooper Lake', 'triplet': '959:AK:SNTL', 'elevation': 1200, 'location': {'lat': 60.39027, 'lng': -149.6936}}, {'name': 'Copeland Lake', 'triplet': '412:CO:SNTL', 'elevation': 8555, 'location': {'lat': 40.20733, 'lng': -105.5695}}, {'name': 'Copper Bottom', 'triplet': '413:MT:SNTL', 'elevation': 5200, 'location': {'lat': 47.05678, 'lng': -112.595}}, {'name': 'Copper Camp', 'triplet': '414:MT:SNTL', 'elevation': 6950, 'location': {'lat': 47.08158, 'lng': -112.72955}}, {'name': 'Copper Mountain', 'triplet': '415:CO:SNTL', 'elevation': 10523, 'location': {'lat': 39.48917, 'lng': -106.17154}}, {'name': 'Corduroy Flat', 'triplet': '1209:NV:SNTL', 'elevation': 8640, 'location': {'lat': 38.99651, 'lng': -115.42478}}, {'name': 'Coronado Trail', 'triplet': '416:AZ:SNTL', 'elevation': 8418, 'location': {'lat': 33.80418, 'lng': -109.15352}}, {'name': 'Corral', 'triplet': '1236:UT:SNTL', 'elevation': 8207, 'location': {'lat': 39.65795, 'lng': -110.37906}}, {'name': 'Corral Canyon', 'triplet': '417:NV:SNTL', 'elevation': 8445, 'location': {'lat': 40.27551, 'lng': -115.54017}}, {'name': 'Corral Pass', 'triplet': '418:WA:SNTL', 'elevation': 5800, 'location': {'lat': 47.01872, 'lng': -121.46464}}, {'name': 'Cottonwood Creek', 'triplet': '419:WY:SNTL', 'elevation': 7670, 'location': {'lat': 42.6459, 'lng': -110.81482}}, {'name': 'Couch Summit', 'triplet': '1306:ID:SNTL', 'elevation': 6800, 'location': {'lat': 43.51768, 'lng': -114.8022}}, {'name': 'Cougar Mountain', 'triplet': '420:WA:SNTL', 'elevation': 3200, 'location': {'lat': 47.27666, 'lng': -121.67138}}, {'name': 'County Line', 'triplet': '422:OR:SNTL', 'elevation': 4830, 'location': {'lat': 45.19107, 'lng': -118.55015}}, {'name': 'Cozy Cove', 'triplet': '423:ID:SNTL', 'elevation': 5400, 'location': {'lat': 44.28846, 'lng': -115.65508}}, {'name': 'Crab Creek', 'triplet': '424:ID:SNTL', 'elevation': 6900, 'location': {'lat': 44.437, 'lng': -111.99384}}, {'name': 'Crater Meadows', 'triplet': '425:ID:SNTL', 'elevation': 5960, 'location': {'lat': 46.56394, 'lng': -115.28903}}, {'name': 'Crazyman Flat', 'triplet': '1010:OR:SNTL', 'elevation': 6180, 'location': {'lat': 42.6381, 'lng': -120.94917}}, {'name': 'Creamers Field', 'triplet': '1302:AK:SNTL', 'elevation': 440, 'location': {'lat': 64.86534, 'lng': -147.73617}}, {'name': 'Crosho', 'triplet': '426:CO:SNTL', 'elevation': 8973, 'location': {'lat': 40.16749, 'lng': -107.05769}}, {'name': 'Crow Creek', 'triplet': '1045:WY:SNTL', 'elevation': 8335, 'location': {'lat': 41.22824, 'lng': -105.38571}}, {'name': 'Crowder Flat', 'triplet': '977:CA:SNTL', 'elevation': 5170, 'location': {'lat': 41.89318, 'lng': -120.75202}}, {'name': 'Crystal Lake', 'triplet': '427:MT:SNTL', 'elevation': 6050, 'location': {'lat': 46.78942, 'lng': -109.51205}}, {'name': 'Css Lab', 'triplet': '428:CA:SNTL', 'elevation': 6894, 'location': {'lat': 39.32565, 'lng': -120.36807}}, {'name': 'Culebra #2', 'triplet': '430:CO:SNTL', 'elevation': 10562, 'location': {'lat': 37.20939, 'lng': -105.19988}}, {'name': 'Cumbres Trestle', 'triplet': '431:CO:SNTL', 'elevation': 10035, 'location': {'lat': 37.01877, 'lng': -106.45275}}, {'name': 'Currant Creek', 'triplet': '432:UT:SNTL', 'elevation': 7915, 'location': {'lat': 40.35747, 'lng': -111.08993}}, {'name': 'Dahl Creek', 'triplet': '1303:AK:SNTL', 'elevation': 260, 'location': {'lat': 66.94517, 'lng': -156.90318}}, {'name': 'Daisy Peak', 'triplet': '919:MT:SNTL', 'elevation': 7600, 'location': {'lat': 46.66858, 'lng': -110.33022}}, {'name': 'Daly Creek', 'triplet': '433:MT:SNTL', 'elevation': 5780, 'location': {'lat': 46.18367, 'lng': -113.8533}}, {'name': 'Daly Lake', 'triplet': '434:OR:SNTL', 'elevation': 3690, 'location': {'lat': 44.52147, 'lng': -122.08718}}, {'name': 'Daniels-Strawberry', 'triplet': '435:UT:SNTL', 'elevation': 8008, 'location': {'lat': 40.2953, 'lng': -111.25677}}, {'name': 'Darkhorse Lake', 'triplet': '436:MT:SNTL', 'elevation': 8945, 'location': {'lat': 45.17367, 'lng': -113.58448}}, {'name': 'Deadman Creek', 'triplet': '437:MT:SNTL', 'elevation': 6450, 'location': {'lat': 46.79279, 'lng': -110.67545}}, {'name': 'Deadman Hill', 'triplet': '438:CO:SNTL', 'elevation': 10239, 'location': {'lat': 40.80572, 'lng': -105.77018}}, {'name': 'Deadwood Summit', 'triplet': '439:ID:SNTL', 'elevation': 6860, 'location': {'lat': 44.54514, 'lng': -115.5638}}, {'name': 'Deer Park', 'triplet': '923:WY:SNTL', 'elevation': 9700, 'location': {'lat': 42.59076, 'lng': -108.90273}}, {'name': 'Defiance Mines', 'triplet': '1210:NV:SNTL', 'elevation': 9302, 'location': {'lat': 39.08527, 'lng': -114.89977}}, {'name': 'Derr.', 'triplet': '440:OR:SNTL', 'elevation': 5850, 'location': {'lat': 44.4465, 'lng': -119.93012}}, {'name': 'Diamond Lake', 'triplet': '442:OR:SNTL', 'elevation': 5280, 'location': {'lat': 43.18787, 'lng': -122.14003}}, {'name': 'Diamond Peak', 'triplet': '443:NV:SNTL', 'elevation': 8017, 'location': {'lat': 39.56361, 'lng': -115.84421}}, {'name': 'Dills Camp', 'triplet': '444:UT:SNTL', 'elevation': 9228, 'location': {'lat': 39.04554, 'lng': -111.46875}}, {'name': 'Disaster Peak', 'triplet': '445:NV:SNTL', 'elevation': 6260, 'location': {'lat': 41.96737, 'lng': -118.18934}}, {'name': 'Dismal Swamp', 'triplet': '446:CA:SNTL', 'elevation': 7360, 'location': {'lat': 41.99127, 'lng': -120.18033}}, {'name': 'Divide', 'triplet': '448:MT:SNTL', 'elevation': 7800, 'location': {'lat': 44.79317, 'lng': -112.05645}}, {'name': 'Divide Peak', 'triplet': '449:WY:SNTL', 'elevation': 8730, 'location': {'lat': 41.30399, 'lng': -107.15255}}, {'name': 'Dollarhide Summit', 'triplet': '450:ID:SNTL', 'elevation': 8420, 'location': {'lat': 43.6025, 'lng': -114.67417}}, {'name': 'Dome Lake', 'triplet': '451:WY:SNTL', 'elevation': 8880, 'location': {'lat': 44.57462, 'lng': -107.29537}}, {'name': 'Donkey Reservoir', 'triplet': '452:UT:SNTL', 'elevation': 9799, 'location': {'lat': 38.2084, 'lng': -111.47412}}, {'name': 'Dorsey Basin', 'triplet': '453:NV:SNTL', 'elevation': 7903, 'location': {'lat': 40.89343, 'lng': -115.21104}}, {'name': 'Draw Creek', 'triplet': '454:NV:SNTL', 'elevation': 7332, 'location': {'lat': 41.661, 'lng': -115.3234}}, {'name': 'Dry Bread Pond', 'triplet': '455:UT:SNTL', 'elevation': 8302, 'location': {'lat': 41.41289, 'lng': -111.5377}}, {'name': 'Dry Creek', 'triplet': '1243:NV:SNTL', 'elevation': 6555, 'location': {'lat': 40.8638, 'lng': -115.22014}}, {'name': 'Dry Fork', 'triplet': '906:UT:SNTL', 'elevation': 7093, 'location': {'lat': 40.56533, 'lng': -112.17343}}, {'name': 'Dry Lake', 'triplet': '457:CO:SNTL', 'elevation': 8271, 'location': {'lat': 40.5337, 'lng': -106.7814}}, {'name': 'Dungeness', 'triplet': '943:WA:SNTL', 'elevation': 4010, 'location': {'lat': 47.87224, 'lng': -123.0788}}, {'name': 'Dupuyer Creek', 'triplet': '458:MT:SNTL', 'elevation': 5750, 'location': {'lat': 48.06341, 'lng': -112.7573}}, {'name': 'Eagle Summit', 'triplet': '960:AK:SNTL', 'elevation': 3650, 'location': {'lat': 65.48588, 'lng': -145.41212}}, {'name': 'East Boulder Mine', 'triplet': '1105:MT:SNTL', 'elevation': 6335, 'location': {'lat': 45.50381, 'lng': -110.08019}}, {'name': 'East Palmer', 'triplet': '953:AK:SNTL', 'elevation': 230, 'location': {'lat': 61.59858, 'lng': -149.09637}}, {'name': 'East Rim Divide', 'triplet': '460:WY:SNTL', 'elevation': 7930, 'location': {'lat': 43.13097, 'lng': -110.2023}}, {'name': 'East Willow Creek', 'triplet': '461:UT:SNTL', 'elevation': 8302, 'location': {'lat': 39.31213, 'lng': -109.53179}}, {'name': 'Easy Pass', 'triplet': '998:WA:SNTL', 'elevation': 5270, 'location': {'lat': 48.85933, 'lng': -121.43895}}, {'name': 'Ebbetts Pass', 'triplet': '462:CA:SNTL', 'elevation': 8661, 'location': {'lat': 38.5497, 'lng': -119.80468}}, {'name': 'Echo Lake', 'triplet': '936:CO:SNTL', 'elevation': 10694, 'location': {'lat': 39.65539, 'lng': -105.59358}}, {'name': 'Echo Peak', 'triplet': '463:CA:SNTL', 'elevation': 7653, 'location': {'lat': 38.849, 'lng': -120.0795}}, {'name': 'EF Blacks Fork GS', 'triplet': '1163:UT:SNTL', 'elevation': 9360, 'location': {'lat': 40.88472, 'lng': -110.54056}}, {'name': 'Eilertson Meadows', 'triplet': '464:OR:SNTL', 'elevation': 5510, 'location': {'lat': 44.86887, 'lng': -118.11387}}, {'name': 'El Diente Peak', 'triplet': '465:CO:SNTL', 'elevation': 10217, 'location': {'lat': 37.78607, 'lng': -108.02235}}, {'name': 'Elbow Lake', 'triplet': '910:WA:SNTL', 'elevation': 3040, 'location': {'lat': 48.69092, 'lng': -121.90893}}, {'name': 'Elk Butte', 'triplet': '466:ID:SNTL', 'elevation': 5690, 'location': {'lat': 46.83998, 'lng': -116.12233}}, {'name': 'Elk Cabin', 'triplet': '921:NM:SNTL', 'elevation': 8239, 'location': {'lat': 35.7073, 'lng': -105.80584}}, {'name': 'Elk Peak', 'triplet': '1106:MT:SNTL', 'elevation': 7600, 'location': {'lat': 46.4845, 'lng': -110.7125}}, {'name': 'Elk River', 'triplet': '467:CO:SNTL', 'elevation': 8739, 'location': {'lat': 40.84758, 'lng': -106.96861}}, {'name': 'Elkhart Park G.S.', 'triplet': '468:WY:SNTL', 'elevation': 9400, 'location': {'lat': 43.00657, 'lng': -109.75893}}, {'name': 'Elkhead Divide', 'triplet': '1252:CO:SNTL', 'elevation': 8800, 'location': {'lat': 40.79637, 'lng': -107.10113}}, {'name': 'Elliot Ridge', 'triplet': '1120:CO:SNTL', 'elevation': 10549, 'location': {'lat': 39.8638, 'lng': -106.42473}}, {'name': 'Emery Creek', 'triplet': '469:MT:SNTL', 'elevation': 4350, 'location': {'lat': 48.43412, 'lng': -113.93725}}, {'name': 'Emigrant Springs', 'triplet': '470:OR:SNTL', 'elevation': 3800, 'location': {'lat': 45.55808, 'lng': -118.45383}}, {'name': 'Emigrant Summit', 'triplet': '471:ID:SNTL', 'elevation': 7390, 'location': {'lat': 42.36055, 'lng': -111.56085}}, {'name': 'Esther Island', 'triplet': '1071:AK:SNTL', 'elevation': 50, 'location': {'lat': 60.798, 'lng': -148.0857}}, {'name': 'Evening Star', 'triplet': '472:WY:SNTL', 'elevation': 9200, 'location': {'lat': 44.65258, 'lng': -109.78422}}, {'name': 'Exit Glacier', 'triplet': '1092:AK:SNTL', 'elevation': 400, 'location': {'lat': 60.19033, 'lng': -149.62117}}, {'name': 'Fallen Leaf', 'triplet': '473:CA:SNTL', 'elevation': 6242, 'location': {'lat': 38.93403, 'lng': -120.0545}}, {'name': 'Farmington', 'triplet': '474:UT:SNTL', 'elevation': 7902, 'location': {'lat': 40.97462, 'lng': -111.80975}}, {'name': 'Farmington Lower', 'triplet': '1054:UT:SNTL', 'elevation': 6779, 'location': {'lat': 40.992, 'lng': -111.81702}}, {'name': 'Farnsworth Lake', 'triplet': '475:UT:SNTL', 'elevation': 9623, 'location': {'lat': 38.77246, 'lng': -111.67662}}, {'name': 'Fawn Creek', 'triplet': '476:NV:SNTL', 'elevation': 7031, 'location': {'lat': 41.82098, 'lng': -116.10153}}, {'name': 'Fielding Lake', 'triplet': '1268:AK:SNTL', 'elevation': 3000, 'location': {'lat': 63.20267, 'lng': -145.6305}}, {'name': 'Fifteenmile', 'triplet': '1314:OR:SNTL', 'elevation': 5970, 'location': {'lat': 45.35265, 'lng': -121.53}}, {'name': 'Fish Ck', 'triplet': '1305:ID:SNTL', 'elevation': 6330, 'location': {'lat': 43.55542, 'lng': -113.71924}}, {'name': 'Fish Creek', 'triplet': '477:OR:SNTL', 'elevation': 7660, 'location': {'lat': 42.70992, 'lng': -118.6321}}, {'name': 'Fish Lake', 'triplet': '478:WA:SNTL', 'elevation': 3430, 'location': {'lat': 47.53565, 'lng': -121.08553}}, {'name': 'Fish Lake Utah', 'triplet': '1149:UT:SNTL', 'elevation': 8798, 'location': {'lat': 38.50455, 'lng': -111.76693}}, {'name': 'Fish Lk.', 'triplet': '479:OR:SNTL', 'elevation': 4660, 'location': {'lat': 42.3801, 'lng': -122.34943}}, {'name': 'Fisher Creek', 'triplet': '480:MT:SNTL', 'elevation': 9100, 'location': {'lat': 45.06235, 'lng': -109.94488}}, {'name': 'Five Points Lake', 'triplet': '481:UT:SNTL', 'elevation': 10943, 'location': {'lat': 40.71785, 'lng': -110.46721}}, {'name': 'Flattop Mtn.', 'triplet': '482:MT:SNTL', 'elevation': 6300, 'location': {'lat': 48.80225, 'lng': -113.85713}}, {'name': 'Flower Mountain', 'triplet': '1285:AK:SNTL', 'elevation': 2510, 'location': {'lat': 59.39617, 'lng': -136.28123}}, {'name': 'Fool Creek', 'triplet': '1186:CO:SNTL', 'elevation': 11156, 'location': {'lat': 39.86866, 'lng': -105.86765}}, {'name': 'Forestdale Creek', 'triplet': '1049:CA:SNTL', 'elevation': 8017, 'location': {'lat': 38.68245, 'lng': -119.9597}}, {'name': 'Fort Valley', 'triplet': '1121:AZ:SNTL', 'elevation': 7371, 'location': {'lat': 35.26773, 'lng': -111.74479}}, {'name': 'Fort Yukon', 'triplet': '961:AK:SNTL', 'elevation': 430, 'location': {'lat': 66.5705, 'lng': -145.24553}}, {'name': 'Fourmile Lake', 'triplet': '483:OR:SNTL', 'elevation': 5970, 'location': {'lat': 42.43933, 'lng': -122.2288}}, {'name': 'Franklin Basin', 'triplet': '484:ID:SNTL', 'elevation': 8140, 'location': {'lat': 42.0505, 'lng': -111.6012}}, {'name': 'Fredonyer Peak', 'triplet': '1277:CA:SNTL', 'elevation': 7208, 'location': {'lat': 40.68799, 'lng': -120.60805}}, {'name': 'Fremont Pass', 'triplet': '485:CO:SNTL', 'elevation': 11326, 'location': {'lat': 39.38014, 'lng': -106.19784}}, {'name': 'Frisco Divide', 'triplet': '486:NM:SNTL', 'elevation': 8013, 'location': {'lat': 33.73687, 'lng': -108.94327}}, {'name': 'Frohner Meadow', 'triplet': '487:MT:SNTL', 'elevation': 6480, 'location': {'lat': 46.43545, 'lng': -112.19277}}, {'name': 'Frostbite Bottom', 'triplet': '641:AK:SNTL', 'elevation': 2700, 'location': {'lat': 61.74722, 'lng': -149.2688}}, {'name': 'Fry', 'triplet': '488:AZ:SNTL', 'elevation': 7236, 'location': {'lat': 35.07356, 'lng': -111.84477}}, {'name': 'Fry Canyon', 'triplet': '1262:NV:SNTL', 'elevation': 6798, 'location': {'lat': 41.57022, 'lng': -115.93645}}, {'name': 'Galena', 'triplet': '489:ID:SNTL', 'elevation': 7470, 'location': {'lat': 43.87722, 'lng': -114.6725}}, {'name': 'Galena AK', 'triplet': '429:AK:SNTL', 'elevation': 410, 'location': {'lat': 64.69662, 'lng': -156.71497}}, {'name': 'Galena Summit', 'triplet': '490:ID:SNTL', 'elevation': 8780, 'location': {'lat': 43.87497, 'lng': -114.71363}}, {'name': 'Gallegos Peak', 'triplet': '491:NM:SNTL', 'elevation': 9480, 'location': {'lat': 36.19418, 'lng': -105.55742}}, {'name': 'Garden City Summit', 'triplet': '1114:UT:SNTL', 'elevation': 7705, 'location': {'lat': 41.9215, 'lng': -111.4693}}, {'name': 'Gardner Peak', 'triplet': '1066:UT:SNTL', 'elevation': 8322, 'location': {'lat': 37.40083, 'lng': -113.45988}}, {'name': 'Garfield R.S.', 'triplet': '492:ID:SNTL', 'elevation': 6560, 'location': {'lat': 43.6104, 'lng': -113.9308}}, {'name': 'Garita Peak', 'triplet': '1173:NM:SNTL', 'elevation': 10115, 'location': {'lat': 36.00469, 'lng': -106.54805}}, {'name': 'Garver Creek', 'triplet': '918:MT:SNTL', 'elevation': 4250, 'location': {'lat': 48.97523, 'lng': -115.81915}}, {'name': 'GBRC HQ', 'triplet': '1221:UT:SNTL', 'elevation': 8801, 'location': {'lat': 39.32019, 'lng': -111.48827}}, {'name': 'GBRC Meadows', 'triplet': '1222:UT:SNTL', 'elevation': 9858, 'location': {'lat': 39.30229, 'lng': -111.45383}}, {'name': 'George Creek', 'triplet': '1151:UT:SNTL', 'elevation': 8964, 'location': {'lat': 41.91562, 'lng': -113.41154}}, {'name': 'Gerber Reservoir', 'triplet': '945:OR:SNTL', 'elevation': 4890, 'location': {'lat': 42.2062, 'lng': -121.1334}}, {'name': 'Giveout', 'triplet': '493:ID:SNTL', 'elevation': 6930, 'location': {'lat': 42.4132, 'lng': -111.1663}}, {'name': 'Glen Cove', 'triplet': '1057:CO:SNTL', 'elevation': 11391, 'location': {'lat': 38.87602, 'lng': -105.07605}}, {'name': 'Gobblers Knob', 'triplet': '962:AK:SNTL', 'elevation': 2030, 'location': {'lat': 66.745, 'lng': -150.6675}}, {'name': 'Golconda', 'triplet': '1195:NV:SNTL', 'elevation': 6616, 'location': {'lat': 40.88358, 'lng': -117.58812}}, {'name': 'Gold Axe Camp', 'triplet': '1159:WA:SNTL', 'elevation': 5360, 'location': {'lat': 48.9516, 'lng': -118.9864}}, {'name': 'Gold Basin', 'triplet': '1304:UT:SNTL', 'elevation': 10076, 'location': {'lat': 38.46516, 'lng': -109.26332}}, {'name': 'Gold Center', 'triplet': '494:OR:SNTL', 'elevation': 5410, 'location': {'lat': 44.7638, 'lng': -118.3117}}, {'name': 'Gold Mountain', 'triplet': '1256:WA:SNTL', 'elevation': 4390, 'location': {'lat': 48.18934, 'lng': -118.4559}}, {'name': 'Gooseberry RS', 'triplet': '495:UT:SNTL', 'elevation': 7944, 'location': {'lat': 38.80034, 'lng': -111.68333}}, {'name': 'Gooseberry RS Up', 'triplet': '1184:UT:SNTL', 'elevation': 8396, 'location': {'lat': 38.7882, 'lng': -111.68892}}, {'name': 'Graham Guard Sta.', 'triplet': '496:ID:SNTL', 'elevation': 5690, 'location': {'lat': 43.9538, 'lng': -115.27387}}, {'name': 'Grand Targhee', 'triplet': '1082:WY:SNTL', 'elevation': 9260, 'location': {'lat': 43.77933, 'lng': -110.92783}}, {'name': 'Grandview', 'triplet': '956:AK:SNTL', 'elevation': 1100, 'location': {'lat': 60.60832, 'lng': -149.06313}}, {'name': 'Granite Creek', 'triplet': '497:WY:SNTL', 'elevation': 6770, 'location': {'lat': 43.34298, 'lng': -110.43495}}, {'name': 'Granite Crk', 'triplet': '963:AK:SNTL', 'elevation': 1240, 'location': {'lat': 63.94382, 'lng': -145.39993}}, {'name': 'Granite Peak', 'triplet': '498:NV:SNTL', 'elevation': 8503, 'location': {'lat': 41.67032, 'lng': -117.56668}}, {'name': 'Grassy Lake', 'triplet': '499:WY:SNTL', 'elevation': 7265, 'location': {'lat': 44.12612, 'lng': -110.83435}}, {'name': 'Grave Creek', 'triplet': '500:MT:SNTL', 'elevation': 4300, 'location': {'lat': 48.91453, 'lng': -114.76663}}, {'name': 'Grave Springs', 'triplet': '501:WY:SNTL', 'elevation': 8550, 'location': {'lat': 43.46643, 'lng': -107.23977}}, {'name': 'Grayback', 'triplet': '1058:CO:SNTL', 'elevation': 11626, 'location': {'lat': 37.47051, 'lng': -106.5379}}, {'name': 'Green Lake', 'triplet': '502:WA:SNTL', 'elevation': 5920, 'location': {'lat': 46.54741, 'lng': -121.17093}}, {'name': 'Green Mountain', 'triplet': '503:NV:SNTL', 'elevation': 8185, 'location': {'lat': 40.3848, 'lng': -115.52757}}, {'name': 'Greenpoint', 'triplet': '504:OR:SNTL', 'elevation': 3310, 'location': {'lat': 45.62237, 'lng': -121.70415}}, {'name': 'Grizzly Peak', 'triplet': '505:CO:SNTL', 'elevation': 11139, 'location': {'lat': 39.64646, 'lng': -105.8694}}, {'name': 'Gros Ventre Summit', 'triplet': '506:WY:SNTL', 'elevation': 8750, 'location': {'lat': 43.38939, 'lng': -110.12943}}, {'name': 'Grouse Camp', 'triplet': '507:WA:SNTL', 'elevation': 5390, 'location': {'lat': 47.28107, 'lng': -120.48771}}, {'name': 'Grouse Creek Divide', 'triplet': '964:AK:SNTL', 'elevation': 700, 'location': {'lat': 60.25965, 'lng': -149.34228}}, {'name': 'Gulkana River', 'triplet': '2222:AK:SNTL', 'elevation': 1830, 'location': {'lat': 62.40962, 'lng': -145.37513}}, {'name': 'Gunsight Pass', 'triplet': '944:WY:SNTL', 'elevation': 9820, 'location': {'lat': 43.38332, 'lng': -109.87815}}, {'name': 'Gutz Peak', 'triplet': '1065:UT:SNTL', 'elevation': 6763, 'location': {'lat': 37.49617, 'lng': -113.94235}}, {'name': 'Hagans Meadow', 'triplet': '508:CA:SNTL', 'elevation': 7742, 'location': {'lat': 38.8519, 'lng': -119.9374}}, {'name': 'Hams Fork', 'triplet': '509:WY:SNTL', 'elevation': 7840, 'location': {'lat': 42.146, 'lng': -110.67833}}, {'name': 'Hand Creek', 'triplet': '510:MT:SNTL', 'elevation': 5035, 'location': {'lat': 48.30754, 'lng': -114.84075}}, {'name': 'Hannagan Meadows', 'triplet': '511:AZ:SNTL', 'elevation': 9027, 'location': {'lat': 33.65352, 'lng': -109.30877}}, {'name': 'Hansen Sawmill', 'triplet': '512:WY:SNTL', 'elevation': 8360, 'location': {'lat': 44.25602, 'lng': -106.97983}}, {'name': 'Happy Jack', 'triplet': '969:AZ:SNTL', 'elevation': 7539, 'location': {'lat': 34.74594, 'lng': -111.41219}}, {'name': 'Hardscrabble', 'triplet': '896:UT:SNTL', 'elevation': 7250, 'location': {'lat': 40.86833, 'lng': -111.71865}}, {'name': 'Harris Flat', 'triplet': '514:UT:SNTL', 'elevation': 7792, 'location': {'lat': 37.48997, 'lng': -112.57602}}, {'name': 'Harts Pass', 'triplet': '515:WA:SNTL', 'elevation': 6490, 'location': {'lat': 48.72047, 'lng': -120.6586}}, {'name': 'Hawkins Lake', 'triplet': '516:MT:SNTL', 'elevation': 6450, 'location': {'lat': 48.9723, 'lng': -115.95337}}, {'name': 'Hawley Lake', 'triplet': '1271:AZ:SNTL', 'elevation': 8314, 'location': {'lat': 33.97121, 'lng': -109.76531}}, {'name': 'Hayden Fork', 'triplet': '517:UT:SNTL', 'elevation': 9130, 'location': {'lat': 40.79669, 'lng': -110.88472}}, {'name': 'Hayden Pass', 'triplet': '1102:CO:SNTL', 'elevation': 10699, 'location': {'lat': 38.29303, 'lng': -105.85027}}, {'name': 'Heavenly Valley', 'triplet': '518:CA:SNTL', 'elevation': 8534, 'location': {'lat': 38.92431, 'lng': -119.91641}}, {'name': 'Heber', 'triplet': '519:AZ:SNTL', 'elevation': 7654, 'location': {'lat': 34.31254, 'lng': -110.75433}}, {'name': 'Heen Latinee', 'triplet': '1270:AK:SNTL', 'elevation': 2065, 'location': {'lat': 58.69652, 'lng': -134.86448}}, {'name': 'Hemlock Butte', 'triplet': '520:ID:SNTL', 'elevation': 5810, 'location': {'lat': 46.48111, 'lng': -115.63361}}, {'name': 'Hewinta', 'triplet': '521:UT:SNTL', 'elevation': 9500, 'location': {'lat': 40.95009, 'lng': -110.48419}}, {'name': 'Hickerson Park', 'triplet': '522:UT:SNTL', 'elevation': 9122, 'location': {'lat': 40.90663, 'lng': -109.96287}}, {'name': 'Hidden Lake', 'triplet': '988:ID:SNTL', 'elevation': 5040, 'location': {'lat': 48.8937, 'lng': -116.75748}}, {'name': 'High Lonesome', 'triplet': '1187:CO:SNTL', 'elevation': 10638, 'location': {'lat': 40.0359, 'lng': -105.75472}}, {'name': 'High Ridge', 'triplet': '523:OR:SNTL', 'elevation': 4920, 'location': {'lat': 45.69682, 'lng': -118.10657}}, {'name': 'Hilts Creek', 'triplet': '524:ID:SNTL', 'elevation': 8000, 'location': {'lat': 44.01897, 'lng': -113.4723}}, {'name': 'Hobble Creek', 'triplet': '1223:UT:SNTL', 'elevation': 7377, 'location': {'lat': 40.18538, 'lng': -111.35971}}, {'name': 'Hobbs Park', 'triplet': '525:WY:SNTL', 'elevation': 10100, 'location': {'lat': 42.86984, 'lng': -109.09455}}, {'name': 'Hogg Pass', 'triplet': '526:OR:SNTL', 'elevation': 4790, 'location': {'lat': 44.42042, 'lng': -121.85655}}, {'name': 'Hole-in-Mountain', 'triplet': '527:NV:SNTL', 'elevation': 8163, 'location': {'lat': 40.94168, 'lng': -115.0954}}, {'name': 'Hole-in-Rock', 'triplet': '528:UT:SNTL', 'elevation': 9168, 'location': {'lat': 40.92167, 'lng': -110.18623}}, {'name': 'Holland Meadows', 'triplet': '529:OR:SNTL', 'elevation': 4930, 'location': {'lat': 43.66917, 'lng': -122.56877}}, {'name': 'Hoodoo Basin', 'triplet': '530:MT:SNTL', 'elevation': 6050, 'location': {'lat': 46.9751, 'lng': -115.0349}}, {'name': 'Hoosier Pass', 'triplet': '531:CO:SNTL', 'elevation': 11611, 'location': {'lat': 39.36092, 'lng': -106.05999}}, {'name': 'Hopewell', 'triplet': '532:NM:SNTL', 'elevation': 10095, 'location': {'lat': 36.71632, 'lng': -106.2637}}, {'name': 'Horse Meadow', 'triplet': '1050:CA:SNTL', 'elevation': 8557, 'location': {'lat': 38.83652, 'lng': -119.88732}}, {'name': 'Horse Ridge', 'triplet': '533:UT:SNTL', 'elevation': 8199, 'location': {'lat': 41.31372, 'lng': -111.44624}}, {'name': 'Hourglass Lake', 'triplet': '1122:CO:SNTL', 'elevation': 9417, 'location': {'lat': 40.57717, 'lng': -105.62584}}, {'name': 'Howard Prairie', 'triplet': '1158:OR:SNTL', 'elevation': 4580, 'location': {'lat': 42.215, 'lng': -122.3713}}, {'name': 'Howell Canyon', 'triplet': '534:ID:SNTL', 'elevation': 7980, 'location': {'lat': 42.32029, 'lng': -113.61587}}, {'name': 'Hozatka Lake', 'triplet': '2210:AK:SNTL', 'elevation': 206, 'location': {'lat': 65.198, 'lng': -156.635}}, {'name': 'Hozomeen Camp', 'triplet': '991:WA:SNTL', 'elevation': 1690, 'location': {'lat': 48.98075, 'lng': -121.07976}}, {'name': 'Huckleberry Creek', 'triplet': '928:WA:SNTL', 'elevation': 2250, 'location': {'lat': 47.06565, 'lng': -121.58778}}, {'name': 'Humboldt Gulch', 'triplet': '535:ID:SNTL', 'elevation': 4250, 'location': {'lat': 47.53178, 'lng': -115.77643}}, {'name': 'Huntington Horse', 'triplet': '1216:UT:SNTL', 'elevation': 9652, 'location': {'lat': 39.61774, 'lng': -111.30576}}, {'name': 'Hyndman', 'triplet': '537:ID:SNTL', 'elevation': 7620, 'location': {'lat': 43.71077, 'lng': -114.15894}}, {'name': 'Idarado', 'triplet': '538:CO:SNTL', 'elevation': 9812, 'location': {'lat': 37.93389, 'lng': -107.6762}}, {'name': 'Imnaviat Creek', 'triplet': '968:AK:SNTL', 'elevation': 3050, 'location': {'lat': 68.61683, 'lng': -149.30017}}, {'name': 'Independence Camp', 'triplet': '539:CA:SNTL', 'elevation': 6980, 'location': {'lat': 39.45269, 'lng': -120.29367}}, {'name': 'Independence Creek', 'triplet': '540:CA:SNTL', 'elevation': 6436, 'location': {'lat': 39.49001, 'lng': -120.28226}}, {'name': 'Independence Lake', 'triplet': '541:CA:SNTL', 'elevation': 8338, 'location': {'lat': 39.42752, 'lng': -120.31342}}, {'name': 'Independence Mine', 'triplet': '1091:AK:SNTL', 'elevation': 3550, 'location': {'lat': 61.79001, 'lng': -149.2839}}, {'name': 'Independence Pass', 'triplet': '542:CO:SNTL', 'elevation': 10598, 'location': {'lat': 39.07543, 'lng': -106.61154}}, {'name': 'Indian Creek', 'triplet': '544:WY:SNTL', 'elevation': 9425, 'location': {'lat': 42.30023, 'lng': -110.67753}}, {'name': 'Indian Pass', 'triplet': '946:AK:SNTL', 'elevation': 2350, 'location': {'lat': 61.06767, 'lng': -149.4795}}, {'name': 'Indian Rock', 'triplet': '1129:WA:SNTL', 'elevation': 5360, 'location': {'lat': 45.99077, 'lng': -120.80767}}, {'name': 'Irish Taylor', 'triplet': '545:OR:SNTL', 'elevation': 5540, 'location': {'lat': 43.80368, 'lng': -121.94793}}, {'name': 'Island Park', 'triplet': '546:ID:SNTL', 'elevation': 6290, 'location': {'lat': 44.4203, 'lng': -111.38512}}, {'name': 'Ivanhoe', 'triplet': '547:CO:SNTL', 'elevation': 10541, 'location': {'lat': 39.29228, 'lng': -106.54907}}, {'name': 'Jack Creek Upper', 'triplet': '548:NV:SNTL', 'elevation': 7377, 'location': {'lat': 41.54675, 'lng': -116.00517}}, {'name': 'Jack Wade Jct', 'triplet': '1275:AK:SNTL', 'elevation': 3585, 'location': {'lat': 64.1529, 'lng': -141.32693}}, {'name': 'Jacks Peak', 'triplet': '549:NV:SNTL', 'elevation': 8424, 'location': {'lat': 41.5136, 'lng': -116.0117}}, {'name': 'Jackson Peak', 'triplet': '550:ID:SNTL', 'elevation': 7070, 'location': {'lat': 44.05092, 'lng': -115.44322}}, {'name': 'Jackwhacker Gulch', 'triplet': '935:CO:SNTL', 'elevation': 11054, 'location': {'lat': 39.57096, 'lng': -105.80355}}, {'name': 'Jakes Creek', 'triplet': '1211:NV:SNTL', 'elevation': 7380, 'location': {'lat': 41.5687, 'lng': -115.03243}}, {'name': 'JL Meadow', 'triplet': '1287:MT:SNTL', 'elevation': 8800, 'location': {'lat': 44.77665, 'lng': -113.12217}}, {'name': 'Joe Wright', 'triplet': '551:CO:SNTL', 'elevation': 10158, 'location': {'lat': 40.53285, 'lng': -105.88747}}, {'name': 'Johnsons Camp', 'triplet': '1036:AK:SNTL', 'elevation': 25, 'location': {'lat': 64.5646, 'lng': -164.29257}}, {'name': 'Jones Corral', 'triplet': '1099:UT:SNTL', 'elevation': 9749, 'location': {'lat': 38.07125, 'lng': -112.16788}}, {'name': 'Jones Pass', 'triplet': '970:CO:SNTL', 'elevation': 10426, 'location': {'lat': 39.7645, 'lng': -105.90655}}, {'name': 'Jump Off Joe', 'triplet': '552:OR:SNTL', 'elevation': 3520, 'location': {'lat': 44.38605, 'lng': -122.16683}}, {'name': 'June Lake', 'triplet': '553:WA:SNTL', 'elevation': 3440, 'location': {'lat': 46.14778, 'lng': -122.15413}}, {'name': 'Kalamazoo', 'triplet': '1150:NV:SNTL', 'elevation': 7775, 'location': {'lat': 39.5579, 'lng': -114.62762}}, {'name': 'Kantishna', 'triplet': '1072:AK:SNTL', 'elevation': 1550, 'location': {'lat': 63.54167, 'lng': -150.994}}, {'name': 'Kelley R.S.', 'triplet': '554:WY:SNTL', 'elevation': 8180, 'location': {'lat': 42.26554, 'lng': -110.80177}}, {'name': 'Kelly Station', 'triplet': '1175:AK:SNTL', 'elevation': 310, 'location': {'lat': 67.93333, 'lng': -162.28333}}, {'name': 'Kenai Moose Pens', 'triplet': '966:AK:SNTL', 'elevation': 300, 'location': {'lat': 60.727, 'lng': -150.47517}}, {'name': 'Kendall R.S.', 'triplet': '555:WY:SNTL', 'elevation': 7740, 'location': {'lat': 43.2493, 'lng': -110.01662}}, {'name': 'Kilfoil Creek', 'triplet': '1145:UT:SNTL', 'elevation': 7220, 'location': {'lat': 41.24764, 'lng': -111.41249}}, {'name': 'Kiln', 'triplet': '556:CO:SNTL', 'elevation': 9624, 'location': {'lat': 39.3172, 'lng': -106.61501}}, {'name': 'Kimberly Mine', 'triplet': '557:UT:SNTL', 'elevation': 9101, 'location': {'lat': 38.48383, 'lng': -112.39273}}, {'name': 'King Mountain', 'triplet': '558:OR:SNTL', 'elevation': 4340, 'location': {'lat': 42.72395, 'lng': -123.20037}}, {'name': 'Kings Cabin', 'triplet': '559:UT:SNTL', 'elevation': 8728, 'location': {'lat': 40.71632, 'lng': -109.54401}}, {'name': 'Kirwin', 'triplet': '560:WY:SNTL', 'elevation': 9550, 'location': {'lat': 43.86067, 'lng': -109.32163}}, {'name': 'Klondike Narrows', 'triplet': '1115:UT:SNTL', 'elevation': 7250, 'location': {'lat': 41.96769, 'lng': -111.59713}}, {'name': 'Kolob', 'triplet': '561:UT:SNTL', 'elevation': 9263, 'location': {'lat': 37.52664, 'lng': -113.05386}}, {'name': 'Kraft Creek', 'triplet': '562:MT:SNTL', 'elevation': 4750, 'location': {'lat': 47.42749, 'lng': -113.77515}}, {'name': 'Lake Creek R.S.', 'triplet': '563:OR:SNTL', 'elevation': 5240, 'location': {'lat': 44.21007, 'lng': -118.63752}}, {'name': 'Lake Eldora', 'triplet': '564:CO:SNTL', 'elevation': 9728, 'location': {'lat': 39.93659, 'lng': -105.59031}}, {'name': 'Lake Irene', 'triplet': '565:CO:SNTL', 'elevation': 10682, 'location': {'lat': 40.41446, 'lng': -105.81941}}, {'name': 'Lakefork #1', 'triplet': '566:UT:SNTL', 'elevation': 10128, 'location': {'lat': 40.59709, 'lng': -110.43316}}, {'name': 'Lakefork #3', 'triplet': '1116:UT:SNTL', 'elevation': 8464, 'location': {'lat': 40.5502, 'lng': -110.3529}}, {'name': 'Lakefork Basin', 'triplet': '513:UT:SNTL', 'elevation': 10885, 'location': {'lat': 40.73785, 'lng': -110.62121}}, {'name': 'Lakeview Ridge', 'triplet': '568:MT:SNTL', 'elevation': 7400, 'location': {'lat': 44.58907, 'lng': -111.82498}}, {'name': 'Lamance Creek', 'triplet': '569:NV:SNTL', 'elevation': 6395, 'location': {'lat': 41.51542, 'lng': -117.63197}}, {'name': 'Lamoille #3', 'triplet': '570:NV:SNTL', 'elevation': 8051, 'location': {'lat': 40.6448, 'lng': -115.3812}}, {'name': 'Lamoille Upper', 'triplet': '1310:NV:SNTL', 'elevation': 8993, 'location': {'lat': 40.59965, 'lng': -115.37902}}, {'name': 'Laprele Creek', 'triplet': '571:WY:SNTL', 'elevation': 8390, 'location': {'lat': 42.43566, 'lng': -105.86051}}, {'name': 'Larsen Creek', 'triplet': '1134:WY:SNTL', 'elevation': 9000, 'location': {'lat': 42.5801, 'lng': -109.0883}}, {'name': 'Lasal Mountain', 'triplet': '572:UT:SNTL', 'elevation': 9578, 'location': {'lat': 38.48226, 'lng': -109.27198}}, {'name': 'Lasal Mountain-Lower', 'triplet': '1215:UT:SNTL', 'elevation': 8783, 'location': {'lat': 38.48167, 'lng': -109.29164}}, {'name': 'Laurel Draw', 'triplet': '573:NV:SNTL', 'elevation': 6682, 'location': {'lat': 41.77637, 'lng': -116.02957}}, {'name': 'Leavitt Lake', 'triplet': '574:CA:SNTL', 'elevation': 9604, 'location': {'lat': 38.27594, 'lng': -119.61281}}, {'name': 'Leavitt Meadows', 'triplet': '575:CA:SNTL', 'elevation': 7198, 'location': {'lat': 38.30367, 'lng': -119.55111}}, {'name': 'Lee Canyon', 'triplet': '1112:NV:SNTL', 'elevation': 8626, 'location': {'lat': 36.30537, 'lng': -115.67508}}, {'name': 'Lemhi Ridge', 'triplet': '576:MT:SNTL', 'elevation': 8100, 'location': {'lat': 44.9938, 'lng': -113.44399}}, {'name': 'Lewis Lake Divide', 'triplet': '577:WY:SNTL', 'elevation': 7850, 'location': {'lat': 44.20862, 'lng': -110.66628}}, {'name': 'Lewis Peak', 'triplet': '1006:NV:SNTL', 'elevation': 7370, 'location': {'lat': 40.3572, 'lng': -116.8647}}, {'name': 'Lick Creek', 'triplet': '578:MT:SNTL', 'elevation': 6860, 'location': {'lat': 45.5041, 'lng': -110.96625}}, {'name': 'Lightning Ridge', 'triplet': '1056:UT:SNTL', 'elevation': 8215, 'location': {'lat': 41.35891, 'lng': -111.48749}}, {'name': 'Lily Lake', 'triplet': '579:UT:SNTL', 'elevation': 9133, 'location': {'lat': 40.86493, 'lng': -110.79813}}, {'name': 'Lily Pond', 'triplet': '580:CO:SNTL', 'elevation': 11069, 'location': {'lat': 37.38028, 'lng': -106.54823}}, {'name': 'Little Bear', 'triplet': '582:UT:SNTL', 'elevation': 6548, 'location': {'lat': 41.40562, 'lng': -111.82607}}, {'name': 'Little Chena Ridge', 'triplet': '947:AK:SNTL', 'elevation': 2000, 'location': {'lat': 65.12422, 'lng': -146.7339}}, {'name': 'Little Goose', 'triplet': '1131:WY:SNTL', 'elevation': 8870, 'location': {'lat': 44.54315, 'lng': -107.17865}}, {'name': 'Little Grassy', 'triplet': '583:UT:SNTL', 'elevation': 6065, 'location': {'lat': 37.48631, 'lng': -113.84582}}, {'name': 'Little Meadows', 'triplet': '584:OR:SNTL', 'elevation': 4020, 'location': {'lat': 44.61297, 'lng': -122.22565}}, {'name': 'Little Snake River', 'triplet': '1047:WY:SNTL', 'elevation': 8928, 'location': {'lat': 41.07051, 'lng': -106.94284}}, {'name': 'Little Valley', 'triplet': '1242:NV:SNTL', 'elevation': 6493, 'location': {'lat': 39.25259, 'lng': -119.8771}}, {'name': 'Little Warm', 'triplet': '585:WY:SNTL', 'elevation': 9370, 'location': {'lat': 43.50278, 'lng': -109.752}}, {'name': 'Lizard Head Pass', 'triplet': '586:CO:SNTL', 'elevation': 10193, 'location': {'lat': 37.79895, 'lng': -107.92475}}, {'name': 'Lobdell Lake', 'triplet': '587:CA:SNTL', 'elevation': 9249, 'location': {'lat': 38.43745, 'lng': -119.36572}}, {'name': 'Lolo Pass', 'triplet': '588:ID:SNTL', 'elevation': 5240, 'location': {'lat': 46.63448, 'lng': -114.58072}}, {'name': 'Lone Cone', 'triplet': '589:CO:SNTL', 'elevation': 9755, 'location': {'lat': 37.89169, 'lng': -108.19636}}, {'name': 'Lone Mountain', 'triplet': '590:MT:SNTL', 'elevation': 8880, 'location': {'lat': 45.27412, 'lng': -111.42692}}, {'name': 'Lone Pine', 'triplet': '591:WA:SNTL', 'elevation': 3930, 'location': {'lat': 46.27143, 'lng': -121.96288}}, {'name': 'Lonesome Beaver', 'triplet': '1261:UT:SNTL', 'elevation': 9410, 'location': {'lat': 38.07, 'lng': -110.77241}}, {'name': 'Long Draw Resv', 'triplet': '1123:CO:SNTL', 'elevation': 10008, 'location': {'lat': 40.51154, 'lng': -105.7654}}, {'name': 'Long Flat', 'triplet': '592:UT:SNTL', 'elevation': 7982, 'location': {'lat': 37.51255, 'lng': -113.39661}}, {'name': 'Long Lake', 'triplet': '1001:AK:SNTL', 'elevation': 850, 'location': {'lat': 58.186, 'lng': -133.83217}}, {'name': 'Long Valley', 'triplet': '1016:ID:SNTL', 'elevation': 4890, 'location': {'lat': 44.78835, 'lng': -116.08878}}, {'name': 'Long Valley Jct', 'triplet': '593:UT:SNTL', 'elevation': 7465, 'location': {'lat': 37.48756, 'lng': -112.51458}}, {'name': 'Lookout', 'triplet': '594:ID:SNTL', 'elevation': 5190, 'location': {'lat': 47.45749, 'lng': -115.70457}}, {'name': 'Lookout Mountain', 'triplet': '595:NM:SNTL', 'elevation': 8509, 'location': {'lat': 33.36089, 'lng': -107.83203}}, {'name': 'Lookout Peak', 'triplet': '596:UT:SNTL', 'elevation': 8161, 'location': {'lat': 40.83731, 'lng': -111.70965}}, {'name': 'Loomis Park', 'triplet': '597:WY:SNTL', 'elevation': 8240, 'location': {'lat': 43.17387, 'lng': -110.14007}}, {'name': 'Lost Creek Resv', 'triplet': '1118:UT:SNTL', 'elevation': 6082, 'location': {'lat': 41.22155, 'lng': -111.35947}}, {'name': 'Lost Dog', 'triplet': '940:CO:SNTL', 'elevation': 9327, 'location': {'lat': 40.81557, 'lng': -106.74833}}, {'name': 'Lost Horse', 'triplet': '599:WA:SNTL', 'elevation': 5120, 'location': {'lat': 46.3575, 'lng': -121.08095}}, {'name': 'Lost Lake', 'triplet': '600:ID:SNTL', 'elevation': 6110, 'location': {'lat': 47.0809, 'lng': -115.9604}}, {'name': 'Lost-Wood Divide', 'triplet': '601:ID:SNTL', 'elevation': 7900, 'location': {'lat': 43.82432, 'lng': -114.26402}}, {'name': 'Louis Meadow', 'triplet': '972:UT:SNTL', 'elevation': 6700, 'location': {'lat': 40.83033, 'lng': -111.76457}}, {'name': 'Loveland Basin', 'triplet': '602:CO:SNTL', 'elevation': 11427, 'location': {'lat': 39.67428, 'lng': -105.90264}}, {'name': 'Lower Kachemak Creek', 'triplet': '1265:AK:SNTL', 'elevation': 1915, 'location': {'lat': 59.73507, 'lng': -150.69327}}, {'name': 'Lower Twin', 'triplet': '603:MT:SNTL', 'elevation': 7900, 'location': {'lat': 45.50871, 'lng': -111.92288}}, {'name': 'Lubrecht Flume', 'triplet': '604:MT:SNTL', 'elevation': 4680, 'location': {'lat': 46.88293, 'lng': -113.32228}}, {'name': 'Lucky Strike', 'triplet': '605:OR:SNTL', 'elevation': 4970, 'location': {'lat': 45.27478, 'lng': -118.8479}}, {'name': 'Lyman Lake', 'triplet': '606:WA:SNTL', 'elevation': 5980, 'location': {'lat': 48.19798, 'lng': -120.91678}}, {'name': 'Lynn Lake', 'triplet': '1069:WA:SNTL', 'elevation': 3900, 'location': {'lat': 47.20172, 'lng': -121.77972}}, {'name': 'Lynx Pass', 'triplet': '607:CO:SNTL', 'elevation': 8919, 'location': {'lat': 40.07832, 'lng': -106.67095}}, {'name': 'Madison Butte', 'triplet': '608:OR:SNTL', 'elevation': 5150, 'location': {'lat': 45.10513, 'lng': -119.49585}}, {'name': 'Madison Plateau', 'triplet': '609:MT:SNTL', 'elevation': 7750, 'location': {'lat': 44.58623, 'lng': -111.11627}}, {'name': 'Magic Mountain', 'triplet': '610:ID:SNTL', 'elevation': 6880, 'location': {'lat': 42.18072, 'lng': -114.28662}}, {'name': 'Mammoth-Cottonwood', 'triplet': '612:UT:SNTL', 'elevation': 8709, 'location': {'lat': 39.68338, 'lng': -111.31818}}, {'name': 'Mancos', 'triplet': '905:CO:SNTL', 'elevation': 10044, 'location': {'lat': 37.43109, 'lng': -108.17005}}, {'name': 'Many Glacier', 'triplet': '613:MT:SNTL', 'elevation': 4900, 'location': {'lat': 48.79698, 'lng': -113.6705}}, {'name': 'Marion Forks', 'triplet': '614:OR:SNTL', 'elevation': 2590, 'location': {'lat': 44.59397, 'lng': -121.97365}}, {'name': 'Marlette Lake', 'triplet': '615:NV:SNTL', 'elevation': 7884, 'location': {'lat': 39.16395, 'lng': -119.89672}}, {'name': 'Marquette', 'triplet': '616:WY:SNTL', 'elevation': 8760, 'location': {'lat': 44.3016, 'lng': -109.24019}}, {'name': 'Marten Ridge', 'triplet': '999:WA:SNTL', 'elevation': 3520, 'location': {'lat': 48.76292, 'lng': -121.69823}}, {'name': 'Maverick Fork', 'triplet': '617:AZ:SNTL', 'elevation': 9220, 'location': {'lat': 33.92123, 'lng': -109.45872}}, {'name': 'May Creek', 'triplet': '1096:AK:SNTL', 'elevation': 1610, 'location': {'lat': 61.34783, 'lng': -142.70967}}, {'name': 'Mc Clure Pass', 'triplet': '618:CO:SNTL', 'elevation': 8774, 'location': {'lat': 39.12899, 'lng': -107.28834}}, {'name': 'Mccoy Park', 'triplet': '1040:CO:SNTL', 'elevation': 9516, 'location': {'lat': 39.60231, 'lng': -106.544}}, {'name': 'McGrath', 'triplet': '785:AK:SNTL', 'elevation': 340, 'location': {'lat': 62.94652, 'lng': -155.6102}}, {'name': 'Mckenzie', 'triplet': '619:OR:SNTL', 'elevation': 4770, 'location': {'lat': 44.2103, 'lng': -121.87292}}, {'name': 'Mcknight Cabin', 'triplet': '1048:NM:SNTL', 'elevation': 9242, 'location': {'lat': 33.00796, 'lng': -107.86982}}, {'name': 'Mcneil Canyon', 'triplet': '1003:AK:SNTL', 'elevation': 1320, 'location': {'lat': 59.74433, 'lng': -151.25133}}, {'name': 'Mcneil River SGS', 'triplet': '1191:AK:SNTL', 'elevation': 140, 'location': {'lat': 59.08332, 'lng': -154.27543}}, {'name': 'Meadow Lake', 'triplet': '620:ID:SNTL', 'elevation': 9150, 'location': {'lat': 44.43655, 'lng': -113.31815}}, {'name': 'Meadows Pass', 'triplet': '897:WA:SNTL', 'elevation': 3230, 'location': {'lat': 47.28312, 'lng': -121.47197}}, {'name': 'Med Bow', 'triplet': '1196:WY:SNTL', 'elevation': 10512, 'location': {'lat': 41.37833, 'lng': -106.34697}}, {'name': 'Medano Pass', 'triplet': '914:CO:SNTL', 'elevation': 9668, 'location': {'lat': 37.85192, 'lng': -105.43666}}, {'name': 'Merchant Valley', 'triplet': '621:UT:SNTL', 'elevation': 8705, 'location': {'lat': 38.30285, 'lng': -112.43637}}, {'name': 'Merritt Mountain', 'triplet': '1207:NV:SNTL', 'elevation': 6915, 'location': {'lat': 41.8927, 'lng': -115.858}}, {'name': 'Mesa Lakes', 'triplet': '622:CO:SNTL', 'elevation': 10168, 'location': {'lat': 39.05738, 'lng': -108.05756}}, {'name': 'MF Nooksack', 'triplet': '1011:WA:SNTL', 'elevation': 4970, 'location': {'lat': 48.82453, 'lng': -121.92951}}, {'name': 'Mica Creek', 'triplet': '623:ID:SNTL', 'elevation': 4510, 'location': {'lat': 47.15045, 'lng': -116.26643}}, {'name': 'Michigan Creek', 'triplet': '937:CO:SNTL', 'elevation': 10702, 'location': {'lat': 39.43579, 'lng': -105.91072}}, {'name': 'Midas', 'triplet': '1206:NV:SNTL', 'elevation': 6630, 'location': {'lat': 41.26873, 'lng': -116.80332}}, {'name': 'Middle Creek', 'triplet': '624:CO:SNTL', 'elevation': 11269, 'location': {'lat': 37.61779, 'lng': -107.03932}}, {'name': 'Middle Fork Bradley', 'triplet': '1064:AK:SNTL', 'elevation': 2300, 'location': {'lat': 59.77683, 'lng': -150.75733}}, {'name': 'Middle Fork Camp', 'triplet': '1014:CO:SNTL', 'elevation': 8969, 'location': {'lat': 39.79565, 'lng': -106.02802}}, {'name': 'Middle Powder', 'triplet': '625:WY:SNTL', 'elevation': 7760, 'location': {'lat': 43.62728, 'lng': -107.18138}}, {'name': 'Midway Valley', 'triplet': '626:UT:SNTL', 'elevation': 9827, 'location': {'lat': 37.56933, 'lng': -112.83849}}, {'name': 'Milk Shakes', 'triplet': '1079:OR:SNTL', 'elevation': 5580, 'location': {'lat': 45.9821, 'lng': -117.94883}}, {'name': 'Mill Creek Summit', 'triplet': '627:ID:SNTL', 'elevation': 8800, 'location': {'lat': 44.47212, 'lng': -114.48992}}, {'name': 'Mill-D North', 'triplet': '628:UT:SNTL', 'elevation': 8963, 'location': {'lat': 40.65883, 'lng': -111.63683}}, {'name': 'Miller Woods', 'triplet': '1084:OR:SNTL', 'elevation': 420, 'location': {'lat': 45.24755, 'lng': -123.27563}}, {'name': 'Mineral Creek', 'triplet': '629:CO:SNTL', 'elevation': 10046, 'location': {'lat': 37.84737, 'lng': -107.72657}}, {'name': 'Mining Fork', 'triplet': '631:UT:SNTL', 'elevation': 8295, 'location': {'lat': 40.49384, 'lng': -112.61141}}, {'name': 'Molas Lake', 'triplet': '632:CO:SNTL', 'elevation': 10631, 'location': {'lat': 37.74929, 'lng': -107.68933}}, {'name': 'Monahan Flat', 'triplet': '1094:AK:SNTL', 'elevation': 2710, 'location': {'lat': 63.30533, 'lng': -147.64633}}, {'name': 'Monitor Pass', 'triplet': '633:CA:SNTL', 'elevation': 8306, 'location': {'lat': 38.6683, 'lng': -119.6087}}, {'name': 'Monte Cristo', 'triplet': '634:UT:SNTL', 'elevation': 8932, 'location': {'lat': 41.46547, 'lng': -111.49688}}, {'name': 'Monument Creek', 'triplet': '949:AK:SNTL', 'elevation': 1850, 'location': {'lat': 65.07833, 'lng': -145.87067}}, {'name': 'Monument Peak', 'triplet': '635:MT:SNTL', 'elevation': 8850, 'location': {'lat': 45.21759, 'lng': -110.237}}, {'name': 'Moon Pass', 'triplet': '1124:CO:SNTL', 'elevation': 11128, 'location': {'lat': 37.96627, 'lng': -106.55857}}, {'name': 'Moonshine', 'triplet': '636:ID:SNTL', 'elevation': 7440, 'location': {'lat': 44.4147, 'lng': -113.39812}}, {'name': 'Moore Creek Bridge', 'triplet': '1176:AK:SNTL', 'elevation': 2250, 'location': {'lat': 59.58783, 'lng': -135.2105}}, {'name': 'Moose Creek', 'triplet': '638:ID:SNTL', 'elevation': 6200, 'location': {'lat': 45.67008, 'lng': -113.95315}}, {'name': 'Moraine', 'triplet': '1035:AK:SNTL', 'elevation': 2100, 'location': {'lat': 61.37727, 'lng': -148.99917}}, {'name': 'Mores Creek Summit', 'triplet': '637:ID:SNTL', 'elevation': 6100, 'location': {'lat': 43.932, 'lng': -115.66588}}, {'name': 'Morgan Creek', 'triplet': '639:ID:SNTL', 'elevation': 7600, 'location': {'lat': 44.84237, 'lng': -114.26871}}, {'name': 'Mormon Mountain', 'triplet': '640:AZ:SNTL', 'elevation': 7500, 'location': {'lat': 34.94141, 'lng': -111.51864}}, {'name': 'Mormon Mtn Summit', 'triplet': '1125:AZ:SNTL', 'elevation': 8462, 'location': {'lat': 34.96942, 'lng': -111.50868}}, {'name': 'Morse Lake', 'triplet': '642:WA:SNTL', 'elevation': 5410, 'location': {'lat': 46.90585, 'lng': -121.4827}}, {'name': 'Mosby Mtn.', 'triplet': '643:UT:SNTL', 'elevation': 9553, 'location': {'lat': 40.60798, 'lng': -109.8881}}, {'name': 'Moscow Mountain', 'triplet': '989:ID:SNTL', 'elevation': 4700, 'location': {'lat': 46.805, 'lng': -116.8535}}, {'name': 'Moses Mtn', 'triplet': '644:WA:SNTL', 'elevation': 5010, 'location': {'lat': 48.36163, 'lng': -119.08159}}, {'name': 'Mosquito Ridge', 'triplet': '645:ID:SNTL', 'elevation': 5260, 'location': {'lat': 48.05726, 'lng': -116.23055}}, {'name': 'Moss Peak', 'triplet': '646:MT:SNTL', 'elevation': 6780, 'location': {'lat': 47.68493, 'lng': -113.9623}}, {'name': 'Moss Springs', 'triplet': '647:OR:SNTL', 'elevation': 5760, 'location': {'lat': 45.27173, 'lng': -117.68747}}, {'name': 'Mount Crag', 'triplet': '648:WA:SNTL', 'elevation': 3960, 'location': {'lat': 47.7637, 'lng': -123.026}}, {'name': 'Mount Gardner', 'triplet': '898:WA:SNTL', 'elevation': 2920, 'location': {'lat': 47.35768, 'lng': -121.56812}}, {'name': 'Mount Lockhart', 'triplet': '649:MT:SNTL', 'elevation': 6400, 'location': {'lat': 47.91727, 'lng': -112.8238}}, {'name': 'Mountain Meadows', 'triplet': '650:ID:SNTL', 'elevation': 6320, 'location': {'lat': 45.69694, 'lng': -115.22972}}, {'name': 'Mowich', 'triplet': '941:WA:SNTL', 'elevation': 3160, 'location': {'lat': 46.92833, 'lng': -121.95232}}, {'name': 'Mt Baldy', 'triplet': '1224:UT:SNTL', 'elevation': 9524, 'location': {'lat': 39.13648, 'lng': -111.50527}}, {'name': 'Mt Hood Test Site', 'triplet': '651:OR:SNTL', 'elevation': 5370, 'location': {'lat': 45.32097, 'lng': -121.7158}}, {'name': 'Mt Pennell', 'triplet': '1269:UT:SNTL', 'elevation': 9209, 'location': {'lat': 37.97793, 'lng': -110.7933}}, {'name': 'Mt Rose Ski Area', 'triplet': '652:NV:SNTL', 'elevation': 8801, 'location': {'lat': 39.31573, 'lng': -119.89473}}, {'name': 'Mt. Alyeska', 'triplet': '1103:AK:SNTL', 'elevation': 1540, 'location': {'lat': 60.95983, 'lng': -149.08617}}, {'name': 'Mt. Eyak', 'triplet': '1073:AK:SNTL', 'elevation': 1405, 'location': {'lat': 60.55, 'lng': -145.745}}, {'name': 'Mt. Howard', 'triplet': '653:OR:SNTL', 'elevation': 7910, 'location': {'lat': 45.26522, 'lng': -117.17373}}, {'name': 'Mt. Ryan', 'triplet': '948:AK:SNTL', 'elevation': 2800, 'location': {'lat': 65.25113, 'lng': -146.15133}}, {'name': 'Mt. Tebo', 'triplet': '1126:WA:SNTL', 'elevation': 3384, 'location': {'lat': 47.46061, 'lng': -123.41219}}, {'name': 'Muckamuck', 'triplet': '1259:WA:SNTL', 'elevation': 4470, 'location': {'lat': 48.58526, 'lng': -119.86624}}, {'name': 'Mud Flat', 'triplet': '654:ID:SNTL', 'elevation': 5730, 'location': {'lat': 42.6004, 'lng': -116.55925}}, {'name': 'Mud Ridge', 'triplet': '655:OR:SNTL', 'elevation': 4070, 'location': {'lat': 45.25362, 'lng': -121.73673}}, {'name': 'Mule Creek', 'triplet': '656:MT:SNTL', 'elevation': 8300, 'location': {'lat': 45.40957, 'lng': -112.95927}}, {'name': 'Munson Ridge', 'triplet': '950:AK:SNTL', 'elevation': 3100, 'location': {'lat': 64.85033, 'lng': -146.20945}}, {'name': 'Myrtle Creek', 'triplet': '1053:ID:SNTL', 'elevation': 3520, 'location': {'lat': 48.72263, 'lng': -116.46312}}, {'name': 'N Fk Elk Creek', 'triplet': '657:MT:SNTL', 'elevation': 6250, 'location': {'lat': 46.8716, 'lng': -113.27725}}, {'name': 'Nast Lake', 'triplet': '658:CO:SNTL', 'elevation': 8731, 'location': {'lat': 39.29695, 'lng': -106.60786}}, {'name': 'Navajo Whiskey Ck', 'triplet': '1138:NM:SNTL', 'elevation': 9064, 'location': {'lat': 36.17716, 'lng': -108.94556}}, {'name': 'Nenana', 'triplet': '2081:AK:SNTL', 'elevation': 415, 'location': {'lat': 64.68582, 'lng': -148.9113}}, {'name': 'Nevada Ridge', 'triplet': '903:MT:SNTL', 'elevation': 7020, 'location': {'lat': 46.84234, 'lng': -112.50787}}, {'name': 'Never Summer', 'triplet': '1031:CO:SNTL', 'elevation': 10323, 'location': {'lat': 40.40392, 'lng': -105.95567}}, {'name': 'New Crescent Lake', 'triplet': '660:OR:SNTL', 'elevation': 4910, 'location': {'lat': 43.51185, 'lng': -121.97982}}, {'name': 'New Fork Lake', 'triplet': '661:WY:SNTL', 'elevation': 8340, 'location': {'lat': 43.11265, 'lng': -109.94947}}, {'name': 'Nez Perce Camp', 'triplet': '662:MT:SNTL', 'elevation': 5650, 'location': {'lat': 45.73107, 'lng': -114.48075}}, {'name': 'Niwot', 'triplet': '663:CO:SNTL', 'elevation': 9979, 'location': {'lat': 40.03581, 'lng': -105.5452}}, {'name': 'Noisy Basin', 'triplet': '664:MT:SNTL', 'elevation': 6040, 'location': {'lat': 48.15678, 'lng': -113.94637}}, {'name': 'North Costilla', 'triplet': '665:NM:SNTL', 'elevation': 10598, 'location': {'lat': 36.99396, 'lng': -105.25988}}, {'name': 'North Fork', 'triplet': '666:OR:SNTL', 'elevation': 3060, 'location': {'lat': 45.5505, 'lng': -122.00283}}, {'name': 'North Fork Jocko', 'triplet': '667:MT:SNTL', 'elevation': 6330, 'location': {'lat': 47.2726, 'lng': -113.75617}}, {'name': 'North French Creek', 'triplet': '668:WY:SNTL', 'elevation': 10153, 'location': {'lat': 41.33087, 'lng': -106.37558}}, {'name': 'North Lost Trail', 'triplet': '669:CO:SNTL', 'elevation': 9219, 'location': {'lat': 39.07818, 'lng': -107.14388}}, {'name': 'North Rapid Creek', 'triplet': '920:SD:SNTL', 'elevation': 6130, 'location': {'lat': 44.20617, 'lng': -103.78758}}, {'name': 'Northeast Entrance', 'triplet': '670:MT:SNTL', 'elevation': 7350, 'location': {'lat': 45.00565, 'lng': -110.01406}}, {'name': 'Nuka Glacier', 'triplet': '1037:AK:SNTL', 'elevation': 1250, 'location': {'lat': 59.69867, 'lng': -150.70967}}, {'name': 'Nutrioso', 'triplet': '1127:AZ:SNTL', 'elevation': 8571, 'location': {'lat': 33.89791, 'lng': -109.15465}}, {'name': 'Oak Creek', 'triplet': '1146:UT:SNTL', 'elevation': 7850, 'location': {'lat': 39.3485, 'lng': -112.32639}}, {'name': 'Ochoco Meadows', 'triplet': '671:OR:SNTL', 'elevation': 5430, 'location': {'lat': 44.42917, 'lng': -120.3311}}, {'name': 'Olallie Meadows', 'triplet': '672:WA:SNTL', 'elevation': 4030, 'location': {'lat': 47.37406, 'lng': -121.44213}}, {'name': 'ONeil Creek', 'triplet': '1272:NV:SNTL', 'elevation': 6520, 'location': {'lat': 41.8642, 'lng': -115.08316}}, {'name': 'Onion Park', 'triplet': '1008:MT:SNTL', 'elevation': 7410, 'location': {'lat': 46.91348, 'lng': -110.8536}}, {'name': 'Overland Res.', 'triplet': '675:CO:SNTL', 'elevation': 9893, 'location': {'lat': 39.09035, 'lng': -107.63583}}, {'name': 'Owl Creek', 'triplet': '676:WY:SNTL', 'elevation': 8975, 'location': {'lat': 43.65868, 'lng': -109.00988}}, {'name': 'Oxford Spring', 'triplet': '677:ID:SNTL', 'elevation': 6740, 'location': {'lat': 42.26015, 'lng': -112.12515}}, {'name': 'Palisades Tahoe', 'triplet': '784:CA:SNTL', 'elevation': 8013, 'location': {'lat': 39.18986, 'lng': -120.26576}}, {'name': 'Palo', 'triplet': '1170:NM:SNTL', 'elevation': 9343, 'location': {'lat': 36.40869, 'lng': -105.33038}}, {'name': 'Panguitch Lake RS', 'triplet': '1148:UT:SNTL', 'elevation': 8350, 'location': {'lat': 37.70463, 'lng': -112.65037}}, {'name': 'Paradise', 'triplet': '679:WA:SNTL', 'elevation': 5130, 'location': {'lat': 46.78265, 'lng': -121.74765}}, {'name': 'Paradise Hill', 'triplet': '1301:AK:SNTL', 'elevation': 2010, 'location': {'lat': 62.83329, 'lng': -141.40918}}, {'name': 'Pargon Creek', 'triplet': '986:AK:SNTL', 'elevation': 100, 'location': {'lat': 64.9935, 'lng': -163.10317}}, {'name': 'Park Cone', 'triplet': '680:CO:SNTL', 'elevation': 9621, 'location': {'lat': 38.81982, 'lng': -106.58962}}, {'name': 'Park Creek Ridge', 'triplet': '681:WA:SNTL', 'elevation': 4600, 'location': {'lat': 48.44488, 'lng': -120.91551}}, {'name': 'Park Reservoir', 'triplet': '682:CO:SNTL', 'elevation': 9987, 'location': {'lat': 39.04433, 'lng': -107.87951}}, {'name': 'Parker Peak', 'triplet': '683:WY:SNTL', 'elevation': 9400, 'location': {'lat': 44.73396, 'lng': -109.91484}}, {'name': 'Parleys Summit', 'triplet': '684:UT:SNTL', 'elevation': 7585, 'location': {'lat': 40.76184, 'lng': -111.62917}}, {'name': 'Parleys Upper', 'triplet': '856:UT:SNTL', 'elevation': 8353, 'location': {'lat': 40.70194, 'lng': -111.60619}}, {'name': 'Parrish Creek', 'triplet': '971:UT:SNTL', 'elevation': 7740, 'location': {'lat': 40.93417, 'lng': -111.81372}}, {'name': 'Payson R.S.', 'triplet': '686:UT:SNTL', 'elevation': 8044, 'location': {'lat': 39.92976, 'lng': -111.63109}}, {'name': 'Peavine Ridge', 'triplet': '687:OR:SNTL', 'elevation': 3420, 'location': {'lat': 45.04148, 'lng': -121.93252}}, {'name': 'Pebble Creek', 'triplet': '1299:ID:SNTL', 'elevation': 6513, 'location': {'lat': 42.7674, 'lng': -112.10648}}, {'name': 'Pepper Creek', 'triplet': '1104:WA:SNTL', 'elevation': 2140, 'location': {'lat': 46.10242, 'lng': -121.95555}}, {'name': 'Peterson Meadows', 'triplet': '930:MT:SNTL', 'elevation': 7200, 'location': {'lat': 46.12588, 'lng': -113.30792}}, {'name': 'Phantom Valley', 'triplet': '688:CO:SNTL', 'elevation': 9045, 'location': {'lat': 40.39803, 'lng': -105.84606}}, {'name': 'Phillips Bench', 'triplet': '689:WY:SNTL', 'elevation': 8200, 'location': {'lat': 43.51687, 'lng': -110.91258}}, {'name': 'Pickfoot Creek', 'triplet': '690:MT:SNTL', 'elevation': 6650, 'location': {'lat': 46.57978, 'lng': -111.26832}}, {'name': 'Pickle Keg', 'triplet': '691:UT:SNTL', 'elevation': 9020, 'location': {'lat': 39.01219, 'lng': -111.58259}}, {'name': 'Pierce R.S.', 'triplet': '1142:ID:SNTL', 'elevation': 3080, 'location': {'lat': 46.49597, 'lng': -115.7957}}, {'name': 'Pigtail Peak', 'triplet': '692:WA:SNTL', 'elevation': 5800, 'location': {'lat': 46.62153, 'lng': -121.38643}}, {'name': 'Pike Creek', 'triplet': '693:MT:SNTL', 'elevation': 5930, 'location': {'lat': 48.30305, 'lng': -113.32868}}, {'name': 'Pine Creek', 'triplet': '694:UT:SNTL', 'elevation': 8734, 'location': {'lat': 38.88185, 'lng': -112.24915}}, {'name': 'Pine Creek Pass', 'triplet': '695:ID:SNTL', 'elevation': 6720, 'location': {'lat': 43.56998, 'lng': -111.21157}}, {'name': 'Pinto Rock', 'triplet': '1263:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.32318, 'lng': -121.94219}}, {'name': 'Placer Basin', 'triplet': '696:MT:SNTL', 'elevation': 8830, 'location': {'lat': 45.41905, 'lng': -110.08844}}, {'name': 'Pocket Creek', 'triplet': '1133:WY:SNTL', 'elevation': 9360, 'location': {'lat': 42.7121, 'lng': -109.4112}}, {'name': 'Poison Flat', 'triplet': '697:CA:SNTL', 'elevation': 7736, 'location': {'lat': 38.50576, 'lng': -119.62624}}, {'name': 'Pole Canyon', 'triplet': '1244:NV:SNTL', 'elevation': 7760, 'location': {'lat': 40.86293, 'lng': -115.12067}}, {'name': 'Pole Creek R.S.', 'triplet': '698:NV:SNTL', 'elevation': 8360, 'location': {'lat': 41.87255, 'lng': -115.24713}}, {'name': 'Poorman Creek', 'triplet': '932:MT:SNTL', 'elevation': 5100, 'location': {'lat': 48.12672, 'lng': -115.62333}}, {'name': 'Pope Ridge', 'triplet': '699:WA:SNTL', 'elevation': 3590, 'location': {'lat': 47.9909, 'lng': -120.56622}}, {'name': 'Porcupine', 'triplet': '700:MT:SNTL', 'elevation': 6500, 'location': {'lat': 46.11192, 'lng': -110.4696}}, {'name': 'Porphyry Creek', 'triplet': '701:CO:SNTL', 'elevation': 10788, 'location': {'lat': 38.48864, 'lng': -106.33967}}, {'name': 'Port Graham', 'triplet': '987:AK:SNTL', 'elevation': 300, 'location': {'lat': 59.35065, 'lng': -151.84768}}, {'name': 'Porter Canyon', 'triplet': '2170:NV:SNTL', 'elevation': 7187, 'location': {'lat': 39.46544, 'lng': -117.62069}}, {'name': 'Potato Hill', 'triplet': '702:WA:SNTL', 'elevation': 4510, 'location': {'lat': 46.34963, 'lng': -121.51435}}, {'name': 'Powder Mountain', 'triplet': '1300:UT:SNTL', 'elevation': 8505, 'location': {'lat': 41.37428, 'lng': -111.76673}}, {'name': 'Powder River Pass', 'triplet': '703:WY:SNTL', 'elevation': 9480, 'location': {'lat': 44.16188, 'lng': -107.12622}}, {'name': 'Prairie', 'triplet': '704:ID:SNTL', 'elevation': 4800, 'location': {'lat': 43.50513, 'lng': -115.573}}, {'name': 'Promontory', 'triplet': '705:AZ:SNTL', 'elevation': 7942, 'location': {'lat': 34.36848, 'lng': -111.01088}}, {'name': 'Prudhoe Bay', 'triplet': '1177:AK:SNTL', 'elevation': 30, 'location': {'lat': 70.26666, 'lng': -148.56666}}, {'name': 'Quartz Mountain', 'triplet': '706:OR:SNTL', 'elevation': 5720, 'location': {'lat': 42.31923, 'lng': -120.82533}}, {'name': 'Quartz Peak', 'triplet': '707:WA:SNTL', 'elevation': 4700, 'location': {'lat': 47.87927, 'lng': -117.08938}}, {'name': 'Quemazon', 'triplet': '708:NM:SNTL', 'elevation': 9507, 'location': {'lat': 35.92195, 'lng': -106.39179}}, {'name': 'Rabbit Ears', 'triplet': '709:CO:SNTL', 'elevation': 9411, 'location': {'lat': 40.36735, 'lng': -106.74118}}, {'name': 'Ragged Mountain', 'triplet': '1081:ID:SNTL', 'elevation': 4210, 'location': {'lat': 47.85583, 'lng': -117.03667}}, {'name': 'Railroad Overpass', 'triplet': '710:OR:SNTL', 'elevation': 2680, 'location': {'lat': 43.65887, 'lng': -122.21272}}, {'name': 'Rainbow Canyon', 'triplet': '1110:NV:SNTL', 'elevation': 7860, 'location': {'lat': 36.2493, 'lng': -115.62972}}, {'name': 'Rainy Pass', 'triplet': '711:WA:SNTL', 'elevation': 4890, 'location': {'lat': 48.51865, 'lng': -120.7358}}, {'name': 'Rawah', 'triplet': '1032:CO:SNTL', 'elevation': 9069, 'location': {'lat': 40.70794, 'lng': -106.00727}}, {'name': 'Red Hill', 'triplet': '712:OR:SNTL', 'elevation': 4410, 'location': {'lat': 45.4643, 'lng': -121.70428}}, {'name': 'Red Mountain Pass', 'triplet': '713:CO:SNTL', 'elevation': 11080, 'location': {'lat': 37.89168, 'lng': -107.71389}}, {'name': 'Red Pine Ridge', 'triplet': '714:UT:SNTL', 'elevation': 8988, 'location': {'lat': 39.45197, 'lng': -111.27221}}, {'name': 'Red River Pass #2', 'triplet': '715:NM:SNTL', 'elevation': 9855, 'location': {'lat': 36.69935, 'lng': -105.34145}}, {'name': 'Redden Mine Lwr', 'triplet': '1225:UT:SNTL', 'elevation': 8532, 'location': {'lat': 40.67505, 'lng': -111.21765}}, {'name': 'Rees Flat', 'triplet': '1217:UT:SNTL', 'elevation': 7206, 'location': {'lat': 39.49667, 'lng': -111.72508}}, {'name': 'Reno Hill', 'triplet': '716:WY:SNTL', 'elevation': 8430, 'location': {'lat': 42.57089, 'lng': -106.08969}}, {'name': 'Rex River', 'triplet': '911:WA:SNTL', 'elevation': 3810, 'location': {'lat': 47.30218, 'lng': -121.60475}}, {'name': 'Reynolds Creek', 'triplet': '2029:ID:SNTL', 'elevation': 5600, 'location': {'lat': 43.28863, 'lng': -116.8431}}, {'name': 'Rice Park', 'triplet': '933:NM:SNTL', 'elevation': 8497, 'location': {'lat': 35.23658, 'lng': -108.27404}}, {'name': 'Rio Santa Barbara', 'triplet': '1254:NM:SNTL', 'elevation': 10664, 'location': {'lat': 36.07196, 'lng': -105.62949}}, {'name': 'Ripple Creek', 'triplet': '717:CO:SNTL', 'elevation': 10350, 'location': {'lat': 40.10844, 'lng': -107.29383}}, {'name': 'Roach', 'triplet': '718:CO:SNTL', 'elevation': 9740, 'location': {'lat': 40.87498, 'lng': -106.04675}}, {'name': 'Roaring River', 'triplet': '719:OR:SNTL', 'elevation': 4950, 'location': {'lat': 43.90098, 'lng': -122.03063}}, {'name': 'Rock Creek', 'triplet': '720:UT:SNTL', 'elevation': 7886, 'location': {'lat': 40.54875, 'lng': -110.69292}}, {'name': 'Rock Springs', 'triplet': '721:OR:SNTL', 'elevation': 5290, 'location': {'lat': 44.00883, 'lng': -118.83842}}, {'name': 'Rocker Peak', 'triplet': '722:MT:SNTL', 'elevation': 8000, 'location': {'lat': 46.35613, 'lng': -112.26176}}, {'name': 'Rockwood GS', 'triplet': '1309:UT:SNTL', 'elevation': 8593, 'location': {'lat': 38.67101, 'lng': -112.3305}}, {'name': 'Rocky Basin-Settleme', 'triplet': '723:UT:SNTL', 'elevation': 8704, 'location': {'lat': 40.44293, 'lng': -112.22377}}, {'name': 'Rocky Boy', 'triplet': '917:MT:SNTL', 'elevation': 4700, 'location': {'lat': 48.17478, 'lng': -109.64728}}, {'name': 'Rocky Point', 'triplet': '973:AK:SNTL', 'elevation': 250, 'location': {'lat': 64.53482, 'lng': -163.4214}}, {'name': 'Rough And Tumble', 'triplet': '939:CO:SNTL', 'elevation': 10432, 'location': {'lat': 39.02611, 'lng': -106.08063}}, {'name': 'Rubicon #2', 'triplet': '724:CA:SNTL', 'elevation': 7619, 'location': {'lat': 38.99927, 'lng': -120.13139}}, {'name': 'S Fork Shields', 'triplet': '725:MT:SNTL', 'elevation': 8100, 'location': {'lat': 46.0896, 'lng': -110.43363}}, {'name': 'Sacajawea', 'triplet': '929:MT:SNTL', 'elevation': 6550, 'location': {'lat': 45.87395, 'lng': -110.92783}}, {'name': 'Saddle Mountain', 'triplet': '726:OR:SNTL', 'elevation': 3110, 'location': {'lat': 45.54477, 'lng': -123.37315}}, {'name': 'Saddle Mtn.', 'triplet': '727:MT:SNTL', 'elevation': 7940, 'location': {'lat': 45.69259, 'lng': -113.96828}}, {'name': 'Sage Creek Basin', 'triplet': '1015:WY:SNTL', 'elevation': 7850, 'location': {'lat': 41.40107, 'lng': -107.2574}}, {'name': 'Sagwon', 'triplet': '1183:AK:SNTL', 'elevation': 1000, 'location': {'lat': 69.42417, 'lng': -148.6925}}, {'name': 'Saint Elmo', 'triplet': '1100:CO:SNTL', 'elevation': 10450, 'location': {'lat': 38.69985, 'lng': -106.36805}}, {'name': 'Salmon Meadows', 'triplet': '728:WA:SNTL', 'elevation': 4460, 'location': {'lat': 48.65518, 'lng': -119.8383}}, {'name': 'Salt Creek Falls', 'triplet': '729:OR:SNTL', 'elevation': 4220, 'location': {'lat': 43.61193, 'lng': -122.11758}}, {'name': 'Salt River Summit', 'triplet': '730:WY:SNTL', 'elevation': 7640, 'location': {'lat': 42.5075, 'lng': -110.9099}}, {'name': 'San Antonio Sink', 'triplet': '1172:NM:SNTL', 'elevation': 9143, 'location': {'lat': 36.85967, 'lng': -106.22657}}, {'name': 'Sand Lake', 'triplet': '731:WY:SNTL', 'elevation': 10098, 'location': {'lat': 41.4625, 'lng': -106.281}}, {'name': 'Sandstone RS', 'triplet': '732:WY:SNTL', 'elevation': 8152, 'location': {'lat': 41.11179, 'lng': -107.17043}}, {'name': 'Santa Fe', 'triplet': '922:NM:SNTL', 'elevation': 11465, 'location': {'lat': 35.77154, 'lng': -105.78487}}, {'name': 'Santaquin Meadows', 'triplet': '1280:UT:SNTL', 'elevation': 7835, 'location': {'lat': 39.92076, 'lng': -111.71802}}, {'name': 'Santiam Jct.', 'triplet': '733:OR:SNTL', 'elevation': 3740, 'location': {'lat': 44.43503, 'lng': -121.94502}}, {'name': 'Sargents Mesa', 'triplet': '1128:CO:SNTL', 'elevation': 11499, 'location': {'lat': 38.2856, 'lng': -106.37085}}, {'name': 'Sasse Ridge', 'triplet': '734:WA:SNTL', 'elevation': 4340, 'location': {'lat': 47.38485, 'lng': -121.06323}}, {'name': 'Satus Pass', 'triplet': '1231:WA:SNTL', 'elevation': 3960, 'location': {'lat': 45.98797, 'lng': -120.67734}}, {'name': 'Savage Pass', 'triplet': '735:ID:SNTL', 'elevation': 6190, 'location': {'lat': 46.46633, 'lng': -114.63333}}, {'name': 'Sawmill Ridge', 'triplet': '1068:WA:SNTL', 'elevation': 4640, 'location': {'lat': 47.15992, 'lng': -121.42172}}, {'name': 'Sawtooth', 'triplet': '1251:CO:SNTL', 'elevation': 9676, 'location': {'lat': 40.13632, 'lng': -105.58486}}, {'name': 'Schneider Meadows', 'triplet': '736:OR:SNTL', 'elevation': 5400, 'location': {'lat': 45.00107, 'lng': -117.16522}}, {'name': 'Schofield Pass', 'triplet': '737:CO:SNTL', 'elevation': 10653, 'location': {'lat': 39.01467, 'lng': -107.04933}}, {'name': 'Schwartz Lake', 'triplet': '915:ID:SNTL', 'elevation': 8630, 'location': {'lat': 44.84618, 'lng': -113.83732}}, {'name': 'Schweitzer Basin', 'triplet': '738:ID:SNTL', 'elevation': 6090, 'location': {'lat': 48.37428, 'lng': -116.63917}}, {'name': 'Scotch Creek', 'triplet': '739:CO:SNTL', 'elevation': 9195, 'location': {'lat': 37.64562, 'lng': -108.00833}}, {'name': 'Secesh Summit', 'triplet': '740:ID:SNTL', 'elevation': 6540, 'location': {'lat': 45.18848, 'lng': -115.97152}}, {'name': 'Sedgwick Peak', 'triplet': '741:ID:SNTL', 'elevation': 7850, 'location': {'lat': 42.52497, 'lng': -111.95635}}, {'name': 'Seeley Creek', 'triplet': '742:UT:SNTL', 'elevation': 9904, 'location': {'lat': 39.31042, 'lng': -111.43297}}, {'name': 'Seine Creek', 'triplet': '743:OR:SNTL', 'elevation': 2060, 'location': {'lat': 45.52688, 'lng': -123.29857}}, {'name': 'Senorita Divide #2', 'triplet': '744:NM:SNTL', 'elevation': 8569, 'location': {'lat': 36.00152, 'lng': -106.83408}}, {'name': 'Sentinel Butte', 'triplet': '1043:WA:SNTL', 'elevation': 4680, 'location': {'lat': 48.86133, 'lng': -118.39843}}, {'name': 'Sevenmile Marsh', 'triplet': '745:OR:SNTL', 'elevation': 5700, 'location': {'lat': 42.69825, 'lng': -122.14165}}, {'name': 'Seventysix Creek', 'triplet': '746:NV:SNTL', 'elevation': 7350, 'location': {'lat': 41.73732, 'lng': -115.47215}}, {'name': 'Shanghi Summit', 'triplet': '747:ID:SNTL', 'elevation': 4600, 'location': {'lat': 46.56603, 'lng': -115.74216}}, {'name': 'Sharkstooth', 'triplet': '1060:CO:SNTL', 'elevation': 10747, 'location': {'lat': 37.50356, 'lng': -108.11405}}, {'name': 'Sheep Canyon', 'triplet': '748:WA:SNTL', 'elevation': 3990, 'location': {'lat': 46.19325, 'lng': -122.25393}}, {'name': 'Sheep Mtn.', 'triplet': '749:ID:SNTL', 'elevation': 6650, 'location': {'lat': 43.2103, 'lng': -111.68792}}, {'name': 'Sheldon', 'triplet': '750:NV:SNTL', 'elevation': 5865, 'location': {'lat': 41.90435, 'lng': -119.44464}}, {'name': 'Shell Creek', 'triplet': '751:WY:SNTL', 'elevation': 9580, 'location': {'lat': 44.50012, 'lng': -107.42947}}, {'name': 'Sherwin', 'triplet': '752:ID:SNTL', 'elevation': 3200, 'location': {'lat': 46.95028, 'lng': -116.33972}}, {'name': 'Short Creek', 'triplet': '753:MT:SNTL', 'elevation': 7000, 'location': {'lat': 44.97572, 'lng': -111.95215}}, {'name': 'Shower Falls', 'triplet': '754:MT:SNTL', 'elevation': 8100, 'location': {'lat': 45.40125, 'lng': -110.95758}}, {'name': 'Shuree', 'triplet': '1169:NM:SNTL', 'elevation': 10092, 'location': {'lat': 36.78765, 'lng': -105.2392}}, {'name': 'Sierra Blanca', 'triplet': '1034:NM:SNTL', 'elevation': 10268, 'location': {'lat': 33.40682, 'lng': -105.79467}}, {'name': 'Signal Peak', 'triplet': '755:NM:SNTL', 'elevation': 8405, 'location': {'lat': 32.92342, 'lng': -108.14546}}, {'name': 'Silver Creek', 'triplet': '756:OR:SNTL', 'elevation': 5740, 'location': {'lat': 42.95615, 'lng': -121.18123}}, {'name': 'Silver Creek Divide', 'triplet': '757:NM:SNTL', 'elevation': 9096, 'location': {'lat': 33.3696, 'lng': -108.70711}}, {'name': 'Silver Creek Nv', 'triplet': '1205:NV:SNTL', 'elevation': 8200, 'location': {'lat': 39.23305, 'lng': -114.2429}}, {'name': 'Silvies', 'triplet': '759:OR:SNTL', 'elevation': 6990, 'location': {'lat': 42.75333, 'lng': -118.68785}}, {'name': 'Skalkaho Summit', 'triplet': '760:MT:SNTL', 'elevation': 7250, 'location': {'lat': 46.24212, 'lng': -113.7725}}, {'name': 'Skate Creek', 'triplet': '1257:WA:SNTL', 'elevation': 3770, 'location': {'lat': 46.64336, 'lng': -121.83044}}, {'name': 'Skookum Creek', 'triplet': '912:WA:SNTL', 'elevation': 3310, 'location': {'lat': 47.68433, 'lng': -121.61007}}, {'name': 'Slagamelt Lakes', 'triplet': '1286:MT:SNTL', 'elevation': 8620, 'location': {'lat': 45.36526, 'lng': -113.71834}}, {'name': 'Sleeping Woman', 'triplet': '783:MT:SNTL', 'elevation': 6150, 'location': {'lat': 47.17902, 'lng': -114.33368}}, {'name': 'Slug Creek Divide', 'triplet': '761:ID:SNTL', 'elevation': 7225, 'location': {'lat': 42.56248, 'lng': -111.29797}}, {'name': 'Slumgullion', 'triplet': '762:CO:SNTL', 'elevation': 11560, 'location': {'lat': 37.99076, 'lng': -107.20392}}, {'name': 'Smiley Mountain', 'triplet': '926:ID:SNTL', 'elevation': 9520, 'location': {'lat': 43.72718, 'lng': -113.83402}}, {'name': 'Smith  Morehouse', 'triplet': '763:UT:SNTL', 'elevation': 7631, 'location': {'lat': 40.78931, 'lng': -111.09192}}, {'name': 'Smith Ridge', 'triplet': '1167:OR:SNTL', 'elevation': 3270, 'location': {'lat': 44.30325, 'lng': -122.04053}}, {'name': 'Snake River Station', 'triplet': '764:WY:SNTL', 'elevation': 6920, 'location': {'lat': 44.13361, 'lng': -110.66917}}, {'name': 'Snider Basin', 'triplet': '765:WY:SNTL', 'elevation': 8060, 'location': {'lat': 42.4949, 'lng': -110.53203}}, {'name': 'Snow Mountain', 'triplet': '767:OR:SNTL', 'elevation': 6230, 'location': {'lat': 43.94885, 'lng': -119.54013}}, {'name': 'Snowbird', 'triplet': '766:UT:SNTL', 'elevation': 9177, 'location': {'lat': 40.56914, 'lng': -111.65852}}, {'name': 'Snowslide Canyon', 'triplet': '927:AZ:SNTL', 'elevation': 9744, 'location': {'lat': 35.34179, 'lng': -111.65084}}, {'name': 'Snowstorm Mtn', 'triplet': '1208:NV:SNTL', 'elevation': 7403, 'location': {'lat': 41.33981, 'lng': -116.98044}}, {'name': 'Soldier Park', 'triplet': '1132:WY:SNTL', 'elevation': 8720, 'location': {'lat': 44.34847, 'lng': -107.0136}}, {'name': 'Soldier R.S.', 'triplet': '769:ID:SNTL', 'elevation': 5740, 'location': {'lat': 43.48407, 'lng': -114.82692}}, {'name': 'Somsen Ranch', 'triplet': '770:ID:SNTL', 'elevation': 6800, 'location': {'lat': 42.95275, 'lng': -111.35933}}, {'name': 'Sonora Pass', 'triplet': '771:CA:SNTL', 'elevation': 8770, 'location': {'lat': 38.31021, 'lng': -119.6003}}, {'name': 'Sourdough Gulch', 'triplet': '985:WA:SNTL', 'elevation': 4000, 'location': {'lat': 46.23718, 'lng': -117.39438}}, {'name': 'South Brush Creek', 'triplet': '772:WY:SNTL', 'elevation': 8495, 'location': {'lat': 41.3295, 'lng': -106.5025}}, {'name': 'South Colony', 'triplet': '773:CO:SNTL', 'elevation': 10868, 'location': {'lat': 37.96647, 'lng': -105.53671}}, {'name': 'South Fork Bull Run', 'triplet': '925:OR:SNTL', 'elevation': 2690, 'location': {'lat': 45.44575, 'lng': -122.03125}}, {'name': 'South Mtn.', 'triplet': '774:ID:SNTL', 'elevation': 6500, 'location': {'lat': 42.76478, 'lng': -116.90037}}, {'name': 'South Pass', 'triplet': '775:WY:SNTL', 'elevation': 9040, 'location': {'lat': 42.57317, 'lng': -108.84325}}, {'name': 'Spencer Meadow', 'triplet': '776:WA:SNTL', 'elevation': 3400, 'location': {'lat': 46.1795, 'lng': -121.92661}}, {'name': 'Spirit Lake', 'triplet': '777:WA:SNTL', 'elevation': 3520, 'location': {'lat': 46.26113, 'lng': -122.1772}}, {'name': 'Spirit Lk', 'triplet': '1117:UT:SNTL', 'elevation': 10235, 'location': {'lat': 40.83868, 'lng': -110.00527}}, {'name': 'Spratt Creek', 'triplet': '778:CA:SNTL', 'elevation': 6063, 'location': {'lat': 38.66627, 'lng': -119.81741}}, {'name': 'Spring Creek', 'triplet': '2044:AK:SNTL', 'elevation': 580, 'location': {'lat': 61.65722, 'lng': -149.12853}}, {'name': 'Spring Creek Divide', 'triplet': '779:WY:SNTL', 'elevation': 9000, 'location': {'lat': 42.52516, 'lng': -110.66148}}, {'name': 'Spruce Springs', 'triplet': '984:WA:SNTL', 'elevation': 5700, 'location': {'lat': 46.18287, 'lng': -117.54155}}, {'name': 'Spud Mountain', 'triplet': '780:CO:SNTL', 'elevation': 10674, 'location': {'lat': 37.69883, 'lng': -107.77841}}, {'name': 'Spur Park', 'triplet': '781:MT:SNTL', 'elevation': 8100, 'location': {'lat': 46.77962, 'lng': -110.62165}}, {'name': 'Squaw Flat', 'triplet': '782:ID:SNTL', 'elevation': 6240, 'location': {'lat': 44.77091, 'lng': -116.24805}}, {'name': 'St. Lawrence Alt', 'triplet': '786:WY:SNTL', 'elevation': 8620, 'location': {'lat': 43.03313, 'lng': -109.17025}}, {'name': 'Stag Mountain', 'triplet': '1203:NV:SNTL', 'elevation': 7640, 'location': {'lat': 41.408, 'lng': -115.4464}}, {'name': 'Stahl Peak', 'triplet': '787:MT:SNTL', 'elevation': 6030, 'location': {'lat': 48.90902, 'lng': -114.86298}}, {'name': 'Stampede Pass', 'triplet': '788:WA:SNTL', 'elevation': 3850, 'location': {'lat': 47.27427, 'lng': -121.34162}}, {'name': 'Starr Ridge', 'triplet': '789:OR:SNTL', 'elevation': 5250, 'location': {'lat': 44.26423, 'lng': -119.02162}}, {'name': 'State Line', 'triplet': '1258:CA:SNTL', 'elevation': 5680, 'location': {'lat': 41.98609, 'lng': -120.71574}}, {'name': 'Steel Creek Park', 'triplet': '790:UT:SNTL', 'elevation': 10158, 'location': {'lat': 40.90862, 'lng': -110.50462}}, {'name': 'Stevens Pass', 'triplet': '791:WA:SNTL', 'elevation': 3950, 'location': {'lat': 47.74607, 'lng': -121.09288}}, {'name': 'Stickney Mill', 'triplet': '792:ID:SNTL', 'elevation': 7430, 'location': {'lat': 43.86117, 'lng': -114.20902}}, {'name': 'Stillwater Creek', 'triplet': '793:CO:SNTL', 'elevation': 8880, 'location': {'lat': 40.22532, 'lng': -105.9198}}, {'name': 'Strawberry', 'triplet': '794:OR:SNTL', 'elevation': 5770, 'location': {'lat': 42.12587, 'lng': -120.8361}}, {'name': 'Strawberry Divide', 'triplet': '795:UT:SNTL', 'elevation': 8123, 'location': {'lat': 40.16483, 'lng': -111.20665}}, {'name': 'Stringer Creek', 'triplet': '1009:MT:SNTL', 'elevation': 6550, 'location': {'lat': 46.9269, 'lng': -110.90198}}, {'name': 'Stryker Basin', 'triplet': '1311:MT:SNTL', 'elevation': 6155, 'location': {'lat': 48.6802, 'lng': -114.664}}, {'name': 'Stuart Mountain', 'triplet': '901:MT:SNTL', 'elevation': 7400, 'location': {'lat': 46.99523, 'lng': -113.92664}}, {'name': 'Stump Lakes', 'triplet': '797:CO:SNTL', 'elevation': 11248, 'location': {'lat': 37.47647, 'lng': -107.63348}}, {'name': 'Sucker Creek', 'triplet': '798:WY:SNTL', 'elevation': 8880, 'location': {'lat': 44.7225, 'lng': -107.40033}}, {'name': 'Sugarloaf Mtn', 'triplet': '1095:AK:SNTL', 'elevation': 550, 'location': {'lat': 61.081, 'lng': -146.2995}}, {'name': 'Summer Rim', 'triplet': '800:OR:SNTL', 'elevation': 7080, 'location': {'lat': 42.6957, 'lng': -120.80158}}, {'name': 'Summit Creek', 'triplet': '955:AK:SNTL', 'elevation': 1400, 'location': {'lat': 60.61713, 'lng': -149.53128}}, {'name': 'Summit Lake', 'triplet': '801:OR:SNTL', 'elevation': 5610, 'location': {'lat': 43.44907, 'lng': -122.13808}}, {'name': 'Summit Lk', 'triplet': '1194:NV:SNTL', 'elevation': 7615, 'location': {'lat': 41.48953, 'lng': -118.99663}}, {'name': 'Summit Meadow', 'triplet': '1052:CA:SNTL', 'elevation': 9313, 'location': {'lat': 38.39747, 'lng': -119.53522}}, {'name': 'Summit Ranch', 'triplet': '802:CO:SNTL', 'elevation': 9371, 'location': {'lat': 39.71803, 'lng': -106.1577}}, {'name': 'Sun Pass', 'triplet': '1078:OR:SNTL', 'elevation': 5400, 'location': {'lat': 42.78637, 'lng': -121.97715}}, {'name': 'Sunflower Flat', 'triplet': '1249:UT:SNTL', 'elevation': 10018, 'location': {'lat': 38.048, 'lng': -111.33981}}, {'name': 'Sunset', 'triplet': '803:ID:SNTL', 'elevation': 5540, 'location': {'lat': 47.55545, 'lng': -115.82422}}, {'name': 'Surprise Lakes', 'triplet': '804:WA:SNTL', 'elevation': 4290, 'location': {'lat': 46.09497, 'lng': -121.76345}}, {'name': 'Susitna Valley High', 'triplet': '967:AK:SNTL', 'elevation': 375, 'location': {'lat': 62.13333, 'lng': -150.04167}}, {'name': 'Suu Ranch', 'triplet': '1248:UT:SNTL', 'elevation': 8050, 'location': {'lat': 37.59711, 'lng': -112.92949}}, {'name': 'Swamp Creek', 'triplet': '975:WA:SNTL', 'elevation': 3930, 'location': {'lat': 48.57142, 'lng': -120.78267}}, {'name': 'Swan Lake Mtn', 'triplet': '1077:OR:SNTL', 'elevation': 6830, 'location': {'lat': 42.41323, 'lng': -121.68002}}, {'name': 'Swede Peak', 'triplet': '805:ID:SNTL', 'elevation': 7640, 'location': {'lat': 43.626, 'lng': -113.96887}}, {'name': 'Swift Creek', 'triplet': '1012:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.1638, 'lng': -122.18402}}, {'name': 'Sylvan Lake', 'triplet': '806:WY:SNTL', 'elevation': 8420, 'location': {'lat': 44.47764, 'lng': -110.15651}}, {'name': 'Sylvan Road', 'triplet': '807:WY:SNTL', 'elevation': 7120, 'location': {'lat': 44.47825, 'lng': -110.03808}}, {'name': 'Tahoe City Cross', 'triplet': '809:CA:SNTL', 'elevation': 6797, 'location': {'lat': 39.17162, 'lng': -120.15362}}, {'name': 'Takka Wiiya', 'triplet': '1247:UT:SNTL', 'elevation': 9122, 'location': {'lat': 39.74104, 'lng': -113.98262}}, {'name': 'Taos Powderhorn', 'triplet': '1168:NM:SNTL', 'elevation': 11045, 'location': {'lat': 36.58195, 'lng': -105.45617}}, {'name': 'Taos Pueblo', 'triplet': '1307:NM:SNTL', 'elevation': 11020, 'location': {'lat': 36.54099, 'lng': -105.35944}}, {'name': 'Taylor Butte', 'triplet': '810:OR:SNTL', 'elevation': 5030, 'location': {'lat': 42.69108, 'lng': -121.42592}}, {'name': 'Taylor Canyon', 'triplet': '811:NV:SNTL', 'elevation': 6325, 'location': {'lat': 41.2287, 'lng': -116.0293}}, {'name': 'Taylor Green', 'triplet': '812:OR:SNTL', 'elevation': 5740, 'location': {'lat': 45.07707, 'lng': -117.55067}}, {'name': 'Telaquana Lake', 'triplet': '1266:AK:SNTL', 'elevation': 1275, 'location': {'lat': 60.98243, 'lng': -153.91772}}, {'name': 'Temple Fork', 'triplet': '1013:UT:SNTL', 'elevation': 7406, 'location': {'lat': 41.793, 'lng': -111.54605}}, {'name': 'Tent Mtn Lower', 'triplet': '1202:NV:SNTL', 'elevation': 7100, 'location': {'lat': 40.97852, 'lng': -115.17215}}, {'name': 'Tepee Creek', 'triplet': '813:MT:SNTL', 'elevation': 8000, 'location': {'lat': 44.78562, 'lng': -111.71}}, {'name': 'Teuchet Creek', 'triplet': '951:AK:SNTL', 'elevation': 1640, 'location': {'lat': 64.94583, 'lng': -145.51667}}, {'name': 'Thaynes Canyon', 'triplet': '814:UT:SNTL', 'elevation': 9230, 'location': {'lat': 40.6235, 'lng': -111.53322}}, {'name': 'Thistle Flat', 'triplet': '1226:UT:SNTL', 'elevation': 8787, 'location': {'lat': 39.23803, 'lng': -111.51998}}, {'name': 'Three Creeks Meadow', 'triplet': '815:OR:SNTL', 'elevation': 5690, 'location': {'lat': 44.14425, 'lng': -121.64095}}, {'name': 'Thumb Divide', 'triplet': '816:WY:SNTL', 'elevation': 7980, 'location': {'lat': 44.36917, 'lng': -110.57717}}, {'name': 'Thunder Basin', 'triplet': '817:WA:SNTL', 'elevation': 4320, 'location': {'lat': 48.52753, 'lng': -120.9895}}, {'name': 'Tie Creek', 'triplet': '818:WY:SNTL', 'elevation': 6870, 'location': {'lat': 44.81243, 'lng': -107.41017}}, {'name': 'Timber Creek', 'triplet': '819:WY:SNTL', 'elevation': 7950, 'location': {'lat': 44.0274, 'lng': -109.17879}}, {'name': 'Timberline', 'triplet': '1097:UT:SNTL', 'elevation': 8736, 'location': {'lat': 39.67712, 'lng': -110.43395}}, {'name': 'Timpanogos Divide', 'triplet': '820:UT:SNTL', 'elevation': 8140, 'location': {'lat': 40.42817, 'lng': -111.61633}}, {'name': 'Tinkham Creek', 'triplet': '899:WA:SNTL', 'elevation': 2990, 'location': {'lat': 47.33198, 'lng': -121.46975}}, {'name': 'Tipton', 'triplet': '821:OR:SNTL', 'elevation': 5150, 'location': {'lat': 44.65567, 'lng': -118.42617}}, {'name': 'Tizer Basin', 'triplet': '893:MT:SNTL', 'elevation': 6880, 'location': {'lat': 46.34937, 'lng': -111.85308}}, {'name': 'Toe Jam', 'triplet': '1136:NV:SNTL', 'elevation': 7690, 'location': {'lat': 41.3187, 'lng': -116.3408}}, {'name': 'Togwotee Pass', 'triplet': '822:WY:SNTL', 'elevation': 9580, 'location': {'lat': 43.74902, 'lng': -110.0578}}, {'name': 'Tok', 'triplet': '2080:AK:SNTL', 'elevation': 1630, 'location': {'lat': 63.3532, 'lng': -142.98164}}, {'name': 'Toketee Airstrip', 'triplet': '1044:OR:SNTL', 'elevation': 3240, 'location': {'lat': 43.22718, 'lng': -122.42537}}, {'name': 'Tokositna Valley', 'triplet': '1089:AK:SNTL', 'elevation': 850, 'location': {'lat': 62.63, 'lng': -150.77617}}, {'name': 'Tolby', 'triplet': '934:NM:SNTL', 'elevation': 10220, 'location': {'lat': 36.47498, 'lng': -105.19534}}, {'name': 'Tony Grove Lake', 'triplet': '823:UT:SNTL', 'elevation': 8474, 'location': {'lat': 41.89833, 'lng': -111.62957}}, {'name': 'Tony Grove RS', 'triplet': '1113:UT:SNTL', 'elevation': 6332, 'location': {'lat': 41.88573, 'lng': -111.56918}}, {'name': 'Touchet', 'triplet': '824:WA:SNTL', 'elevation': 5530, 'location': {'lat': 46.11868, 'lng': -117.8505}}, {'name': 'Tower', 'triplet': '825:CO:SNTL', 'elevation': 10620, 'location': {'lat': 40.5374, 'lng': -106.67655}}, {'name': 'Townsend Creek', 'triplet': '826:WY:SNTL', 'elevation': 8700, 'location': {'lat': 42.69525, 'lng': -108.89572}}, {'name': 'Trapper Lake', 'triplet': '827:CO:SNTL', 'elevation': 9759, 'location': {'lat': 39.99881, 'lng': -107.23618}}, {'name': 'Tres Ritos', 'triplet': '1083:NM:SNTL', 'elevation': 8755, 'location': {'lat': 36.1279, 'lng': -105.52706}}, {'name': 'Trial Lake', 'triplet': '828:UT:SNTL', 'elevation': 9992, 'location': {'lat': 40.678, 'lng': -110.94873}}, {'name': 'Trinchera', 'triplet': '829:CO:SNTL', 'elevation': 10922, 'location': {'lat': 37.35296, 'lng': -105.23259}}, {'name': 'Trinity', 'triplet': '1171:WA:SNTL', 'elevation': 2930, 'location': {'lat': 48.0747, 'lng': -120.8493}}, {'name': 'Trinity Mtn.', 'triplet': '830:ID:SNTL', 'elevation': 7770, 'location': {'lat': 43.62903, 'lng': -115.43818}}, {'name': 'Triple Peak', 'triplet': '831:WY:SNTL', 'elevation': 8500, 'location': {'lat': 42.76393, 'lng': -110.5914}}, {'name': 'Trough', 'triplet': '832:WA:SNTL', 'elevation': 5480, 'location': {'lat': 47.23328, 'lng': -120.29412}}, {'name': 'Trout Creek', 'triplet': '833:UT:SNTL', 'elevation': 9518, 'location': {'lat': 40.739, 'lng': -109.6728}}, {'name': 'Truckee #2', 'triplet': '834:CA:SNTL', 'elevation': 6509, 'location': {'lat': 39.30087, 'lng': -120.18407}}, {'name': 'Turnagain Pass', 'triplet': '954:AK:SNTL', 'elevation': 1880, 'location': {'lat': 60.78043, 'lng': -149.18325}}, {'name': 'Twelvemile Creek', 'triplet': '835:MT:SNTL', 'elevation': 5600, 'location': {'lat': 46.14287, 'lng': -114.44755}}, {'name': 'Twin Lakes', 'triplet': '836:MT:SNTL', 'elevation': 6400, 'location': {'lat': 46.1438, 'lng': -114.5056}}, {'name': 'Two Ocean Plateau', 'triplet': '837:WY:SNTL', 'elevation': 9240, 'location': {'lat': 44.15178, 'lng': -110.22122}}, {'name': 'University Camp', 'triplet': '838:CO:SNTL', 'elevation': 10360, 'location': {'lat': 40.03307, 'lng': -105.57562}}, {'name': 'Upper Chena', 'triplet': '952:AK:SNTL', 'elevation': 2850, 'location': {'lat': 65.1, 'lng': -144.93317}}, {'name': 'Upper Joes Valley', 'triplet': '1227:UT:SNTL', 'elevation': 8596, 'location': {'lat': 39.4155, 'lng': -111.2491}}, {'name': 'Upper Nome Creek', 'triplet': '1090:AK:SNTL', 'elevation': 2520, 'location': {'lat': 65.3671, 'lng': -146.592}}, {'name': 'Upper Rio Grande', 'triplet': '839:CO:SNTL', 'elevation': 9379, 'location': {'lat': 37.72172, 'lng': -107.25971}}, {'name': 'Upper San Juan', 'triplet': '840:CO:SNTL', 'elevation': 10140, 'location': {'lat': 37.48563, 'lng': -106.83528}}, {'name': 'Upper Taylor', 'triplet': '1141:CO:SNTL', 'elevation': 10717, 'location': {'lat': 38.99071, 'lng': -106.74504}}, {'name': 'Upper Tsaina River', 'triplet': '1055:AK:SNTL', 'elevation': 1750, 'location': {'lat': 61.19112, 'lng': -145.64807}}, {'name': 'Upper Wheeler', 'triplet': '841:WA:SNTL', 'elevation': 4330, 'location': {'lat': 47.28734, 'lng': -120.37015}}, {'name': 'Usu Doc Daniel', 'triplet': '1098:UT:SNTL', 'elevation': 8270, 'location': {'lat': 41.86425, 'lng': -111.50603}}, {'name': 'Ute Creek', 'triplet': '1005:CO:SNTL', 'elevation': 10734, 'location': {'lat': 37.6148, 'lng': -105.37322}}, {'name': 'Vacarro Springs', 'triplet': '1137:NV:SNTL', 'elevation': 7890, 'location': {'lat': 39.4495, 'lng': -115.9834}}, {'name': 'Vacas Locas', 'triplet': '1017:NM:SNTL', 'elevation': 9364, 'location': {'lat': 36.02653, 'lng': -106.81361}}, {'name': 'Vail Mountain', 'triplet': '842:CO:SNTL', 'elevation': 10310, 'location': {'lat': 39.61765, 'lng': -106.38019}}, {'name': 'Vallecito', 'triplet': '843:CO:SNTL', 'elevation': 10782, 'location': {'lat': 37.48524, 'lng': -107.50748}}, {'name': 'Van Wyck', 'triplet': '979:ID:SNTL', 'elevation': 4920, 'location': {'lat': 44.37665, 'lng': -116.3366}}, {'name': 'Vernon Creek', 'triplet': '844:UT:SNTL', 'elevation': 7401, 'location': {'lat': 39.93667, 'lng': -112.41478}}, {'name': 'Vienna Mine', 'triplet': '845:ID:SNTL', 'elevation': 8960, 'location': {'lat': 43.79942, 'lng': -114.85273}}, {'name': 'Virginia Lakes Ridge', 'triplet': '846:CA:SNTL', 'elevation': 9400, 'location': {'lat': 38.07298, 'lng': -119.23433}}, {'name': 'Wager Gulch', 'triplet': '1188:CO:SNTL', 'elevation': 11132, 'location': {'lat': 37.88248, 'lng': -107.36428}}, {'name': 'Waldron', 'triplet': '847:MT:SNTL', 'elevation': 5600, 'location': {'lat': 47.91998, 'lng': -112.79087}}, {'name': 'Ward Creek #3', 'triplet': '848:CA:SNTL', 'elevation': 6745, 'location': {'lat': 39.13545, 'lng': -120.21865}}, {'name': 'Ward Mountain', 'triplet': '849:NV:SNTL', 'elevation': 9163, 'location': {'lat': 39.13242, 'lng': -114.95575}}, {'name': 'Warm Springs', 'triplet': '850:MT:SNTL', 'elevation': 7800, 'location': {'lat': 46.27368, 'lng': -113.164}}, {'name': 'Waterhole', 'triplet': '974:WA:SNTL', 'elevation': 5010, 'location': {'lat': 47.94485, 'lng': -123.42594}}, {'name': 'Webber Springs', 'triplet': '852:WY:SNTL', 'elevation': 9260, 'location': {'lat': 41.1591, 'lng': -106.92809}}, {'name': 'Webster Flat', 'triplet': '853:UT:SNTL', 'elevation': 9203, 'location': {'lat': 37.575, 'lng': -112.90155}}, {'name': 'Wells Creek', 'triplet': '909:WA:SNTL', 'elevation': 4030, 'location': {'lat': 48.8661, 'lng': -121.78976}}, {'name': 'Weminuche Creek', 'triplet': '1160:CO:SNTL', 'elevation': 10749, 'location': {'lat': 37.51968, 'lng': -107.32139}}, {'name': 'Wesner Springs', 'triplet': '854:NM:SNTL', 'elevation': 11151, 'location': {'lat': 35.77584, 'lng': -105.54337}}, {'name': 'West Branch', 'triplet': '855:ID:SNTL', 'elevation': 5560, 'location': {'lat': 45.0722, 'lng': -116.45413}}, {'name': 'West Yellowstone', 'triplet': '924:MT:SNTL', 'elevation': 6700, 'location': {'lat': 44.65866, 'lng': -111.09199}}, {'name': 'Wheeler Peak', 'triplet': '1147:NV:SNTL', 'elevation': 10060, 'location': {'lat': 39.00995, 'lng': -114.31021}}, {'name': 'Whiskey Ck', 'triplet': '857:CO:SNTL', 'elevation': 10290, 'location': {'lat': 37.21423, 'lng': -105.12262}}, {'name': 'Whiskey Creek', 'triplet': '858:MT:SNTL', 'elevation': 6800, 'location': {'lat': 44.61088, 'lng': -111.14998}}, {'name': 'Whiskey Park', 'triplet': '859:WY:SNTL', 'elevation': 9020, 'location': {'lat': 41.00368, 'lng': -106.90795}}, {'name': 'White Elephant', 'triplet': '860:ID:SNTL', 'elevation': 7710, 'location': {'lat': 44.53267, 'lng': -111.41085}}, {'name': 'White Horse Lake', 'triplet': '861:AZ:SNTL', 'elevation': 7203, 'location': {'lat': 35.14189, 'lng': -112.14966}}, {'name': 'White Mill', 'triplet': '862:MT:SNTL', 'elevation': 8700, 'location': {'lat': 45.04575, 'lng': -109.90987}}, {'name': 'White Pass E.S.', 'triplet': '863:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.64142, 'lng': -121.38153}}, {'name': 'White River #1', 'triplet': '864:UT:SNTL', 'elevation': 8641, 'location': {'lat': 39.9645, 'lng': -110.98845}}, {'name': 'White River Nv', 'triplet': '1213:NV:SNTL', 'elevation': 7367, 'location': {'lat': 38.94557, 'lng': -115.37922}}, {'name': 'Widtsoe #3', 'triplet': '865:UT:SNTL', 'elevation': 9640, 'location': {'lat': 37.83633, 'lng': -111.88163}}, {'name': 'Wilbur Bench', 'triplet': '543:UT:SNTL', 'elevation': 9171, 'location': {'lat': 39.89166, 'lng': -110.74604}}, {'name': 'Wild Basin', 'triplet': '1042:CO:SNTL', 'elevation': 9439, 'location': {'lat': 40.201, 'lng': -105.6025}}, {'name': 'Wildcat', 'triplet': '866:AZ:SNTL', 'elevation': 7868, 'location': {'lat': 33.74347, 'lng': -109.48078}}, {'name': 'Wildhorse Divide', 'triplet': '867:ID:SNTL', 'elevation': 6490, 'location': {'lat': 42.75743, 'lng': -112.47783}}, {'name': 'Willow Creek', 'triplet': '868:WY:SNTL', 'elevation': 8080, 'location': {'lat': 42.81513, 'lng': -110.83515}}, {'name': 'Willow Creek Pass', 'triplet': '869:CO:SNTL', 'elevation': 9523, 'location': {'lat': 40.34734, 'lng': -106.0952}}, {'name': 'Willow Park', 'triplet': '870:CO:SNTL', 'elevation': 10732, 'location': {'lat': 40.43397, 'lng': -105.73588}}, {'name': 'Wilson Creek', 'triplet': '871:ID:SNTL', 'elevation': 7120, 'location': {'lat': 42.01257, 'lng': -115.00278}}, {'name': 'Windy Peak', 'triplet': '872:WY:SNTL', 'elevation': 7915, 'location': {'lat': 42.27991, 'lng': -105.57782}}, {'name': 'Wolf Creek', 'triplet': '873:OR:SNTL', 'elevation': 5630, 'location': {'lat': 45.06703, 'lng': -118.15192}}, {'name': 'Wolf Creek Peak', 'triplet': '1164:UT:SNTL', 'elevation': 9796, 'location': {'lat': 40.47733, 'lng': -111.04469}}, {'name': 'Wolf Creek Summit', 'triplet': '874:CO:SNTL', 'elevation': 10957, 'location': {'lat': 37.47903, 'lng': -106.80234}}, {'name': 'Wolverine', 'triplet': '875:WY:SNTL', 'elevation': 7650, 'location': {'lat': 44.80417, 'lng': -109.657}}, {'name': 'Wood Creek', 'triplet': '876:MT:SNTL', 'elevation': 5960, 'location': {'lat': 47.44847, 'lng': -112.81428}}, {'name': 'Workman Creek', 'triplet': '877:AZ:SNTL', 'elevation': 7032, 'location': {'lat': 33.81259, 'lng': -110.91852}}, {'name': 'Wrigley Creek', 'triplet': '1228:UT:SNTL', 'elevation': 9327, 'location': {'lat': 39.13233, 'lng': -111.35685}}, {'name': 'Yankee Reservoir', 'triplet': '1197:UT:SNTL', 'elevation': 8692, 'location': {'lat': 37.74797, 'lng': -112.77495}}, {'name': 'Younts Peak', 'triplet': '878:WY:SNTL', 'elevation': 8350, 'location': {'lat': 43.93225, 'lng': -109.81775}}, {'name': 'Zirkel', 'triplet': '1033:CO:SNTL', 'elevation': 9338, 'location': {'lat': 40.79492, 'lng': -106.59544}}]\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/bBiB8GKwgT3o/data_snotel_station_only.py\", line 75, in <module>\n    for index, row in station_locations.iterrows():\nAttributeError: 'list' object has no attribute 'iterrows'\n",
  "history_begin_time" : 1703486338969,
  "history_end_time" : 1703486339870,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "dHRsHXjYuOHu",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\nstation_locations = read_json_file(f'{working_dir}/snotelStations.json')\nprint(station_locations)\n\nresult_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_mapping.iterrows():\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\n    \n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\n[{'name': 'Adin Mtn', 'triplet': '301:CA:SNTL', 'elevation': 6190, 'location': {'lat': 41.23583, 'lng': -120.79192}}, {'name': 'Agua Canyon', 'triplet': '907:UT:SNTL', 'elevation': 8900, 'location': {'lat': 37.52217, 'lng': -112.27118}}, {'name': 'Albro Lake', 'triplet': '916:MT:SNTL', 'elevation': 8300, 'location': {'lat': 45.59723, 'lng': -111.95902}}, {'name': 'Alexander Lake', 'triplet': '1267:AK:SNTL', 'elevation': 160, 'location': {'lat': 61.74967, 'lng': -150.88967}}, {'name': 'Alpine Meadows', 'triplet': '908:WA:SNTL', 'elevation': 3500, 'location': {'lat': 47.77957, 'lng': -121.69847}}, {'name': 'American Creek', 'triplet': '1189:AK:SNTL', 'elevation': 1050, 'location': {'lat': 64.78969, 'lng': -141.23376}}, {'name': 'Anchor River Divide', 'triplet': '1062:AK:SNTL', 'elevation': 1653, 'location': {'lat': 59.85972, 'lng': -151.315}}, {'name': 'Anchorage Hillside', 'triplet': '1070:AK:SNTL', 'elevation': 2080, 'location': {'lat': 61.11483, 'lng': -149.66683}}, {'name': 'Aneroid Lake #2', 'triplet': '302:OR:SNTL', 'elevation': 7400, 'location': {'lat': 45.21328, 'lng': -117.19258}}, {'name': 'Aniak', 'triplet': '2065:AK:SNTL', 'elevation': 80, 'location': {'lat': 61.58337, 'lng': -159.57708}}, {'name': 'Annie Springs', 'triplet': '1000:OR:SNTL', 'elevation': 6010, 'location': {'lat': 42.87007, 'lng': -122.16518}}, {'name': 'Apishapa', 'triplet': '303:CO:SNTL', 'elevation': 10027, 'location': {'lat': 37.33067, 'lng': -105.06766}}, {'name': 'Arapaho Ridge', 'triplet': '1030:CO:SNTL', 'elevation': 10976, 'location': {'lat': 40.35098, 'lng': -106.38141}}, {'name': 'Arbuckle Mtn', 'triplet': '304:OR:SNTL', 'elevation': 5770, 'location': {'lat': 45.19085, 'lng': -119.25392}}, {'name': 'Atigun Pass', 'triplet': '957:AK:SNTL', 'elevation': 4800, 'location': {'lat': 68.12983, 'lng': -149.47817}}, {'name': 'Atlanta Summit', 'triplet': '306:ID:SNTL', 'elevation': 7580, 'location': {'lat': 43.7569, 'lng': -115.23907}}, {'name': 'Atwater', 'triplet': '1308:UT:SNTL', 'elevation': 8753, 'location': {'lat': 40.59124, 'lng': -111.63775}}, {'name': 'Badger Pass', 'triplet': '307:MT:SNTL', 'elevation': 6900, 'location': {'lat': 48.13088, 'lng': -113.02317}}, {'name': 'Baker Butte', 'triplet': '308:AZ:SNTL', 'elevation': 7363, 'location': {'lat': 34.45654, 'lng': -111.40651}}, {'name': 'Baker Butte Smt', 'triplet': '1140:AZ:SNTL', 'elevation': 7752, 'location': {'lat': 34.45552, 'lng': -111.38262}}, {'name': 'Bald Mtn.', 'triplet': '309:WY:SNTL', 'elevation': 9380, 'location': {'lat': 44.8007, 'lng': -107.84442}}, {'name': 'Baldy', 'triplet': '310:AZ:SNTL', 'elevation': 9221, 'location': {'lat': 33.97845, 'lng': -109.50357}}, {'name': 'Banfield Mountain', 'triplet': '311:MT:SNTL', 'elevation': 5600, 'location': {'lat': 48.5712, 'lng': -115.44573}}, {'name': 'Banner Summit', 'triplet': '312:ID:SNTL', 'elevation': 7040, 'location': {'lat': 44.30342, 'lng': -115.23447}}, {'name': 'Bar M', 'triplet': '1212:AZ:SNTL', 'elevation': 6397, 'location': {'lat': 34.86142, 'lng': -111.60497}}, {'name': 'Barker Lakes', 'triplet': '313:MT:SNTL', 'elevation': 8250, 'location': {'lat': 46.09713, 'lng': -113.13038}}, {'name': 'Base Camp', 'triplet': '314:WY:SNTL', 'elevation': 7060, 'location': {'lat': 43.94019, 'lng': -110.44544}}, {'name': 'Basin Creek', 'triplet': '315:MT:SNTL', 'elevation': 7180, 'location': {'lat': 45.79737, 'lng': -112.52047}}, {'name': 'Bassoo Peak', 'triplet': '1190:MT:SNTL', 'elevation': 5150, 'location': {'lat': 47.85562, 'lng': -114.75841}}, {'name': 'Bateman', 'triplet': '316:NM:SNTL', 'elevation': 9249, 'location': {'lat': 36.51174, 'lng': -106.31543}}, {'name': 'Battle Mountain', 'triplet': '317:WY:SNTL', 'elevation': 7498, 'location': {'lat': 41.05402, 'lng': -107.26674}}, {'name': 'Beagle Springs', 'triplet': '318:MT:SNTL', 'elevation': 8850, 'location': {'lat': 44.47147, 'lng': -112.98191}}, {'name': 'Bear Basin', 'triplet': '319:ID:SNTL', 'elevation': 5350, 'location': {'lat': 44.95222, 'lng': -116.14293}}, {'name': 'Bear Canyon', 'triplet': '320:ID:SNTL', 'elevation': 7900, 'location': {'lat': 43.74367, 'lng': -113.93797}}, {'name': 'Bear Creek', 'triplet': '321:NV:SNTL', 'elevation': 8040, 'location': {'lat': 41.83384, 'lng': -115.45278}}, {'name': 'Bear Grass', 'triplet': '1166:OR:SNTL', 'elevation': 4720, 'location': {'lat': 44.3253, 'lng': -122.0938}}, {'name': 'Bear Lake', 'triplet': '322:CO:SNTL', 'elevation': 9522, 'location': {'lat': 40.31176, 'lng': -105.6467}}, {'name': 'Bear Mountain', 'triplet': '323:ID:SNTL', 'elevation': 5400, 'location': {'lat': 48.30577, 'lng': -116.07448}}, {'name': 'Bear River', 'triplet': '1061:CO:SNTL', 'elevation': 9112, 'location': {'lat': 40.06152, 'lng': -107.00948}}, {'name': 'Bear River RS', 'triplet': '992:UT:SNTL', 'elevation': 8777, 'location': {'lat': 40.8852, 'lng': -110.8277}}, {'name': 'Bear Saddle', 'triplet': '324:ID:SNTL', 'elevation': 6180, 'location': {'lat': 44.60533, 'lng': -116.98097}}, {'name': 'Bear Trap Meadow', 'triplet': '325:WY:SNTL', 'elevation': 8200, 'location': {'lat': 43.88743, 'lng': -107.06135}}, {'name': 'Beartooth Lake', 'triplet': '326:WY:SNTL', 'elevation': 9360, 'location': {'lat': 44.94307, 'lng': -109.56743}}, {'name': 'Beartown', 'triplet': '327:CO:SNTL', 'elevation': 11600, 'location': {'lat': 37.71433, 'lng': -107.5124}}, {'name': 'Beaver Ck Village', 'triplet': '1041:CO:SNTL', 'elevation': 8565, 'location': {'lat': 39.59871, 'lng': -106.51113}}, {'name': 'Beaver Creek', 'triplet': '328:MT:SNTL', 'elevation': 7850, 'location': {'lat': 44.94966, 'lng': -111.35852}}, {'name': 'Beaver Dams', 'triplet': '329:UT:SNTL', 'elevation': 7990, 'location': {'lat': 39.13683, 'lng': -111.55813}}, {'name': 'Beaver Divide', 'triplet': '330:UT:SNTL', 'elevation': 8280, 'location': {'lat': 40.61233, 'lng': -111.09782}}, {'name': 'Beaver Head', 'triplet': '902:AZ:SNTL', 'elevation': 8076, 'location': {'lat': 33.69115, 'lng': -109.21685}}, {'name': 'Beaver Pass', 'triplet': '990:WA:SNTL', 'elevation': 3630, 'location': {'lat': 48.8793, 'lng': -121.2555}}, {'name': 'Beaver Reservoir', 'triplet': '331:OR:SNTL', 'elevation': 5150, 'location': {'lat': 45.14532, 'lng': -118.219}}, {'name': 'Beaver Spring', 'triplet': '1143:AZ:SNTL', 'elevation': 9255, 'location': {'lat': 36.32671, 'lng': -109.05702}}, {'name': 'Ben Lomond Peak', 'triplet': '332:UT:SNTL', 'elevation': 7689, 'location': {'lat': 41.37603, 'lng': -111.94405}}, {'name': 'Ben Lomond Trail', 'triplet': '333:UT:SNTL', 'elevation': 5972, 'location': {'lat': 41.38291, 'lng': -111.92103}}, {'name': 'Berry Creek', 'triplet': '334:NV:SNTL', 'elevation': 9377, 'location': {'lat': 39.31917, 'lng': -114.62278}}, {'name': 'Berthoud Summit', 'triplet': '335:CO:SNTL', 'elevation': 11314, 'location': {'lat': 39.80364, 'lng': -105.77786}}, {'name': 'Bettles Field', 'triplet': '1182:AK:SNTL', 'elevation': 640, 'location': {'lat': 66.91667, 'lng': -151.53333}}, {'name': 'Bevans Cabin', 'triplet': '1214:UT:SNTL', 'elevation': 6520, 'location': {'lat': 40.46182, 'lng': -112.25233}}, {'name': 'Big Bend', 'triplet': '336:NV:SNTL', 'elevation': 6898, 'location': {'lat': 41.76168, 'lng': -115.6931}}, {'name': 'Big Creek Sum', 'triplet': '337:NV:SNTL', 'elevation': 8685, 'location': {'lat': 39.29148, 'lng': -117.11506}}, {'name': 'Big Creek Summit', 'triplet': '338:ID:SNTL', 'elevation': 6560, 'location': {'lat': 44.62621, 'lng': -115.79561}}, {'name': 'Big Flat', 'triplet': '339:UT:SNTL', 'elevation': 10349, 'location': {'lat': 38.30183, 'lng': -112.35672}}, {'name': 'Big Goose', 'triplet': '931:WY:SNTL', 'elevation': 7990, 'location': {'lat': 44.57924, 'lng': -107.20068}}, {'name': 'Big Meadow', 'triplet': '340:NV:SNTL', 'elevation': 8235, 'location': {'lat': 39.455, 'lng': -119.9422}}, {'name': 'Big Red Mountain', 'triplet': '341:OR:SNTL', 'elevation': 6050, 'location': {'lat': 42.05257, 'lng': -122.85487}}, {'name': 'Big Sandy Opening', 'triplet': '342:WY:SNTL', 'elevation': 9080, 'location': {'lat': 42.6458, 'lng': -109.25965}}, {'name': 'Bigelow Camp', 'triplet': '343:OR:SNTL', 'elevation': 5130, 'location': {'lat': 42.07875, 'lng': -123.34393}}, {'name': 'Billie Creek Divide', 'triplet': '344:OR:SNTL', 'elevation': 5280, 'location': {'lat': 42.40717, 'lng': -122.26617}}, {'name': 'Bird Creek', 'triplet': '1155:NV:SNTL', 'elevation': 7537, 'location': {'lat': 39.46138, 'lng': -114.64863}}, {'name': 'Bison Lake', 'triplet': '345:CO:SNTL', 'elevation': 10964, 'location': {'lat': 39.76458, 'lng': -107.35628}}, {'name': 'Bisson Creek', 'triplet': '346:MT:SNTL', 'elevation': 4920, 'location': {'lat': 47.68389, 'lng': -113.99901}}, {'name': 'Black Bear', 'triplet': '347:MT:SNTL', 'elevation': 8170, 'location': {'lat': 44.50832, 'lng': -111.12803}}, {'name': 'Black Flat-U.M. Ck', 'triplet': '348:UT:SNTL', 'elevation': 9414, 'location': {'lat': 38.6799, 'lng': -111.59765}}, {'name': 'Black Mesa', 'triplet': '1185:CO:SNTL', 'elevation': 11564, 'location': {'lat': 37.78968, 'lng': -108.18376}}, {'name': 'Black Mountain', 'triplet': '1161:CO:SNTL', 'elevation': 8980, 'location': {'lat': 40.8879, 'lng': -105.66404}}, {'name': 'Black Pine', 'triplet': '349:MT:SNTL', 'elevation': 7210, 'location': {'lat': 46.414, 'lng': -113.43095}}, {'name': 'Blackhall Mtn', 'triplet': '1119:WY:SNTL', 'elevation': 9839, 'location': {'lat': 41.05623, 'lng': -106.714}}, {'name': 'Blacks Fork Jct', 'triplet': '1162:UT:SNTL', 'elevation': 8869, 'location': {'lat': 40.95814, 'lng': -110.5828}}, {'name': 'Blacktail Mtn', 'triplet': '1144:MT:SNTL', 'elevation': 5650, 'location': {'lat': 47.98288, 'lng': -114.3543}}, {'name': 'Blackwater', 'triplet': '350:WY:SNTL', 'elevation': 9780, 'location': {'lat': 44.37667, 'lng': -109.79333}}, {'name': 'Blazed Alder', 'triplet': '351:OR:SNTL', 'elevation': 3650, 'location': {'lat': 45.4287, 'lng': -121.85605}}, {'name': 'Blewett Pass', 'triplet': '352:WA:SNTL', 'elevation': 4240, 'location': {'lat': 47.35037, 'lng': -120.6796}}, {'name': 'Blind Bull Sum', 'triplet': '353:WY:SNTL', 'elevation': 8650, 'location': {'lat': 42.964, 'lng': -110.60973}}, {'name': 'Blind Park', 'triplet': '354:SD:SNTL', 'elevation': 6890, 'location': {'lat': 44.10772, 'lng': -103.97688}}, {'name': 'Bloody Dick', 'triplet': '355:MT:SNTL', 'elevation': 7600, 'location': {'lat': 45.16507, 'lng': -113.50099}}, {'name': 'Blue Lakes', 'triplet': '356:CA:SNTL', 'elevation': 8067, 'location': {'lat': 38.608, 'lng': -119.92437}}, {'name': 'Blue Mountain Spring', 'triplet': '357:OR:SNTL', 'elevation': 5870, 'location': {'lat': 44.24767, 'lng': -118.51722}}, {'name': 'Bobs Hollow', 'triplet': '1278:UT:SNTL', 'elevation': 9319, 'location': {'lat': 38.94569, 'lng': -112.15349}}, {'name': 'Bogus Basin', 'triplet': '978:ID:SNTL', 'elevation': 6340, 'location': {'lat': 43.76377, 'lng': -116.09685}}, {'name': 'Bone Springs Div', 'triplet': '358:WY:SNTL', 'elevation': 9350, 'location': {'lat': 44.67888, 'lng': -107.5811}}, {'name': 'Bostetter R.S.', 'triplet': '359:ID:SNTL', 'elevation': 7500, 'location': {'lat': 42.16442, 'lng': -114.19272}}, {'name': 'Boulder Mountain', 'triplet': '360:MT:SNTL', 'elevation': 7950, 'location': {'lat': 46.5596, 'lng': -111.28973}}, {'name': 'Bourne', 'triplet': '361:OR:SNTL', 'elevation': 5850, 'location': {'lat': 44.83052, 'lng': -118.18787}}, {'name': 'Bowman Springs', 'triplet': '362:OR:SNTL', 'elevation': 4530, 'location': {'lat': 45.36428, 'lng': -118.46715}}, {'name': 'Box Canyon', 'triplet': '363:MT:SNTL', 'elevation': 6670, 'location': {'lat': 45.2719, 'lng': -110.24903}}, {'name': 'Box Creek', 'triplet': '364:UT:SNTL', 'elevation': 9853, 'location': {'lat': 38.50809, 'lng': -112.01856}}, {'name': 'Box Springs', 'triplet': '1156:UT:SNTL', 'elevation': 9228, 'location': {'lat': 38.49746, 'lng': -112.00779}}, {'name': 'Brackett Creek', 'triplet': '365:MT:SNTL', 'elevation': 7320, 'location': {'lat': 45.89107, 'lng': -110.93851}}, {'name': 'Brian Head', 'triplet': '1154:UT:SNTL', 'elevation': 10039, 'location': {'lat': 37.67994, 'lng': -112.85674}}, {'name': 'Brighton', 'triplet': '366:UT:SNTL', 'elevation': 8766, 'location': {'lat': 40.59936, 'lng': -111.58167}}, {'name': 'Bristlecone Trail', 'triplet': '1111:NV:SNTL', 'elevation': 8890, 'location': {'lat': 36.31575, 'lng': -115.69543}}, {'name': 'Brooklyn Lake', 'triplet': '367:WY:SNTL', 'elevation': 10250, 'location': {'lat': 41.36038, 'lng': -106.23038}}, {'name': 'Brown Duck', 'triplet': '368:UT:SNTL', 'elevation': 10574, 'location': {'lat': 40.58102, 'lng': -110.58587}}, {'name': 'Brown Top', 'triplet': '1080:WA:SNTL', 'elevation': 5830, 'location': {'lat': 48.92755, 'lng': -121.19713}}, {'name': 'Brumley', 'triplet': '369:CO:SNTL', 'elevation': 10594, 'location': {'lat': 39.08758, 'lng': -106.54231}}, {'name': 'Brundage Reservoir', 'triplet': '370:ID:SNTL', 'elevation': 6250, 'location': {'lat': 45.04315, 'lng': -116.13253}}, {'name': 'Buck Flat', 'triplet': '371:UT:SNTL', 'elevation': 9409, 'location': {'lat': 39.134, 'lng': -111.43722}}, {'name': 'Buck Pasture', 'triplet': '1192:UT:SNTL', 'elevation': 9632, 'location': {'lat': 40.84456, 'lng': -110.66068}}, {'name': 'Buckboard Flat', 'triplet': '1153:UT:SNTL', 'elevation': 8924, 'location': {'lat': 37.86943, 'lng': -109.44717}}, {'name': 'Buckinghorse', 'triplet': '1107:WA:SNTL', 'elevation': 4870, 'location': {'lat': 47.7086, 'lng': -123.45747}}, {'name': 'Buckskin Joe', 'triplet': '938:CO:SNTL', 'elevation': 11166, 'location': {'lat': 39.30378, 'lng': -106.11316}}, {'name': 'Buckskin Lower', 'triplet': '373:NV:SNTL', 'elevation': 6930, 'location': {'lat': 41.75067, 'lng': -117.53182}}, {'name': 'Buffalo Park', 'triplet': '913:CO:SNTL', 'elevation': 9249, 'location': {'lat': 40.22838, 'lng': -106.5962}}, {'name': 'Bug Lake', 'triplet': '374:UT:SNTL', 'elevation': 7987, 'location': {'lat': 41.68541, 'lng': -111.41987}}, {'name': 'Bumping Ridge', 'triplet': '375:WA:SNTL', 'elevation': 4610, 'location': {'lat': 46.81003, 'lng': -121.33058}}, {'name': 'Bunchgrass Mdw', 'triplet': '376:WA:SNTL', 'elevation': 5000, 'location': {'lat': 48.68688, 'lng': -117.17633}}, {'name': 'Burgess Junction', 'triplet': '377:WY:SNTL', 'elevation': 7880, 'location': {'lat': 44.78765, 'lng': -107.52917}}, {'name': 'Burnside Lake', 'triplet': '1051:CA:SNTL', 'elevation': 8129, 'location': {'lat': 38.71943, 'lng': -119.8942}}, {'name': 'Burnt Mountain', 'triplet': '942:WA:SNTL', 'elevation': 4170, 'location': {'lat': 47.0444, 'lng': -121.94032}}, {'name': 'Burnt Mtn', 'triplet': '981:MT:SNTL', 'elevation': 5880, 'location': {'lat': 45.2401, 'lng': -109.45961}}, {'name': 'Burro Mountain', 'triplet': '378:CO:SNTL', 'elevation': 9317, 'location': {'lat': 39.87504, 'lng': -107.59902}}, {'name': 'Burroughs Creek', 'triplet': '379:WY:SNTL', 'elevation': 8750, 'location': {'lat': 43.69733, 'lng': -109.67021}}, {'name': 'Burts Miller Ranch', 'triplet': '1135:UT:SNTL', 'elevation': 8000, 'location': {'lat': 40.98492, 'lng': -110.85075}}, {'name': 'Butte', 'triplet': '380:CO:SNTL', 'elevation': 10200, 'location': {'lat': 38.89435, 'lng': -106.95327}}, {'name': 'Calamity', 'triplet': '1109:WA:SNTL', 'elevation': 2500, 'location': {'lat': 45.90362, 'lng': -122.21633}}, {'name': 'Calvert Creek', 'triplet': '381:MT:SNTL', 'elevation': 6430, 'location': {'lat': 45.8838, 'lng': -113.32553}}, {'name': 'Camas Creek Divide', 'triplet': '382:ID:SNTL', 'elevation': 5710, 'location': {'lat': 43.26548, 'lng': -115.3453}}, {'name': 'Camp Jackson', 'triplet': '383:UT:SNTL', 'elevation': 8858, 'location': {'lat': 37.81333, 'lng': -109.48723}}, {'name': 'Canyon', 'triplet': '384:WY:SNTL', 'elevation': 7870, 'location': {'lat': 44.71961, 'lng': -110.51084}}, {'name': 'Carrot Basin', 'triplet': '385:MT:SNTL', 'elevation': 9000, 'location': {'lat': 44.96192, 'lng': -111.29403}}, {'name': 'Carson Pass', 'triplet': '1067:CA:SNTL', 'elevation': 8360, 'location': {'lat': 38.6927, 'lng': -120.0022}}, {'name': 'Cascade #2', 'triplet': '387:CO:SNTL', 'elevation': 9012, 'location': {'lat': 37.65751, 'lng': -107.80287}}, {'name': 'Cascade Mountain', 'triplet': '1039:UT:SNTL', 'elevation': 7774, 'location': {'lat': 40.283, 'lng': -111.60992}}, {'name': 'Cascade Summit', 'triplet': '388:OR:SNTL', 'elevation': 5100, 'location': {'lat': 43.59042, 'lng': -122.0601}}, {'name': 'Casper Mtn.', 'triplet': '389:WY:SNTL', 'elevation': 7920, 'location': {'lat': 42.73362, 'lng': -106.31789}}, {'name': 'Castle Creek', 'triplet': '1130:WY:SNTL', 'elevation': 8400, 'location': {'lat': 43.6748, 'lng': -109.3774}}, {'name': 'Castle Valley', 'triplet': '390:UT:SNTL', 'elevation': 9607, 'location': {'lat': 37.66098, 'lng': -112.74093}}, {'name': 'Cave Mountain', 'triplet': '1152:NV:SNTL', 'elevation': 10578, 'location': {'lat': 39.16337, 'lng': -114.6133}}, {'name': 'Cayuse Pass', 'triplet': '1085:WA:SNTL', 'elevation': 5240, 'location': {'lat': 46.86954, 'lng': -121.5343}}, {'name': 'Cedar Pass', 'triplet': '391:CA:SNTL', 'elevation': 7030, 'location': {'lat': 41.58233, 'lng': -120.3025}}, {'name': 'Chalender', 'triplet': '1139:AZ:SNTL', 'elevation': 7035, 'location': {'lat': 35.26238, 'lng': -112.06221}}, {'name': 'Chalk Creek #1', 'triplet': '392:UT:SNTL', 'elevation': 9171, 'location': {'lat': 40.85464, 'lng': -111.04765}}, {'name': 'Chalk Creek #2', 'triplet': '393:UT:SNTL', 'elevation': 8208, 'location': {'lat': 40.88529, 'lng': -111.06954}}, {'name': 'Chamita', 'triplet': '394:NM:SNTL', 'elevation': 8383, 'location': {'lat': 36.95606, 'lng': -106.65723}}, {'name': 'Chapman Tunnel', 'triplet': '1101:CO:SNTL', 'elevation': 10100, 'location': {'lat': 39.2621, 'lng': -106.62944}}, {'name': 'Chemult Alternate', 'triplet': '395:OR:SNTL', 'elevation': 4850, 'location': {'lat': 43.22625, 'lng': -121.80662}}, {'name': 'Chena Lakes', 'triplet': '1260:AK:SNTL', 'elevation': 500, 'location': {'lat': 64.75793, 'lng': -147.21823}}, {'name': 'Chepeta', 'triplet': '396:UT:SNTL', 'elevation': 10499, 'location': {'lat': 40.77458, 'lng': -110.0105}}, {'name': 'Chicago Ridge', 'triplet': '1312:MT:SNTL', 'elevation': 5800, 'location': {'lat': 48.062, 'lng': -115.698}}, {'name': 'Chisana', 'triplet': '1093:AK:SNTL', 'elevation': 3320, 'location': {'lat': 62.069, 'lng': -142.049}}, {'name': 'Chocolate Gulch', 'triplet': '895:ID:SNTL', 'elevation': 6310, 'location': {'lat': 43.7685, 'lng': -114.41812}}, {'name': 'Cinnabar Park', 'triplet': '1046:WY:SNTL', 'elevation': 9707, 'location': {'lat': 41.23843, 'lng': -106.23101}}, {'name': 'Clackamas Lake', 'triplet': '398:OR:SNTL', 'elevation': 3400, 'location': {'lat': 45.09658, 'lng': -121.75443}}, {'name': 'Clayton Springs', 'triplet': '983:UT:SNTL', 'elevation': 10049, 'location': {'lat': 37.9725, 'lng': -111.83355}}, {'name': 'Clear Creek #1', 'triplet': '399:UT:SNTL', 'elevation': 8975, 'location': {'lat': 39.86671, 'lng': -111.28363}}, {'name': 'Clear Creek #2', 'triplet': '400:UT:SNTL', 'elevation': 7837, 'location': {'lat': 39.89275, 'lng': -111.25154}}, {'name': 'Clear Lake', 'triplet': '401:OR:SNTL', 'elevation': 3810, 'location': {'lat': 45.18832, 'lng': -121.6916}}, {'name': 'Cloud Peak Reservoir', 'triplet': '402:WY:SNTL', 'elevation': 9860, 'location': {'lat': 44.40343, 'lng': -107.06057}}, {'name': 'Clover Meadow', 'triplet': '403:MT:SNTL', 'elevation': 8600, 'location': {'lat': 45.01788, 'lng': -111.8456}}, {'name': 'Cochetopa Pass', 'triplet': '1059:CO:SNTL', 'elevation': 10061, 'location': {'lat': 38.16273, 'lng': -106.5988}}, {'name': 'Cold Springs', 'triplet': '405:WY:SNTL', 'elevation': 9630, 'location': {'lat': 43.27676, 'lng': -109.44585}}, {'name': 'Cold Springs Camp', 'triplet': '406:OR:SNTL', 'elevation': 5940, 'location': {'lat': 42.53305, 'lng': -122.17683}}, {'name': 'Coldfoot', 'triplet': '958:AK:SNTL', 'elevation': 1040, 'location': {'lat': 67.25333, 'lng': -150.183}}, {'name': 'Cole Canyon', 'triplet': '982:WY:SNTL', 'elevation': 5910, 'location': {'lat': 44.48632, 'lng': -104.41057}}, {'name': 'Cole Creek', 'triplet': '407:MT:SNTL', 'elevation': 7850, 'location': {'lat': 45.19405, 'lng': -109.34548}}, {'name': 'Columbia Basin', 'triplet': '1204:NV:SNTL', 'elevation': 6483, 'location': {'lat': 41.67167, 'lng': -116.07033}}, {'name': 'Columbine', 'triplet': '408:CO:SNTL', 'elevation': 9167, 'location': {'lat': 40.39591, 'lng': -106.60437}}, {'name': 'Columbine Pass', 'triplet': '409:CO:SNTL', 'elevation': 9171, 'location': {'lat': 38.41819, 'lng': -108.38313}}, {'name': 'Columbus Basin', 'triplet': '904:CO:SNTL', 'elevation': 10781, 'location': {'lat': 37.44146, 'lng': -108.02468}}, {'name': 'Combination', 'triplet': '410:MT:SNTL', 'elevation': 5600, 'location': {'lat': 46.46523, 'lng': -113.39358}}, {'name': 'Cool Creek', 'triplet': '411:ID:SNTL', 'elevation': 6280, 'location': {'lat': 46.76361, 'lng': -115.29528}}, {'name': 'Cooper Lake', 'triplet': '959:AK:SNTL', 'elevation': 1200, 'location': {'lat': 60.39027, 'lng': -149.6936}}, {'name': 'Copeland Lake', 'triplet': '412:CO:SNTL', 'elevation': 8555, 'location': {'lat': 40.20733, 'lng': -105.5695}}, {'name': 'Copper Bottom', 'triplet': '413:MT:SNTL', 'elevation': 5200, 'location': {'lat': 47.05678, 'lng': -112.595}}, {'name': 'Copper Camp', 'triplet': '414:MT:SNTL', 'elevation': 6950, 'location': {'lat': 47.08158, 'lng': -112.72955}}, {'name': 'Copper Mountain', 'triplet': '415:CO:SNTL', 'elevation': 10523, 'location': {'lat': 39.48917, 'lng': -106.17154}}, {'name': 'Corduroy Flat', 'triplet': '1209:NV:SNTL', 'elevation': 8640, 'location': {'lat': 38.99651, 'lng': -115.42478}}, {'name': 'Coronado Trail', 'triplet': '416:AZ:SNTL', 'elevation': 8418, 'location': {'lat': 33.80418, 'lng': -109.15352}}, {'name': 'Corral', 'triplet': '1236:UT:SNTL', 'elevation': 8207, 'location': {'lat': 39.65795, 'lng': -110.37906}}, {'name': 'Corral Canyon', 'triplet': '417:NV:SNTL', 'elevation': 8445, 'location': {'lat': 40.27551, 'lng': -115.54017}}, {'name': 'Corral Pass', 'triplet': '418:WA:SNTL', 'elevation': 5800, 'location': {'lat': 47.01872, 'lng': -121.46464}}, {'name': 'Cottonwood Creek', 'triplet': '419:WY:SNTL', 'elevation': 7670, 'location': {'lat': 42.6459, 'lng': -110.81482}}, {'name': 'Couch Summit', 'triplet': '1306:ID:SNTL', 'elevation': 6800, 'location': {'lat': 43.51768, 'lng': -114.8022}}, {'name': 'Cougar Mountain', 'triplet': '420:WA:SNTL', 'elevation': 3200, 'location': {'lat': 47.27666, 'lng': -121.67138}}, {'name': 'County Line', 'triplet': '422:OR:SNTL', 'elevation': 4830, 'location': {'lat': 45.19107, 'lng': -118.55015}}, {'name': 'Cozy Cove', 'triplet': '423:ID:SNTL', 'elevation': 5400, 'location': {'lat': 44.28846, 'lng': -115.65508}}, {'name': 'Crab Creek', 'triplet': '424:ID:SNTL', 'elevation': 6900, 'location': {'lat': 44.437, 'lng': -111.99384}}, {'name': 'Crater Meadows', 'triplet': '425:ID:SNTL', 'elevation': 5960, 'location': {'lat': 46.56394, 'lng': -115.28903}}, {'name': 'Crazyman Flat', 'triplet': '1010:OR:SNTL', 'elevation': 6180, 'location': {'lat': 42.6381, 'lng': -120.94917}}, {'name': 'Creamers Field', 'triplet': '1302:AK:SNTL', 'elevation': 440, 'location': {'lat': 64.86534, 'lng': -147.73617}}, {'name': 'Crosho', 'triplet': '426:CO:SNTL', 'elevation': 8973, 'location': {'lat': 40.16749, 'lng': -107.05769}}, {'name': 'Crow Creek', 'triplet': '1045:WY:SNTL', 'elevation': 8335, 'location': {'lat': 41.22824, 'lng': -105.38571}}, {'name': 'Crowder Flat', 'triplet': '977:CA:SNTL', 'elevation': 5170, 'location': {'lat': 41.89318, 'lng': -120.75202}}, {'name': 'Crystal Lake', 'triplet': '427:MT:SNTL', 'elevation': 6050, 'location': {'lat': 46.78942, 'lng': -109.51205}}, {'name': 'Css Lab', 'triplet': '428:CA:SNTL', 'elevation': 6894, 'location': {'lat': 39.32565, 'lng': -120.36807}}, {'name': 'Culebra #2', 'triplet': '430:CO:SNTL', 'elevation': 10562, 'location': {'lat': 37.20939, 'lng': -105.19988}}, {'name': 'Cumbres Trestle', 'triplet': '431:CO:SNTL', 'elevation': 10035, 'location': {'lat': 37.01877, 'lng': -106.45275}}, {'name': 'Currant Creek', 'triplet': '432:UT:SNTL', 'elevation': 7915, 'location': {'lat': 40.35747, 'lng': -111.08993}}, {'name': 'Dahl Creek', 'triplet': '1303:AK:SNTL', 'elevation': 260, 'location': {'lat': 66.94517, 'lng': -156.90318}}, {'name': 'Daisy Peak', 'triplet': '919:MT:SNTL', 'elevation': 7600, 'location': {'lat': 46.66858, 'lng': -110.33022}}, {'name': 'Daly Creek', 'triplet': '433:MT:SNTL', 'elevation': 5780, 'location': {'lat': 46.18367, 'lng': -113.8533}}, {'name': 'Daly Lake', 'triplet': '434:OR:SNTL', 'elevation': 3690, 'location': {'lat': 44.52147, 'lng': -122.08718}}, {'name': 'Daniels-Strawberry', 'triplet': '435:UT:SNTL', 'elevation': 8008, 'location': {'lat': 40.2953, 'lng': -111.25677}}, {'name': 'Darkhorse Lake', 'triplet': '436:MT:SNTL', 'elevation': 8945, 'location': {'lat': 45.17367, 'lng': -113.58448}}, {'name': 'Deadman Creek', 'triplet': '437:MT:SNTL', 'elevation': 6450, 'location': {'lat': 46.79279, 'lng': -110.67545}}, {'name': 'Deadman Hill', 'triplet': '438:CO:SNTL', 'elevation': 10239, 'location': {'lat': 40.80572, 'lng': -105.77018}}, {'name': 'Deadwood Summit', 'triplet': '439:ID:SNTL', 'elevation': 6860, 'location': {'lat': 44.54514, 'lng': -115.5638}}, {'name': 'Deer Park', 'triplet': '923:WY:SNTL', 'elevation': 9700, 'location': {'lat': 42.59076, 'lng': -108.90273}}, {'name': 'Defiance Mines', 'triplet': '1210:NV:SNTL', 'elevation': 9302, 'location': {'lat': 39.08527, 'lng': -114.89977}}, {'name': 'Derr.', 'triplet': '440:OR:SNTL', 'elevation': 5850, 'location': {'lat': 44.4465, 'lng': -119.93012}}, {'name': 'Diamond Lake', 'triplet': '442:OR:SNTL', 'elevation': 5280, 'location': {'lat': 43.18787, 'lng': -122.14003}}, {'name': 'Diamond Peak', 'triplet': '443:NV:SNTL', 'elevation': 8017, 'location': {'lat': 39.56361, 'lng': -115.84421}}, {'name': 'Dills Camp', 'triplet': '444:UT:SNTL', 'elevation': 9228, 'location': {'lat': 39.04554, 'lng': -111.46875}}, {'name': 'Disaster Peak', 'triplet': '445:NV:SNTL', 'elevation': 6260, 'location': {'lat': 41.96737, 'lng': -118.18934}}, {'name': 'Dismal Swamp', 'triplet': '446:CA:SNTL', 'elevation': 7360, 'location': {'lat': 41.99127, 'lng': -120.18033}}, {'name': 'Divide', 'triplet': '448:MT:SNTL', 'elevation': 7800, 'location': {'lat': 44.79317, 'lng': -112.05645}}, {'name': 'Divide Peak', 'triplet': '449:WY:SNTL', 'elevation': 8730, 'location': {'lat': 41.30399, 'lng': -107.15255}}, {'name': 'Dollarhide Summit', 'triplet': '450:ID:SNTL', 'elevation': 8420, 'location': {'lat': 43.6025, 'lng': -114.67417}}, {'name': 'Dome Lake', 'triplet': '451:WY:SNTL', 'elevation': 8880, 'location': {'lat': 44.57462, 'lng': -107.29537}}, {'name': 'Donkey Reservoir', 'triplet': '452:UT:SNTL', 'elevation': 9799, 'location': {'lat': 38.2084, 'lng': -111.47412}}, {'name': 'Dorsey Basin', 'triplet': '453:NV:SNTL', 'elevation': 7903, 'location': {'lat': 40.89343, 'lng': -115.21104}}, {'name': 'Draw Creek', 'triplet': '454:NV:SNTL', 'elevation': 7332, 'location': {'lat': 41.661, 'lng': -115.3234}}, {'name': 'Dry Bread Pond', 'triplet': '455:UT:SNTL', 'elevation': 8302, 'location': {'lat': 41.41289, 'lng': -111.5377}}, {'name': 'Dry Creek', 'triplet': '1243:NV:SNTL', 'elevation': 6555, 'location': {'lat': 40.8638, 'lng': -115.22014}}, {'name': 'Dry Fork', 'triplet': '906:UT:SNTL', 'elevation': 7093, 'location': {'lat': 40.56533, 'lng': -112.17343}}, {'name': 'Dry Lake', 'triplet': '457:CO:SNTL', 'elevation': 8271, 'location': {'lat': 40.5337, 'lng': -106.7814}}, {'name': 'Dungeness', 'triplet': '943:WA:SNTL', 'elevation': 4010, 'location': {'lat': 47.87224, 'lng': -123.0788}}, {'name': 'Dupuyer Creek', 'triplet': '458:MT:SNTL', 'elevation': 5750, 'location': {'lat': 48.06341, 'lng': -112.7573}}, {'name': 'Eagle Summit', 'triplet': '960:AK:SNTL', 'elevation': 3650, 'location': {'lat': 65.48588, 'lng': -145.41212}}, {'name': 'East Boulder Mine', 'triplet': '1105:MT:SNTL', 'elevation': 6335, 'location': {'lat': 45.50381, 'lng': -110.08019}}, {'name': 'East Palmer', 'triplet': '953:AK:SNTL', 'elevation': 230, 'location': {'lat': 61.59858, 'lng': -149.09637}}, {'name': 'East Rim Divide', 'triplet': '460:WY:SNTL', 'elevation': 7930, 'location': {'lat': 43.13097, 'lng': -110.2023}}, {'name': 'East Willow Creek', 'triplet': '461:UT:SNTL', 'elevation': 8302, 'location': {'lat': 39.31213, 'lng': -109.53179}}, {'name': 'Easy Pass', 'triplet': '998:WA:SNTL', 'elevation': 5270, 'location': {'lat': 48.85933, 'lng': -121.43895}}, {'name': 'Ebbetts Pass', 'triplet': '462:CA:SNTL', 'elevation': 8661, 'location': {'lat': 38.5497, 'lng': -119.80468}}, {'name': 'Echo Lake', 'triplet': '936:CO:SNTL', 'elevation': 10694, 'location': {'lat': 39.65539, 'lng': -105.59358}}, {'name': 'Echo Peak', 'triplet': '463:CA:SNTL', 'elevation': 7653, 'location': {'lat': 38.849, 'lng': -120.0795}}, {'name': 'EF Blacks Fork GS', 'triplet': '1163:UT:SNTL', 'elevation': 9360, 'location': {'lat': 40.88472, 'lng': -110.54056}}, {'name': 'Eilertson Meadows', 'triplet': '464:OR:SNTL', 'elevation': 5510, 'location': {'lat': 44.86887, 'lng': -118.11387}}, {'name': 'El Diente Peak', 'triplet': '465:CO:SNTL', 'elevation': 10217, 'location': {'lat': 37.78607, 'lng': -108.02235}}, {'name': 'Elbow Lake', 'triplet': '910:WA:SNTL', 'elevation': 3040, 'location': {'lat': 48.69092, 'lng': -121.90893}}, {'name': 'Elk Butte', 'triplet': '466:ID:SNTL', 'elevation': 5690, 'location': {'lat': 46.83998, 'lng': -116.12233}}, {'name': 'Elk Cabin', 'triplet': '921:NM:SNTL', 'elevation': 8239, 'location': {'lat': 35.7073, 'lng': -105.80584}}, {'name': 'Elk Peak', 'triplet': '1106:MT:SNTL', 'elevation': 7600, 'location': {'lat': 46.4845, 'lng': -110.7125}}, {'name': 'Elk River', 'triplet': '467:CO:SNTL', 'elevation': 8739, 'location': {'lat': 40.84758, 'lng': -106.96861}}, {'name': 'Elkhart Park G.S.', 'triplet': '468:WY:SNTL', 'elevation': 9400, 'location': {'lat': 43.00657, 'lng': -109.75893}}, {'name': 'Elkhead Divide', 'triplet': '1252:CO:SNTL', 'elevation': 8800, 'location': {'lat': 40.79637, 'lng': -107.10113}}, {'name': 'Elliot Ridge', 'triplet': '1120:CO:SNTL', 'elevation': 10549, 'location': {'lat': 39.8638, 'lng': -106.42473}}, {'name': 'Emery Creek', 'triplet': '469:MT:SNTL', 'elevation': 4350, 'location': {'lat': 48.43412, 'lng': -113.93725}}, {'name': 'Emigrant Springs', 'triplet': '470:OR:SNTL', 'elevation': 3800, 'location': {'lat': 45.55808, 'lng': -118.45383}}, {'name': 'Emigrant Summit', 'triplet': '471:ID:SNTL', 'elevation': 7390, 'location': {'lat': 42.36055, 'lng': -111.56085}}, {'name': 'Esther Island', 'triplet': '1071:AK:SNTL', 'elevation': 50, 'location': {'lat': 60.798, 'lng': -148.0857}}, {'name': 'Evening Star', 'triplet': '472:WY:SNTL', 'elevation': 9200, 'location': {'lat': 44.65258, 'lng': -109.78422}}, {'name': 'Exit Glacier', 'triplet': '1092:AK:SNTL', 'elevation': 400, 'location': {'lat': 60.19033, 'lng': -149.62117}}, {'name': 'Fallen Leaf', 'triplet': '473:CA:SNTL', 'elevation': 6242, 'location': {'lat': 38.93403, 'lng': -120.0545}}, {'name': 'Farmington', 'triplet': '474:UT:SNTL', 'elevation': 7902, 'location': {'lat': 40.97462, 'lng': -111.80975}}, {'name': 'Farmington Lower', 'triplet': '1054:UT:SNTL', 'elevation': 6779, 'location': {'lat': 40.992, 'lng': -111.81702}}, {'name': 'Farnsworth Lake', 'triplet': '475:UT:SNTL', 'elevation': 9623, 'location': {'lat': 38.77246, 'lng': -111.67662}}, {'name': 'Fawn Creek', 'triplet': '476:NV:SNTL', 'elevation': 7031, 'location': {'lat': 41.82098, 'lng': -116.10153}}, {'name': 'Fielding Lake', 'triplet': '1268:AK:SNTL', 'elevation': 3000, 'location': {'lat': 63.20267, 'lng': -145.6305}}, {'name': 'Fifteenmile', 'triplet': '1314:OR:SNTL', 'elevation': 5970, 'location': {'lat': 45.35265, 'lng': -121.53}}, {'name': 'Fish Ck', 'triplet': '1305:ID:SNTL', 'elevation': 6330, 'location': {'lat': 43.55542, 'lng': -113.71924}}, {'name': 'Fish Creek', 'triplet': '477:OR:SNTL', 'elevation': 7660, 'location': {'lat': 42.70992, 'lng': -118.6321}}, {'name': 'Fish Lake', 'triplet': '478:WA:SNTL', 'elevation': 3430, 'location': {'lat': 47.53565, 'lng': -121.08553}}, {'name': 'Fish Lake Utah', 'triplet': '1149:UT:SNTL', 'elevation': 8798, 'location': {'lat': 38.50455, 'lng': -111.76693}}, {'name': 'Fish Lk.', 'triplet': '479:OR:SNTL', 'elevation': 4660, 'location': {'lat': 42.3801, 'lng': -122.34943}}, {'name': 'Fisher Creek', 'triplet': '480:MT:SNTL', 'elevation': 9100, 'location': {'lat': 45.06235, 'lng': -109.94488}}, {'name': 'Five Points Lake', 'triplet': '481:UT:SNTL', 'elevation': 10943, 'location': {'lat': 40.71785, 'lng': -110.46721}}, {'name': 'Flattop Mtn.', 'triplet': '482:MT:SNTL', 'elevation': 6300, 'location': {'lat': 48.80225, 'lng': -113.85713}}, {'name': 'Flower Mountain', 'triplet': '1285:AK:SNTL', 'elevation': 2510, 'location': {'lat': 59.39617, 'lng': -136.28123}}, {'name': 'Fool Creek', 'triplet': '1186:CO:SNTL', 'elevation': 11156, 'location': {'lat': 39.86866, 'lng': -105.86765}}, {'name': 'Forestdale Creek', 'triplet': '1049:CA:SNTL', 'elevation': 8017, 'location': {'lat': 38.68245, 'lng': -119.9597}}, {'name': 'Fort Valley', 'triplet': '1121:AZ:SNTL', 'elevation': 7371, 'location': {'lat': 35.26773, 'lng': -111.74479}}, {'name': 'Fort Yukon', 'triplet': '961:AK:SNTL', 'elevation': 430, 'location': {'lat': 66.5705, 'lng': -145.24553}}, {'name': 'Fourmile Lake', 'triplet': '483:OR:SNTL', 'elevation': 5970, 'location': {'lat': 42.43933, 'lng': -122.2288}}, {'name': 'Franklin Basin', 'triplet': '484:ID:SNTL', 'elevation': 8140, 'location': {'lat': 42.0505, 'lng': -111.6012}}, {'name': 'Fredonyer Peak', 'triplet': '1277:CA:SNTL', 'elevation': 7208, 'location': {'lat': 40.68799, 'lng': -120.60805}}, {'name': 'Fremont Pass', 'triplet': '485:CO:SNTL', 'elevation': 11326, 'location': {'lat': 39.38014, 'lng': -106.19784}}, {'name': 'Frisco Divide', 'triplet': '486:NM:SNTL', 'elevation': 8013, 'location': {'lat': 33.73687, 'lng': -108.94327}}, {'name': 'Frohner Meadow', 'triplet': '487:MT:SNTL', 'elevation': 6480, 'location': {'lat': 46.43545, 'lng': -112.19277}}, {'name': 'Frostbite Bottom', 'triplet': '641:AK:SNTL', 'elevation': 2700, 'location': {'lat': 61.74722, 'lng': -149.2688}}, {'name': 'Fry', 'triplet': '488:AZ:SNTL', 'elevation': 7236, 'location': {'lat': 35.07356, 'lng': -111.84477}}, {'name': 'Fry Canyon', 'triplet': '1262:NV:SNTL', 'elevation': 6798, 'location': {'lat': 41.57022, 'lng': -115.93645}}, {'name': 'Galena', 'triplet': '489:ID:SNTL', 'elevation': 7470, 'location': {'lat': 43.87722, 'lng': -114.6725}}, {'name': 'Galena AK', 'triplet': '429:AK:SNTL', 'elevation': 410, 'location': {'lat': 64.69662, 'lng': -156.71497}}, {'name': 'Galena Summit', 'triplet': '490:ID:SNTL', 'elevation': 8780, 'location': {'lat': 43.87497, 'lng': -114.71363}}, {'name': 'Gallegos Peak', 'triplet': '491:NM:SNTL', 'elevation': 9480, 'location': {'lat': 36.19418, 'lng': -105.55742}}, {'name': 'Garden City Summit', 'triplet': '1114:UT:SNTL', 'elevation': 7705, 'location': {'lat': 41.9215, 'lng': -111.4693}}, {'name': 'Gardner Peak', 'triplet': '1066:UT:SNTL', 'elevation': 8322, 'location': {'lat': 37.40083, 'lng': -113.45988}}, {'name': 'Garfield R.S.', 'triplet': '492:ID:SNTL', 'elevation': 6560, 'location': {'lat': 43.6104, 'lng': -113.9308}}, {'name': 'Garita Peak', 'triplet': '1173:NM:SNTL', 'elevation': 10115, 'location': {'lat': 36.00469, 'lng': -106.54805}}, {'name': 'Garver Creek', 'triplet': '918:MT:SNTL', 'elevation': 4250, 'location': {'lat': 48.97523, 'lng': -115.81915}}, {'name': 'GBRC HQ', 'triplet': '1221:UT:SNTL', 'elevation': 8801, 'location': {'lat': 39.32019, 'lng': -111.48827}}, {'name': 'GBRC Meadows', 'triplet': '1222:UT:SNTL', 'elevation': 9858, 'location': {'lat': 39.30229, 'lng': -111.45383}}, {'name': 'George Creek', 'triplet': '1151:UT:SNTL', 'elevation': 8964, 'location': {'lat': 41.91562, 'lng': -113.41154}}, {'name': 'Gerber Reservoir', 'triplet': '945:OR:SNTL', 'elevation': 4890, 'location': {'lat': 42.2062, 'lng': -121.1334}}, {'name': 'Giveout', 'triplet': '493:ID:SNTL', 'elevation': 6930, 'location': {'lat': 42.4132, 'lng': -111.1663}}, {'name': 'Glen Cove', 'triplet': '1057:CO:SNTL', 'elevation': 11391, 'location': {'lat': 38.87602, 'lng': -105.07605}}, {'name': 'Gobblers Knob', 'triplet': '962:AK:SNTL', 'elevation': 2030, 'location': {'lat': 66.745, 'lng': -150.6675}}, {'name': 'Golconda', 'triplet': '1195:NV:SNTL', 'elevation': 6616, 'location': {'lat': 40.88358, 'lng': -117.58812}}, {'name': 'Gold Axe Camp', 'triplet': '1159:WA:SNTL', 'elevation': 5360, 'location': {'lat': 48.9516, 'lng': -118.9864}}, {'name': 'Gold Basin', 'triplet': '1304:UT:SNTL', 'elevation': 10076, 'location': {'lat': 38.46516, 'lng': -109.26332}}, {'name': 'Gold Center', 'triplet': '494:OR:SNTL', 'elevation': 5410, 'location': {'lat': 44.7638, 'lng': -118.3117}}, {'name': 'Gold Mountain', 'triplet': '1256:WA:SNTL', 'elevation': 4390, 'location': {'lat': 48.18934, 'lng': -118.4559}}, {'name': 'Gooseberry RS', 'triplet': '495:UT:SNTL', 'elevation': 7944, 'location': {'lat': 38.80034, 'lng': -111.68333}}, {'name': 'Gooseberry RS Up', 'triplet': '1184:UT:SNTL', 'elevation': 8396, 'location': {'lat': 38.7882, 'lng': -111.68892}}, {'name': 'Graham Guard Sta.', 'triplet': '496:ID:SNTL', 'elevation': 5690, 'location': {'lat': 43.9538, 'lng': -115.27387}}, {'name': 'Grand Targhee', 'triplet': '1082:WY:SNTL', 'elevation': 9260, 'location': {'lat': 43.77933, 'lng': -110.92783}}, {'name': 'Grandview', 'triplet': '956:AK:SNTL', 'elevation': 1100, 'location': {'lat': 60.60832, 'lng': -149.06313}}, {'name': 'Granite Creek', 'triplet': '497:WY:SNTL', 'elevation': 6770, 'location': {'lat': 43.34298, 'lng': -110.43495}}, {'name': 'Granite Crk', 'triplet': '963:AK:SNTL', 'elevation': 1240, 'location': {'lat': 63.94382, 'lng': -145.39993}}, {'name': 'Granite Peak', 'triplet': '498:NV:SNTL', 'elevation': 8503, 'location': {'lat': 41.67032, 'lng': -117.56668}}, {'name': 'Grassy Lake', 'triplet': '499:WY:SNTL', 'elevation': 7265, 'location': {'lat': 44.12612, 'lng': -110.83435}}, {'name': 'Grave Creek', 'triplet': '500:MT:SNTL', 'elevation': 4300, 'location': {'lat': 48.91453, 'lng': -114.76663}}, {'name': 'Grave Springs', 'triplet': '501:WY:SNTL', 'elevation': 8550, 'location': {'lat': 43.46643, 'lng': -107.23977}}, {'name': 'Grayback', 'triplet': '1058:CO:SNTL', 'elevation': 11626, 'location': {'lat': 37.47051, 'lng': -106.5379}}, {'name': 'Green Lake', 'triplet': '502:WA:SNTL', 'elevation': 5920, 'location': {'lat': 46.54741, 'lng': -121.17093}}, {'name': 'Green Mountain', 'triplet': '503:NV:SNTL', 'elevation': 8185, 'location': {'lat': 40.3848, 'lng': -115.52757}}, {'name': 'Greenpoint', 'triplet': '504:OR:SNTL', 'elevation': 3310, 'location': {'lat': 45.62237, 'lng': -121.70415}}, {'name': 'Grizzly Peak', 'triplet': '505:CO:SNTL', 'elevation': 11139, 'location': {'lat': 39.64646, 'lng': -105.8694}}, {'name': 'Gros Ventre Summit', 'triplet': '506:WY:SNTL', 'elevation': 8750, 'location': {'lat': 43.38939, 'lng': -110.12943}}, {'name': 'Grouse Camp', 'triplet': '507:WA:SNTL', 'elevation': 5390, 'location': {'lat': 47.28107, 'lng': -120.48771}}, {'name': 'Grouse Creek Divide', 'triplet': '964:AK:SNTL', 'elevation': 700, 'location': {'lat': 60.25965, 'lng': -149.34228}}, {'name': 'Gulkana River', 'triplet': '2222:AK:SNTL', 'elevation': 1830, 'location': {'lat': 62.40962, 'lng': -145.37513}}, {'name': 'Gunsight Pass', 'triplet': '944:WY:SNTL', 'elevation': 9820, 'location': {'lat': 43.38332, 'lng': -109.87815}}, {'name': 'Gutz Peak', 'triplet': '1065:UT:SNTL', 'elevation': 6763, 'location': {'lat': 37.49617, 'lng': -113.94235}}, {'name': 'Hagans Meadow', 'triplet': '508:CA:SNTL', 'elevation': 7742, 'location': {'lat': 38.8519, 'lng': -119.9374}}, {'name': 'Hams Fork', 'triplet': '509:WY:SNTL', 'elevation': 7840, 'location': {'lat': 42.146, 'lng': -110.67833}}, {'name': 'Hand Creek', 'triplet': '510:MT:SNTL', 'elevation': 5035, 'location': {'lat': 48.30754, 'lng': -114.84075}}, {'name': 'Hannagan Meadows', 'triplet': '511:AZ:SNTL', 'elevation': 9027, 'location': {'lat': 33.65352, 'lng': -109.30877}}, {'name': 'Hansen Sawmill', 'triplet': '512:WY:SNTL', 'elevation': 8360, 'location': {'lat': 44.25602, 'lng': -106.97983}}, {'name': 'Happy Jack', 'triplet': '969:AZ:SNTL', 'elevation': 7539, 'location': {'lat': 34.74594, 'lng': -111.41219}}, {'name': 'Hardscrabble', 'triplet': '896:UT:SNTL', 'elevation': 7250, 'location': {'lat': 40.86833, 'lng': -111.71865}}, {'name': 'Harris Flat', 'triplet': '514:UT:SNTL', 'elevation': 7792, 'location': {'lat': 37.48997, 'lng': -112.57602}}, {'name': 'Harts Pass', 'triplet': '515:WA:SNTL', 'elevation': 6490, 'location': {'lat': 48.72047, 'lng': -120.6586}}, {'name': 'Hawkins Lake', 'triplet': '516:MT:SNTL', 'elevation': 6450, 'location': {'lat': 48.9723, 'lng': -115.95337}}, {'name': 'Hawley Lake', 'triplet': '1271:AZ:SNTL', 'elevation': 8314, 'location': {'lat': 33.97121, 'lng': -109.76531}}, {'name': 'Hayden Fork', 'triplet': '517:UT:SNTL', 'elevation': 9130, 'location': {'lat': 40.79669, 'lng': -110.88472}}, {'name': 'Hayden Pass', 'triplet': '1102:CO:SNTL', 'elevation': 10699, 'location': {'lat': 38.29303, 'lng': -105.85027}}, {'name': 'Heavenly Valley', 'triplet': '518:CA:SNTL', 'elevation': 8534, 'location': {'lat': 38.92431, 'lng': -119.91641}}, {'name': 'Heber', 'triplet': '519:AZ:SNTL', 'elevation': 7654, 'location': {'lat': 34.31254, 'lng': -110.75433}}, {'name': 'Heen Latinee', 'triplet': '1270:AK:SNTL', 'elevation': 2065, 'location': {'lat': 58.69652, 'lng': -134.86448}}, {'name': 'Hemlock Butte', 'triplet': '520:ID:SNTL', 'elevation': 5810, 'location': {'lat': 46.48111, 'lng': -115.63361}}, {'name': 'Hewinta', 'triplet': '521:UT:SNTL', 'elevation': 9500, 'location': {'lat': 40.95009, 'lng': -110.48419}}, {'name': 'Hickerson Park', 'triplet': '522:UT:SNTL', 'elevation': 9122, 'location': {'lat': 40.90663, 'lng': -109.96287}}, {'name': 'Hidden Lake', 'triplet': '988:ID:SNTL', 'elevation': 5040, 'location': {'lat': 48.8937, 'lng': -116.75748}}, {'name': 'High Lonesome', 'triplet': '1187:CO:SNTL', 'elevation': 10638, 'location': {'lat': 40.0359, 'lng': -105.75472}}, {'name': 'High Ridge', 'triplet': '523:OR:SNTL', 'elevation': 4920, 'location': {'lat': 45.69682, 'lng': -118.10657}}, {'name': 'Hilts Creek', 'triplet': '524:ID:SNTL', 'elevation': 8000, 'location': {'lat': 44.01897, 'lng': -113.4723}}, {'name': 'Hobble Creek', 'triplet': '1223:UT:SNTL', 'elevation': 7377, 'location': {'lat': 40.18538, 'lng': -111.35971}}, {'name': 'Hobbs Park', 'triplet': '525:WY:SNTL', 'elevation': 10100, 'location': {'lat': 42.86984, 'lng': -109.09455}}, {'name': 'Hogg Pass', 'triplet': '526:OR:SNTL', 'elevation': 4790, 'location': {'lat': 44.42042, 'lng': -121.85655}}, {'name': 'Hole-in-Mountain', 'triplet': '527:NV:SNTL', 'elevation': 8163, 'location': {'lat': 40.94168, 'lng': -115.0954}}, {'name': 'Hole-in-Rock', 'triplet': '528:UT:SNTL', 'elevation': 9168, 'location': {'lat': 40.92167, 'lng': -110.18623}}, {'name': 'Holland Meadows', 'triplet': '529:OR:SNTL', 'elevation': 4930, 'location': {'lat': 43.66917, 'lng': -122.56877}}, {'name': 'Hoodoo Basin', 'triplet': '530:MT:SNTL', 'elevation': 6050, 'location': {'lat': 46.9751, 'lng': -115.0349}}, {'name': 'Hoosier Pass', 'triplet': '531:CO:SNTL', 'elevation': 11611, 'location': {'lat': 39.36092, 'lng': -106.05999}}, {'name': 'Hopewell', 'triplet': '532:NM:SNTL', 'elevation': 10095, 'location': {'lat': 36.71632, 'lng': -106.2637}}, {'name': 'Horse Meadow', 'triplet': '1050:CA:SNTL', 'elevation': 8557, 'location': {'lat': 38.83652, 'lng': -119.88732}}, {'name': 'Horse Ridge', 'triplet': '533:UT:SNTL', 'elevation': 8199, 'location': {'lat': 41.31372, 'lng': -111.44624}}, {'name': 'Hourglass Lake', 'triplet': '1122:CO:SNTL', 'elevation': 9417, 'location': {'lat': 40.57717, 'lng': -105.62584}}, {'name': 'Howard Prairie', 'triplet': '1158:OR:SNTL', 'elevation': 4580, 'location': {'lat': 42.215, 'lng': -122.3713}}, {'name': 'Howell Canyon', 'triplet': '534:ID:SNTL', 'elevation': 7980, 'location': {'lat': 42.32029, 'lng': -113.61587}}, {'name': 'Hozatka Lake', 'triplet': '2210:AK:SNTL', 'elevation': 206, 'location': {'lat': 65.198, 'lng': -156.635}}, {'name': 'Hozomeen Camp', 'triplet': '991:WA:SNTL', 'elevation': 1690, 'location': {'lat': 48.98075, 'lng': -121.07976}}, {'name': 'Huckleberry Creek', 'triplet': '928:WA:SNTL', 'elevation': 2250, 'location': {'lat': 47.06565, 'lng': -121.58778}}, {'name': 'Humboldt Gulch', 'triplet': '535:ID:SNTL', 'elevation': 4250, 'location': {'lat': 47.53178, 'lng': -115.77643}}, {'name': 'Huntington Horse', 'triplet': '1216:UT:SNTL', 'elevation': 9652, 'location': {'lat': 39.61774, 'lng': -111.30576}}, {'name': 'Hyndman', 'triplet': '537:ID:SNTL', 'elevation': 7620, 'location': {'lat': 43.71077, 'lng': -114.15894}}, {'name': 'Idarado', 'triplet': '538:CO:SNTL', 'elevation': 9812, 'location': {'lat': 37.93389, 'lng': -107.6762}}, {'name': 'Imnaviat Creek', 'triplet': '968:AK:SNTL', 'elevation': 3050, 'location': {'lat': 68.61683, 'lng': -149.30017}}, {'name': 'Independence Camp', 'triplet': '539:CA:SNTL', 'elevation': 6980, 'location': {'lat': 39.45269, 'lng': -120.29367}}, {'name': 'Independence Creek', 'triplet': '540:CA:SNTL', 'elevation': 6436, 'location': {'lat': 39.49001, 'lng': -120.28226}}, {'name': 'Independence Lake', 'triplet': '541:CA:SNTL', 'elevation': 8338, 'location': {'lat': 39.42752, 'lng': -120.31342}}, {'name': 'Independence Mine', 'triplet': '1091:AK:SNTL', 'elevation': 3550, 'location': {'lat': 61.79001, 'lng': -149.2839}}, {'name': 'Independence Pass', 'triplet': '542:CO:SNTL', 'elevation': 10598, 'location': {'lat': 39.07543, 'lng': -106.61154}}, {'name': 'Indian Creek', 'triplet': '544:WY:SNTL', 'elevation': 9425, 'location': {'lat': 42.30023, 'lng': -110.67753}}, {'name': 'Indian Pass', 'triplet': '946:AK:SNTL', 'elevation': 2350, 'location': {'lat': 61.06767, 'lng': -149.4795}}, {'name': 'Indian Rock', 'triplet': '1129:WA:SNTL', 'elevation': 5360, 'location': {'lat': 45.99077, 'lng': -120.80767}}, {'name': 'Irish Taylor', 'triplet': '545:OR:SNTL', 'elevation': 5540, 'location': {'lat': 43.80368, 'lng': -121.94793}}, {'name': 'Island Park', 'triplet': '546:ID:SNTL', 'elevation': 6290, 'location': {'lat': 44.4203, 'lng': -111.38512}}, {'name': 'Ivanhoe', 'triplet': '547:CO:SNTL', 'elevation': 10541, 'location': {'lat': 39.29228, 'lng': -106.54907}}, {'name': 'Jack Creek Upper', 'triplet': '548:NV:SNTL', 'elevation': 7377, 'location': {'lat': 41.54675, 'lng': -116.00517}}, {'name': 'Jack Wade Jct', 'triplet': '1275:AK:SNTL', 'elevation': 3585, 'location': {'lat': 64.1529, 'lng': -141.32693}}, {'name': 'Jacks Peak', 'triplet': '549:NV:SNTL', 'elevation': 8424, 'location': {'lat': 41.5136, 'lng': -116.0117}}, {'name': 'Jackson Peak', 'triplet': '550:ID:SNTL', 'elevation': 7070, 'location': {'lat': 44.05092, 'lng': -115.44322}}, {'name': 'Jackwhacker Gulch', 'triplet': '935:CO:SNTL', 'elevation': 11054, 'location': {'lat': 39.57096, 'lng': -105.80355}}, {'name': 'Jakes Creek', 'triplet': '1211:NV:SNTL', 'elevation': 7380, 'location': {'lat': 41.5687, 'lng': -115.03243}}, {'name': 'JL Meadow', 'triplet': '1287:MT:SNTL', 'elevation': 8800, 'location': {'lat': 44.77665, 'lng': -113.12217}}, {'name': 'Joe Wright', 'triplet': '551:CO:SNTL', 'elevation': 10158, 'location': {'lat': 40.53285, 'lng': -105.88747}}, {'name': 'Johnsons Camp', 'triplet': '1036:AK:SNTL', 'elevation': 25, 'location': {'lat': 64.5646, 'lng': -164.29257}}, {'name': 'Jones Corral', 'triplet': '1099:UT:SNTL', 'elevation': 9749, 'location': {'lat': 38.07125, 'lng': -112.16788}}, {'name': 'Jones Pass', 'triplet': '970:CO:SNTL', 'elevation': 10426, 'location': {'lat': 39.7645, 'lng': -105.90655}}, {'name': 'Jump Off Joe', 'triplet': '552:OR:SNTL', 'elevation': 3520, 'location': {'lat': 44.38605, 'lng': -122.16683}}, {'name': 'June Lake', 'triplet': '553:WA:SNTL', 'elevation': 3440, 'location': {'lat': 46.14778, 'lng': -122.15413}}, {'name': 'Kalamazoo', 'triplet': '1150:NV:SNTL', 'elevation': 7775, 'location': {'lat': 39.5579, 'lng': -114.62762}}, {'name': 'Kantishna', 'triplet': '1072:AK:SNTL', 'elevation': 1550, 'location': {'lat': 63.54167, 'lng': -150.994}}, {'name': 'Kelley R.S.', 'triplet': '554:WY:SNTL', 'elevation': 8180, 'location': {'lat': 42.26554, 'lng': -110.80177}}, {'name': 'Kelly Station', 'triplet': '1175:AK:SNTL', 'elevation': 310, 'location': {'lat': 67.93333, 'lng': -162.28333}}, {'name': 'Kenai Moose Pens', 'triplet': '966:AK:SNTL', 'elevation': 300, 'location': {'lat': 60.727, 'lng': -150.47517}}, {'name': 'Kendall R.S.', 'triplet': '555:WY:SNTL', 'elevation': 7740, 'location': {'lat': 43.2493, 'lng': -110.01662}}, {'name': 'Kilfoil Creek', 'triplet': '1145:UT:SNTL', 'elevation': 7220, 'location': {'lat': 41.24764, 'lng': -111.41249}}, {'name': 'Kiln', 'triplet': '556:CO:SNTL', 'elevation': 9624, 'location': {'lat': 39.3172, 'lng': -106.61501}}, {'name': 'Kimberly Mine', 'triplet': '557:UT:SNTL', 'elevation': 9101, 'location': {'lat': 38.48383, 'lng': -112.39273}}, {'name': 'King Mountain', 'triplet': '558:OR:SNTL', 'elevation': 4340, 'location': {'lat': 42.72395, 'lng': -123.20037}}, {'name': 'Kings Cabin', 'triplet': '559:UT:SNTL', 'elevation': 8728, 'location': {'lat': 40.71632, 'lng': -109.54401}}, {'name': 'Kirwin', 'triplet': '560:WY:SNTL', 'elevation': 9550, 'location': {'lat': 43.86067, 'lng': -109.32163}}, {'name': 'Klondike Narrows', 'triplet': '1115:UT:SNTL', 'elevation': 7250, 'location': {'lat': 41.96769, 'lng': -111.59713}}, {'name': 'Kolob', 'triplet': '561:UT:SNTL', 'elevation': 9263, 'location': {'lat': 37.52664, 'lng': -113.05386}}, {'name': 'Kraft Creek', 'triplet': '562:MT:SNTL', 'elevation': 4750, 'location': {'lat': 47.42749, 'lng': -113.77515}}, {'name': 'Lake Creek R.S.', 'triplet': '563:OR:SNTL', 'elevation': 5240, 'location': {'lat': 44.21007, 'lng': -118.63752}}, {'name': 'Lake Eldora', 'triplet': '564:CO:SNTL', 'elevation': 9728, 'location': {'lat': 39.93659, 'lng': -105.59031}}, {'name': 'Lake Irene', 'triplet': '565:CO:SNTL', 'elevation': 10682, 'location': {'lat': 40.41446, 'lng': -105.81941}}, {'name': 'Lakefork #1', 'triplet': '566:UT:SNTL', 'elevation': 10128, 'location': {'lat': 40.59709, 'lng': -110.43316}}, {'name': 'Lakefork #3', 'triplet': '1116:UT:SNTL', 'elevation': 8464, 'location': {'lat': 40.5502, 'lng': -110.3529}}, {'name': 'Lakefork Basin', 'triplet': '513:UT:SNTL', 'elevation': 10885, 'location': {'lat': 40.73785, 'lng': -110.62121}}, {'name': 'Lakeview Ridge', 'triplet': '568:MT:SNTL', 'elevation': 7400, 'location': {'lat': 44.58907, 'lng': -111.82498}}, {'name': 'Lamance Creek', 'triplet': '569:NV:SNTL', 'elevation': 6395, 'location': {'lat': 41.51542, 'lng': -117.63197}}, {'name': 'Lamoille #3', 'triplet': '570:NV:SNTL', 'elevation': 8051, 'location': {'lat': 40.6448, 'lng': -115.3812}}, {'name': 'Lamoille Upper', 'triplet': '1310:NV:SNTL', 'elevation': 8993, 'location': {'lat': 40.59965, 'lng': -115.37902}}, {'name': 'Laprele Creek', 'triplet': '571:WY:SNTL', 'elevation': 8390, 'location': {'lat': 42.43566, 'lng': -105.86051}}, {'name': 'Larsen Creek', 'triplet': '1134:WY:SNTL', 'elevation': 9000, 'location': {'lat': 42.5801, 'lng': -109.0883}}, {'name': 'Lasal Mountain', 'triplet': '572:UT:SNTL', 'elevation': 9578, 'location': {'lat': 38.48226, 'lng': -109.27198}}, {'name': 'Lasal Mountain-Lower', 'triplet': '1215:UT:SNTL', 'elevation': 8783, 'location': {'lat': 38.48167, 'lng': -109.29164}}, {'name': 'Laurel Draw', 'triplet': '573:NV:SNTL', 'elevation': 6682, 'location': {'lat': 41.77637, 'lng': -116.02957}}, {'name': 'Leavitt Lake', 'triplet': '574:CA:SNTL', 'elevation': 9604, 'location': {'lat': 38.27594, 'lng': -119.61281}}, {'name': 'Leavitt Meadows', 'triplet': '575:CA:SNTL', 'elevation': 7198, 'location': {'lat': 38.30367, 'lng': -119.55111}}, {'name': 'Lee Canyon', 'triplet': '1112:NV:SNTL', 'elevation': 8626, 'location': {'lat': 36.30537, 'lng': -115.67508}}, {'name': 'Lemhi Ridge', 'triplet': '576:MT:SNTL', 'elevation': 8100, 'location': {'lat': 44.9938, 'lng': -113.44399}}, {'name': 'Lewis Lake Divide', 'triplet': '577:WY:SNTL', 'elevation': 7850, 'location': {'lat': 44.20862, 'lng': -110.66628}}, {'name': 'Lewis Peak', 'triplet': '1006:NV:SNTL', 'elevation': 7370, 'location': {'lat': 40.3572, 'lng': -116.8647}}, {'name': 'Lick Creek', 'triplet': '578:MT:SNTL', 'elevation': 6860, 'location': {'lat': 45.5041, 'lng': -110.96625}}, {'name': 'Lightning Ridge', 'triplet': '1056:UT:SNTL', 'elevation': 8215, 'location': {'lat': 41.35891, 'lng': -111.48749}}, {'name': 'Lily Lake', 'triplet': '579:UT:SNTL', 'elevation': 9133, 'location': {'lat': 40.86493, 'lng': -110.79813}}, {'name': 'Lily Pond', 'triplet': '580:CO:SNTL', 'elevation': 11069, 'location': {'lat': 37.38028, 'lng': -106.54823}}, {'name': 'Little Bear', 'triplet': '582:UT:SNTL', 'elevation': 6548, 'location': {'lat': 41.40562, 'lng': -111.82607}}, {'name': 'Little Chena Ridge', 'triplet': '947:AK:SNTL', 'elevation': 2000, 'location': {'lat': 65.12422, 'lng': -146.7339}}, {'name': 'Little Goose', 'triplet': '1131:WY:SNTL', 'elevation': 8870, 'location': {'lat': 44.54315, 'lng': -107.17865}}, {'name': 'Little Grassy', 'triplet': '583:UT:SNTL', 'elevation': 6065, 'location': {'lat': 37.48631, 'lng': -113.84582}}, {'name': 'Little Meadows', 'triplet': '584:OR:SNTL', 'elevation': 4020, 'location': {'lat': 44.61297, 'lng': -122.22565}}, {'name': 'Little Snake River', 'triplet': '1047:WY:SNTL', 'elevation': 8928, 'location': {'lat': 41.07051, 'lng': -106.94284}}, {'name': 'Little Valley', 'triplet': '1242:NV:SNTL', 'elevation': 6493, 'location': {'lat': 39.25259, 'lng': -119.8771}}, {'name': 'Little Warm', 'triplet': '585:WY:SNTL', 'elevation': 9370, 'location': {'lat': 43.50278, 'lng': -109.752}}, {'name': 'Lizard Head Pass', 'triplet': '586:CO:SNTL', 'elevation': 10193, 'location': {'lat': 37.79895, 'lng': -107.92475}}, {'name': 'Lobdell Lake', 'triplet': '587:CA:SNTL', 'elevation': 9249, 'location': {'lat': 38.43745, 'lng': -119.36572}}, {'name': 'Lolo Pass', 'triplet': '588:ID:SNTL', 'elevation': 5240, 'location': {'lat': 46.63448, 'lng': -114.58072}}, {'name': 'Lone Cone', 'triplet': '589:CO:SNTL', 'elevation': 9755, 'location': {'lat': 37.89169, 'lng': -108.19636}}, {'name': 'Lone Mountain', 'triplet': '590:MT:SNTL', 'elevation': 8880, 'location': {'lat': 45.27412, 'lng': -111.42692}}, {'name': 'Lone Pine', 'triplet': '591:WA:SNTL', 'elevation': 3930, 'location': {'lat': 46.27143, 'lng': -121.96288}}, {'name': 'Lonesome Beaver', 'triplet': '1261:UT:SNTL', 'elevation': 9410, 'location': {'lat': 38.07, 'lng': -110.77241}}, {'name': 'Long Draw Resv', 'triplet': '1123:CO:SNTL', 'elevation': 10008, 'location': {'lat': 40.51154, 'lng': -105.7654}}, {'name': 'Long Flat', 'triplet': '592:UT:SNTL', 'elevation': 7982, 'location': {'lat': 37.51255, 'lng': -113.39661}}, {'name': 'Long Lake', 'triplet': '1001:AK:SNTL', 'elevation': 850, 'location': {'lat': 58.186, 'lng': -133.83217}}, {'name': 'Long Valley', 'triplet': '1016:ID:SNTL', 'elevation': 4890, 'location': {'lat': 44.78835, 'lng': -116.08878}}, {'name': 'Long Valley Jct', 'triplet': '593:UT:SNTL', 'elevation': 7465, 'location': {'lat': 37.48756, 'lng': -112.51458}}, {'name': 'Lookout', 'triplet': '594:ID:SNTL', 'elevation': 5190, 'location': {'lat': 47.45749, 'lng': -115.70457}}, {'name': 'Lookout Mountain', 'triplet': '595:NM:SNTL', 'elevation': 8509, 'location': {'lat': 33.36089, 'lng': -107.83203}}, {'name': 'Lookout Peak', 'triplet': '596:UT:SNTL', 'elevation': 8161, 'location': {'lat': 40.83731, 'lng': -111.70965}}, {'name': 'Loomis Park', 'triplet': '597:WY:SNTL', 'elevation': 8240, 'location': {'lat': 43.17387, 'lng': -110.14007}}, {'name': 'Lost Creek Resv', 'triplet': '1118:UT:SNTL', 'elevation': 6082, 'location': {'lat': 41.22155, 'lng': -111.35947}}, {'name': 'Lost Dog', 'triplet': '940:CO:SNTL', 'elevation': 9327, 'location': {'lat': 40.81557, 'lng': -106.74833}}, {'name': 'Lost Horse', 'triplet': '599:WA:SNTL', 'elevation': 5120, 'location': {'lat': 46.3575, 'lng': -121.08095}}, {'name': 'Lost Lake', 'triplet': '600:ID:SNTL', 'elevation': 6110, 'location': {'lat': 47.0809, 'lng': -115.9604}}, {'name': 'Lost-Wood Divide', 'triplet': '601:ID:SNTL', 'elevation': 7900, 'location': {'lat': 43.82432, 'lng': -114.26402}}, {'name': 'Louis Meadow', 'triplet': '972:UT:SNTL', 'elevation': 6700, 'location': {'lat': 40.83033, 'lng': -111.76457}}, {'name': 'Loveland Basin', 'triplet': '602:CO:SNTL', 'elevation': 11427, 'location': {'lat': 39.67428, 'lng': -105.90264}}, {'name': 'Lower Kachemak Creek', 'triplet': '1265:AK:SNTL', 'elevation': 1915, 'location': {'lat': 59.73507, 'lng': -150.69327}}, {'name': 'Lower Twin', 'triplet': '603:MT:SNTL', 'elevation': 7900, 'location': {'lat': 45.50871, 'lng': -111.92288}}, {'name': 'Lubrecht Flume', 'triplet': '604:MT:SNTL', 'elevation': 4680, 'location': {'lat': 46.88293, 'lng': -113.32228}}, {'name': 'Lucky Strike', 'triplet': '605:OR:SNTL', 'elevation': 4970, 'location': {'lat': 45.27478, 'lng': -118.8479}}, {'name': 'Lyman Lake', 'triplet': '606:WA:SNTL', 'elevation': 5980, 'location': {'lat': 48.19798, 'lng': -120.91678}}, {'name': 'Lynn Lake', 'triplet': '1069:WA:SNTL', 'elevation': 3900, 'location': {'lat': 47.20172, 'lng': -121.77972}}, {'name': 'Lynx Pass', 'triplet': '607:CO:SNTL', 'elevation': 8919, 'location': {'lat': 40.07832, 'lng': -106.67095}}, {'name': 'Madison Butte', 'triplet': '608:OR:SNTL', 'elevation': 5150, 'location': {'lat': 45.10513, 'lng': -119.49585}}, {'name': 'Madison Plateau', 'triplet': '609:MT:SNTL', 'elevation': 7750, 'location': {'lat': 44.58623, 'lng': -111.11627}}, {'name': 'Magic Mountain', 'triplet': '610:ID:SNTL', 'elevation': 6880, 'location': {'lat': 42.18072, 'lng': -114.28662}}, {'name': 'Mammoth-Cottonwood', 'triplet': '612:UT:SNTL', 'elevation': 8709, 'location': {'lat': 39.68338, 'lng': -111.31818}}, {'name': 'Mancos', 'triplet': '905:CO:SNTL', 'elevation': 10044, 'location': {'lat': 37.43109, 'lng': -108.17005}}, {'name': 'Many Glacier', 'triplet': '613:MT:SNTL', 'elevation': 4900, 'location': {'lat': 48.79698, 'lng': -113.6705}}, {'name': 'Marion Forks', 'triplet': '614:OR:SNTL', 'elevation': 2590, 'location': {'lat': 44.59397, 'lng': -121.97365}}, {'name': 'Marlette Lake', 'triplet': '615:NV:SNTL', 'elevation': 7884, 'location': {'lat': 39.16395, 'lng': -119.89672}}, {'name': 'Marquette', 'triplet': '616:WY:SNTL', 'elevation': 8760, 'location': {'lat': 44.3016, 'lng': -109.24019}}, {'name': 'Marten Ridge', 'triplet': '999:WA:SNTL', 'elevation': 3520, 'location': {'lat': 48.76292, 'lng': -121.69823}}, {'name': 'Maverick Fork', 'triplet': '617:AZ:SNTL', 'elevation': 9220, 'location': {'lat': 33.92123, 'lng': -109.45872}}, {'name': 'May Creek', 'triplet': '1096:AK:SNTL', 'elevation': 1610, 'location': {'lat': 61.34783, 'lng': -142.70967}}, {'name': 'Mc Clure Pass', 'triplet': '618:CO:SNTL', 'elevation': 8774, 'location': {'lat': 39.12899, 'lng': -107.28834}}, {'name': 'Mccoy Park', 'triplet': '1040:CO:SNTL', 'elevation': 9516, 'location': {'lat': 39.60231, 'lng': -106.544}}, {'name': 'McGrath', 'triplet': '785:AK:SNTL', 'elevation': 340, 'location': {'lat': 62.94652, 'lng': -155.6102}}, {'name': 'Mckenzie', 'triplet': '619:OR:SNTL', 'elevation': 4770, 'location': {'lat': 44.2103, 'lng': -121.87292}}, {'name': 'Mcknight Cabin', 'triplet': '1048:NM:SNTL', 'elevation': 9242, 'location': {'lat': 33.00796, 'lng': -107.86982}}, {'name': 'Mcneil Canyon', 'triplet': '1003:AK:SNTL', 'elevation': 1320, 'location': {'lat': 59.74433, 'lng': -151.25133}}, {'name': 'Mcneil River SGS', 'triplet': '1191:AK:SNTL', 'elevation': 140, 'location': {'lat': 59.08332, 'lng': -154.27543}}, {'name': 'Meadow Lake', 'triplet': '620:ID:SNTL', 'elevation': 9150, 'location': {'lat': 44.43655, 'lng': -113.31815}}, {'name': 'Meadows Pass', 'triplet': '897:WA:SNTL', 'elevation': 3230, 'location': {'lat': 47.28312, 'lng': -121.47197}}, {'name': 'Med Bow', 'triplet': '1196:WY:SNTL', 'elevation': 10512, 'location': {'lat': 41.37833, 'lng': -106.34697}}, {'name': 'Medano Pass', 'triplet': '914:CO:SNTL', 'elevation': 9668, 'location': {'lat': 37.85192, 'lng': -105.43666}}, {'name': 'Merchant Valley', 'triplet': '621:UT:SNTL', 'elevation': 8705, 'location': {'lat': 38.30285, 'lng': -112.43637}}, {'name': 'Merritt Mountain', 'triplet': '1207:NV:SNTL', 'elevation': 6915, 'location': {'lat': 41.8927, 'lng': -115.858}}, {'name': 'Mesa Lakes', 'triplet': '622:CO:SNTL', 'elevation': 10168, 'location': {'lat': 39.05738, 'lng': -108.05756}}, {'name': 'MF Nooksack', 'triplet': '1011:WA:SNTL', 'elevation': 4970, 'location': {'lat': 48.82453, 'lng': -121.92951}}, {'name': 'Mica Creek', 'triplet': '623:ID:SNTL', 'elevation': 4510, 'location': {'lat': 47.15045, 'lng': -116.26643}}, {'name': 'Michigan Creek', 'triplet': '937:CO:SNTL', 'elevation': 10702, 'location': {'lat': 39.43579, 'lng': -105.91072}}, {'name': 'Midas', 'triplet': '1206:NV:SNTL', 'elevation': 6630, 'location': {'lat': 41.26873, 'lng': -116.80332}}, {'name': 'Middle Creek', 'triplet': '624:CO:SNTL', 'elevation': 11269, 'location': {'lat': 37.61779, 'lng': -107.03932}}, {'name': 'Middle Fork Bradley', 'triplet': '1064:AK:SNTL', 'elevation': 2300, 'location': {'lat': 59.77683, 'lng': -150.75733}}, {'name': 'Middle Fork Camp', 'triplet': '1014:CO:SNTL', 'elevation': 8969, 'location': {'lat': 39.79565, 'lng': -106.02802}}, {'name': 'Middle Powder', 'triplet': '625:WY:SNTL', 'elevation': 7760, 'location': {'lat': 43.62728, 'lng': -107.18138}}, {'name': 'Midway Valley', 'triplet': '626:UT:SNTL', 'elevation': 9827, 'location': {'lat': 37.56933, 'lng': -112.83849}}, {'name': 'Milk Shakes', 'triplet': '1079:OR:SNTL', 'elevation': 5580, 'location': {'lat': 45.9821, 'lng': -117.94883}}, {'name': 'Mill Creek Summit', 'triplet': '627:ID:SNTL', 'elevation': 8800, 'location': {'lat': 44.47212, 'lng': -114.48992}}, {'name': 'Mill-D North', 'triplet': '628:UT:SNTL', 'elevation': 8963, 'location': {'lat': 40.65883, 'lng': -111.63683}}, {'name': 'Miller Woods', 'triplet': '1084:OR:SNTL', 'elevation': 420, 'location': {'lat': 45.24755, 'lng': -123.27563}}, {'name': 'Mineral Creek', 'triplet': '629:CO:SNTL', 'elevation': 10046, 'location': {'lat': 37.84737, 'lng': -107.72657}}, {'name': 'Mining Fork', 'triplet': '631:UT:SNTL', 'elevation': 8295, 'location': {'lat': 40.49384, 'lng': -112.61141}}, {'name': 'Molas Lake', 'triplet': '632:CO:SNTL', 'elevation': 10631, 'location': {'lat': 37.74929, 'lng': -107.68933}}, {'name': 'Monahan Flat', 'triplet': '1094:AK:SNTL', 'elevation': 2710, 'location': {'lat': 63.30533, 'lng': -147.64633}}, {'name': 'Monitor Pass', 'triplet': '633:CA:SNTL', 'elevation': 8306, 'location': {'lat': 38.6683, 'lng': -119.6087}}, {'name': 'Monte Cristo', 'triplet': '634:UT:SNTL', 'elevation': 8932, 'location': {'lat': 41.46547, 'lng': -111.49688}}, {'name': 'Monument Creek', 'triplet': '949:AK:SNTL', 'elevation': 1850, 'location': {'lat': 65.07833, 'lng': -145.87067}}, {'name': 'Monument Peak', 'triplet': '635:MT:SNTL', 'elevation': 8850, 'location': {'lat': 45.21759, 'lng': -110.237}}, {'name': 'Moon Pass', 'triplet': '1124:CO:SNTL', 'elevation': 11128, 'location': {'lat': 37.96627, 'lng': -106.55857}}, {'name': 'Moonshine', 'triplet': '636:ID:SNTL', 'elevation': 7440, 'location': {'lat': 44.4147, 'lng': -113.39812}}, {'name': 'Moore Creek Bridge', 'triplet': '1176:AK:SNTL', 'elevation': 2250, 'location': {'lat': 59.58783, 'lng': -135.2105}}, {'name': 'Moose Creek', 'triplet': '638:ID:SNTL', 'elevation': 6200, 'location': {'lat': 45.67008, 'lng': -113.95315}}, {'name': 'Moraine', 'triplet': '1035:AK:SNTL', 'elevation': 2100, 'location': {'lat': 61.37727, 'lng': -148.99917}}, {'name': 'Mores Creek Summit', 'triplet': '637:ID:SNTL', 'elevation': 6100, 'location': {'lat': 43.932, 'lng': -115.66588}}, {'name': 'Morgan Creek', 'triplet': '639:ID:SNTL', 'elevation': 7600, 'location': {'lat': 44.84237, 'lng': -114.26871}}, {'name': 'Mormon Mountain', 'triplet': '640:AZ:SNTL', 'elevation': 7500, 'location': {'lat': 34.94141, 'lng': -111.51864}}, {'name': 'Mormon Mtn Summit', 'triplet': '1125:AZ:SNTL', 'elevation': 8462, 'location': {'lat': 34.96942, 'lng': -111.50868}}, {'name': 'Morse Lake', 'triplet': '642:WA:SNTL', 'elevation': 5410, 'location': {'lat': 46.90585, 'lng': -121.4827}}, {'name': 'Mosby Mtn.', 'triplet': '643:UT:SNTL', 'elevation': 9553, 'location': {'lat': 40.60798, 'lng': -109.8881}}, {'name': 'Moscow Mountain', 'triplet': '989:ID:SNTL', 'elevation': 4700, 'location': {'lat': 46.805, 'lng': -116.8535}}, {'name': 'Moses Mtn', 'triplet': '644:WA:SNTL', 'elevation': 5010, 'location': {'lat': 48.36163, 'lng': -119.08159}}, {'name': 'Mosquito Ridge', 'triplet': '645:ID:SNTL', 'elevation': 5260, 'location': {'lat': 48.05726, 'lng': -116.23055}}, {'name': 'Moss Peak', 'triplet': '646:MT:SNTL', 'elevation': 6780, 'location': {'lat': 47.68493, 'lng': -113.9623}}, {'name': 'Moss Springs', 'triplet': '647:OR:SNTL', 'elevation': 5760, 'location': {'lat': 45.27173, 'lng': -117.68747}}, {'name': 'Mount Crag', 'triplet': '648:WA:SNTL', 'elevation': 3960, 'location': {'lat': 47.7637, 'lng': -123.026}}, {'name': 'Mount Gardner', 'triplet': '898:WA:SNTL', 'elevation': 2920, 'location': {'lat': 47.35768, 'lng': -121.56812}}, {'name': 'Mount Lockhart', 'triplet': '649:MT:SNTL', 'elevation': 6400, 'location': {'lat': 47.91727, 'lng': -112.8238}}, {'name': 'Mountain Meadows', 'triplet': '650:ID:SNTL', 'elevation': 6320, 'location': {'lat': 45.69694, 'lng': -115.22972}}, {'name': 'Mowich', 'triplet': '941:WA:SNTL', 'elevation': 3160, 'location': {'lat': 46.92833, 'lng': -121.95232}}, {'name': 'Mt Baldy', 'triplet': '1224:UT:SNTL', 'elevation': 9524, 'location': {'lat': 39.13648, 'lng': -111.50527}}, {'name': 'Mt Hood Test Site', 'triplet': '651:OR:SNTL', 'elevation': 5370, 'location': {'lat': 45.32097, 'lng': -121.7158}}, {'name': 'Mt Pennell', 'triplet': '1269:UT:SNTL', 'elevation': 9209, 'location': {'lat': 37.97793, 'lng': -110.7933}}, {'name': 'Mt Rose Ski Area', 'triplet': '652:NV:SNTL', 'elevation': 8801, 'location': {'lat': 39.31573, 'lng': -119.89473}}, {'name': 'Mt. Alyeska', 'triplet': '1103:AK:SNTL', 'elevation': 1540, 'location': {'lat': 60.95983, 'lng': -149.08617}}, {'name': 'Mt. Eyak', 'triplet': '1073:AK:SNTL', 'elevation': 1405, 'location': {'lat': 60.55, 'lng': -145.745}}, {'name': 'Mt. Howard', 'triplet': '653:OR:SNTL', 'elevation': 7910, 'location': {'lat': 45.26522, 'lng': -117.17373}}, {'name': 'Mt. Ryan', 'triplet': '948:AK:SNTL', 'elevation': 2800, 'location': {'lat': 65.25113, 'lng': -146.15133}}, {'name': 'Mt. Tebo', 'triplet': '1126:WA:SNTL', 'elevation': 3384, 'location': {'lat': 47.46061, 'lng': -123.41219}}, {'name': 'Muckamuck', 'triplet': '1259:WA:SNTL', 'elevation': 4470, 'location': {'lat': 48.58526, 'lng': -119.86624}}, {'name': 'Mud Flat', 'triplet': '654:ID:SNTL', 'elevation': 5730, 'location': {'lat': 42.6004, 'lng': -116.55925}}, {'name': 'Mud Ridge', 'triplet': '655:OR:SNTL', 'elevation': 4070, 'location': {'lat': 45.25362, 'lng': -121.73673}}, {'name': 'Mule Creek', 'triplet': '656:MT:SNTL', 'elevation': 8300, 'location': {'lat': 45.40957, 'lng': -112.95927}}, {'name': 'Munson Ridge', 'triplet': '950:AK:SNTL', 'elevation': 3100, 'location': {'lat': 64.85033, 'lng': -146.20945}}, {'name': 'Myrtle Creek', 'triplet': '1053:ID:SNTL', 'elevation': 3520, 'location': {'lat': 48.72263, 'lng': -116.46312}}, {'name': 'N Fk Elk Creek', 'triplet': '657:MT:SNTL', 'elevation': 6250, 'location': {'lat': 46.8716, 'lng': -113.27725}}, {'name': 'Nast Lake', 'triplet': '658:CO:SNTL', 'elevation': 8731, 'location': {'lat': 39.29695, 'lng': -106.60786}}, {'name': 'Navajo Whiskey Ck', 'triplet': '1138:NM:SNTL', 'elevation': 9064, 'location': {'lat': 36.17716, 'lng': -108.94556}}, {'name': 'Nenana', 'triplet': '2081:AK:SNTL', 'elevation': 415, 'location': {'lat': 64.68582, 'lng': -148.9113}}, {'name': 'Nevada Ridge', 'triplet': '903:MT:SNTL', 'elevation': 7020, 'location': {'lat': 46.84234, 'lng': -112.50787}}, {'name': 'Never Summer', 'triplet': '1031:CO:SNTL', 'elevation': 10323, 'location': {'lat': 40.40392, 'lng': -105.95567}}, {'name': 'New Crescent Lake', 'triplet': '660:OR:SNTL', 'elevation': 4910, 'location': {'lat': 43.51185, 'lng': -121.97982}}, {'name': 'New Fork Lake', 'triplet': '661:WY:SNTL', 'elevation': 8340, 'location': {'lat': 43.11265, 'lng': -109.94947}}, {'name': 'Nez Perce Camp', 'triplet': '662:MT:SNTL', 'elevation': 5650, 'location': {'lat': 45.73107, 'lng': -114.48075}}, {'name': 'Niwot', 'triplet': '663:CO:SNTL', 'elevation': 9979, 'location': {'lat': 40.03581, 'lng': -105.5452}}, {'name': 'Noisy Basin', 'triplet': '664:MT:SNTL', 'elevation': 6040, 'location': {'lat': 48.15678, 'lng': -113.94637}}, {'name': 'North Costilla', 'triplet': '665:NM:SNTL', 'elevation': 10598, 'location': {'lat': 36.99396, 'lng': -105.25988}}, {'name': 'North Fork', 'triplet': '666:OR:SNTL', 'elevation': 3060, 'location': {'lat': 45.5505, 'lng': -122.00283}}, {'name': 'North Fork Jocko', 'triplet': '667:MT:SNTL', 'elevation': 6330, 'location': {'lat': 47.2726, 'lng': -113.75617}}, {'name': 'North French Creek', 'triplet': '668:WY:SNTL', 'elevation': 10153, 'location': {'lat': 41.33087, 'lng': -106.37558}}, {'name': 'North Lost Trail', 'triplet': '669:CO:SNTL', 'elevation': 9219, 'location': {'lat': 39.07818, 'lng': -107.14388}}, {'name': 'North Rapid Creek', 'triplet': '920:SD:SNTL', 'elevation': 6130, 'location': {'lat': 44.20617, 'lng': -103.78758}}, {'name': 'Northeast Entrance', 'triplet': '670:MT:SNTL', 'elevation': 7350, 'location': {'lat': 45.00565, 'lng': -110.01406}}, {'name': 'Nuka Glacier', 'triplet': '1037:AK:SNTL', 'elevation': 1250, 'location': {'lat': 59.69867, 'lng': -150.70967}}, {'name': 'Nutrioso', 'triplet': '1127:AZ:SNTL', 'elevation': 8571, 'location': {'lat': 33.89791, 'lng': -109.15465}}, {'name': 'Oak Creek', 'triplet': '1146:UT:SNTL', 'elevation': 7850, 'location': {'lat': 39.3485, 'lng': -112.32639}}, {'name': 'Ochoco Meadows', 'triplet': '671:OR:SNTL', 'elevation': 5430, 'location': {'lat': 44.42917, 'lng': -120.3311}}, {'name': 'Olallie Meadows', 'triplet': '672:WA:SNTL', 'elevation': 4030, 'location': {'lat': 47.37406, 'lng': -121.44213}}, {'name': 'ONeil Creek', 'triplet': '1272:NV:SNTL', 'elevation': 6520, 'location': {'lat': 41.8642, 'lng': -115.08316}}, {'name': 'Onion Park', 'triplet': '1008:MT:SNTL', 'elevation': 7410, 'location': {'lat': 46.91348, 'lng': -110.8536}}, {'name': 'Overland Res.', 'triplet': '675:CO:SNTL', 'elevation': 9893, 'location': {'lat': 39.09035, 'lng': -107.63583}}, {'name': 'Owl Creek', 'triplet': '676:WY:SNTL', 'elevation': 8975, 'location': {'lat': 43.65868, 'lng': -109.00988}}, {'name': 'Oxford Spring', 'triplet': '677:ID:SNTL', 'elevation': 6740, 'location': {'lat': 42.26015, 'lng': -112.12515}}, {'name': 'Palisades Tahoe', 'triplet': '784:CA:SNTL', 'elevation': 8013, 'location': {'lat': 39.18986, 'lng': -120.26576}}, {'name': 'Palo', 'triplet': '1170:NM:SNTL', 'elevation': 9343, 'location': {'lat': 36.40869, 'lng': -105.33038}}, {'name': 'Panguitch Lake RS', 'triplet': '1148:UT:SNTL', 'elevation': 8350, 'location': {'lat': 37.70463, 'lng': -112.65037}}, {'name': 'Paradise', 'triplet': '679:WA:SNTL', 'elevation': 5130, 'location': {'lat': 46.78265, 'lng': -121.74765}}, {'name': 'Paradise Hill', 'triplet': '1301:AK:SNTL', 'elevation': 2010, 'location': {'lat': 62.83329, 'lng': -141.40918}}, {'name': 'Pargon Creek', 'triplet': '986:AK:SNTL', 'elevation': 100, 'location': {'lat': 64.9935, 'lng': -163.10317}}, {'name': 'Park Cone', 'triplet': '680:CO:SNTL', 'elevation': 9621, 'location': {'lat': 38.81982, 'lng': -106.58962}}, {'name': 'Park Creek Ridge', 'triplet': '681:WA:SNTL', 'elevation': 4600, 'location': {'lat': 48.44488, 'lng': -120.91551}}, {'name': 'Park Reservoir', 'triplet': '682:CO:SNTL', 'elevation': 9987, 'location': {'lat': 39.04433, 'lng': -107.87951}}, {'name': 'Parker Peak', 'triplet': '683:WY:SNTL', 'elevation': 9400, 'location': {'lat': 44.73396, 'lng': -109.91484}}, {'name': 'Parleys Summit', 'triplet': '684:UT:SNTL', 'elevation': 7585, 'location': {'lat': 40.76184, 'lng': -111.62917}}, {'name': 'Parleys Upper', 'triplet': '856:UT:SNTL', 'elevation': 8353, 'location': {'lat': 40.70194, 'lng': -111.60619}}, {'name': 'Parrish Creek', 'triplet': '971:UT:SNTL', 'elevation': 7740, 'location': {'lat': 40.93417, 'lng': -111.81372}}, {'name': 'Payson R.S.', 'triplet': '686:UT:SNTL', 'elevation': 8044, 'location': {'lat': 39.92976, 'lng': -111.63109}}, {'name': 'Peavine Ridge', 'triplet': '687:OR:SNTL', 'elevation': 3420, 'location': {'lat': 45.04148, 'lng': -121.93252}}, {'name': 'Pebble Creek', 'triplet': '1299:ID:SNTL', 'elevation': 6513, 'location': {'lat': 42.7674, 'lng': -112.10648}}, {'name': 'Pepper Creek', 'triplet': '1104:WA:SNTL', 'elevation': 2140, 'location': {'lat': 46.10242, 'lng': -121.95555}}, {'name': 'Peterson Meadows', 'triplet': '930:MT:SNTL', 'elevation': 7200, 'location': {'lat': 46.12588, 'lng': -113.30792}}, {'name': 'Phantom Valley', 'triplet': '688:CO:SNTL', 'elevation': 9045, 'location': {'lat': 40.39803, 'lng': -105.84606}}, {'name': 'Phillips Bench', 'triplet': '689:WY:SNTL', 'elevation': 8200, 'location': {'lat': 43.51687, 'lng': -110.91258}}, {'name': 'Pickfoot Creek', 'triplet': '690:MT:SNTL', 'elevation': 6650, 'location': {'lat': 46.57978, 'lng': -111.26832}}, {'name': 'Pickle Keg', 'triplet': '691:UT:SNTL', 'elevation': 9020, 'location': {'lat': 39.01219, 'lng': -111.58259}}, {'name': 'Pierce R.S.', 'triplet': '1142:ID:SNTL', 'elevation': 3080, 'location': {'lat': 46.49597, 'lng': -115.7957}}, {'name': 'Pigtail Peak', 'triplet': '692:WA:SNTL', 'elevation': 5800, 'location': {'lat': 46.62153, 'lng': -121.38643}}, {'name': 'Pike Creek', 'triplet': '693:MT:SNTL', 'elevation': 5930, 'location': {'lat': 48.30305, 'lng': -113.32868}}, {'name': 'Pine Creek', 'triplet': '694:UT:SNTL', 'elevation': 8734, 'location': {'lat': 38.88185, 'lng': -112.24915}}, {'name': 'Pine Creek Pass', 'triplet': '695:ID:SNTL', 'elevation': 6720, 'location': {'lat': 43.56998, 'lng': -111.21157}}, {'name': 'Pinto Rock', 'triplet': '1263:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.32318, 'lng': -121.94219}}, {'name': 'Placer Basin', 'triplet': '696:MT:SNTL', 'elevation': 8830, 'location': {'lat': 45.41905, 'lng': -110.08844}}, {'name': 'Pocket Creek', 'triplet': '1133:WY:SNTL', 'elevation': 9360, 'location': {'lat': 42.7121, 'lng': -109.4112}}, {'name': 'Poison Flat', 'triplet': '697:CA:SNTL', 'elevation': 7736, 'location': {'lat': 38.50576, 'lng': -119.62624}}, {'name': 'Pole Canyon', 'triplet': '1244:NV:SNTL', 'elevation': 7760, 'location': {'lat': 40.86293, 'lng': -115.12067}}, {'name': 'Pole Creek R.S.', 'triplet': '698:NV:SNTL', 'elevation': 8360, 'location': {'lat': 41.87255, 'lng': -115.24713}}, {'name': 'Poorman Creek', 'triplet': '932:MT:SNTL', 'elevation': 5100, 'location': {'lat': 48.12672, 'lng': -115.62333}}, {'name': 'Pope Ridge', 'triplet': '699:WA:SNTL', 'elevation': 3590, 'location': {'lat': 47.9909, 'lng': -120.56622}}, {'name': 'Porcupine', 'triplet': '700:MT:SNTL', 'elevation': 6500, 'location': {'lat': 46.11192, 'lng': -110.4696}}, {'name': 'Porphyry Creek', 'triplet': '701:CO:SNTL', 'elevation': 10788, 'location': {'lat': 38.48864, 'lng': -106.33967}}, {'name': 'Port Graham', 'triplet': '987:AK:SNTL', 'elevation': 300, 'location': {'lat': 59.35065, 'lng': -151.84768}}, {'name': 'Porter Canyon', 'triplet': '2170:NV:SNTL', 'elevation': 7187, 'location': {'lat': 39.46544, 'lng': -117.62069}}, {'name': 'Potato Hill', 'triplet': '702:WA:SNTL', 'elevation': 4510, 'location': {'lat': 46.34963, 'lng': -121.51435}}, {'name': 'Powder Mountain', 'triplet': '1300:UT:SNTL', 'elevation': 8505, 'location': {'lat': 41.37428, 'lng': -111.76673}}, {'name': 'Powder River Pass', 'triplet': '703:WY:SNTL', 'elevation': 9480, 'location': {'lat': 44.16188, 'lng': -107.12622}}, {'name': 'Prairie', 'triplet': '704:ID:SNTL', 'elevation': 4800, 'location': {'lat': 43.50513, 'lng': -115.573}}, {'name': 'Promontory', 'triplet': '705:AZ:SNTL', 'elevation': 7942, 'location': {'lat': 34.36848, 'lng': -111.01088}}, {'name': 'Prudhoe Bay', 'triplet': '1177:AK:SNTL', 'elevation': 30, 'location': {'lat': 70.26666, 'lng': -148.56666}}, {'name': 'Quartz Mountain', 'triplet': '706:OR:SNTL', 'elevation': 5720, 'location': {'lat': 42.31923, 'lng': -120.82533}}, {'name': 'Quartz Peak', 'triplet': '707:WA:SNTL', 'elevation': 4700, 'location': {'lat': 47.87927, 'lng': -117.08938}}, {'name': 'Quemazon', 'triplet': '708:NM:SNTL', 'elevation': 9507, 'location': {'lat': 35.92195, 'lng': -106.39179}}, {'name': 'Rabbit Ears', 'triplet': '709:CO:SNTL', 'elevation': 9411, 'location': {'lat': 40.36735, 'lng': -106.74118}}, {'name': 'Ragged Mountain', 'triplet': '1081:ID:SNTL', 'elevation': 4210, 'location': {'lat': 47.85583, 'lng': -117.03667}}, {'name': 'Railroad Overpass', 'triplet': '710:OR:SNTL', 'elevation': 2680, 'location': {'lat': 43.65887, 'lng': -122.21272}}, {'name': 'Rainbow Canyon', 'triplet': '1110:NV:SNTL', 'elevation': 7860, 'location': {'lat': 36.2493, 'lng': -115.62972}}, {'name': 'Rainy Pass', 'triplet': '711:WA:SNTL', 'elevation': 4890, 'location': {'lat': 48.51865, 'lng': -120.7358}}, {'name': 'Rawah', 'triplet': '1032:CO:SNTL', 'elevation': 9069, 'location': {'lat': 40.70794, 'lng': -106.00727}}, {'name': 'Red Hill', 'triplet': '712:OR:SNTL', 'elevation': 4410, 'location': {'lat': 45.4643, 'lng': -121.70428}}, {'name': 'Red Mountain Pass', 'triplet': '713:CO:SNTL', 'elevation': 11080, 'location': {'lat': 37.89168, 'lng': -107.71389}}, {'name': 'Red Pine Ridge', 'triplet': '714:UT:SNTL', 'elevation': 8988, 'location': {'lat': 39.45197, 'lng': -111.27221}}, {'name': 'Red River Pass #2', 'triplet': '715:NM:SNTL', 'elevation': 9855, 'location': {'lat': 36.69935, 'lng': -105.34145}}, {'name': 'Redden Mine Lwr', 'triplet': '1225:UT:SNTL', 'elevation': 8532, 'location': {'lat': 40.67505, 'lng': -111.21765}}, {'name': 'Rees Flat', 'triplet': '1217:UT:SNTL', 'elevation': 7206, 'location': {'lat': 39.49667, 'lng': -111.72508}}, {'name': 'Reno Hill', 'triplet': '716:WY:SNTL', 'elevation': 8430, 'location': {'lat': 42.57089, 'lng': -106.08969}}, {'name': 'Rex River', 'triplet': '911:WA:SNTL', 'elevation': 3810, 'location': {'lat': 47.30218, 'lng': -121.60475}}, {'name': 'Reynolds Creek', 'triplet': '2029:ID:SNTL', 'elevation': 5600, 'location': {'lat': 43.28863, 'lng': -116.8431}}, {'name': 'Rice Park', 'triplet': '933:NM:SNTL', 'elevation': 8497, 'location': {'lat': 35.23658, 'lng': -108.27404}}, {'name': 'Rio Santa Barbara', 'triplet': '1254:NM:SNTL', 'elevation': 10664, 'location': {'lat': 36.07196, 'lng': -105.62949}}, {'name': 'Ripple Creek', 'triplet': '717:CO:SNTL', 'elevation': 10350, 'location': {'lat': 40.10844, 'lng': -107.29383}}, {'name': 'Roach', 'triplet': '718:CO:SNTL', 'elevation': 9740, 'location': {'lat': 40.87498, 'lng': -106.04675}}, {'name': 'Roaring River', 'triplet': '719:OR:SNTL', 'elevation': 4950, 'location': {'lat': 43.90098, 'lng': -122.03063}}, {'name': 'Rock Creek', 'triplet': '720:UT:SNTL', 'elevation': 7886, 'location': {'lat': 40.54875, 'lng': -110.69292}}, {'name': 'Rock Springs', 'triplet': '721:OR:SNTL', 'elevation': 5290, 'location': {'lat': 44.00883, 'lng': -118.83842}}, {'name': 'Rocker Peak', 'triplet': '722:MT:SNTL', 'elevation': 8000, 'location': {'lat': 46.35613, 'lng': -112.26176}}, {'name': 'Rockwood GS', 'triplet': '1309:UT:SNTL', 'elevation': 8593, 'location': {'lat': 38.67101, 'lng': -112.3305}}, {'name': 'Rocky Basin-Settleme', 'triplet': '723:UT:SNTL', 'elevation': 8704, 'location': {'lat': 40.44293, 'lng': -112.22377}}, {'name': 'Rocky Boy', 'triplet': '917:MT:SNTL', 'elevation': 4700, 'location': {'lat': 48.17478, 'lng': -109.64728}}, {'name': 'Rocky Point', 'triplet': '973:AK:SNTL', 'elevation': 250, 'location': {'lat': 64.53482, 'lng': -163.4214}}, {'name': 'Rough And Tumble', 'triplet': '939:CO:SNTL', 'elevation': 10432, 'location': {'lat': 39.02611, 'lng': -106.08063}}, {'name': 'Rubicon #2', 'triplet': '724:CA:SNTL', 'elevation': 7619, 'location': {'lat': 38.99927, 'lng': -120.13139}}, {'name': 'S Fork Shields', 'triplet': '725:MT:SNTL', 'elevation': 8100, 'location': {'lat': 46.0896, 'lng': -110.43363}}, {'name': 'Sacajawea', 'triplet': '929:MT:SNTL', 'elevation': 6550, 'location': {'lat': 45.87395, 'lng': -110.92783}}, {'name': 'Saddle Mountain', 'triplet': '726:OR:SNTL', 'elevation': 3110, 'location': {'lat': 45.54477, 'lng': -123.37315}}, {'name': 'Saddle Mtn.', 'triplet': '727:MT:SNTL', 'elevation': 7940, 'location': {'lat': 45.69259, 'lng': -113.96828}}, {'name': 'Sage Creek Basin', 'triplet': '1015:WY:SNTL', 'elevation': 7850, 'location': {'lat': 41.40107, 'lng': -107.2574}}, {'name': 'Sagwon', 'triplet': '1183:AK:SNTL', 'elevation': 1000, 'location': {'lat': 69.42417, 'lng': -148.6925}}, {'name': 'Saint Elmo', 'triplet': '1100:CO:SNTL', 'elevation': 10450, 'location': {'lat': 38.69985, 'lng': -106.36805}}, {'name': 'Salmon Meadows', 'triplet': '728:WA:SNTL', 'elevation': 4460, 'location': {'lat': 48.65518, 'lng': -119.8383}}, {'name': 'Salt Creek Falls', 'triplet': '729:OR:SNTL', 'elevation': 4220, 'location': {'lat': 43.61193, 'lng': -122.11758}}, {'name': 'Salt River Summit', 'triplet': '730:WY:SNTL', 'elevation': 7640, 'location': {'lat': 42.5075, 'lng': -110.9099}}, {'name': 'San Antonio Sink', 'triplet': '1172:NM:SNTL', 'elevation': 9143, 'location': {'lat': 36.85967, 'lng': -106.22657}}, {'name': 'Sand Lake', 'triplet': '731:WY:SNTL', 'elevation': 10098, 'location': {'lat': 41.4625, 'lng': -106.281}}, {'name': 'Sandstone RS', 'triplet': '732:WY:SNTL', 'elevation': 8152, 'location': {'lat': 41.11179, 'lng': -107.17043}}, {'name': 'Santa Fe', 'triplet': '922:NM:SNTL', 'elevation': 11465, 'location': {'lat': 35.77154, 'lng': -105.78487}}, {'name': 'Santaquin Meadows', 'triplet': '1280:UT:SNTL', 'elevation': 7835, 'location': {'lat': 39.92076, 'lng': -111.71802}}, {'name': 'Santiam Jct.', 'triplet': '733:OR:SNTL', 'elevation': 3740, 'location': {'lat': 44.43503, 'lng': -121.94502}}, {'name': 'Sargents Mesa', 'triplet': '1128:CO:SNTL', 'elevation': 11499, 'location': {'lat': 38.2856, 'lng': -106.37085}}, {'name': 'Sasse Ridge', 'triplet': '734:WA:SNTL', 'elevation': 4340, 'location': {'lat': 47.38485, 'lng': -121.06323}}, {'name': 'Satus Pass', 'triplet': '1231:WA:SNTL', 'elevation': 3960, 'location': {'lat': 45.98797, 'lng': -120.67734}}, {'name': 'Savage Pass', 'triplet': '735:ID:SNTL', 'elevation': 6190, 'location': {'lat': 46.46633, 'lng': -114.63333}}, {'name': 'Sawmill Ridge', 'triplet': '1068:WA:SNTL', 'elevation': 4640, 'location': {'lat': 47.15992, 'lng': -121.42172}}, {'name': 'Sawtooth', 'triplet': '1251:CO:SNTL', 'elevation': 9676, 'location': {'lat': 40.13632, 'lng': -105.58486}}, {'name': 'Schneider Meadows', 'triplet': '736:OR:SNTL', 'elevation': 5400, 'location': {'lat': 45.00107, 'lng': -117.16522}}, {'name': 'Schofield Pass', 'triplet': '737:CO:SNTL', 'elevation': 10653, 'location': {'lat': 39.01467, 'lng': -107.04933}}, {'name': 'Schwartz Lake', 'triplet': '915:ID:SNTL', 'elevation': 8630, 'location': {'lat': 44.84618, 'lng': -113.83732}}, {'name': 'Schweitzer Basin', 'triplet': '738:ID:SNTL', 'elevation': 6090, 'location': {'lat': 48.37428, 'lng': -116.63917}}, {'name': 'Scotch Creek', 'triplet': '739:CO:SNTL', 'elevation': 9195, 'location': {'lat': 37.64562, 'lng': -108.00833}}, {'name': 'Secesh Summit', 'triplet': '740:ID:SNTL', 'elevation': 6540, 'location': {'lat': 45.18848, 'lng': -115.97152}}, {'name': 'Sedgwick Peak', 'triplet': '741:ID:SNTL', 'elevation': 7850, 'location': {'lat': 42.52497, 'lng': -111.95635}}, {'name': 'Seeley Creek', 'triplet': '742:UT:SNTL', 'elevation': 9904, 'location': {'lat': 39.31042, 'lng': -111.43297}}, {'name': 'Seine Creek', 'triplet': '743:OR:SNTL', 'elevation': 2060, 'location': {'lat': 45.52688, 'lng': -123.29857}}, {'name': 'Senorita Divide #2', 'triplet': '744:NM:SNTL', 'elevation': 8569, 'location': {'lat': 36.00152, 'lng': -106.83408}}, {'name': 'Sentinel Butte', 'triplet': '1043:WA:SNTL', 'elevation': 4680, 'location': {'lat': 48.86133, 'lng': -118.39843}}, {'name': 'Sevenmile Marsh', 'triplet': '745:OR:SNTL', 'elevation': 5700, 'location': {'lat': 42.69825, 'lng': -122.14165}}, {'name': 'Seventysix Creek', 'triplet': '746:NV:SNTL', 'elevation': 7350, 'location': {'lat': 41.73732, 'lng': -115.47215}}, {'name': 'Shanghi Summit', 'triplet': '747:ID:SNTL', 'elevation': 4600, 'location': {'lat': 46.56603, 'lng': -115.74216}}, {'name': 'Sharkstooth', 'triplet': '1060:CO:SNTL', 'elevation': 10747, 'location': {'lat': 37.50356, 'lng': -108.11405}}, {'name': 'Sheep Canyon', 'triplet': '748:WA:SNTL', 'elevation': 3990, 'location': {'lat': 46.19325, 'lng': -122.25393}}, {'name': 'Sheep Mtn.', 'triplet': '749:ID:SNTL', 'elevation': 6650, 'location': {'lat': 43.2103, 'lng': -111.68792}}, {'name': 'Sheldon', 'triplet': '750:NV:SNTL', 'elevation': 5865, 'location': {'lat': 41.90435, 'lng': -119.44464}}, {'name': 'Shell Creek', 'triplet': '751:WY:SNTL', 'elevation': 9580, 'location': {'lat': 44.50012, 'lng': -107.42947}}, {'name': 'Sherwin', 'triplet': '752:ID:SNTL', 'elevation': 3200, 'location': {'lat': 46.95028, 'lng': -116.33972}}, {'name': 'Short Creek', 'triplet': '753:MT:SNTL', 'elevation': 7000, 'location': {'lat': 44.97572, 'lng': -111.95215}}, {'name': 'Shower Falls', 'triplet': '754:MT:SNTL', 'elevation': 8100, 'location': {'lat': 45.40125, 'lng': -110.95758}}, {'name': 'Shuree', 'triplet': '1169:NM:SNTL', 'elevation': 10092, 'location': {'lat': 36.78765, 'lng': -105.2392}}, {'name': 'Sierra Blanca', 'triplet': '1034:NM:SNTL', 'elevation': 10268, 'location': {'lat': 33.40682, 'lng': -105.79467}}, {'name': 'Signal Peak', 'triplet': '755:NM:SNTL', 'elevation': 8405, 'location': {'lat': 32.92342, 'lng': -108.14546}}, {'name': 'Silver Creek', 'triplet': '756:OR:SNTL', 'elevation': 5740, 'location': {'lat': 42.95615, 'lng': -121.18123}}, {'name': 'Silver Creek Divide', 'triplet': '757:NM:SNTL', 'elevation': 9096, 'location': {'lat': 33.3696, 'lng': -108.70711}}, {'name': 'Silver Creek Nv', 'triplet': '1205:NV:SNTL', 'elevation': 8200, 'location': {'lat': 39.23305, 'lng': -114.2429}}, {'name': 'Silvies', 'triplet': '759:OR:SNTL', 'elevation': 6990, 'location': {'lat': 42.75333, 'lng': -118.68785}}, {'name': 'Skalkaho Summit', 'triplet': '760:MT:SNTL', 'elevation': 7250, 'location': {'lat': 46.24212, 'lng': -113.7725}}, {'name': 'Skate Creek', 'triplet': '1257:WA:SNTL', 'elevation': 3770, 'location': {'lat': 46.64336, 'lng': -121.83044}}, {'name': 'Skookum Creek', 'triplet': '912:WA:SNTL', 'elevation': 3310, 'location': {'lat': 47.68433, 'lng': -121.61007}}, {'name': 'Slagamelt Lakes', 'triplet': '1286:MT:SNTL', 'elevation': 8620, 'location': {'lat': 45.36526, 'lng': -113.71834}}, {'name': 'Sleeping Woman', 'triplet': '783:MT:SNTL', 'elevation': 6150, 'location': {'lat': 47.17902, 'lng': -114.33368}}, {'name': 'Slug Creek Divide', 'triplet': '761:ID:SNTL', 'elevation': 7225, 'location': {'lat': 42.56248, 'lng': -111.29797}}, {'name': 'Slumgullion', 'triplet': '762:CO:SNTL', 'elevation': 11560, 'location': {'lat': 37.99076, 'lng': -107.20392}}, {'name': 'Smiley Mountain', 'triplet': '926:ID:SNTL', 'elevation': 9520, 'location': {'lat': 43.72718, 'lng': -113.83402}}, {'name': 'Smith  Morehouse', 'triplet': '763:UT:SNTL', 'elevation': 7631, 'location': {'lat': 40.78931, 'lng': -111.09192}}, {'name': 'Smith Ridge', 'triplet': '1167:OR:SNTL', 'elevation': 3270, 'location': {'lat': 44.30325, 'lng': -122.04053}}, {'name': 'Snake River Station', 'triplet': '764:WY:SNTL', 'elevation': 6920, 'location': {'lat': 44.13361, 'lng': -110.66917}}, {'name': 'Snider Basin', 'triplet': '765:WY:SNTL', 'elevation': 8060, 'location': {'lat': 42.4949, 'lng': -110.53203}}, {'name': 'Snow Mountain', 'triplet': '767:OR:SNTL', 'elevation': 6230, 'location': {'lat': 43.94885, 'lng': -119.54013}}, {'name': 'Snowbird', 'triplet': '766:UT:SNTL', 'elevation': 9177, 'location': {'lat': 40.56914, 'lng': -111.65852}}, {'name': 'Snowslide Canyon', 'triplet': '927:AZ:SNTL', 'elevation': 9744, 'location': {'lat': 35.34179, 'lng': -111.65084}}, {'name': 'Snowstorm Mtn', 'triplet': '1208:NV:SNTL', 'elevation': 7403, 'location': {'lat': 41.33981, 'lng': -116.98044}}, {'name': 'Soldier Park', 'triplet': '1132:WY:SNTL', 'elevation': 8720, 'location': {'lat': 44.34847, 'lng': -107.0136}}, {'name': 'Soldier R.S.', 'triplet': '769:ID:SNTL', 'elevation': 5740, 'location': {'lat': 43.48407, 'lng': -114.82692}}, {'name': 'Somsen Ranch', 'triplet': '770:ID:SNTL', 'elevation': 6800, 'location': {'lat': 42.95275, 'lng': -111.35933}}, {'name': 'Sonora Pass', 'triplet': '771:CA:SNTL', 'elevation': 8770, 'location': {'lat': 38.31021, 'lng': -119.6003}}, {'name': 'Sourdough Gulch', 'triplet': '985:WA:SNTL', 'elevation': 4000, 'location': {'lat': 46.23718, 'lng': -117.39438}}, {'name': 'South Brush Creek', 'triplet': '772:WY:SNTL', 'elevation': 8495, 'location': {'lat': 41.3295, 'lng': -106.5025}}, {'name': 'South Colony', 'triplet': '773:CO:SNTL', 'elevation': 10868, 'location': {'lat': 37.96647, 'lng': -105.53671}}, {'name': 'South Fork Bull Run', 'triplet': '925:OR:SNTL', 'elevation': 2690, 'location': {'lat': 45.44575, 'lng': -122.03125}}, {'name': 'South Mtn.', 'triplet': '774:ID:SNTL', 'elevation': 6500, 'location': {'lat': 42.76478, 'lng': -116.90037}}, {'name': 'South Pass', 'triplet': '775:WY:SNTL', 'elevation': 9040, 'location': {'lat': 42.57317, 'lng': -108.84325}}, {'name': 'Spencer Meadow', 'triplet': '776:WA:SNTL', 'elevation': 3400, 'location': {'lat': 46.1795, 'lng': -121.92661}}, {'name': 'Spirit Lake', 'triplet': '777:WA:SNTL', 'elevation': 3520, 'location': {'lat': 46.26113, 'lng': -122.1772}}, {'name': 'Spirit Lk', 'triplet': '1117:UT:SNTL', 'elevation': 10235, 'location': {'lat': 40.83868, 'lng': -110.00527}}, {'name': 'Spratt Creek', 'triplet': '778:CA:SNTL', 'elevation': 6063, 'location': {'lat': 38.66627, 'lng': -119.81741}}, {'name': 'Spring Creek', 'triplet': '2044:AK:SNTL', 'elevation': 580, 'location': {'lat': 61.65722, 'lng': -149.12853}}, {'name': 'Spring Creek Divide', 'triplet': '779:WY:SNTL', 'elevation': 9000, 'location': {'lat': 42.52516, 'lng': -110.66148}}, {'name': 'Spruce Springs', 'triplet': '984:WA:SNTL', 'elevation': 5700, 'location': {'lat': 46.18287, 'lng': -117.54155}}, {'name': 'Spud Mountain', 'triplet': '780:CO:SNTL', 'elevation': 10674, 'location': {'lat': 37.69883, 'lng': -107.77841}}, {'name': 'Spur Park', 'triplet': '781:MT:SNTL', 'elevation': 8100, 'location': {'lat': 46.77962, 'lng': -110.62165}}, {'name': 'Squaw Flat', 'triplet': '782:ID:SNTL', 'elevation': 6240, 'location': {'lat': 44.77091, 'lng': -116.24805}}, {'name': 'St. Lawrence Alt', 'triplet': '786:WY:SNTL', 'elevation': 8620, 'location': {'lat': 43.03313, 'lng': -109.17025}}, {'name': 'Stag Mountain', 'triplet': '1203:NV:SNTL', 'elevation': 7640, 'location': {'lat': 41.408, 'lng': -115.4464}}, {'name': 'Stahl Peak', 'triplet': '787:MT:SNTL', 'elevation': 6030, 'location': {'lat': 48.90902, 'lng': -114.86298}}, {'name': 'Stampede Pass', 'triplet': '788:WA:SNTL', 'elevation': 3850, 'location': {'lat': 47.27427, 'lng': -121.34162}}, {'name': 'Starr Ridge', 'triplet': '789:OR:SNTL', 'elevation': 5250, 'location': {'lat': 44.26423, 'lng': -119.02162}}, {'name': 'State Line', 'triplet': '1258:CA:SNTL', 'elevation': 5680, 'location': {'lat': 41.98609, 'lng': -120.71574}}, {'name': 'Steel Creek Park', 'triplet': '790:UT:SNTL', 'elevation': 10158, 'location': {'lat': 40.90862, 'lng': -110.50462}}, {'name': 'Stevens Pass', 'triplet': '791:WA:SNTL', 'elevation': 3950, 'location': {'lat': 47.74607, 'lng': -121.09288}}, {'name': 'Stickney Mill', 'triplet': '792:ID:SNTL', 'elevation': 7430, 'location': {'lat': 43.86117, 'lng': -114.20902}}, {'name': 'Stillwater Creek', 'triplet': '793:CO:SNTL', 'elevation': 8880, 'location': {'lat': 40.22532, 'lng': -105.9198}}, {'name': 'Strawberry', 'triplet': '794:OR:SNTL', 'elevation': 5770, 'location': {'lat': 42.12587, 'lng': -120.8361}}, {'name': 'Strawberry Divide', 'triplet': '795:UT:SNTL', 'elevation': 8123, 'location': {'lat': 40.16483, 'lng': -111.20665}}, {'name': 'Stringer Creek', 'triplet': '1009:MT:SNTL', 'elevation': 6550, 'location': {'lat': 46.9269, 'lng': -110.90198}}, {'name': 'Stryker Basin', 'triplet': '1311:MT:SNTL', 'elevation': 6155, 'location': {'lat': 48.6802, 'lng': -114.664}}, {'name': 'Stuart Mountain', 'triplet': '901:MT:SNTL', 'elevation': 7400, 'location': {'lat': 46.99523, 'lng': -113.92664}}, {'name': 'Stump Lakes', 'triplet': '797:CO:SNTL', 'elevation': 11248, 'location': {'lat': 37.47647, 'lng': -107.63348}}, {'name': 'Sucker Creek', 'triplet': '798:WY:SNTL', 'elevation': 8880, 'location': {'lat': 44.7225, 'lng': -107.40033}}, {'name': 'Sugarloaf Mtn', 'triplet': '1095:AK:SNTL', 'elevation': 550, 'location': {'lat': 61.081, 'lng': -146.2995}}, {'name': 'Summer Rim', 'triplet': '800:OR:SNTL', 'elevation': 7080, 'location': {'lat': 42.6957, 'lng': -120.80158}}, {'name': 'Summit Creek', 'triplet': '955:AK:SNTL', 'elevation': 1400, 'location': {'lat': 60.61713, 'lng': -149.53128}}, {'name': 'Summit Lake', 'triplet': '801:OR:SNTL', 'elevation': 5610, 'location': {'lat': 43.44907, 'lng': -122.13808}}, {'name': 'Summit Lk', 'triplet': '1194:NV:SNTL', 'elevation': 7615, 'location': {'lat': 41.48953, 'lng': -118.99663}}, {'name': 'Summit Meadow', 'triplet': '1052:CA:SNTL', 'elevation': 9313, 'location': {'lat': 38.39747, 'lng': -119.53522}}, {'name': 'Summit Ranch', 'triplet': '802:CO:SNTL', 'elevation': 9371, 'location': {'lat': 39.71803, 'lng': -106.1577}}, {'name': 'Sun Pass', 'triplet': '1078:OR:SNTL', 'elevation': 5400, 'location': {'lat': 42.78637, 'lng': -121.97715}}, {'name': 'Sunflower Flat', 'triplet': '1249:UT:SNTL', 'elevation': 10018, 'location': {'lat': 38.048, 'lng': -111.33981}}, {'name': 'Sunset', 'triplet': '803:ID:SNTL', 'elevation': 5540, 'location': {'lat': 47.55545, 'lng': -115.82422}}, {'name': 'Surprise Lakes', 'triplet': '804:WA:SNTL', 'elevation': 4290, 'location': {'lat': 46.09497, 'lng': -121.76345}}, {'name': 'Susitna Valley High', 'triplet': '967:AK:SNTL', 'elevation': 375, 'location': {'lat': 62.13333, 'lng': -150.04167}}, {'name': 'Suu Ranch', 'triplet': '1248:UT:SNTL', 'elevation': 8050, 'location': {'lat': 37.59711, 'lng': -112.92949}}, {'name': 'Swamp Creek', 'triplet': '975:WA:SNTL', 'elevation': 3930, 'location': {'lat': 48.57142, 'lng': -120.78267}}, {'name': 'Swan Lake Mtn', 'triplet': '1077:OR:SNTL', 'elevation': 6830, 'location': {'lat': 42.41323, 'lng': -121.68002}}, {'name': 'Swede Peak', 'triplet': '805:ID:SNTL', 'elevation': 7640, 'location': {'lat': 43.626, 'lng': -113.96887}}, {'name': 'Swift Creek', 'triplet': '1012:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.1638, 'lng': -122.18402}}, {'name': 'Sylvan Lake', 'triplet': '806:WY:SNTL', 'elevation': 8420, 'location': {'lat': 44.47764, 'lng': -110.15651}}, {'name': 'Sylvan Road', 'triplet': '807:WY:SNTL', 'elevation': 7120, 'location': {'lat': 44.47825, 'lng': -110.03808}}, {'name': 'Tahoe City Cross', 'triplet': '809:CA:SNTL', 'elevation': 6797, 'location': {'lat': 39.17162, 'lng': -120.15362}}, {'name': 'Takka Wiiya', 'triplet': '1247:UT:SNTL', 'elevation': 9122, 'location': {'lat': 39.74104, 'lng': -113.98262}}, {'name': 'Taos Powderhorn', 'triplet': '1168:NM:SNTL', 'elevation': 11045, 'location': {'lat': 36.58195, 'lng': -105.45617}}, {'name': 'Taos Pueblo', 'triplet': '1307:NM:SNTL', 'elevation': 11020, 'location': {'lat': 36.54099, 'lng': -105.35944}}, {'name': 'Taylor Butte', 'triplet': '810:OR:SNTL', 'elevation': 5030, 'location': {'lat': 42.69108, 'lng': -121.42592}}, {'name': 'Taylor Canyon', 'triplet': '811:NV:SNTL', 'elevation': 6325, 'location': {'lat': 41.2287, 'lng': -116.0293}}, {'name': 'Taylor Green', 'triplet': '812:OR:SNTL', 'elevation': 5740, 'location': {'lat': 45.07707, 'lng': -117.55067}}, {'name': 'Telaquana Lake', 'triplet': '1266:AK:SNTL', 'elevation': 1275, 'location': {'lat': 60.98243, 'lng': -153.91772}}, {'name': 'Temple Fork', 'triplet': '1013:UT:SNTL', 'elevation': 7406, 'location': {'lat': 41.793, 'lng': -111.54605}}, {'name': 'Tent Mtn Lower', 'triplet': '1202:NV:SNTL', 'elevation': 7100, 'location': {'lat': 40.97852, 'lng': -115.17215}}, {'name': 'Tepee Creek', 'triplet': '813:MT:SNTL', 'elevation': 8000, 'location': {'lat': 44.78562, 'lng': -111.71}}, {'name': 'Teuchet Creek', 'triplet': '951:AK:SNTL', 'elevation': 1640, 'location': {'lat': 64.94583, 'lng': -145.51667}}, {'name': 'Thaynes Canyon', 'triplet': '814:UT:SNTL', 'elevation': 9230, 'location': {'lat': 40.6235, 'lng': -111.53322}}, {'name': 'Thistle Flat', 'triplet': '1226:UT:SNTL', 'elevation': 8787, 'location': {'lat': 39.23803, 'lng': -111.51998}}, {'name': 'Three Creeks Meadow', 'triplet': '815:OR:SNTL', 'elevation': 5690, 'location': {'lat': 44.14425, 'lng': -121.64095}}, {'name': 'Thumb Divide', 'triplet': '816:WY:SNTL', 'elevation': 7980, 'location': {'lat': 44.36917, 'lng': -110.57717}}, {'name': 'Thunder Basin', 'triplet': '817:WA:SNTL', 'elevation': 4320, 'location': {'lat': 48.52753, 'lng': -120.9895}}, {'name': 'Tie Creek', 'triplet': '818:WY:SNTL', 'elevation': 6870, 'location': {'lat': 44.81243, 'lng': -107.41017}}, {'name': 'Timber Creek', 'triplet': '819:WY:SNTL', 'elevation': 7950, 'location': {'lat': 44.0274, 'lng': -109.17879}}, {'name': 'Timberline', 'triplet': '1097:UT:SNTL', 'elevation': 8736, 'location': {'lat': 39.67712, 'lng': -110.43395}}, {'name': 'Timpanogos Divide', 'triplet': '820:UT:SNTL', 'elevation': 8140, 'location': {'lat': 40.42817, 'lng': -111.61633}}, {'name': 'Tinkham Creek', 'triplet': '899:WA:SNTL', 'elevation': 2990, 'location': {'lat': 47.33198, 'lng': -121.46975}}, {'name': 'Tipton', 'triplet': '821:OR:SNTL', 'elevation': 5150, 'location': {'lat': 44.65567, 'lng': -118.42617}}, {'name': 'Tizer Basin', 'triplet': '893:MT:SNTL', 'elevation': 6880, 'location': {'lat': 46.34937, 'lng': -111.85308}}, {'name': 'Toe Jam', 'triplet': '1136:NV:SNTL', 'elevation': 7690, 'location': {'lat': 41.3187, 'lng': -116.3408}}, {'name': 'Togwotee Pass', 'triplet': '822:WY:SNTL', 'elevation': 9580, 'location': {'lat': 43.74902, 'lng': -110.0578}}, {'name': 'Tok', 'triplet': '2080:AK:SNTL', 'elevation': 1630, 'location': {'lat': 63.3532, 'lng': -142.98164}}, {'name': 'Toketee Airstrip', 'triplet': '1044:OR:SNTL', 'elevation': 3240, 'location': {'lat': 43.22718, 'lng': -122.42537}}, {'name': 'Tokositna Valley', 'triplet': '1089:AK:SNTL', 'elevation': 850, 'location': {'lat': 62.63, 'lng': -150.77617}}, {'name': 'Tolby', 'triplet': '934:NM:SNTL', 'elevation': 10220, 'location': {'lat': 36.47498, 'lng': -105.19534}}, {'name': 'Tony Grove Lake', 'triplet': '823:UT:SNTL', 'elevation': 8474, 'location': {'lat': 41.89833, 'lng': -111.62957}}, {'name': 'Tony Grove RS', 'triplet': '1113:UT:SNTL', 'elevation': 6332, 'location': {'lat': 41.88573, 'lng': -111.56918}}, {'name': 'Touchet', 'triplet': '824:WA:SNTL', 'elevation': 5530, 'location': {'lat': 46.11868, 'lng': -117.8505}}, {'name': 'Tower', 'triplet': '825:CO:SNTL', 'elevation': 10620, 'location': {'lat': 40.5374, 'lng': -106.67655}}, {'name': 'Townsend Creek', 'triplet': '826:WY:SNTL', 'elevation': 8700, 'location': {'lat': 42.69525, 'lng': -108.89572}}, {'name': 'Trapper Lake', 'triplet': '827:CO:SNTL', 'elevation': 9759, 'location': {'lat': 39.99881, 'lng': -107.23618}}, {'name': 'Tres Ritos', 'triplet': '1083:NM:SNTL', 'elevation': 8755, 'location': {'lat': 36.1279, 'lng': -105.52706}}, {'name': 'Trial Lake', 'triplet': '828:UT:SNTL', 'elevation': 9992, 'location': {'lat': 40.678, 'lng': -110.94873}}, {'name': 'Trinchera', 'triplet': '829:CO:SNTL', 'elevation': 10922, 'location': {'lat': 37.35296, 'lng': -105.23259}}, {'name': 'Trinity', 'triplet': '1171:WA:SNTL', 'elevation': 2930, 'location': {'lat': 48.0747, 'lng': -120.8493}}, {'name': 'Trinity Mtn.', 'triplet': '830:ID:SNTL', 'elevation': 7770, 'location': {'lat': 43.62903, 'lng': -115.43818}}, {'name': 'Triple Peak', 'triplet': '831:WY:SNTL', 'elevation': 8500, 'location': {'lat': 42.76393, 'lng': -110.5914}}, {'name': 'Trough', 'triplet': '832:WA:SNTL', 'elevation': 5480, 'location': {'lat': 47.23328, 'lng': -120.29412}}, {'name': 'Trout Creek', 'triplet': '833:UT:SNTL', 'elevation': 9518, 'location': {'lat': 40.739, 'lng': -109.6728}}, {'name': 'Truckee #2', 'triplet': '834:CA:SNTL', 'elevation': 6509, 'location': {'lat': 39.30087, 'lng': -120.18407}}, {'name': 'Turnagain Pass', 'triplet': '954:AK:SNTL', 'elevation': 1880, 'location': {'lat': 60.78043, 'lng': -149.18325}}, {'name': 'Twelvemile Creek', 'triplet': '835:MT:SNTL', 'elevation': 5600, 'location': {'lat': 46.14287, 'lng': -114.44755}}, {'name': 'Twin Lakes', 'triplet': '836:MT:SNTL', 'elevation': 6400, 'location': {'lat': 46.1438, 'lng': -114.5056}}, {'name': 'Two Ocean Plateau', 'triplet': '837:WY:SNTL', 'elevation': 9240, 'location': {'lat': 44.15178, 'lng': -110.22122}}, {'name': 'University Camp', 'triplet': '838:CO:SNTL', 'elevation': 10360, 'location': {'lat': 40.03307, 'lng': -105.57562}}, {'name': 'Upper Chena', 'triplet': '952:AK:SNTL', 'elevation': 2850, 'location': {'lat': 65.1, 'lng': -144.93317}}, {'name': 'Upper Joes Valley', 'triplet': '1227:UT:SNTL', 'elevation': 8596, 'location': {'lat': 39.4155, 'lng': -111.2491}}, {'name': 'Upper Nome Creek', 'triplet': '1090:AK:SNTL', 'elevation': 2520, 'location': {'lat': 65.3671, 'lng': -146.592}}, {'name': 'Upper Rio Grande', 'triplet': '839:CO:SNTL', 'elevation': 9379, 'location': {'lat': 37.72172, 'lng': -107.25971}}, {'name': 'Upper San Juan', 'triplet': '840:CO:SNTL', 'elevation': 10140, 'location': {'lat': 37.48563, 'lng': -106.83528}}, {'name': 'Upper Taylor', 'triplet': '1141:CO:SNTL', 'elevation': 10717, 'location': {'lat': 38.99071, 'lng': -106.74504}}, {'name': 'Upper Tsaina River', 'triplet': '1055:AK:SNTL', 'elevation': 1750, 'location': {'lat': 61.19112, 'lng': -145.64807}}, {'name': 'Upper Wheeler', 'triplet': '841:WA:SNTL', 'elevation': 4330, 'location': {'lat': 47.28734, 'lng': -120.37015}}, {'name': 'Usu Doc Daniel', 'triplet': '1098:UT:SNTL', 'elevation': 8270, 'location': {'lat': 41.86425, 'lng': -111.50603}}, {'name': 'Ute Creek', 'triplet': '1005:CO:SNTL', 'elevation': 10734, 'location': {'lat': 37.6148, 'lng': -105.37322}}, {'name': 'Vacarro Springs', 'triplet': '1137:NV:SNTL', 'elevation': 7890, 'location': {'lat': 39.4495, 'lng': -115.9834}}, {'name': 'Vacas Locas', 'triplet': '1017:NM:SNTL', 'elevation': 9364, 'location': {'lat': 36.02653, 'lng': -106.81361}}, {'name': 'Vail Mountain', 'triplet': '842:CO:SNTL', 'elevation': 10310, 'location': {'lat': 39.61765, 'lng': -106.38019}}, {'name': 'Vallecito', 'triplet': '843:CO:SNTL', 'elevation': 10782, 'location': {'lat': 37.48524, 'lng': -107.50748}}, {'name': 'Van Wyck', 'triplet': '979:ID:SNTL', 'elevation': 4920, 'location': {'lat': 44.37665, 'lng': -116.3366}}, {'name': 'Vernon Creek', 'triplet': '844:UT:SNTL', 'elevation': 7401, 'location': {'lat': 39.93667, 'lng': -112.41478}}, {'name': 'Vienna Mine', 'triplet': '845:ID:SNTL', 'elevation': 8960, 'location': {'lat': 43.79942, 'lng': -114.85273}}, {'name': 'Virginia Lakes Ridge', 'triplet': '846:CA:SNTL', 'elevation': 9400, 'location': {'lat': 38.07298, 'lng': -119.23433}}, {'name': 'Wager Gulch', 'triplet': '1188:CO:SNTL', 'elevation': 11132, 'location': {'lat': 37.88248, 'lng': -107.36428}}, {'name': 'Waldron', 'triplet': '847:MT:SNTL', 'elevation': 5600, 'location': {'lat': 47.91998, 'lng': -112.79087}}, {'name': 'Ward Creek #3', 'triplet': '848:CA:SNTL', 'elevation': 6745, 'location': {'lat': 39.13545, 'lng': -120.21865}}, {'name': 'Ward Mountain', 'triplet': '849:NV:SNTL', 'elevation': 9163, 'location': {'lat': 39.13242, 'lng': -114.95575}}, {'name': 'Warm Springs', 'triplet': '850:MT:SNTL', 'elevation': 7800, 'location': {'lat': 46.27368, 'lng': -113.164}}, {'name': 'Waterhole', 'triplet': '974:WA:SNTL', 'elevation': 5010, 'location': {'lat': 47.94485, 'lng': -123.42594}}, {'name': 'Webber Springs', 'triplet': '852:WY:SNTL', 'elevation': 9260, 'location': {'lat': 41.1591, 'lng': -106.92809}}, {'name': 'Webster Flat', 'triplet': '853:UT:SNTL', 'elevation': 9203, 'location': {'lat': 37.575, 'lng': -112.90155}}, {'name': 'Wells Creek', 'triplet': '909:WA:SNTL', 'elevation': 4030, 'location': {'lat': 48.8661, 'lng': -121.78976}}, {'name': 'Weminuche Creek', 'triplet': '1160:CO:SNTL', 'elevation': 10749, 'location': {'lat': 37.51968, 'lng': -107.32139}}, {'name': 'Wesner Springs', 'triplet': '854:NM:SNTL', 'elevation': 11151, 'location': {'lat': 35.77584, 'lng': -105.54337}}, {'name': 'West Branch', 'triplet': '855:ID:SNTL', 'elevation': 5560, 'location': {'lat': 45.0722, 'lng': -116.45413}}, {'name': 'West Yellowstone', 'triplet': '924:MT:SNTL', 'elevation': 6700, 'location': {'lat': 44.65866, 'lng': -111.09199}}, {'name': 'Wheeler Peak', 'triplet': '1147:NV:SNTL', 'elevation': 10060, 'location': {'lat': 39.00995, 'lng': -114.31021}}, {'name': 'Whiskey Ck', 'triplet': '857:CO:SNTL', 'elevation': 10290, 'location': {'lat': 37.21423, 'lng': -105.12262}}, {'name': 'Whiskey Creek', 'triplet': '858:MT:SNTL', 'elevation': 6800, 'location': {'lat': 44.61088, 'lng': -111.14998}}, {'name': 'Whiskey Park', 'triplet': '859:WY:SNTL', 'elevation': 9020, 'location': {'lat': 41.00368, 'lng': -106.90795}}, {'name': 'White Elephant', 'triplet': '860:ID:SNTL', 'elevation': 7710, 'location': {'lat': 44.53267, 'lng': -111.41085}}, {'name': 'White Horse Lake', 'triplet': '861:AZ:SNTL', 'elevation': 7203, 'location': {'lat': 35.14189, 'lng': -112.14966}}, {'name': 'White Mill', 'triplet': '862:MT:SNTL', 'elevation': 8700, 'location': {'lat': 45.04575, 'lng': -109.90987}}, {'name': 'White Pass E.S.', 'triplet': '863:WA:SNTL', 'elevation': 4440, 'location': {'lat': 46.64142, 'lng': -121.38153}}, {'name': 'White River #1', 'triplet': '864:UT:SNTL', 'elevation': 8641, 'location': {'lat': 39.9645, 'lng': -110.98845}}, {'name': 'White River Nv', 'triplet': '1213:NV:SNTL', 'elevation': 7367, 'location': {'lat': 38.94557, 'lng': -115.37922}}, {'name': 'Widtsoe #3', 'triplet': '865:UT:SNTL', 'elevation': 9640, 'location': {'lat': 37.83633, 'lng': -111.88163}}, {'name': 'Wilbur Bench', 'triplet': '543:UT:SNTL', 'elevation': 9171, 'location': {'lat': 39.89166, 'lng': -110.74604}}, {'name': 'Wild Basin', 'triplet': '1042:CO:SNTL', 'elevation': 9439, 'location': {'lat': 40.201, 'lng': -105.6025}}, {'name': 'Wildcat', 'triplet': '866:AZ:SNTL', 'elevation': 7868, 'location': {'lat': 33.74347, 'lng': -109.48078}}, {'name': 'Wildhorse Divide', 'triplet': '867:ID:SNTL', 'elevation': 6490, 'location': {'lat': 42.75743, 'lng': -112.47783}}, {'name': 'Willow Creek', 'triplet': '868:WY:SNTL', 'elevation': 8080, 'location': {'lat': 42.81513, 'lng': -110.83515}}, {'name': 'Willow Creek Pass', 'triplet': '869:CO:SNTL', 'elevation': 9523, 'location': {'lat': 40.34734, 'lng': -106.0952}}, {'name': 'Willow Park', 'triplet': '870:CO:SNTL', 'elevation': 10732, 'location': {'lat': 40.43397, 'lng': -105.73588}}, {'name': 'Wilson Creek', 'triplet': '871:ID:SNTL', 'elevation': 7120, 'location': {'lat': 42.01257, 'lng': -115.00278}}, {'name': 'Windy Peak', 'triplet': '872:WY:SNTL', 'elevation': 7915, 'location': {'lat': 42.27991, 'lng': -105.57782}}, {'name': 'Wolf Creek', 'triplet': '873:OR:SNTL', 'elevation': 5630, 'location': {'lat': 45.06703, 'lng': -118.15192}}, {'name': 'Wolf Creek Peak', 'triplet': '1164:UT:SNTL', 'elevation': 9796, 'location': {'lat': 40.47733, 'lng': -111.04469}}, {'name': 'Wolf Creek Summit', 'triplet': '874:CO:SNTL', 'elevation': 10957, 'location': {'lat': 37.47903, 'lng': -106.80234}}, {'name': 'Wolverine', 'triplet': '875:WY:SNTL', 'elevation': 7650, 'location': {'lat': 44.80417, 'lng': -109.657}}, {'name': 'Wood Creek', 'triplet': '876:MT:SNTL', 'elevation': 5960, 'location': {'lat': 47.44847, 'lng': -112.81428}}, {'name': 'Workman Creek', 'triplet': '877:AZ:SNTL', 'elevation': 7032, 'location': {'lat': 33.81259, 'lng': -110.91852}}, {'name': 'Wrigley Creek', 'triplet': '1228:UT:SNTL', 'elevation': 9327, 'location': {'lat': 39.13233, 'lng': -111.35685}}, {'name': 'Yankee Reservoir', 'triplet': '1197:UT:SNTL', 'elevation': 8692, 'location': {'lat': 37.74797, 'lng': -112.77495}}, {'name': 'Younts Peak', 'triplet': '878:WY:SNTL', 'elevation': 8350, 'location': {'lat': 43.93225, 'lng': -109.81775}}, {'name': 'Zirkel', 'triplet': '1033:CO:SNTL', 'elevation': 9338, 'location': {'lat': 40.79492, 'lng': -106.59544}}]\n0  /  700  iterations completed.\n1  /  700  iterations completed.\n2  /  700  iterations completed.\n3  /  700  iterations completed.\n4  /  700  iterations completed.\n5  /  700  iterations completed.\n6  /  700  iterations completed.\n7  /  700  iterations completed.\n8  /  700  iterations completed.\n9  /  700  iterations completed.\n10  /  700  iterations completed.\n11  /  700  iterations completed.\n12  /  700  iterations completed.\n13  /  700  iterations completed.\n14  /  700  iterations completed.\n15  /  700  iterations completed.\n16  /  700  iterations completed.\n17  /  700  iterations completed.\n18  /  700  iterations completed.\n19  /  700  iterations completed.\n20  /  700  iterations completed.\n21  /  700  iterations completed.\n22  /  700  iterations completed.\n23  /  700  iterations completed.\n24  /  700  iterations completed.\n25  /  700  iterations completed.\n26  /  700  iterations completed.\n27  /  700  iterations completed.\n28  /  700  iterations completed.\n29  /  700  iterations completed.\n30  /  700  iterations completed.\n31  /  700  iterations completed.\n32  /  700  iterations completed.\n33  /  700  iterations completed.\n34  /  700  iterations completed.\n35  /  700  iterations completed.\n36  /  700  iterations completed.\n37  /  700  iterations completed.\n38  /  700  iterations completed.\n39  /  700  iterations completed.\n40  /  700  iterations completed.\n41  /  700  iterations completed.\n42  /  700  iterations completed.\n43  /  700  iterations completed.\n44  /  700  iterations completed.\n45  /  700  iterations completed.\n46  /  700  iterations completed.\n47  /  700  iterations completed.\n48  /  700  iterations completed.\n49  /  700  iterations completed.\n50  /  700  iterations completed.\n51  /  700  iterations completed.\n52  /  700  iterations completed.\n53  /  700  iterations completed.\n54  /  700  iterations completed.\n55  /  700  iterations completed.\n56  /  700  iterations completed.\n57  /  700  iterations completed.\n58  /  700  iterations completed.\n59  /  700  iterations completed.\n60  /  700  iterations completed.\n61  /  700  iterations completed.\n62  /  700  iterations completed.\n63  /  700  iterations completed.\n64  /  700  iterations completed.\n65  /  700  iterations completed.\n66  /  700  iterations completed.\n67  /  700  iterations completed.\n68  /  700  iterations completed.\n69  /  700  iterations completed.\n70  /  700  iterations completed.\n71  /  700  iterations completed.\n72  /  700  iterations completed.\n73  /  700  iterations completed.\n74  /  700  iterations completed.\n75  /  700  iterations completed.\n76  /  700  iterations completed.\n77  /  700  iterations completed.\n78  /  700  iterations completed.\n79  /  700  iterations completed.\n80  /  700  iterations completed.\n81  /  700  iterations completed.\n82  /  700  iterations completed.\n83  /  700  iterations completed.\n84  /  700  iterations completed.\n85  /  700  iterations completed.\n86  /  700  iterations completed.\n87  /  700  iterations completed.\n88  /  700  iterations completed.\n89  /  700  iterations completed.\n90  /  700  iterations completed.\n91  /  700  iterations completed.\n92  /  700  iterations completed.\n93  /  700  iterations completed.\n94  /  700  iterations completed.\n",
  "history_begin_time" : 1703486128966,
  "history_end_time" : 1703487059934,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "9sWJnWR13jEv",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\ndef read_json_file(file_path):\n    '''\n    Read and parse a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file.\n\n    Returns:\n        dict: The parsed JSON data.\n    '''\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\ndef haversine(lat1, lon1, lat2, lon2):\n    '''\n    Calculate the Haversine distance between two sets of latitude and longitude coordinates.\n\n    Args:\n        lat1 (float): Latitude of the first point.\n        lon1 (float): Longitude of the first point.\n        lat2 (float): Latitude of the second point.\n        lon2 (float): Longitude of the second point.\n\n    Returns:\n        float: The Haversine distance between the two points in kilometers.\n    '''\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    '''\n    Find the nearest location in a list of locations to a target latitude and longitude.\n\n    Args:\n        locations (list): List of locations, each represented as a dictionary.\n        target_lat (float): Target latitude.\n        target_lon (float): Target longitude.\n\n    Returns:\n        dict: The nearest location from the list.\n    '''\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\ndef csv_to_json(csv_text):\n    '''\n    Convert CSV text to JSON format.\n\n    Args:\n        csv_text (str): The CSV text to convert.\n\n    Returns:\n        str: The JSON representation of the CSV data.\n    '''\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\ndef download_file(url, destination):\n    response = requests.get(url)\n    with open(destination, 'wb') as file:\n        file.write(response.content)\n          \ndef remove_commented_lines(text):\n    '''\n    Remove lines starting with '#' from the input text.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        str: The input text with lines starting with '#' removed.\n    '''\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\ndef start_to_collect_snotel():\n    '''\n    Start the process of collecting SNOTEL data and saving it to a CSV file.\n    '''\n    csv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_check.csv'\n    start_date = \"2019-01-01\"\n    end_date = \"2022-12-12\"\n\n    if os.path.exists(csv_file):\n        print(f\"The file '{csv_file}' exists.\")\n        return\n\n    # stop mapping station to grid cells. Just use the original station lat/lon to collect data.\n    stations_file =f'{working_dir}/ground_measures_metadata.csv'\n    if not os.path.exists(stations_file):\n        url = \"https://raw.githubusercontent.com/geo-smart/SnowCast/main/data/snowcast_provided/ground_measures_metadata.csv\"\n        print(f\"Downloading file from {url}...\")\n        download_file(url, stations_file)\n        print(\"Download complete.\")\n    station_df = pd.read_csv(stations_file)\n    print(station_df.head())\n\n    result_df = pd.DataFrame(columns=['station_id', 'date', 'lat', 'lon', 'swe_value'])\n    for index, row in station_df.iterrows():\n        print(index, ' / ', len(station_df), ' iterations completed.')\n        \n        \n\n        location_name = nearest_location['name']\n        location_triplet = nearest_location['triplet']\n        location_elevation = nearest_location['elevation']\n        location_station_lat = nearest_location['location']['lat']\n        location_station_long = nearest_location['location']['lng']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n        print(url)\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'date': entry['Date'], \n                             'lat': row['lat'], \n                             'lon': row['lon'],\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nstart_to_collect_snotel()\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\n  station_id            name  elevation_m   latitude   longitude       state\n0   CDEC:ADM   Adin Mountain      1889.76  41.237000 -120.792000  California\n1   CDEC:AGP      Agnew Pass      2880.36  37.726631 -119.141731  California\n2   CDEC:ALP    Alpha (Smud)      2316.48  38.804192 -120.215652  California\n3   CDEC:BCB  Blackcap Basin      3139.44  37.066685 -118.773010  California\n4   CDEC:BCH   Beach Meadows      2331.72  36.126095 -118.293457  California\n0  /  700  iterations completed.\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/9sWJnWR13jEv/data_snotel_station_only.py\", line 167, in <module>\n    start_to_collect_snotel()\n  File \"/home/chetana/gw-workspace/9sWJnWR13jEv/data_snotel_station_only.py\", line 144, in start_to_collect_snotel\n    location_name = nearest_location['name']\nNameError: name 'nearest_location' is not defined\n",
  "history_begin_time" : 1703485917918,
  "history_end_time" : 1703485918710,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "95XXy9xcVYPD",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\ndef read_json_file(file_path):\n    '''\n    Read and parse a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file.\n\n    Returns:\n        dict: The parsed JSON data.\n    '''\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\ndef haversine(lat1, lon1, lat2, lon2):\n    '''\n    Calculate the Haversine distance between two sets of latitude and longitude coordinates.\n\n    Args:\n        lat1 (float): Latitude of the first point.\n        lon1 (float): Longitude of the first point.\n        lat2 (float): Latitude of the second point.\n        lon2 (float): Longitude of the second point.\n\n    Returns:\n        float: The Haversine distance between the two points in kilometers.\n    '''\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    '''\n    Find the nearest location in a list of locations to a target latitude and longitude.\n\n    Args:\n        locations (list): List of locations, each represented as a dictionary.\n        target_lat (float): Target latitude.\n        target_lon (float): Target longitude.\n\n    Returns:\n        dict: The nearest location from the list.\n    '''\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\ndef csv_to_json(csv_text):\n    '''\n    Convert CSV text to JSON format.\n\n    Args:\n        csv_text (str): The CSV text to convert.\n\n    Returns:\n        str: The JSON representation of the CSV data.\n    '''\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\ndef download_file(url, destination):\n    response = requests.get(url)\n    with open(destination, 'wb') as file:\n        file.write(response.content)\n          \ndef remove_commented_lines(text):\n    '''\n    Remove lines starting with '#' from the input text.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        str: The input text with lines starting with '#' removed.\n    '''\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\ndef start_to_collect_snotel():\n    '''\n    Start the process of collecting SNOTEL data and saving it to a CSV file.\n    '''\n    csv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_check.csv'\n    start_date = \"2019-01-01\"\n    end_date = \"2022-12-12\"\n\n    if os.path.exists(csv_file):\n        print(f\"The file '{csv_file}' exists.\")\n        return\n\n    # stop mapping station to grid cells. Just use the original station lat/lon to collect data.\n    stations_file =f'{working_dir}/ground_measures_metadata.csv'\n    if not os.path.exists(stations_file):\n        url = \"https://raw.githubusercontent.com/geo-smart/SnowCast/main/data/snowcast_provided/ground_measures_metadata.csv\"\n        print(f\"Downloading file from {url}...\")\n        download_file(url, stations_file)\n        print(\"Download complete.\")\n    station_df = pd.read_csv(stations_file)\n    print(station_df.head())\n\n    result_df = pd.DataFrame(columns=['station_id', 'date', 'lat', 'lon', 'swe_value'])\n    for index, row in station_df.iterrows():\n        print(index, ' / ', len(station_mapping), ' iterations completed.')\n        \n        \n\n        location_name = nearest_location['name']\n        location_triplet = nearest_location['triplet']\n        location_elevation = nearest_location['elevation']\n        location_station_lat = nearest_location['location']['lat']\n        location_station_long = nearest_location['location']['lng']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n        print(url)\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'date': entry['Date'], \n                             'lat': row['lat'], \n                             'lon': row['lon'],\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nstart_to_collect_snotel()\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\n  station_id            name  elevation_m   latitude   longitude       state\n0   CDEC:ADM   Adin Mountain      1889.76  41.237000 -120.792000  California\n1   CDEC:AGP      Agnew Pass      2880.36  37.726631 -119.141731  California\n2   CDEC:ALP    Alpha (Smud)      2316.48  38.804192 -120.215652  California\n3   CDEC:BCB  Blackcap Basin      3139.44  37.066685 -118.773010  California\n4   CDEC:BCH   Beach Meadows      2331.72  36.126095 -118.293457  California\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/95XXy9xcVYPD/data_snotel_station_only.py\", line 167, in <module>\n    start_to_collect_snotel()\n  File \"/home/chetana/gw-workspace/95XXy9xcVYPD/data_snotel_station_only.py\", line 140, in start_to_collect_snotel\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\nNameError: name 'station_mapping' is not defined\n",
  "history_begin_time" : 1703485885460,
  "history_end_time" : 1703485886249,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "eoGJp7LO0wp9",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\ndef read_json_file(file_path):\n    '''\n    Read and parse a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file.\n\n    Returns:\n        dict: The parsed JSON data.\n    '''\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\ndef haversine(lat1, lon1, lat2, lon2):\n    '''\n    Calculate the Haversine distance between two sets of latitude and longitude coordinates.\n\n    Args:\n        lat1 (float): Latitude of the first point.\n        lon1 (float): Longitude of the first point.\n        lat2 (float): Latitude of the second point.\n        lon2 (float): Longitude of the second point.\n\n    Returns:\n        float: The Haversine distance between the two points in kilometers.\n    '''\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    '''\n    Find the nearest location in a list of locations to a target latitude and longitude.\n\n    Args:\n        locations (list): List of locations, each represented as a dictionary.\n        target_lat (float): Target latitude.\n        target_lon (float): Target longitude.\n\n    Returns:\n        dict: The nearest location from the list.\n    '''\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\ndef csv_to_json(csv_text):\n    '''\n    Convert CSV text to JSON format.\n\n    Args:\n        csv_text (str): The CSV text to convert.\n\n    Returns:\n        str: The JSON representation of the CSV data.\n    '''\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\ndef download_file(url, destination):\n    response = requests.get(url)\n    with open(destination, 'wb') as file:\n        file.write(response.content)\n          \ndef remove_commented_lines(text):\n    '''\n    Remove lines starting with '#' from the input text.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        str: The input text with lines starting with '#' removed.\n    '''\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\ndef start_to_collect_snotel():\n    '''\n    Start the process of collecting SNOTEL data and saving it to a CSV file.\n    '''\n    csv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_check.csv'\n    start_date = \"2019-01-01\"\n    end_date = \"2022-12-12\"\n\n    if os.path.exists(csv_file):\n        print(f\"The file '{csv_file}' exists.\")\n        return\n\n    # stop mapping station to grid cells. Just use the original station lat/lon to collect data.\n    stations_file =f'{working_dir}/ground_measures_metadata.csv'\n    if not os.path.exists(stations_file):\n        url = \"https://raw.githubusercontent.com/geo-smart/SnowCast/main/data/snowcast_provided/ground_measures_metadata.csv\"\n        print(f\"Downloading file from {url}...\")\n        download_file(url, stations_file)\n        print(\"Download complete.\")\n    station_df = pd.read_csv(stations_file)\n    print(station_df.head())\n\n    result_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\n    for index, row in station_mapping.iterrows():\n        print(index, ' / ', len(station_mapping), ' iterations completed.')\n        station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n        nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n        location_name = nearest_location['name']\n        location_triplet = nearest_location['triplet']\n        location_elevation = nearest_location['elevation']\n        location_station_lat = nearest_location['location']['lat']\n        location_station_long = nearest_location['location']['lng']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n        print(url)\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nstart_to_collect_snotel()\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nDownloading file from https://raw.githubusercontent.com/geo-smart/SnowCast/main/data/snowcast_provided/ground_measures_metadata.csv...\nDownload complete.\n  station_id            name  elevation_m   latitude   longitude       state\n0   CDEC:ADM   Adin Mountain      1889.76  41.237000 -120.792000  California\n1   CDEC:AGP      Agnew Pass      2880.36  37.726631 -119.141731  California\n2   CDEC:ALP    Alpha (Smud)      2316.48  38.804192 -120.215652  California\n3   CDEC:BCB  Blackcap Basin      3139.44  37.066685 -118.773010  California\n4   CDEC:BCH   Beach Meadows      2331.72  36.126095 -118.293457  California\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/eoGJp7LO0wp9/data_snotel_station_only.py\", line 165, in <module>\n    start_to_collect_snotel()\n  File \"/home/chetana/gw-workspace/eoGJp7LO0wp9/data_snotel_station_only.py\", line 139, in start_to_collect_snotel\n    for index, row in station_mapping.iterrows():\nNameError: name 'station_mapping' is not defined\n",
  "history_begin_time" : 1703485657658,
  "history_end_time" : 1703485658593,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "Qq2Hf7jF1DBG",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\ndef read_json_file(file_path):\n    '''\n    Read and parse a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file.\n\n    Returns:\n        dict: The parsed JSON data.\n    '''\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\ndef haversine(lat1, lon1, lat2, lon2):\n    '''\n    Calculate the Haversine distance between two sets of latitude and longitude coordinates.\n\n    Args:\n        lat1 (float): Latitude of the first point.\n        lon1 (float): Longitude of the first point.\n        lat2 (float): Latitude of the second point.\n        lon2 (float): Longitude of the second point.\n\n    Returns:\n        float: The Haversine distance between the two points in kilometers.\n    '''\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    '''\n    Find the nearest location in a list of locations to a target latitude and longitude.\n\n    Args:\n        locations (list): List of locations, each represented as a dictionary.\n        target_lat (float): Target latitude.\n        target_lon (float): Target longitude.\n\n    Returns:\n        dict: The nearest location from the list.\n    '''\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\ndef csv_to_json(csv_text):\n    '''\n    Convert CSV text to JSON format.\n\n    Args:\n        csv_text (str): The CSV text to convert.\n\n    Returns:\n        str: The JSON representation of the CSV data.\n    '''\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\ndef download_file(url, destination):\n    response = requests.get(url)\n    with open(destination, 'wb') as file:\n        file.write(response.content)\n          \ndef remove_commented_lines(text):\n    '''\n    Remove lines starting with '#' from the input text.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        str: The input text with lines starting with '#' removed.\n    '''\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\ndef start_to_collect_snotel():\n    '''\n    Start the process of collecting SNOTEL data and saving it to a CSV file.\n    '''\n    csv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_check.csv'\n    start_date = \"2019-01-01\"\n    end_date = \"2022-12-12\"\n\n    if os.path.exists(csv_file):\n        print(f\"The file '{csv_file}' exists.\")\n        return\n\n    # stop mapping station to grid cells. Just use the original station lat/lon to collect data.\n    stations_file =f'{working_dir}/ground_measures_metadata.csv'\n    if not os.path.exists(stations_file):\n        print(f\"Downloading file from {url}...\")\n        download_file(\"https://raw.githubusercontent.com/geo-smart/SnowCast/main/data/snowcast_provided/ground_measures_metadata.csv\",\n                      stations_file)\n        print(\"Download complete.\")\n    station_df = pd.read_csv(stations_file)\n    print(station_df.head())\n\n    result_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\n    for index, row in station_mapping.iterrows():\n        print(index, ' / ', len(station_mapping), ' iterations completed.')\n        station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n        nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n        location_name = nearest_location['name']\n        location_triplet = nearest_location['triplet']\n        location_elevation = nearest_location['elevation']\n        location_station_lat = nearest_location['location']['lat']\n        location_station_long = nearest_location['location']['lng']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n        print(url)\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nstart_to_collect_snotel()\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/Qq2Hf7jF1DBG/data_snotel_station_only.py\", line 165, in <module>\n    start_to_collect_snotel()\n  File \"/home/chetana/gw-workspace/Qq2Hf7jF1DBG/data_snotel_station_only.py\", line 131, in start_to_collect_snotel\n    print(f\"Downloading file from {url}...\")\nUnboundLocalError: local variable 'url' referenced before assignment\n",
  "history_begin_time" : 1703485637542,
  "history_end_time" : 1703485638318,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "WJZmIlcfkqga",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\ndef read_json_file(file_path):\n    '''\n    Read and parse a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file.\n\n    Returns:\n        dict: The parsed JSON data.\n    '''\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\ndef haversine(lat1, lon1, lat2, lon2):\n    '''\n    Calculate the Haversine distance between two sets of latitude and longitude coordinates.\n\n    Args:\n        lat1 (float): Latitude of the first point.\n        lon1 (float): Longitude of the first point.\n        lat2 (float): Latitude of the second point.\n        lon2 (float): Longitude of the second point.\n\n    Returns:\n        float: The Haversine distance between the two points in kilometers.\n    '''\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    '''\n    Find the nearest location in a list of locations to a target latitude and longitude.\n\n    Args:\n        locations (list): List of locations, each represented as a dictionary.\n        target_lat (float): Target latitude.\n        target_lon (float): Target longitude.\n\n    Returns:\n        dict: The nearest location from the list.\n    '''\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\ndef csv_to_json(csv_text):\n    '''\n    Convert CSV text to JSON format.\n\n    Args:\n        csv_text (str): The CSV text to convert.\n\n    Returns:\n        str: The JSON representation of the CSV data.\n    '''\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\ndef remove_commented_lines(text):\n    '''\n    Remove lines starting with '#' from the input text.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        str: The input text with lines starting with '#' removed.\n    '''\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\ndef start_to_collect_snotel():\n    '''\n    Start the process of collecting SNOTEL data and saving it to a CSV file.\n    '''\n    csv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_check.csv'\n    start_date = \"2019-01-01\"\n    end_date = \"2022-12-12\"\n\n    if os.path.exists(csv_file):\n        print(f\"The file '{csv_file}' exists.\")\n        return\n\n    # stop mapping station to grid cells. Just use the original station lat/lon to collect data.\n    stations_file =f'{working_dir}/ground_measures_metadata.csv'\n    station_df = pd.read_csv(stations_file)\n    print(station_df.head())\n\n    result_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\n    for index, row in station_mapping.iterrows():\n        print(index, ' / ', len(station_mapping), ' iterations completed.')\n        station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n        nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n        location_name = nearest_location['name']\n        location_triplet = nearest_location['triplet']\n        location_elevation = nearest_location['elevation']\n        location_station_lat = nearest_location['location']['lat']\n        location_station_long = nearest_location['location']['lng']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n        print(url)\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nstart_to_collect_snotel()\n",
  "history_output" : "today date = 2023-12-25\ntest start date:  2023-01-20\ntest end date:  2023-10-11\n/home/chetana\n2022275\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/WJZmIlcfkqga/data_snotel_station_only.py\", line 155, in <module>\n    start_to_collect_snotel()\n  File \"/home/chetana/gw-workspace/WJZmIlcfkqga/data_snotel_station_only.py\", line 125, in start_to_collect_snotel\n    station_df = pd.read_csv(stations_file)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n    self.handles = get_handle(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 856, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/gridmet_test_run/ground_measures_metadata.csv'\n",
  "history_begin_time" : 1703485531049,
  "history_end_time" : 1703485532424,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "6ublx725rv3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702875592818,
  "history_end_time" : 1702875592818,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wqief2pk6hg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702871264369,
  "history_end_time" : 1702871264369,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "unsqbgp5bge",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702867996382,
  "history_end_time" : 1702867996382,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "27vocoo6wvx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702866593380,
  "history_end_time" : 1702866593380,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "c35fl5aoqf4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702866137602,
  "history_end_time" : 1702866137602,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "npdqqu9vnk1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702657305607,
  "history_end_time" : 1702657305607,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "c5t5g7idye9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702633223037,
  "history_end_time" : 1702633223037,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "s8bynpsqmwh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702633156906,
  "history_end_time" : 1702633163895,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "3y4jd9w48oa",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702274520875,
  "history_end_time" : 1702274520875,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6f1diunqt1i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702257109192,
  "history_end_time" : 1702257109192,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g67npocw6gh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702253506501,
  "history_end_time" : 1702253506501,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "43ucmycn7e7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702047800922,
  "history_end_time" : 1702047800922,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w0xq0g9q2f8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702046671841,
  "history_end_time" : 1702047789480,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "7tlzr1gb3j3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701838624012,
  "history_end_time" : 1701838624012,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "n9mbw0pyatq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701272631467,
  "history_end_time" : 1701272875106,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "kt1tz5qtuzt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701272152695,
  "history_end_time" : 1701272363348,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "zqpz9lw60gi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701269761321,
  "history_end_time" : 1701269761321,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "10ffzfzdw3z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701245472008,
  "history_end_time" : 1701245472008,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w8594djt5i8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701234300610,
  "history_end_time" : 1701234300610,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "oetube474hz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701232375267,
  "history_end_time" : 1701234158040,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "l9w8vjpq8cj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701231048661,
  "history_end_time" : 1701231048661,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "szqurtaf4id",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701230933456,
  "history_end_time" : 1701230952342,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "tpu4owdvdub",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701230796325,
  "history_end_time" : 1701230932249,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "yigho968xt9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701230384877,
  "history_end_time" : 1701230384877,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9ndmhmgdz80",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701229983501,
  "history_end_time" : 1701229983501,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wvund26ggm3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228899364,
  "history_end_time" : 1701228899364,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "b39rhd4vkur",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228374795,
  "history_end_time" : 1701228374795,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "obpy4214jqs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228236335,
  "history_end_time" : 1701228236335,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3hkbih40abn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228118498,
  "history_end_time" : 1701228118498,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "74jgjouvzhl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228056520,
  "history_end_time" : 1701228056520,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7egf7sraa0s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701227912506,
  "history_end_time" : 1701227912506,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w1rgdzd2zxc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701013937400,
  "history_end_time" : 1701015920036,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "69hkeix1b8p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700974688687,
  "history_end_time" : 1700974688687,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "02bowfe60rt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700885116808,
  "history_end_time" : 1700885116808,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "14hs0oykp2s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700471590180,
  "history_end_time" : 1700471590180,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1g21dlwqu7l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700468936408,
  "history_end_time" : 1700468936408,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fc2qeq639az",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700461922981,
  "history_end_time" : 1700462913674,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "qjm1qkfiqdr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700448500133,
  "history_end_time" : 1700448500133,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vmhtx6fczan",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700447319840,
  "history_end_time" : 1700447319840,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pprppfmsf2x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700230067238,
  "history_end_time" : 1700230067238,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ltedl5x9v70",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700229012362,
  "history_end_time" : 1700229012362,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rtmv0aokddf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700210213805,
  "history_end_time" : 1700210213805,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7h3miywm54b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700209780157,
  "history_end_time" : 1700209780157,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1gkifcq5849",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700209729242,
  "history_end_time" : 1700209729242,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2l6yah9hd7i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700203478643,
  "history_end_time" : 1700204245681,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "7oaedpuqw5e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700201828259,
  "history_end_time" : 1700201828259,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rnqdf9cmmpv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700200332851,
  "history_end_time" : 1700200332851,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u4s53oiascj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700145667866,
  "history_end_time" : 1700145667866,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yslq8bmnrx4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700143295301,
  "history_end_time" : 1700143295301,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qdf3zkdq2a9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700141615809,
  "history_end_time" : 1700141615809,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u8yar16vkp5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700134126833,
  "history_end_time" : 1700134126833,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "djhryhs1q1u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700133783699,
  "history_end_time" : 1700133783699,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hd9ypq013ev",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699992839754,
  "history_end_time" : 1699992839754,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "n75lqlboe69",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699982145399,
  "history_end_time" : 1699982145399,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5w05v814dj0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699941614797,
  "history_end_time" : 1699941614797,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5lyo6f89dsl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699939440546,
  "history_end_time" : 1699939440546,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mb84jle580a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699937910462,
  "history_end_time" : 1699937910462,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "s3gw15ewi92",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699805634612,
  "history_end_time" : 1699806085192,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "qj5lyfv5adu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699684154057,
  "history_end_time" : 1699684154057,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cue1e433g6f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699681071335,
  "history_end_time" : 1699681071335,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fvfmom4o2bp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698762678689,
  "history_end_time" : 1698762678689,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rnid7d8dba1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698762637964,
  "history_end_time" : 1698762637964,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "aFLk2eDfGqcc",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\ndef read_json_file(file_path):\n    '''\n    Read and parse a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file.\n\n    Returns:\n        dict: The parsed JSON data.\n    '''\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\ndef haversine(lat1, lon1, lat2, lon2):\n    '''\n    Calculate the Haversine distance between two sets of latitude and longitude coordinates.\n\n    Args:\n        lat1 (float): Latitude of the first point.\n        lon1 (float): Longitude of the first point.\n        lat2 (float): Latitude of the second point.\n        lon2 (float): Longitude of the second point.\n\n    Returns:\n        float: The Haversine distance between the two points in kilometers.\n    '''\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    '''\n    Find the nearest location in a list of locations to a target latitude and longitude.\n\n    Args:\n        locations (list): List of locations, each represented as a dictionary.\n        target_lat (float): Target latitude.\n        target_lon (float): Target longitude.\n\n    Returns:\n        dict: The nearest location from the list.\n    '''\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\ndef csv_to_json(csv_text):\n    '''\n    Convert CSV text to JSON format.\n\n    Args:\n        csv_text (str): The CSV text to convert.\n\n    Returns:\n        str: The JSON representation of the CSV data.\n    '''\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\ndef remove_commented_lines(text):\n    '''\n    Remove lines starting with '#' from the input text.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        str: The input text with lines starting with '#' removed.\n    '''\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\ndef start_to_collect_snotel():\n    '''\n    Start the process of collecting SNOTEL data and saving it to a CSV file.\n    '''\n    csv_file = f'{working_dir}/training_data_ready_snotel_3_yrs_check.csv'\n    start_date = \"2019-01-01\"\n    end_date = \"2022-12-12\"\n\n    if os.path.exists(csv_file):\n        print(f\"The file '{csv_file}' exists.\")\n        return\n\n    station_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\n    result_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\n    for index, row in station_mapping.iterrows():\n        print(index, ' / ', len(station_mapping), ' iterations completed.')\n        station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n        nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n        location_name = nearest_location['name']\n        location_triplet = nearest_location['triplet']\n        location_elevation = nearest_location['elevation']\n        location_station_lat = nearest_location['location']['lat']\n        location_station_long = nearest_location['location']['lng']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n        print(url)\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nstart_to_collect_snotel()\n",
  "history_output" : "today date = 2023-10-26\ntest start date:  2018-01-01\ntest end date:  2023-10-26\n/home/ubuntu\n0  /  700  iterations completed.\nTraceback (most recent call last):\n  File \"/home/ubuntu/gw-workspace/aFLk2eDfGqcc/data_snotel_station_only.py\", line 152, in <module>\n    start_to_collect_snotel()\n  File \"/home/ubuntu/gw-workspace/aFLk2eDfGqcc/data_snotel_station_only.py\", line 128, in start_to_collect_snotel\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/gw-workspace/aFLk2eDfGqcc/data_snotel_station_only.py\", line 22, in read_json_file\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/gridmet_test_run/snotelStations.json'\n",
  "history_begin_time" : 1698363037664,
  "history_end_time" : 1698363038180,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "yZnZe1Wc7QVH",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\ndef read_json_file(file_path):\n    '''\n    Read and parse a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file.\n\n    Returns:\n        dict: The parsed JSON data.\n    '''\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\ndef haversine(lat1, lon1, lat2, lon2):\n    '''\n    Calculate the Haversine distance between two sets of latitude and longitude coordinates.\n\n    Args:\n        lat1 (float): Latitude of the first point.\n        lon1 (float): Longitude of the first point.\n        lat2 (float): Latitude of the second point.\n        lon2 (float): Longitude of the second point.\n\n    Returns:\n        float: The Haversine distance between the two points in kilometers.\n    '''\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    '''\n    Find the nearest location in a list of locations to a target latitude and longitude.\n\n    Args:\n        locations (list): List of locations, each represented as a dictionary.\n        target_lat (float): Target latitude.\n        target_lon (float): Target longitude.\n\n    Returns:\n        dict: The nearest location from the list.\n    '''\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\ndef csv_to_json(csv_text):\n    '''\n    Convert CSV text to JSON format.\n\n    Args:\n        csv_text (str): The CSV text to convert.\n\n    Returns:\n        str: The JSON representation of the CSV data.\n    '''\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\ndef remove_commented_lines(text):\n    '''\n    Remove lines starting with '#' from the input text.\n\n    Args:\n        text (str): The input text.\n\n    Returns:\n        str: The input text with lines starting with '#' removed.\n    '''\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\ndef start_to_collect_snotel():\n    '''\n    Start the process of collecting SNOTEL data and saving it to a CSV file.\n    '''\n    csv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\n    start_date = \"2019-01-01\"\n    end_date = \"2022-12-12\"\n\n    if os.path.exists(csv_file):\n        print(f\"The file '{csv_file}' exists.\")\n        return\n\n    station_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\n    result_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\n    for index, row in station_mapping.iterrows():\n        print(index, ' / ', len(station_mapping), ' iterations completed.')\n        station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n        nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n        location_name = nearest_location['name']\n        location_triplet = nearest_location['triplet']\n        location_elevation = nearest_location['elevation']\n        location_station_lat = nearest_location['location']['lat']\n        location_station_long = nearest_location['location']['lng']\n\n        url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n        print(url)\n\n        r = requests.get(url)\n        text = remove_commented_lines(r.text)\n        reader = csv.DictReader(io.StringIO(text))\n        json_data = json.loads(json.dumps(list(reader)))\n        for entry in json_data:\n            required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                             'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n            result_df.loc[len(result_df.index)] = required_data\n\n    # Save the DataFrame to a CSV file\n    result_df.to_csv(csv_file, index=False)\n\nstart_to_collect_snotel()\n",
  "history_output" : "today date = 2023-10-26\ntest start date:  2018-01-01\ntest end date:  2023-10-26\n/home/ubuntu\nThe file '/home/ubuntu/gridmet_test_run/training_data_ready_snotel_3_yrs.csv' exists.\n",
  "history_begin_time" : 1698363021880,
  "history_end_time" : 1698363022487,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kpr46qfsoq3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698276496954,
  "history_end_time" : 1698276496954,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7w65reb6gap",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698252277358,
  "history_end_time" : 1698252277358,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5jg6hs89790",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698251392460,
  "history_end_time" : 1698251392460,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2euju6ypqnb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698228210945,
  "history_end_time" : 1698228210945,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "op2c1w5985r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698227897132,
  "history_end_time" : 1698227897132,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9bxlj1ape60",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698163737286,
  "history_end_time" : 1698163737286,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jna09mzk9ah",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698163445820,
  "history_end_time" : 1698163445820,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "178fi3mp27e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698163121533,
  "history_end_time" : 1698163121533,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "td5djudrtd3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698160809360,
  "history_end_time" : 1698160809360,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fbf9ek7qbqu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698157805169,
  "history_end_time" : 1698157805169,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nc87odnwl0e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698152099734,
  "history_end_time" : 1698152099734,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vea0ow1itx2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698095495730,
  "history_end_time" : 1698095495730,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9gt46qd9zzs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698075453567,
  "history_end_time" : 1698075453567,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jfhaffijlxb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697349529994,
  "history_end_time" : 1697349529994,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p2yxji27z5c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697348852262,
  "history_end_time" : 1697348852262,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "guqj0dva9f4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697189923547,
  "history_end_time" : 1697189923547,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mwhr8s0jz5l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697188523288,
  "history_end_time" : 1697188523288,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g1ir57jr6pv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697187892253,
  "history_end_time" : 1697187892253,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jpobn7icm0u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697187367958,
  "history_end_time" : 1697187367958,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q1c9kulrzrm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696863953218,
  "history_end_time" : 1696863953218,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vmmps2n5um3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696862402941,
  "history_end_time" : 1696862402941,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ftd84rpbw18",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696832263663,
  "history_end_time" : 1696832263663,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wnz76k37atz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696831867367,
  "history_end_time" : 1696831867367,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eol94iliirq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696830174348,
  "history_end_time" : 1696830174348,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7z1fz3jdbgk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696787541902,
  "history_end_time" : 1696787541902,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yvg4axcehgi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696786838185,
  "history_end_time" : 1696786838185,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7k74j4d4xky",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696771780877,
  "history_end_time" : 1696771780877,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "y12xdpkwcsb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696602943933,
  "history_end_time" : 1696602943933,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "662byq7ktoq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696432484315,
  "history_end_time" : 1696432484315,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sc79jfvu442",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696432299752,
  "history_end_time" : 1696432482233,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "qt5ixnzq5ze",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827991083,
  "history_end_time" : 1695827991083,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rt2pbcgyu8j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827889170,
  "history_end_time" : 1695827964214,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ftp75chvypd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827855638,
  "history_end_time" : 1695827867006,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "7fp9pb03u07",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695696616110,
  "history_end_time" : 1695696616110,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7mnpl7tyr93",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695694257322,
  "history_end_time" : 1695694257322,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wq71z982xi7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695693585741,
  "history_end_time" : 1695693585741,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jfsqvxwphwz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695693149360,
  "history_end_time" : 1695693149360,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "brww2242txp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695580915841,
  "history_end_time" : 1695580915841,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0n2dc9rrm5n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695576291649,
  "history_end_time" : 1695576291649,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vsdxc7m3j8p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695575931007,
  "history_end_time" : 1695575931007,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ya7rzs46fw2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535769206,
  "history_end_time" : 1695535769206,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ioaj1mkzxdj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535478679,
  "history_end_time" : 1695535478679,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j6s19cmk14u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535214018,
  "history_end_time" : 1695535214018,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cjeohho6s32",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695534943582,
  "history_end_time" : 1695534943582,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "94hcq0rmwcf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695534671821,
  "history_end_time" : 1695534671821,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "re83beff6d7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695533024117,
  "history_end_time" : 1695533024117,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "alp8c9v1ziw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695529187859,
  "history_end_time" : 1695529187859,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bgwq3tx2qog",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695528505178,
  "history_end_time" : 1695528505178,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9zpd8qun9ks",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695515862389,
  "history_end_time" : 1695515862389,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p4pl3m90tiw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695506423839,
  "history_end_time" : 1695506423839,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mkvuznq7uw5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695418741333,
  "history_end_time" : 1695418741333,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1tz7ev1kkwx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417619671,
  "history_end_time" : 1695417619671,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xbtncr9eirf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417171273,
  "history_end_time" : 1695417171273,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nnhxll664ho",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417052726,
  "history_end_time" : 1695417052726,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wzgptbcro4b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695416916016,
  "history_end_time" : 1695416916016,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "oF1AWubKxSSz",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\ndef start_to_collect_snotel():\n  csv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\n  start_date = \"2019-01-01\"\n  end_date = \"2022-12-12\"\n  \n  if os.path.exists(csv_file):\n    print(f\"The file '{csv_file}' exists.\")\n    return\n\n  station_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\n  result_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\n  for index, row in station_mapping.iterrows():\n      print(index, ' / ', len(station_mapping), ' iterations completed.')\n      station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n      nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n      location_name = nearest_location['name']\n      location_triplet = nearest_location['triplet']\n      location_elevation = nearest_location['elevation']\n      location_station_lat = nearest_location['location']['lat']\n      location_station_long = nearest_location['location']['lng']\n\n      url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n      r = requests.get(url)\n      text = remove_commented_lines(r.text)\n      reader = csv.DictReader(io.StringIO(text))\n      json_data = json.loads(json.dumps(list(reader)))\n      for entry in json_data:\n          required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                           'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n          result_df.loc[len(result_df.index)] = required_data\n\n  # Save the DataFrame to a CSV file\n  result_df.to_csv(csv_file, index=False)\n  \nstart_to_collect_snotel()\n",
  "history_output" : "today date = 2023-09-20\ntest start date:  2022-03-19\ntest end date:  2023-09-20\n/home/chetana\nThe file '/home/chetana/gridmet_test_run/training_data_ready_snotel_3_yrs.csv' exists.\n",
  "history_begin_time" : 1695180231156,
  "history_end_time" : 1695180232825,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "4bqox8c72zl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695106488973,
  "history_end_time" : 1695106488973,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "m34510diokx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695106316194,
  "history_end_time" : 1695106316194,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jwwnmhdldht",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695054045021,
  "history_end_time" : 1695054045021,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jhgan0bt4sr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695054019754,
  "history_end_time" : 1695054032322,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "6vfgc6jy7q9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053979885,
  "history_end_time" : 1695054019272,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "hmb2wxfmihi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053793400,
  "history_end_time" : 1695053793400,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mwa84ifjts6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053733402,
  "history_end_time" : 1695053733402,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "di6oxpij2qy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694971144817,
  "history_end_time" : 1694972839686,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "7jmpwlz0vym",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970707918,
  "history_end_time" : 1694970707918,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fk6a9ot3srh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970594756,
  "history_end_time" : 1694970594756,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ksuyxf1gl9m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970131561,
  "history_end_time" : 1694970131561,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "79r3inahmjt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694969350051,
  "history_end_time" : 1694969350051,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r5nuavyog89",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694905307655,
  "history_end_time" : 1694905307655,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2siy4l8vzvl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694897887123,
  "history_end_time" : 1694897887123,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zI93DEu613A7",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\nresult_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_mapping.iterrows():\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "today date = 2023-08-15\n/home/chetana\n0  /  700  iterations completed.\n1  /  700  iterations completed.\n2  /  700  iterations completed.\n3  /  700  iterations completed.\n4  /  700  iterations completed.\n5  /  700  iterations completed.\n6  /  700  iterations completed.\n7  /  700  iterations completed.\n8  /  700  iterations completed.\n9  /  700  iterations completed.\n10  /  700  iterations completed.\n11  /  700  iterations completed.\n12  /  700  iterations completed.\n13  /  700  iterations completed.\n14  /  700  iterations completed.\n15  /  700  iterations completed.\n16  /  700  iterations completed.\n17  /  700  iterations completed.\n18  /  700  iterations completed.\n19  /  700  iterations completed.\n20  /  700  iterations completed.\n21  /  700  iterations completed.\n22  /  700  iterations completed.\n23  /  700  iterations completed.\n24  /  700  iterations completed.\n25  /  700  iterations completed.\n26  /  700  iterations completed.\n27  /  700  iterations completed.\n28  /  700  iterations completed.\n29  /  700  iterations completed.\n30  /  700  iterations completed.\n31  /  700  iterations completed.\n32  /  700  iterations completed.\n33  /  700  iterations completed.\n34  /  700  iterations completed.\n35  /  700  iterations completed.\n36  /  700  iterations completed.\n37  /  700  iterations completed.\n38  /  700  iterations completed.\n39  /  700  iterations completed.\n40  /  700  iterations completed.\n41  /  700  iterations completed.\n42  /  700  iterations completed.\n43  /  700  iterations completed.\n44  /  700  iterations completed.\n45  /  700  iterations completed.\n46  /  700  iterations completed.\n47  /  700  iterations completed.\n48  /  700  iterations completed.\n49  /  700  iterations completed.\n50  /  700  iterations completed.\n51  /  700  iterations completed.\n52  /  700  iterations completed.\n53  /  700  iterations completed.\n54  /  700  iterations completed.\n55  /  700  iterations completed.\n56  /  700  iterations completed.\n57  /  700  iterations completed.\n58  /  700  iterations completed.\n59  /  700  iterations completed.\n60  /  700  iterations completed.\n61  /  700  iterations completed.\n62  /  700  iterations completed.\n63  /  700  iterations completed.\n64  /  700  iterations completed.\n65  /  700  iterations completed.\n66  /  700  iterations completed.\n67  /  700  iterations completed.\n68  /  700  iterations completed.\n69  /  700  iterations completed.\n70  /  700  iterations completed.\n71  /  700  iterations completed.\n72  /  700  iterations completed.\n73  /  700  iterations completed.\n74  /  700  iterations completed.\n75  /  700  iterations completed.\n76  /  700  iterations completed.\n77  /  700  iterations completed.\n78  /  700  iterations completed.\n79  /  700  iterations completed.\n80  /  700  iterations completed.\n81  /  700  iterations completed.\n82  /  700  iterations completed.\n83  /  700  iterations completed.\n84  /  700  iterations completed.\n85  /  700  iterations completed.\n86  /  700  iterations completed.\n87  /  700  iterations completed.\n88  /  700  iterations completed.\n89  /  700  iterations completed.\n90  /  700  iterations completed.\n91  /  700  iterations completed.\n92  /  700  iterations completed.\n93  /  700  iterations completed.\n94  /  700  iterations completed.\n95  /  700  iterations completed.\n96  /  700  iterations completed.\n97  /  700  iterations completed.\n98  /  700  iterations completed.\n99  /  700  iterations completed.\n100  /  700  iterations completed.\n101  /  700  iterations completed.\n102  /  700  iterations completed.\n103  /  700  iterations completed.\n104  /  700  iterations completed.\n105  /  700  iterations completed.\n106  /  700  iterations completed.\n107  /  700  iterations completed.\n108  /  700  iterations completed.\n109  /  700  iterations completed.\n110  /  700  iterations completed.\n111  /  700  iterations completed.\n112  /  700  iterations completed.\n113  /  700  iterations completed.\n114  /  700  iterations completed.\n115  /  700  iterations completed.\n116  /  700  iterations completed.\n117  /  700  iterations completed.\n118  /  700  iterations completed.\n119  /  700  iterations completed.\n120  /  700  iterations completed.\n121  /  700  iterations completed.\n122  /  700  iterations completed.\n123  /  700  iterations completed.\n124  /  700  iterations completed.\n125  /  700  iterations completed.\n126  /  700  iterations completed.\n127  /  700  iterations completed.\n128  /  700  iterations completed.\n129  /  700  iterations completed.\n130  /  700  iterations completed.\n131  /  700  iterations completed.\n132  /  700  iterations completed.\n133  /  700  iterations completed.\n134  /  700  iterations completed.\n135  /  700  iterations completed.\n136  /  700  iterations completed.\n137  /  700  iterations completed.\n138  /  700  iterations completed.\n139  /  700  iterations completed.\n140  /  700  iterations completed.\n141  /  700  iterations completed.\n142  /  700  iterations completed.\n143  /  700  iterations completed.\n144  /  700  iterations completed.\n145  /  700  iterations completed.\n146  /  700  iterations completed.\n147  /  700  iterations completed.\n148  /  700  iterations completed.\n149  /  700  iterations completed.\n150  /  700  iterations completed.\n151  /  700  iterations completed.\n152  /  700  iterations completed.\n153  /  700  iterations completed.\n154  /  700  iterations completed.\n155  /  700  iterations completed.\n156  /  700  iterations completed.\n157  /  700  iterations completed.\n158  /  700  iterations completed.\n159  /  700  iterations completed.\n160  /  700  iterations completed.\n161  /  700  iterations completed.\n162  /  700  iterations completed.\n163  /  700  iterations completed.\n164  /  700  iterations completed.\n165  /  700  iterations completed.\n166  /  700  iterations completed.\n167  /  700  iterations completed.\n168  /  700  iterations completed.\n169  /  700  iterations completed.\n170  /  700  iterations completed.\n171  /  700  iterations completed.\n172  /  700  iterations completed.\n173  /  700  iterations completed.\n174  /  700  iterations completed.\n175  /  700  iterations completed.\n176  /  700  iterations completed.\n177  /  700  iterations completed.\n178  /  700  iterations completed.\n179  /  700  iterations completed.\n180  /  700  iterations completed.\n181  /  700  iterations completed.\n182  /  700  iterations completed.\n183  /  700  iterations completed.\n184  /  700  iterations completed.\n185  /  700  iterations completed.\n186  /  700  iterations completed.\n187  /  700  iterations completed.\n188  /  700  iterations completed.\n189  /  700  iterations completed.\n190  /  700  iterations completed.\n191  /  700  iterations completed.\n192  /  700  iterations completed.\n193  /  700  iterations completed.\n194  /  700  iterations completed.\n195  /  700  iterations completed.\n196  /  700  iterations completed.\n197  /  700  iterations completed.\n198  /  700  iterations completed.\n199  /  700  iterations completed.\n200  /  700  iterations completed.\n201  /  700  iterations completed.\n202  /  700  iterations completed.\n203  /  700  iterations completed.\n204  /  700  iterations completed.\n205  /  700  iterations completed.\n206  /  700  iterations completed.\n207  /  700  iterations completed.\n208  /  700  iterations completed.\n209  /  700  iterations completed.\n210  /  700  iterations completed.\n211  /  700  iterations completed.\n212  /  700  iterations completed.\n213  /  700  iterations completed.\n214  /  700  iterations completed.\n215  /  700  iterations completed.\n216  /  700  iterations completed.\n217  /  700  iterations completed.\n218  /  700  iterations completed.\n219  /  700  iterations completed.\n220  /  700  iterations completed.\n221  /  700  iterations completed.\n222  /  700  iterations completed.\n223  /  700  iterations completed.\n224  /  700  iterations completed.\n225  /  700  iterations completed.\n226  /  700  iterations completed.\n227  /  700  iterations completed.\n228  /  700  iterations completed.\n229  /  700  iterations completed.\n230  /  700  iterations completed.\n231  /  700  iterations completed.\n232  /  700  iterations completed.\n233  /  700  iterations completed.\n234  /  700  iterations completed.\n235  /  700  iterations completed.\n236  /  700  iterations completed.\n237  /  700  iterations completed.\n238  /  700  iterations completed.\n239  /  700  iterations completed.\n240  /  700  iterations completed.\n241  /  700  iterations completed.\n242  /  700  iterations completed.\n243  /  700  iterations completed.\n244  /  700  iterations completed.\n245  /  700  iterations completed.\n246  /  700  iterations completed.\n247  /  700  iterations completed.\n248  /  700  iterations completed.\n249  /  700  iterations completed.\n250  /  700  iterations completed.\n251  /  700  iterations completed.\n252  /  700  iterations completed.\n253  /  700  iterations completed.\n254  /  700  iterations completed.\n255  /  700  iterations completed.\n256  /  700  iterations completed.\n257  /  700  iterations completed.\n258  /  700  iterations completed.\n259  /  700  iterations completed.\n260  /  700  iterations completed.\n261  /  700  iterations completed.\n262  /  700  iterations completed.\n263  /  700  iterations completed.\n264  /  700  iterations completed.\n265  /  700  iterations completed.\n266  /  700  iterations completed.\n267  /  700  iterations completed.\n268  /  700  iterations completed.\n269  /  700  iterations completed.\n270  /  700  iterations completed.\n271  /  700  iterations completed.\n272  /  700  iterations completed.\n273  /  700  iterations completed.\n274  /  700  iterations completed.\n275  /  700  iterations completed.\n276  /  700  iterations completed.\n277  /  700  iterations completed.\n278  /  700  iterations completed.\n279  /  700  iterations completed.\n280  /  700  iterations completed.\n281  /  700  iterations completed.\n282  /  700  iterations completed.\n283  /  700  iterations completed.\n284  /  700  iterations completed.\n285  /  700  iterations completed.\n286  /  700  iterations completed.\n287  /  700  iterations completed.\n288  /  700  iterations completed.\n289  /  700  iterations completed.\n290  /  700  iterations completed.\n291  /  700  iterations completed.\n292  /  700  iterations completed.\n293  /  700  iterations completed.\n294  /  700  iterations completed.\n295  /  700  iterations completed.\n296  /  700  iterations completed.\n297  /  700  iterations completed.\n298  /  700  iterations completed.\n299  /  700  iterations completed.\n300  /  700  iterations completed.\n301  /  700  iterations completed.\n302  /  700  iterations completed.\n303  /  700  iterations completed.\n304  /  700  iterations completed.\n305  /  700  iterations completed.\n306  /  700  iterations completed.\n307  /  700  iterations completed.\n308  /  700  iterations completed.\n309  /  700  iterations completed.\n310  /  700  iterations completed.\n311  /  700  iterations completed.\n312  /  700  iterations completed.\n313  /  700  iterations completed.\n314  /  700  iterations completed.\n315  /  700  iterations completed.\n316  /  700  iterations completed.\n317  /  700  iterations completed.\n318  /  700  iterations completed.\n319  /  700  iterations completed.\n320  /  700  iterations completed.\n321  /  700  iterations completed.\n322  /  700  iterations completed.\n323  /  700  iterations completed.\n324  /  700  iterations completed.\n325  /  700  iterations completed.\n326  /  700  iterations completed.\n327  /  700  iterations completed.\n328  /  700  iterations completed.\n329  /  700  iterations completed.\n330  /  700  iterations completed.\n331  /  700  iterations completed.\n332  /  700  iterations completed.\n333  /  700  iterations completed.\n334  /  700  iterations completed.\n335  /  700  iterations completed.\n336  /  700  iterations completed.\n337  /  700  iterations completed.\n338  /  700  iterations completed.\n339  /  700  iterations completed.\n340  /  700  iterations completed.\n341  /  700  iterations completed.\n342  /  700  iterations completed.\n343  /  700  iterations completed.\n344  /  700  iterations completed.\n345  /  700  iterations completed.\n346  /  700  iterations completed.\n347  /  700  iterations completed.\n348  /  700  iterations completed.\n349  /  700  iterations completed.\n350  /  700  iterations completed.\n351  /  700  iterations completed.\n352  /  700  iterations completed.\n353  /  700  iterations completed.\n354  /  700  iterations completed.\n355  /  700  iterations completed.\n356  /  700  iterations completed.\n357  /  700  iterations completed.\n358  /  700  iterations completed.\n359  /  700  iterations completed.\n360  /  700  iterations completed.\n361  /  700  iterations completed.\n362  /  700  iterations completed.\n363  /  700  iterations completed.\n364  /  700  iterations completed.\n365  /  700  iterations completed.\n366  /  700  iterations completed.\n367  /  700  iterations completed.\n368  /  700  iterations completed.\n369  /  700  iterations completed.\n370  /  700  iterations completed.\n371  /  700  iterations completed.\n372  /  700  iterations completed.\n373  /  700  iterations completed.\n374  /  700  iterations completed.\n375  /  700  iterations completed.\n376  /  700  iterations completed.\n377  /  700  iterations completed.\n378  /  700  iterations completed.\n379  /  700  iterations completed.\n380  /  700  iterations completed.\n381  /  700  iterations completed.\n382  /  700  iterations completed.\n383  /  700  iterations completed.\n384  /  700  iterations completed.\n385  /  700  iterations completed.\n386  /  700  iterations completed.\n387  /  700  iterations completed.\n388  /  700  iterations completed.\n389  /  700  iterations completed.\n390  /  700  iterations completed.\n391  /  700  iterations completed.\n392  /  700  iterations completed.\n393  /  700  iterations completed.\n394  /  700  iterations completed.\n395  /  700  iterations completed.\n396  /  700  iterations completed.\n397  /  700  iterations completed.\n398  /  700  iterations completed.\n399  /  700  iterations completed.\n400  /  700  iterations completed.\n401  /  700  iterations completed.\n402  /  700  iterations completed.\n403  /  700  iterations completed.\n404  /  700  iterations completed.\n405  /  700  iterations completed.\n406  /  700  iterations completed.\n407  /  700  iterations completed.\n408  /  700  iterations completed.\n409  /  700  iterations completed.\n410  /  700  iterations completed.\n411  /  700  iterations completed.\n412  /  700  iterations completed.\n413  /  700  iterations completed.\n414  /  700  iterations completed.\n415  /  700  iterations completed.\n416  /  700  iterations completed.\n417  /  700  iterations completed.\n418  /  700  iterations completed.\n419  /  700  iterations completed.\n420  /  700  iterations completed.\n421  /  700  iterations completed.\n422  /  700  iterations completed.\n423  /  700  iterations completed.\n424  /  700  iterations completed.\n425  /  700  iterations completed.\n426  /  700  iterations completed.\n427  /  700  iterations completed.\n428  /  700  iterations completed.\n429  /  700  iterations completed.\n430  /  700  iterations completed.\n431  /  700  iterations completed.\n432  /  700  iterations completed.\n433  /  700  iterations completed.\n434  /  700  iterations completed.\n435  /  700  iterations completed.\n436  /  700  iterations completed.\n437  /  700  iterations completed.\n438  /  700  iterations completed.\n439  /  700  iterations completed.\n440  /  700  iterations completed.\n441  /  700  iterations completed.\n442  /  700  iterations completed.\n443  /  700  iterations completed.\n444  /  700  iterations completed.\n445  /  700  iterations completed.\n446  /  700  iterations completed.\n447  /  700  iterations completed.\n448  /  700  iterations completed.\n449  /  700  iterations completed.\n450  /  700  iterations completed.\n451  /  700  iterations completed.\n452  /  700  iterations completed.\n453  /  700  iterations completed.\n454  /  700  iterations completed.\n455  /  700  iterations completed.\n456  /  700  iterations completed.\n457  /  700  iterations completed.\n458  /  700  iterations completed.\n459  /  700  iterations completed.\n460  /  700  iterations completed.\n461  /  700  iterations completed.\n462  /  700  iterations completed.\n463  /  700  iterations completed.\n464  /  700  iterations completed.\n465  /  700  iterations completed.\n466  /  700  iterations completed.\n467  /  700  iterations completed.\n468  /  700  iterations completed.\n469  /  700  iterations completed.\n470  /  700  iterations completed.\n471  /  700  iterations completed.\n472  /  700  iterations completed.\n473  /  700  iterations completed.\n474  /  700  iterations completed.\n475  /  700  iterations completed.\n476  /  700  iterations completed.\n477  /  700  iterations completed.\n478  /  700  iterations completed.\n479  /  700  iterations completed.\n480  /  700  iterations completed.\n481  /  700  iterations completed.\n482  /  700  iterations completed.\n483  /  700  iterations completed.\n484  /  700  iterations completed.\n485  /  700  iterations completed.\n486  /  700  iterations completed.\n487  /  700  iterations completed.\n488  /  700  iterations completed.\n489  /  700  iterations completed.\n490  /  700  iterations completed.\n491  /  700  iterations completed.\n492  /  700  iterations completed.\n493  /  700  iterations completed.\n494  /  700  iterations completed.\n495  /  700  iterations completed.\n496  /  700  iterations completed.\n497  /  700  iterations completed.\n498  /  700  iterations completed.\n499  /  700  iterations completed.\n500  /  700  iterations completed.\n501  /  700  iterations completed.\n502  /  700  iterations completed.\n503  /  700  iterations completed.\n504  /  700  iterations completed.\n505  /  700  iterations completed.\n506  /  700  iterations completed.\n507  /  700  iterations completed.\n508  /  700  iterations completed.\n509  /  700  iterations completed.\n510  /  700  iterations completed.\n511  /  700  iterations completed.\n512  /  700  iterations completed.\n513  /  700  iterations completed.\n514  /  700  iterations completed.\n515  /  700  iterations completed.\n516  /  700  iterations completed.\n517  /  700  iterations completed.\n518  /  700  iterations completed.\n519  /  700  iterations completed.\n520  /  700  iterations completed.\n521  /  700  iterations completed.\n522  /  700  iterations completed.\n523  /  700  iterations completed.\n524  /  700  iterations completed.\n525  /  700  iterations completed.\n526  /  700  iterations completed.\n527  /  700  iterations completed.\n528  /  700  iterations completed.\n529  /  700  iterations completed.\n530  /  700  iterations completed.\n531  /  700  iterations completed.\n532  /  700  iterations completed.\n533  /  700  iterations completed.\n534  /  700  iterations completed.\n535  /  700  iterations completed.\n536  /  700  iterations completed.\n537  /  700  iterations completed.\n538  /  700  iterations completed.\n539  /  700  iterations completed.\n540  /  700  iterations completed.\n541  /  700  iterations completed.\n542  /  700  iterations completed.\n543  /  700  iterations completed.\n544  /  700  iterations completed.\n545  /  700  iterations completed.\n546  /  700  iterations completed.\n547  /  700  iterations completed.\n548  /  700  iterations completed.\n549  /  700  iterations completed.\n550  /  700  iterations completed.\n551  /  700  iterations completed.\n552  /  700  iterations completed.\n553  /  700  iterations completed.\n554  /  700  iterations completed.\n555  /  700  iterations completed.\n556  /  700  iterations completed.\n557  /  700  iterations completed.\n558  /  700  iterations completed.\n559  /  700  iterations completed.\n560  /  700  iterations completed.\n561  /  700  iterations completed.\n562  /  700  iterations completed.\n563  /  700  iterations completed.\n564  /  700  iterations completed.\n565  /  700  iterations completed.\n566  /  700  iterations completed.\n567  /  700  iterations completed.\n568  /  700  iterations completed.\n569  /  700  iterations completed.\n570  /  700  iterations completed.\n571  /  700  iterations completed.\n572  /  700  iterations completed.\n573  /  700  iterations completed.\n574  /  700  iterations completed.\n575  /  700  iterations completed.\n576  /  700  iterations completed.\n577  /  700  iterations completed.\n578  /  700  iterations completed.\n579  /  700  iterations completed.\n580  /  700  iterations completed.\n581  /  700  iterations completed.\n582  /  700  iterations completed.\n583  /  700  iterations completed.\n584  /  700  iterations completed.\n585  /  700  iterations completed.\n586  /  700  iterations completed.\n587  /  700  iterations completed.\n588  /  700  iterations completed.\n589  /  700  iterations completed.\n590  /  700  iterations completed.\n591  /  700  iterations completed.\n592  /  700  iterations completed.\n593  /  700  iterations completed.\n594  /  700  iterations completed.\n595  /  700  iterations completed.\n596  /  700  iterations completed.\n597  /  700  iterations completed.\n598  /  700  iterations completed.\n599  /  700  iterations completed.\n600  /  700  iterations completed.\n601  /  700  iterations completed.\n602  /  700  iterations completed.\n603  /  700  iterations completed.\n604  /  700  iterations completed.\n605  /  700  iterations completed.\n606  /  700  iterations completed.\n607  /  700  iterations completed.\n608  /  700  iterations completed.\n609  /  700  iterations completed.\n610  /  700  iterations completed.\n611  /  700  iterations completed.\n612  /  700  iterations completed.\n613  /  700  iterations completed.\n614  /  700  iterations completed.\n615  /  700  iterations completed.\n616  /  700  iterations completed.\n617  /  700  iterations completed.\n618  /  700  iterations completed.\n619  /  700  iterations completed.\n620  /  700  iterations completed.\n621  /  700  iterations completed.\n622  /  700  iterations completed.\n623  /  700  iterations completed.\n624  /  700  iterations completed.\n625  /  700  iterations completed.\n626  /  700  iterations completed.\n627  /  700  iterations completed.\n628  /  700  iterations completed.\n629  /  700  iterations completed.\n630  /  700  iterations completed.\n631  /  700  iterations completed.\n632  /  700  iterations completed.\n633  /  700  iterations completed.\n634  /  700  iterations completed.\n635  /  700  iterations completed.\n636  /  700  iterations completed.\n637  /  700  iterations completed.\n638  /  700  iterations completed.\n639  /  700  iterations completed.\n640  /  700  iterations completed.\n641  /  700  iterations completed.\n642  /  700  iterations completed.\n643  /  700  iterations completed.\n644  /  700  iterations completed.\n645  /  700  iterations completed.\n646  /  700  iterations completed.\n647  /  700  iterations completed.\n648  /  700  iterations completed.\n649  /  700  iterations completed.\n650  /  700  iterations completed.\n651  /  700  iterations completed.\n652  /  700  iterations completed.\n653  /  700  iterations completed.\n654  /  700  iterations completed.\n655  /  700  iterations completed.\n656  /  700  iterations completed.\n657  /  700  iterations completed.\n658  /  700  iterations completed.\n659  /  700  iterations completed.\n660  /  700  iterations completed.\n661  /  700  iterations completed.\n662  /  700  iterations completed.\n663  /  700  iterations completed.\n664  /  700  iterations completed.\n665  /  700  iterations completed.\n666  /  700  iterations completed.\n667  /  700  iterations completed.\n668  /  700  iterations completed.\n669  /  700  iterations completed.\n670  /  700  iterations completed.\n671  /  700  iterations completed.\n672  /  700  iterations completed.\n673  /  700  iterations completed.\n674  /  700  iterations completed.\n675  /  700  iterations completed.\n676  /  700  iterations completed.\n677  /  700  iterations completed.\n678  /  700  iterations completed.\n679  /  700  iterations completed.\n680  /  700  iterations completed.\n681  /  700  iterations completed.\n682  /  700  iterations completed.\n683  /  700  iterations completed.\n684  /  700  iterations completed.\n685  /  700  iterations completed.\n686  /  700  iterations completed.\n687  /  700  iterations completed.\n688  /  700  iterations completed.\n689  /  700  iterations completed.\n690  /  700  iterations completed.\n691  /  700  iterations completed.\n692  /  700  iterations completed.\n693  /  700  iterations completed.\n694  /  700  iterations completed.\n695  /  700  iterations completed.\n696  /  700  iterations completed.\n697  /  700  iterations completed.\n698  /  700  iterations completed.\n699  /  700  iterations completed.\n",
  "history_begin_time" : 1692115469530,
  "history_end_time" : 1692164347750,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Wc4jTfDglYg8",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nimport os\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(os.linesep)\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = os.linesep.join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\nresult_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_mapping.iterrows():\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/Wc4jTfDglYg8/data_snotel_station_only.py\", line 86\n    f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \nIndentationError: unexpected indent\n",
  "history_begin_time" : 1692115422993,
  "history_end_time" : 1692115423986,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "jkQygehXFvUp",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\nresult_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_mapping.iterrows():\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/jkQygehXFvUp/data_snotel_station_only.py\", line 57\n    lines = text.split('\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1692115325370,
  "history_end_time" : 1692115326398,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "xZCT7Hq01F9o",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\nresult_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_mapping.iterrows():\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "sh: venv: command not found\n",
  "history_begin_time" : 1692115300135,
  "history_end_time" : 1692115301165,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WSlKA1pUuZVa",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\nresult_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_mapping.iterrows():\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "sh: venv: command not found\n",
  "history_begin_time" : 1692115281073,
  "history_end_time" : 1692115282229,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "pl4lcdSQvvt6",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\nresult_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_mapping.iterrows():\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1692115208849,
  "history_end_time" : 1692115245892,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "rDFRrnj3dmay",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\nfrom snowcast_utils import work_dir\n\nworking_dir = work_dir\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n        return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n            return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n            json_list.append(row_dict)\n            json_string = json.dumps(json_list)\n            return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'):\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\n\ncsv_file = f'{working_dir}/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv(f'{working_dir}/station_cell_mapping.csv')\n\nresult_df = pd.DataFrame(columns=['date', 'lat', 'lon', 'swe_value'])\nfor index, row in station_mapping.iterrows():\n    print(index, ' / ', len(station_mapping), ' iterations completed.')\n    station_locations = read_json_file(f'{working_dir}/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n    for entry in json_data:\n        required_data = {'date': entry['Date'], 'lat': row['lat'], 'lon': row['lon'],\n                         'swe_value': entry['Snow Water Equivalent (in) Start of Day Values']}\n        result_df.loc[len(result_df.index)] = required_data\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1692115007966,
  "history_end_time" : 1692115193115,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "v2bIGfJWpLq1",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\nimport io\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nresult_df = pd.DataFrame(columns=['Date', 'lat', 'lon', 'Snow Water Equivalent (in)',\n                                  'Change In Snow Water Equivalent (in)',\n                                  'Snow Depth (in)', 'Change In Snow Depth (in)',\n                                  'Air Temperature Observed (degF)'])\nfor index, row in station_mapping.iterrows():\n\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n\n    for entry in json_data:\n        entry['lat'] = row['lat']\n        entry['lon'] = row['lon']\n        result_df.loc[len(result_df.index)] = entry\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1692081467804,
  "history_end_time" : 1692106822905,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "7Bcp7BfcPukX",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nresult_df = pd.DataFrame(columns=['Date', 'lat', 'lon', 'Snow Water Equivalent (in)',\n                                  'Change In Snow Water Equivalent (in)',\n                                  'Snow Depth (in)', 'Change In Snow Depth (in)',\n                                  'Air Temperature Observed (degF)'])\nfor index, row in station_mapping.iterrows():\n\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n\n    for entry in json_data:\n        entry['lat'] = row['lat']\n        entry['lon'] = row['lon']\n        result_df.loc[len(result_df.index)] = entry\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/7Bcp7BfcPukX/data_snotel_station_only.py\", line 101, in <module>\n    reader = csv.DictReader(io.StringIO(text))\nNameError: name 'io' is not defined\n",
  "history_begin_time" : 1692081448052,
  "history_end_time" : 1692081448958,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "U2FjUnBNI7EY",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\nimport csv\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nresult_df = pd.DataFrame(columns=['Date', 'lat', 'lon', 'Snow Water Equivalent (in)',\n                                  'Change In Snow Water Equivalent (in)',\n                                  'Snow Depth (in)', 'Change In Snow Depth (in)',\n                                  'Air Temperature Observed (degF)'])\nfor index, row in station_mapping.iterrows():\n\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n\n    for entry in json_data:\n        entry['lat'] = row['lat']\n        entry['lon'] = row['lon']\n        result_df.loc[len(result_df.index)] = entry\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/U2FjUnBNI7EY/data_snotel_station_only.py\", line 101, in <module>\n    reader = csv.DictReader(io.StringIO(text))\nNameError: name 'io' is not defined\n",
  "history_begin_time" : 1692081429629,
  "history_end_time" : 1692081430526,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "JpwdLAzRiMSb",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel_3_yrs.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nresult_df = pd.DataFrame(columns=['Date', 'lat', 'lon', 'Snow Water Equivalent (in)',\n                                  'Change In Snow Water Equivalent (in)',\n                                  'Snow Depth (in)', 'Change In Snow Depth (in)',\n                                  'Air Temperature Observed (degF)'])\nfor index, row in station_mapping.iterrows():\n\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    reader = csv.DictReader(io.StringIO(text))\n    json_data = json.loads(json.dumps(list(reader)))\n\n    for entry in json_data:\n        entry['lat'] = row['lat']\n        entry['lon'] = row['lon']\n        result_df.loc[len(result_df.index)] = entry\n\n# Save the DataFrame to a CSV file\nresult_df.to_csv(csv_file, index=False)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/JpwdLAzRiMSb/data_snotel_station_only.py\", line 100, in <module>\n    reader = csv.DictReader(io.StringIO(text))\nNameError: name 'csv' is not defined\n",
  "history_begin_time" : 1692081391504,
  "history_end_time" : 1692081393177,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "8lfxPReM1jDJ",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel_2000.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, row['lat'], row['lon'])\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1691968129692,
  "history_end_time" : 1691968407525,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "lIkq7eJBWKaS",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel_2000.csv'\nstart_date = \"2020-01-01\"\nend_date = \"2020-01-01\"\n\n#station_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/testing_inputs.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "today date = 2023-08-13\n\nStream closed",
  "history_begin_time" : 1691955337983,
  "history_end_time" : 1691958324228,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "58rgGjqViVRs",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel_2020.csv'\nstart_date = \"2020-01-01\"\nend_date = \"2020-01-01\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1691954131127,
  "history_end_time" : 1691954343418,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "dy79dzh35zu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531335786,
  "history_end_time" : 1691531335786,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "5zvysomqhno",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531292733,
  "history_end_time" : 1691531292733,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "hvhx8sw6ujy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531254585,
  "history_end_time" : 1691531284898,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "lk6yt32otvn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531163849,
  "history_end_time" : 1691531163849,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "kj9nmknryyu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531120864,
  "history_end_time" : 1691531120864,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "zv84phqb7u9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531060881,
  "history_end_time" : 1691531060881,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "2hljj8bjpg2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530848291,
  "history_end_time" : 1691530848291,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "v128rf64zm2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530717687,
  "history_end_time" : 1691530721103,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "lli9gxomqr5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530690133,
  "history_end_time" : 1691530716748,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "6xeeoo0s89l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530621013,
  "history_end_time" : 1691530622437,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "mavp4ta2zsy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530617186,
  "history_end_time" : 1691530617186,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "49i51205ty8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530599786,
  "history_end_time" : 1691530614282,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "uyZX8SPH62dY",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel_2019_2022.csv'\nstart_date = \"2019-01-01\"\nend_date = \"2022-12-30\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/uyZX8SPH62dY/data_snotel_station_only.py\", line 52\n    lines = text.split('\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1691192091697,
  "history_end_time" : 1691192093038,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "dTzLSmHaXMiy",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/dTzLSmHaXMiy/data_snotel_station_only.py\", line 52\n    lines = text.split('\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435447998,
  "history_end_time" : 1690435449046,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "x3KNDLvbtAvp",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split('\\n')\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith('#'): \n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/x3KNDLvbtAvp/data_snotel_station_only.py\", line 52\n    lines = text.split('\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435412976,
  "history_end_time" : 1690435413968,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "2TGec8CwG5YS",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    #lines = text.split(\"\\n\")\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/2TGec8CwG5YS/data_snotel_station_only.py\", line 53\n    \")\n      ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435339980,
  "history_end_time" : 1690435340992,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "mUioimE67bkC",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n    return cleaned_text\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/mUioimE67bkC/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435324515,
  "history_end_time" : 1690435325521,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cKmvfsxkC0tU",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n  with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n    data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n  d_lat = lat2 - lat1\n  d_long = lon2 - lon1\n  a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n  c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n  distance = 6371 * c  # Earth's radius in kilometers\n  return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n  n_location = None\n  min_distance = float('inf')\n  for location in locations:\n    lat = location['location']['lat']\n    lon = location['location']['lng']\n    distance = haversine(lat, lon, target_lat, target_lon)\n    if distance < min_distance:\n      min_distance = distance\n      n_location = location\n      return n_location\n\n\ndef csv_to_json(csv_text):\n  lines = csv_text.splitlines()\n  header = lines[0]\n  field_names = header.split(',')\n  json_list = []\n  for line in lines[1:]:\n    values = line.split(',')\n    row_dict = {}\n    for i, field_name in enumerate(field_names):\n      row_dict[field_name] = values[i]\n      json_list.append(row_dict)\n      json_string = json.dumps(json_list)\n      return json_string\n\n\ndef remove_commented_lines(text):\n  lines = text.split(\"\\n\")\n  cleaned_lines = []\n  for line in lines:\n    if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n      cleaned_lines.append(line)\n      cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n      return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_data_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/cKmvfsxkC0tU/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435275952,
  "history_end_time" : 1690435276968,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "iEXHrf3gJTag",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n  lines = text.split(\"\\n\")\n  cleaned_lines = []\n  for line in lines:\n    if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n      cleaned_lines.append(line)\n      cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n      return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/iEXHrf3gJTag/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690435013488,
  "history_end_time" : 1690435014496,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "bEYVLh3q3RyY",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n            cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n            return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/bEYVLh3q3RyY/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434938239,
  "history_end_time" : 1690434939249,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "OgjJwjOUauMo",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n            cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n            return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/OgjJwjOUauMo/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434932289,
  "history_end_time" : 1690434933299,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "gWG9THFZrUWj",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n  lines = text.split(\"\\n\")\n  cleaned_lines = []\n\n  for line in lines:\n    if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n      cleaned_lines.append(line)\n\n      cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n\n      return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n       \titem['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/gWG9THFZrUWj/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434860319,
  "history_end_time" : 1690434861338,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "oOJ4rclwLg3R",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")\n    cleaned_lines = []\n\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n\n    return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n       \titem['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/oOJ4rclwLg3R/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434809050,
  "history_end_time" : 1690434810072,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vj6uJwzWo9iL",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")  # Split the text into lines\n    cleaned_lines = []\n\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n\n    return cleaned_text\n\n\ncsv_file = '/home/chetana/gridmet_test_run/training_ready_snotel.csv'\nstart_date = \"2002-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('/home/chetana/gridmet_test_run/station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('/home/chetana/gridmet_test_run/snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n       \titem['lat'] = row['lat']\n        item['lon'] = row['lon']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/vj6uJwzWo9iL/data_snotel_station_only.py\", line 52\n    lines = text.split(\"\n                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1690434713804,
  "history_end_time" : 1690434714952,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7gbfaosi0ci",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689632034782,
  "history_end_time" : 1689632036286,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "9lvmt7oy7r5",
  "history_input" : "import math\nimport json\nimport requests\nimport pandas as pd\n\n\ndef read_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8-sig') as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n    d_lat = lat2 - lat1\n    d_long = lon2 - lon1\n    a = math.sin(d_lat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(d_long / 2) ** 2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = 6371 * c  # Earth's radius in kilometers\n    return distance\n\n\ndef find_nearest_location(locations, target_lat, target_lon):\n    n_location = None\n    min_distance = float('inf')\n    for location in locations:\n        lat = location['location']['lat']\n        lon = location['location']['lng']\n        distance = haversine(lat, lon, target_lat, target_lon)\n        if distance < min_distance:\n            min_distance = distance\n            n_location = location\n    return n_location\n\n\ndef csv_to_json(csv_text):\n    lines = csv_text.splitlines()\n    header = lines[0]\n    field_names = header.split(',')\n    json_list = []\n    for line in lines[1:]:\n        values = line.split(',')\n        row_dict = {}\n        for i, field_name in enumerate(field_names):\n            row_dict[field_name] = values[i]\n        json_list.append(row_dict)\n    json_string = json.dumps(json_list)\n    return json_string\n\n\ndef remove_commented_lines(text):\n    lines = text.split(\"\\n\")  # Split the text into lines\n    cleaned_lines = []\n\n    for line in lines:\n        if not line.startswith(\"#\"):  # Check if the line starts with \"#\"\n            cleaned_lines.append(line)\n\n    cleaned_text = \"\\n\".join(cleaned_lines)  # Join the remaining lines\n\n    return cleaned_text\n\n\ncsv_file = 'snotel.csv'\nstart_date = \"2022-01-01\"\nend_date = \"2023-12-12\"\n\nstation_mapping = pd.read_csv('station_cell_mapping.csv')\ndf = pd.DataFrame(columns=['Date', 'Snow Water Equivalent (in) Start of Day Values',\n                           'Change In Snow Water Equivalent (in)',\n                           'Snow Depth (in) Start of Day Values',\n                           'Change In Snow Depth (in)',\n                           'Air Temperature Observed (degF) Start of Day Values',\n                           'station_name',\n                           'station_triplet',\n                           'station_elevation',\n                           'station_lat',\n                           'station_long',\n                           'mapping_station_id',\n                           'mapping_cell_id']\n                  )\n\nfor index, row in station_mapping.iterrows():\n    station_locations = read_json_file('snotelStations.json')\n    nearest_location = find_nearest_location(station_locations, 41.993149, -120.1787155)\n\n    location_name = nearest_location['name']\n    location_triplet = nearest_location['triplet']\n    location_elevation = nearest_location['elevation']\n    location_station_lat = nearest_location['location']['lat']\n    location_station_long = nearest_location['location']['lng']\n\n    url = f\"https://wcc.sc.egov.usda.gov/reportGenerator/view_csv/\" \\\n          f\"customSingleStationReport/daily/{location_triplet}%7Cid%3D%22%22%7Cname/{start_date},{end_date}%2C0/\" \\\n          \"WTEQ%3A%3Avalue%2CWTEQ%3A%3Adelta%2CSNWD%3A%3Avalue%2CSNWD%3A%3Adelta%2CTOBS%3A%3Avalue\"\n\n    r = requests.get(url)\n    text = remove_commented_lines(r.text)\n    json_data = json.loads(csv_to_json(text))\n\n    for item in json_data:\n        item['station_name'] = location_name\n        item['station_triplet'] = location_triplet\n        item['station_elevation'] = location_elevation\n        item['station_lat'] = location_station_lat\n        item['station_long'] = location_station_long\n        item['mapping_station_id'] = row['station_id']\n        item['mapping_cell_id'] = row['cell_id']\n\n    with open(csv_file, 'a') as f:\n        for entry in json_data:\n            pd.DataFrame(entry, index=[0]).to_csv(f, header=True, index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1689631636508,
  "history_end_time" : 1689631638722,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "tq3z35",
  "indicator" : "Done"
},{
  "history_id" : "mom9jp045sp",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689135058746,
  "history_end_time" : 1689135061420,
  "history_notes" : null,
  "history_process" : "br9etb",
  "host_id" : "100001",
  "indicator" : "Failed"
},]
