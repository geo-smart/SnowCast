[{
  "history_id" : "dke8n5dkkyr",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-09-16\ntest end date:  2023-10-09\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 258\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       808\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-09-16.csv\nChecking file: etr_2023.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 258\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       122\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_etr_2023-09-16.csv\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 258\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       909\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-09-16.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 258\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       463.0\ntop            0.0\nfreq      296551.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-09-16.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 258\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       344\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-09-16.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 258\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       505\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-09-16.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 258\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        61\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-09-16.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 258\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       354\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-09-16.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          0.288926\nstd           2.332242\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          55.500000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-09-16.png\n",
  "history_begin_time" : 1696863973909,
  "history_end_time" : 1696864127012,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "on1bumtdxog",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-09-15\ntest end date:  2023-10-09\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 257\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       771\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-09-15.csv\nChecking file: etr_2023.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 257\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       107\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_etr_2023-09-15.csv\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 257\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       913\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-09-15.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 257\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       590.0\ntop            0.0\nfreq      249619.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-09-15.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 257\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       358\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-09-15.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 257\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       485\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-09-15.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 257\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        66\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-09-15.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 257\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       428\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-09-15.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          1.387016\nstd           4.735238\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          82.200000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-09-15.png\n",
  "history_begin_time" : 1696862423829,
  "history_end_time" : 1696862580674,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "h9i2keifpd3",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-06-15\ntest end date:  2023-10-09\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       814\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-06-15.csv\nChecking file: etr_2023.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       209\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_etr_2023-06-15.csv\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       934\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-06-15.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       786.0\ntop            0.0\nfreq      209180.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-06-15.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       353\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-06-15.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       516\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-06-15.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       112\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-06-15.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       423\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-06-15.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          2.611941\nstd           6.724196\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           1.600000\nmax         141.200000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-06-15.png\n",
  "history_begin_time" : 1696832284666,
  "history_end_time" : 1696832441923,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "j3lkdrvxywf",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-12\ntest end date:  2023-10-09\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 42\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       786\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-02-12.csv\nChecking file: etr_2023.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 42\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       111\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_etr_2023-02-12.csv\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 42\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       842\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-02-12.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 42\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       279.0\ntop            0.0\nfreq      284760.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-02-12.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 42\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       430\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-02-12.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 42\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       210\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-02-12.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 42\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       128\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-02-12.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 42\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       383\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-02-12.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  3.7\n54      49.0   -123.056  3.9\n55      49.0   -123.020  4.6\n61      49.0   -122.804  7.6\n62      49.0   -122.768  7.5\ncount    310570.000000\nmean          0.270148\nstd           1.532150\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          38.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-02-12.png\n",
  "history_begin_time" : 1696831892994,
  "history_end_time" : 1696832046572,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wgcb17w1p7v",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 41\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       821\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-02-11.csv\nChecking file: etr_2023.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 41\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       111\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_etr_2023-02-11.csv\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 41\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       845\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-02-11.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 41\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       100.0\ntop            0.0\nfreq      296389.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-02-11.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 41\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       441\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-02-11.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 41\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       204\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-02-11.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 41\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       110\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-02-11.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (280, 585, 1386)\nday_index: 41\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       402\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-02-11.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.6\n54      49.0   -123.056  0.6\n55      49.0   -123.020  0.6\n61      49.0   -122.804  0.5\n62      49.0   -122.768  0.5\ncount    310570.000000\nmean          0.059447\nstd           0.388892\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          19.300000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-02-11.png\n",
  "history_begin_time" : 1696830197477,
  "history_end_time" : 1696830353437,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jnpc3ymg86r",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-02-10\ntest end date:  2023-10-08\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 40\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       800\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-02-10.csv\nChecking file: etr_2023.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 40\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       109\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_etr_2023-02-10.csv\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 40\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       890\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-02-10.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 40\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       204.0\ntop            0.0\nfreq      276400.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-02-10.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 40\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       449\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-02-10.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 40\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       190\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-02-10.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 40\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       105\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-02-10.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 40\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       389\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-02-10.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          0.247126\nstd           1.075288\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          36.100000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-02-10.png\n",
  "history_begin_time" : 1696787561934,
  "history_end_time" : 1696787711380,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lhvmrvhphps",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-01-20.csv already exists. Skipping..\nChecking file: etr_2023.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2023_etr_2023-01-20.csv already exists. Skipping..\nChecking file: rmin_2023.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-01-20.csv already exists. Skipping..\nChecking file: pr_2023.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-20.csv already exists. Skipping..\nChecking file: tmmn_2023.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-01-20.csv already exists. Skipping..\nChecking file: vpd_2023.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-01-20.csv already exists. Skipping..\nChecking file: vs_2023.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2023_vs_2023-01-20.csv already exists. Skipping..\nChecking file: tmmx_2023.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-01-20.csv already exists. Skipping..\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          0.446168\nstd           1.675651\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          30.300000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-20.png\n",
  "history_begin_time" : 1696786843967,
  "history_end_time" : 1696786885941,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t96eigv01bm",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 19\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       701\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-01-20.csv\nChecking file: etr_2023.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 19\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        84\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_etr_2023-01-20.csv\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 19\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       934\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-01-20.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 19\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       234.0\ntop            0.0\nfreq      262383.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-20.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 19\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       416\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-01-20.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 19\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       152\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-01-20.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 19\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        96\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-01-20.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (279, 585, 1386)\nday_index: 19\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       373\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-01-20.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          0.446168\nstd           1.675651\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          30.300000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-20.png\n",
  "history_begin_time" : 1696771801480,
  "history_end_time" : 1696772006975,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "rqu3uv2quoh",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-06\ntest start date:  2023-01-19\ntest end date:  2023-10-06\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (277, 585, 1386)\nday_index: 18\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       654\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-01-19.csv\nChecking file: etr_2023.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (277, 585, 1386)\nday_index: 18\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        74\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_etr_2023-01-19.csv\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (277, 585, 1386)\nday_index: 18\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       948\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-01-19.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (277, 585, 1386)\nday_index: 18\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       190.0\ntop            0.0\nfreq      229979.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-19.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (277, 585, 1386)\nday_index: 18\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       395\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-01-19.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (277, 585, 1386)\nday_index: 18\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       156\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-01-19.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (277, 585, 1386)\nday_index: 18\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        81\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-01-19.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (277, 585, 1386)\nday_index: 18\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       364\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-01-19.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.3\n61      49.0   -122.804  1.3\n62      49.0   -122.768  1.2\ncount    310570.000000\nmean          0.517311\nstd           1.318907\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.300000\nmax          31.400000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-19.png\n",
  "history_begin_time" : 1696602963742,
  "history_end_time" : 1696603159013,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fnd0SqbnX9KS",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-10-04\ntest start date:  2023-01-18\ntest end date:  2023-10-04\n/home/chetana\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-01-18.csv already exists. Skipping..\nChecking file: etr_2023.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2023_etr_2023-01-18.csv already exists. Skipping..\nChecking file: rmin_2023.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-01-18.csv already exists. Skipping..\nChecking file: pr_2023.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-18.csv already exists. Skipping..\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (275, 585, 1386)\nday_index: 17\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       379\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-01-18.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (275, 585, 1386)\nday_index: 17\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       147\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-01-18.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (275, 585, 1386)\nday_index: 17\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       125\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-01-18.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (275, 585, 1386)\nday_index: 17\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       416\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-01-18.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  1.0\n54      49.0   -123.056  1.0\n55      49.0   -123.020  1.4\n61      49.0   -122.804  4.1\n62      49.0   -122.768  4.2\ncount    310570.000000\nmean          2.363110\nstd           5.110521\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           2.400000\nmax          68.300000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-18.png\n",
  "history_begin_time" : 1696432627803,
  "history_end_time" : 1696432720191,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "5w9ru3l5xqe",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1696432491573,
  "history_end_time" : 1696432494850,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "iriq52o6sos",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1696432328894,
  "history_end_time" : 1696432482234,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "xkqxh9vowuc",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-27\ntest start date:  2023-01-15\ntest end date:  2023-09-27\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nChecking file: rmax_2023.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2023_rmax_2023-01-15.csv already exists. Skipping..\nChecking file: etr_2023.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2023_etr_2023-01-15.csv already exists. Skipping..\nChecking file: rmin_2023.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (268, 585, 1386)\nday_index: 14\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       933\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_rmin_2023-01-15.csv\nChecking file: pr_2023.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (268, 585, 1386)\nday_index: 14\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       762\ntop           --\nfreq      151634\nName: pr, dtype: object\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-15.csv\nChecking file: tmmn_2023.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (268, 585, 1386)\nday_index: 14\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       359\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmn_2023-01-15.csv\nChecking file: vpd_2023.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (268, 585, 1386)\nday_index: 14\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       199\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vpd_2023-01-15.csv\nChecking file: vs_2023.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (268, 585, 1386)\nday_index: 14\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       168\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_vs_2023-01-15.csv\nChecking file: tmmx_2023.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (268, 585, 1386)\nday_index: 14\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       384\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2023_tmmx_2023-01-15.csv\n    Latitude  Longitude    pr\n53      49.0   -123.092  10.5\n54      49.0   -123.056   9.9\n55      49.0   -123.020  10.6\n61      49.0   -122.804  11.1\n62      49.0   -122.768  11.0\ncount    310570.000000\nmean          4.052784\nstd           7.407600\nmin           0.000000\n25%           0.000000\n50%           1.300000\n75%           4.600000\nmax         105.700000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2023_pr_2023-01-15.png\n",
  "history_begin_time" : 1695827996262,
  "history_end_time" : 1695828110849,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6vcrn305ozh",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "Running",
  "history_begin_time" : 1695827895003,
  "history_end_time" : 1695827964238,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "chgmw5qpwkj",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "Cannot run program \"/home/chetana/anaconda3/conda/bin/python\" (in directory \"/home/chetana/gw-workspace/chgmw5qpwkj\"): error=2, No such file or directory",
  "history_begin_time" : 1695827858550,
  "history_end_time" : 1695827867009,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gbf1o6ytpqx",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-26\ntest start date:  2022-03-15\ntest end date:  2023-09-26\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-15.csv already exists. Skipping..\nChecking file: vpd_2022.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-15.csv already exists. Skipping..\nChecking file: vs_2022.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-15.csv already exists. Skipping..\nChecking file: tmmn_2022.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-15.csv already exists. Skipping..\nChecking file: pr_2022.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-15.csv already exists. Skipping..\nChecking file: tmmx_2022.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-15.csv already exists. Skipping..\nChecking file: rmin_2022.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-15.csv already exists. Skipping..\nChecking file: etr_2022.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-15.csv already exists. Skipping..\n    Latitude  Longitude   pr\n53      49.0   -123.092  1.5\n54      49.0   -123.056  1.1\n55      49.0   -123.020  1.4\n61      49.0   -122.804  1.6\n62      49.0   -122.768  1.5\ncount    310570.000000\nmean          2.018551\nstd           5.599925\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           1.200000\nmax         112.000000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-15.png\n",
  "history_begin_time" : 1695696621373,
  "history_end_time" : 1695696635863,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "x928qo5m95d",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-26\ntest start date:  2022-04-17\ntest end date:  2023-09-26\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 106\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       859\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-04-17.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 106\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       379\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-04-17.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 106\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       132\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-04-17.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 106\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       428\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-04-17.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 106\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       323.0\ntop            0.0\nfreq      260430.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-04-17.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 106\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       461\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-04-17.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 106\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       980\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-04-17.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 106\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       146\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-04-17.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  4.0\n54      49.0   -123.056  3.8\n55      49.0   -123.020  3.9\n61      49.0   -122.804  3.5\n62      49.0   -122.768  3.5\ncount    310570.000000\nmean          0.448591\nstd           1.792269\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          49.300000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-04-17.png\n",
  "history_begin_time" : 1695694276523,
  "history_end_time" : 1695694400124,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ozjx4y3dbqw",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-26\ntest start date:  2022-01-17\ntest end date:  2023-09-26\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-01-17.csv already exists. Skipping..\nChecking file: vpd_2022.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-01-17.csv already exists. Skipping..\nChecking file: vs_2022.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-01-17.csv already exists. Skipping..\nChecking file: tmmn_2022.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-01-17.csv already exists. Skipping..\nChecking file: pr_2022.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-01-17.csv already exists. Skipping..\nChecking file: tmmx_2022.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-01-17.csv already exists. Skipping..\nChecking file: rmin_2022.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-01-17.csv already exists. Skipping..\nChecking file: etr_2022.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-01-17.csv already exists. Skipping..\n    Latitude  Longitude   pr\n53      49.0   -123.092  6.8\n54      49.0   -123.056  6.9\n55      49.0   -123.020  7.3\n61      49.0   -122.804  9.0\n62      49.0   -122.768  9.1\ncount    310570.000000\nmean          0.227605\nstd           1.119321\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.100000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-01-17.png\n",
  "history_begin_time" : 1695693589880,
  "history_end_time" : 1695693604526,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jqyyilnkhjx",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-26\ntest start date:  2022-01-17\ntest end date:  2023-09-26\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 16\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       813\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-01-17.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 16\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       167\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-01-17.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 16\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       135\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-01-17.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 16\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       394\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-01-17.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 16\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       178.0\ntop            0.0\nfreq      282721.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-01-17.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 16\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       352\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-01-17.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 16\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       990\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-01-17.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 16\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        87\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-01-17.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  6.8\n54      49.0   -123.056  6.9\n55      49.0   -123.020  7.3\n61      49.0   -122.804  9.0\n62      49.0   -122.768  9.1\ncount    310570.000000\nmean          0.227605\nstd           1.119321\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.100000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-01-17.png\n",
  "history_begin_time" : 1695693169425,
  "history_end_time" : 1695693318008,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "477bn37t3su",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-01-16\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 15\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       851\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-01-16.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 15\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       190\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-01-16.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 15\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       113\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-01-16.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 15\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       419\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-01-16.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 15\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique        48.0\ntop            0.0\nfreq      307742.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-01-16.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 15\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       364\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-01-16.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 15\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       959\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-01-16.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 15\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        83\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-01-16.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.7\n62      49.0   -122.768  0.7\ncount    310570.000000\nmean          0.008135\nstd           0.109856\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax           4.900000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-01-16.png\n",
  "history_begin_time" : 1695580935643,
  "history_end_time" : 1695581061117,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8ohwj8p7map",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-10-16\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 288\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       774\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-10-16.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 288\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       326\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-10-16.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 288\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        87\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-10-16.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 288\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       340\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-10-16.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 288\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       582.0\ntop            0.0\nfreq      250592.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-10-16.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 288\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       366\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-10-16.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 288\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       921\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-10-16.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 288\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        81\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-10-16.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          1.926799\nstd           5.383332\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          79.900000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-10-16.png\n",
  "history_begin_time" : 1695576310601,
  "history_end_time" : 1695576434270,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5una4p08vwf",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-12-29\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 362\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       648\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-12-29.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 362\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       161\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-12-29.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 362\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       120\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-12-29.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 362\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       400\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-12-29.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 362\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       811\ntop           --\nfreq      151634\nName: pr, dtype: object\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-12-29.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 362\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       393\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-12-29.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 362\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       866\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-12-29.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 362\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        71\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-12-29.csv\n    Latitude  Longitude    pr\n53      49.0   -123.092  11.1\n54      49.0   -123.056  11.1\n55      49.0   -123.020  11.0\n61      49.0   -122.804  10.2\n62      49.0   -122.768  10.1\ncount    310570.000000\nmean          3.719591\nstd           8.123135\nmin           0.000000\n25%           0.000000\n50%           0.400000\n75%           3.500000\nmax         110.500000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-12-29.png\n",
  "history_begin_time" : 1695575952296,
  "history_end_time" : 1695576119090,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jbv8ihw1bb3",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-12-30\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 363\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       648\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-12-30.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 363\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       107\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-12-30.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 363\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       150\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-12-30.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 363\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       387\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-12-30.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 363\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique      1431\ntop           --\nfreq      151634\nName: pr, dtype: object\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-12-30.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 363\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       339\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-12-30.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 363\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       846\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-12-30.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 363\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        57\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-12-30.csv\n    Latitude  Longitude    pr\n53      49.0   -123.092   9.2\n54      49.0   -123.056   9.9\n55      49.0   -123.020  10.9\n61      49.0   -122.804  13.0\n62      49.0   -122.768  12.7\ncount    310570.000000\nmean          6.139028\nstd          13.319236\nmin           0.000000\n25%           0.000000\n50%           0.700000\n75%           6.600000\nmax         242.500000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1695535788043,
  "history_end_time" : 1695535928815,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mmq89su2uzi",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-10-15\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 287\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       767\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-10-15.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 287\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       374\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-10-15.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 287\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        92\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-10-15.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 287\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       354\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-10-15.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 287\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       459.0\ntop            0.0\nfreq      242346.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-10-15.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 287\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       396\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-10-15.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 287\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       849\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-10-15.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 287\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       111\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-10-15.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          1.461647\nstd           4.265414\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          60.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-10-15.png\n",
  "history_begin_time" : 1695535498786,
  "history_end_time" : 1695535630280,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "c0g673uc1f4",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-06-15\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       894\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-06-15.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       572\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-06-15.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       152\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-06-15.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       375\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-06-15.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       377.0\ntop            0.0\nfreq      266892.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-06-15.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       406\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-06-15.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       854\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-06-15.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 165\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       171\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-06-15.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.5\n54      49.0   -123.056  0.5\n55      49.0   -123.020  0.5\n61      49.0   -122.804  0.4\n62      49.0   -122.768  0.4\ncount    310570.000000\nmean          0.483185\nstd           2.124188\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax         102.500000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-06-15.png\n",
  "history_begin_time" : 1695535235372,
  "history_end_time" : 1695535364554,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "rbdfqcdtsy8",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-03-15\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 73\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       774\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-15.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 73\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       335\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-15.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 73\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       128\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-15.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 73\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       367\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-15.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 73\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       641.0\ntop            0.0\nfreq      205009.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-15.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 73\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       395\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-15.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 73\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       940\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-15.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 73\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       103\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-15.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  1.5\n54      49.0   -123.056  1.1\n55      49.0   -123.020  1.4\n61      49.0   -122.804  1.6\n62      49.0   -122.768  1.5\ncount    310570.000000\nmean          2.018551\nstd           5.599925\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           1.200000\nmax         112.000000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-15.png\n",
  "history_begin_time" : 1695534963793,
  "history_end_time" : 1695535093814,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "02dcc9c7jnu",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-02-28\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 58\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       830\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-02-28.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 58\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       270\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-02-28.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 58\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       188\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-02-28.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 58\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       409\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-02-28.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 58\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique      1121.0\ntop            0.0\nfreq      249540.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-02-28.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 58\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       393\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-02-28.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 58\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       992\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-02-28.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 58\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       141\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-02-28.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  4.9\n54      49.0   -123.056  5.3\n55      49.0   -123.020  5.6\n61      49.0   -122.804  7.1\n62      49.0   -122.768  7.1\ncount    310570.000000\nmean          2.615411\nstd           9.663418\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax         170.900000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-02-28.png\n",
  "history_begin_time" : 1695534690542,
  "history_end_time" : 1695534817208,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9kfqeg358tz",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-02-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       632\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-02-22.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       254\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-02-22.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       146\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-02-22.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       538\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-02-22.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       414.0\ntop            0.0\nfreq      186340.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-02-22.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       600\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-02-22.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       952\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-02-22.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       120\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-02-22.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.8\n62      49.0   -122.768  0.8\ncount    310570.000000\nmean          1.381115\nstd           3.199411\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           1.200000\nmax          57.100000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-02-22.png\n",
  "history_begin_time" : 1695533028474,
  "history_end_time" : 1695533156898,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "uh0j4uknf4s",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-02-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       632\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-02-22.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       254\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-02-22.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       146\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-02-22.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       538\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-02-22.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       414.0\ntop            0.0\nfreq      186340.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-02-22.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       600\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-02-22.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       952\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-02-22.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 52\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       120\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-02-22.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.8\n62      49.0   -122.768  0.8\ncount    310570.000000\nmean          1.381115\nstd           3.199411\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           1.200000\nmax          57.100000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-02-22.png\n",
  "history_begin_time" : 1695529207249,
  "history_end_time" : 1695529333713,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nzbtlu04qmp",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2022.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2022.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2022.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2022.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2022.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2022.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2022.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          0.949258\nstd           3.187787\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.400000\nmax          92.000000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695528511246,
  "history_end_time" : 1695528525665,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qJFkvGzL6JLt",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lon_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       818\ntop           --\nfreq      151634\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       688\ntop           --\nfreq      151634\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       108\ntop           --\nfreq      151634\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       385\ntop           --\nfreq      151634\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique       563.0\ntop            0.0\nfreq      225053.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       388\ntop           --\nfreq      151634\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       845\ntop           --\nfreq      151634\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       132\ntop           --\nfreq      151634\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv\n    Latitude  Longitude   pr\n53      49.0   -123.092  0.0\n54      49.0   -123.056  0.0\n55      49.0   -123.020  0.0\n61      49.0   -122.804  0.0\n62      49.0   -122.768  0.0\ncount    310570.000000\nmean          0.949258\nstd           3.187787\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.400000\nmax          92.000000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695528328136,
  "history_end_time" : 1695528452105,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "y1s9GZjnaGYx",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       251\ntop           --\nfreq      143658\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       186\ntop           --\nfreq      143658\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        40\ntop           --\nfreq      143658\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       109\ntop           --\nfreq      143658\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique        47.0\ntop            0.0\nfreq      260250.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       123\ntop           --\nfreq      143658\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gw-workspace/y1s9GZjnaGYx/gridmet_testing.py:330: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       229\ntop           --\nfreq      143658\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col.shape:  (365, 585, 1386)\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        75\ntop           --\nfreq      143658\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695528152898,
  "history_end_time" : 1695528284033,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "lok1eHUOFav0",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col.shape: \", var_col.shape)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "/home/chetana/gw-workspace/lok1eHUOFav0/gridmet_testing.py:330: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\ntoday date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2022.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2022.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2022.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2022.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2022.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2022.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2022.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695528042498,
  "history_end_time" : 1695528059566,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WoKaJZ8x4vW2",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col: \", var_col)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col:  [[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       251\ntop           --\nfreq      143658\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col:  [[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       186\ntop           --\nfreq      143658\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col:  [[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        40\ntop           --\nfreq      143658\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col:  [[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       109\ntop           --\nfreq      143658\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col:  [[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique        47.0\ntop            0.0\nfreq      260250.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col:  [[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       123\ntop           --\nfreq      143658\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col:  [[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n/home/chetana/gw-workspace/WoKaJZ8x4vW2/gridmet_testing.py:330: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       229\ntop           --\nfreq      143658\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nval_col:  [[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        75\ntop           --\nfreq      143658\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695527786305,
  "history_end_time" : 1695527920068,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ntZgxoR3rjGx",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      print(\"val_col: \", var_col)\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        \n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "/home/chetana/gw-workspace/ntZgxoR3rjGx/gridmet_testing.py:330: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\ntoday date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2022.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2022.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2022.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2022.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2022.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2022.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2022.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695527757605,
  "history_end_time" : 1695527773625,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "CvQmuBYVVjGj",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       251\ntop           --\nfreq      143658\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       186\ntop           --\nfreq      143658\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        40\ntop           --\nfreq      143658\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       109\ntop           --\nfreq      143658\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique        47.0\ntop            0.0\nfreq      260250.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       123\ntop           --\nfreq      143658\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\n/home/chetana/gw-workspace/CvQmuBYVVjGj/gridmet_testing.py:328: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       229\ntop           --\nfreq      143658\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\nIndex(['dem_lat', 'dem_lon', 'x', 'y', 'Elevation', 'gridmet_lat',\n       'gridmet_lon', 'gridmet_lat_idx', 'gridmet_lon_idx'],\n      dtype='object')\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        75\ntop           --\nfreq      143658\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695527349258,
  "history_end_time" : 1695527480702,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "fV3lPtJX3ELw",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.columns)\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  #print(gridmet_var_df[\"Latitude\"].describe())\n  #print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "/home/chetana/gw-workspace/fV3lPtJX3ELw/gridmet_testing.py:328: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\ntoday date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2022.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2022.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2022.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2022.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2022.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2022.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2022.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695526700147,
  "history_end_time" : 1695526716630,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "FldDKCO10vAm",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      print(mapper_df.head())\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      print(\"mapper_df[var_name]: \", mapper_df[var_name].describe())\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  print(gridmet_var_df[\"Latitude\"].describe())\n  print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       251\ntop           --\nfreq      143658\nName: rmax, dtype: object\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       186\ntop           --\nfreq      143658\nName: vpd, dtype: object\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        40\ntop           --\nfreq      143658\nName: vs, dtype: object\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       109\ntop           --\nfreq      143658\nName: tmmn, dtype: object\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204.0\nunique        47.0\ntop            0.0\nfreq      260250.0\nName: pr, dtype: float64\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       123\ntop           --\nfreq      143658\nName: tmmx, dtype: object\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique       229\ntop           --\nfreq      143658\nName: rmin, dtype: object\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gw-workspace/FldDKCO10vAm/gridmet_testing.py:327: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nmapper_df[var_name]:  count     462204\nunique        75\ntop           --\nfreq      143658\nName: etr, dtype: object\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean         39.964000\nstd           4.770064\nmin          31.720000\n25%          35.824000\n50%          39.964000\n75%          44.104000\nmax          48.208000\nName: Latitude, dtype: float64\ncount    318546.000000\nmean       -112.526000\nstd           7.212263\nmin        -125.000000\n25%        -118.772000\n50%        -112.526000\n75%        -106.280000\nmax        -100.052000\nName: Longitude, dtype: float64\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695526339855,
  "history_end_time" : 1695526470910,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "J3xOObcwXoXd",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  print(gridmet_var_df[\"Latitude\"].describe())\n  print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "/home/chetana/gw-workspace/J3xOObcwXoXd/gridmet_testing.py:324: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\ntoday date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv\nChecking file: vpd_2022.nc\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv\nChecking file: vs_2022.nc\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv\nChecking file: tmmn_2022.nc\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv\nChecking file: pr_2022.nc\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv\nChecking file: tmmx_2022.nc\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv\nChecking file: rmin_2022.nc\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv\nChecking file: etr_2022.nc\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean         39.964000\nstd           4.770064\nmin          31.720000\n25%          35.824000\n50%          39.964000\n75%          44.104000\nmax          48.208000\nName: Latitude, dtype: float64\ncount    318546.000000\nmean       -112.526000\nstd           7.212263\nmin        -125.000000\n25%        -118.772000\n50%        -112.526000\n75%        -106.280000\nmax        -100.052000\nName: Longitude, dtype: float64\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695525505484,
  "history_end_time" : 1695525641288,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "XAQra4e5nOzE",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                print(f\"Checking file: {file_name}\")\n                var_name = get_var_from_file_name(file_name)\n                print(\"Variable name:\", var_name)\n                res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n\n                if os.path.exists(res_csv):\n                    #os.remove(res_csv)\n                    print(f\"{res_csv} already exists. Skipping..\")\n                    continue\n\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  print(gridmet_var_df[\"Latitude\"].describe())\n  print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "/home/chetana/gw-workspace/XAQra4e5nOzE/gridmet_testing.py:324: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\ntoday date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: rmax_2022.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2022.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2022.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2022.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2022.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2022.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2022.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2022.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean         39.964000\nstd           4.770064\nmin          31.720000\n25%          35.824000\n50%          39.964000\n75%          44.104000\nmax          48.208000\nName: Latitude, dtype: float64\ncount    318546.000000\nmean       -112.526000\nstd           7.212263\nmin        -125.000000\n25%        -118.772000\n50%        -112.526000\n75%        -106.280000\nmax        -100.052000\nName: Longitude, dtype: float64\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695525436952,
  "history_end_time" : 1695525453119,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kddxTcDimx0a",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            print(f\"Checking file: {file_name}\")\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  print(gridmet_var_df[\"Latitude\"].describe())\n  print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nChecking file: tmmx_2019.csv\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2020.csv\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2020.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2021.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_merged.csv\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2023.csv\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2019.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2021.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2021.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2022.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2021.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2021.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2021.csv\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2020.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2021.csv\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2023.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2022.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2019.csv\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2019.csv\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2021.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2022.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2019.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2023.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: etr_merged.csv\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2020.csv\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2020.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2019.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2022.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2021.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2022.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2019.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2022.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2021.csv\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2021.csv\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2022.csv\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2021.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2023.csv\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_merged.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2022.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_merged.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2022.csv\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2019.csv\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2021.csv\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2023.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2023.csv\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2022.csv\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_merged.csv\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2023.csv\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2023.csv\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2019.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2019.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: training_ready_gridmet.csv\nVariable name: training\nChecking file: etr_2021.csv\nVariable name: etr\n/home/chetana/gw-workspace/kddxTcDimx0a/gridmet_testing.py:323: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2023.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2020.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2020.csv\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: pr_2020.nc\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2022.csv\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2019.csv\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2023.csv\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2022.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2020.csv\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2023.nc\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2020.csv\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: pr_merged.csv\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2019.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_merged.csv\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2019.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2021.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2022.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2023.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2019.nc\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2023.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: rmin_2022.csv\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2020.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2023.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2020.nc\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: etr_2022.nc\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2019.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2020.nc\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2019.csv\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2022.csv\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2020.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: rmax_2020.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nChecking file: tmmn_2020.csv\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nChecking file: vs_merged.csv\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: vs_2023.nc\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nChecking file: tmmx_2023.nc\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nChecking file: vpd_2021.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean         39.964000\nstd           4.770064\nmin          31.720000\n25%          35.824000\n50%          39.964000\n75%          44.104000\nmax          48.208000\nName: Latitude, dtype: float64\ncount    318546.000000\nmean       -112.526000\nstd           7.212263\nmin        -125.000000\n25%        -118.772000\n50%        -112.526000\n75%        -106.280000\nmax        -100.052000\nName: Longitude, dtype: float64\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695525395776,
  "history_end_time" : 1695525412470,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "nifhTZuADpC3",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  print(gridmet_var_df[\"Latitude\"].describe())\n  print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Longitude\"].values, \n              gridmet_var_df[\"Latitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gw-workspace/nifhTZuADpC3/gridmet_testing.py:322: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean         39.964000\nstd           4.770064\nmin          31.720000\n25%          35.824000\n50%          39.964000\n75%          44.104000\nmax          48.208000\nName: Latitude, dtype: float64\ncount    318546.000000\nmean       -112.526000\nstd           7.212263\nmin        -125.000000\n25%        -118.772000\n50%        -112.526000\n75%        -106.280000\nmax        -100.052000\nName: Longitude, dtype: float64\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695524982852,
  "history_end_time" : 1695524998791,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "nkxkXmxFWFU3",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  print(gridmet_var_df[\"Latitude\"].describe())\n  print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Latitude\"].values, \n              gridmet_var_df[\"Longitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gw-workspace/nkxkXmxFWFU3/gridmet_testing.py:322: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean         39.964000\nstd           4.770064\nmin          31.720000\n25%          35.824000\n50%          39.964000\n75%          44.104000\nmax          48.208000\nName: Latitude, dtype: float64\ncount    318546.000000\nmean       -112.526000\nstd           7.212263\nmin        -125.000000\n25%        -118.772000\n50%        -112.526000\n75%        -106.280000\nmax        -100.052000\nName: Longitude, dtype: float64\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695524489064,
  "history_end_time" : 1695524505208,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "yx3neUdJk9QK",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  print(gridmet_var_df[\"Latitude\"].describe())\n  print(gridmet_var_df[\"Longitude\"].describe())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Latitude\"].values, \n              gridmet_var_df[\"Longitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gw-workspace/yx3neUdJk9QK/gridmet_testing.py:322: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean         39.964000\nstd           4.770064\nmin          31.720000\n25%          35.824000\n50%          39.964000\n75%          44.104000\nmax          48.208000\nName: Latitude, dtype: float64\ncount    318546.000000\nmean       -112.526000\nstd           7.212263\nmin        -125.000000\n25%        -118.772000\n50%        -112.526000\n75%        -106.280000\nmax        -100.052000\nName: Longitude, dtype: float64\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695523094949,
  "history_end_time" : 1695523111162,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "HApHBrJkzow0",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  print(gridmet_var_df[\"pr\"].describe())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Latitude\"].values, \n              gridmet_var_df[\"Longitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gw-workspace/HApHBrJkzow0/gridmet_testing.py:320: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ncount    318546.000000\nmean          0.904793\nstd           2.917352\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax          20.800000\nName: pr, dtype: float64\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695522970570,
  "history_end_time" : 1695522986947,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Pe8FZrRiRcMM",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(gridmet_var_df[\"Latitude\"].values, \n              gridmet_var_df[\"Longitude\"].values, \n              label='Pressure', \n              color=colormaplist, \n              marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gw-workspace/Pe8FZrRiRcMM/gridmet_testing.py:319: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  plt.savefig(res_png_path)\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\ntest image is saved at /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.png\n",
  "history_begin_time" : 1695522844848,
  "history_end_time" : 1695522861182,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "srELVZSkgism",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\nimport matplotlib.pyplot as plt\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(X, Y, label='Pressure', color=colormaplist, marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/srELVZSkgism/gridmet_testing.py\", line 338, in <module>\n    plot_gridmet()\n  File \"/home/chetana/gw-workspace/srELVZSkgism/gridmet_testing.py\", line 306, in plot_gridmet\n    plt.scatter(X, Y, label='Pressure', color=colormaplist, marker='o')\nNameError: name 'X' is not defined\n",
  "history_begin_time" : 1695522776765,
  "history_end_time" : 1695522777931,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "OqcvUIkoPfon",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  gridmet_var_df.dropna(inplace=True)\n  gridmet_var_df['pr'] = pd.to_numeric(gridmet_var_df['pr'], errors='coerce')\n  print(gridmet_var_df.head())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(X, Y, label='Pressure', color=colormaplist, marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n       Latitude  Longitude   pr\n15268    48.208   -125.000  0.0\n15269    48.208   -124.964  0.0\n15270    48.208   -124.928  0.0\n15271    48.208   -124.892  0.0\n15272    48.208   -124.856  0.0\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/OqcvUIkoPfon/gridmet_testing.py\", line 337, in <module>\n    plot_gridmet()\n  File \"/home/chetana/gw-workspace/OqcvUIkoPfon/gridmet_testing.py\", line 305, in plot_gridmet\n    plt.scatter(X, Y, label='Pressure', color=colormaplist, marker='o')\nNameError: name 'plt' is not defined\n",
  "history_begin_time" : 1695522757329,
  "history_end_time" : 1695522758527,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "LqNgzyo7LYHX",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  gridmet_var_df.replace('--', pd.NA, inplace=True)\n  print(gridmet_var_df.head())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(X, Y, label='Pressure', color=colormaplist, marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n   Latitude  Longitude    pr\n0      49.0   -125.000  <NA>\n1      49.0   -124.964  <NA>\n2      49.0   -124.928  <NA>\n3      49.0   -124.892  <NA>\n4      49.0   -124.856  <NA>\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/LqNgzyo7LYHX/gridmet_testing.py\", line 335, in <module>\n    plot_gridmet()\n  File \"/home/chetana/gw-workspace/LqNgzyo7LYHX/gridmet_testing.py\", line 300, in plot_gridmet\n    colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  File \"/home/chetana/gw-workspace/LqNgzyo7LYHX/gridmet_testing.py\", line 61, in create_color_maps_with_value_range\n    max_value = df_col.max()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 11941, in max\n    return NDFrame.max(self, axis, skipna, level, numeric_only, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 11383, in max\n    return self._stat_function(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 11353, in _stat_function\n    return self._reduce(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\", line 4816, in _reduce\n    return op(delegate, skipna=skipna, **kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py\", line 155, in f\n    result = alt(values, axis=axis, skipna=skipna, **kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py\", line 418, in new_func\n    result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py\", line 1051, in reduction\n    result = getattr(values, meth)(axis)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\", line 41, in _amax\n    return umr_maximum(a, axis, None, out, keepdims, initial, where)\nTypeError: '>=' not supported between instances of 'float' and 'str'\n",
  "history_begin_time" : 1695522663937,
  "history_end_time" : 1695522665616,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "J4jQu5VbXCOY",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.replace('--', pd.NA, inplace=True)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  df.replace('--', pd.NA, inplace=True)\n  print(gridmet_var_df.head())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(X, Y, label='Pressure', color=colormaplist, marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/J4jQu5VbXCOY/gridmet_testing.py\", line 335, in <module>\n    plot_gridmet()\n  File \"/home/chetana/gw-workspace/J4jQu5VbXCOY/gridmet_testing.py\", line 297, in plot_gridmet\n    df.replace('--', pd.NA, inplace=True)\nNameError: name 'df' is not defined\n",
  "history_begin_time" : 1695522617445,
  "history_end_time" : 1695522618621,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "vXI4d1yaH8h7",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  print(gridmet_var_df.head())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(X, Y, label='Pressure', color=colormaplist, marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/vXI4d1yaH8h7/gridmet_testing.py\", line 333, in <module>\n    plot_gridmet()\n  File \"/home/chetana/gw-workspace/vXI4d1yaH8h7/gridmet_testing.py\", line 298, in plot_gridmet\n    colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  File \"/home/chetana/gw-workspace/vXI4d1yaH8h7/gridmet_testing.py\", line 63, in create_color_maps_with_value_range\n    if min_value < 0:\nTypeError: '<' not supported between instances of 'str' and 'int'\n",
  "history_begin_time" : 1695522532414,
  "history_end_time" : 1695522533431,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "naGOx8w9sssG",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n# Define the custom colormap with specified colors and ranges\ncolors = [\n    (0.8627, 0.8627, 0.8627),  # #DCDCDC - 0 - 1\n    (0.8627, 1.0000, 1.0000),  # #DCFFFF - 1 - 2\n    (0.6000, 1.0000, 1.0000),  # #99FFFF - 2 - 4\n    (0.5569, 0.8235, 1.0000),  # #8ED2FF - 4 - 6\n    (0.4509, 0.6196, 0.8745),  # #739EDF - 6 - 8\n    (0.4157, 0.4706, 1.0000),  # #6A78FF - 8 - 10\n    (0.4235, 0.2784, 1.0000),  # #6C47FF - 10 - 12\n    (0.5529, 0.0980, 1.0000),  # #8D19FF - 12 - 14\n    (0.7333, 0.0000, 0.9176),  # #BB00EA - 14 - 16\n    (0.8392, 0.0000, 0.7490),  # #D600BF - 16 - 18\n    (0.7569, 0.0039, 0.4549),  # #C10074 - 18 - 20\n    (0.6784, 0.0000, 0.1961),  # #AD0032 - 20 - 30\n    (0.5020, 0.0000, 0.0000)   # #800000 - > 30\n]\n\ncmap_name = 'custom_snow_colormap'\ncustom_cmap = mcolors.ListedColormap(colors)\n\n# Define your value ranges for color mapping\n#value_ranges = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 30]\n#value_ranges = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.5, 1.8, 2, 2.5, 3]\n\ndef create_color_maps_with_value_range(df_col, value_ranges=None):\n  if value_ranges == None:\n    max_value = df_col.max()\n    min_value = df_col.min()\n    if min_value < 0:\n      min_value = 0\n    step_size = (max_value - min_value) / 12\n\n    # Create 10 periods\n    new_value_ranges = [min_value + i * step_size for i in range(12)]\n  # Define your custom function to map data values to colors\n  def map_value_to_color(value):\n    # Iterate through the value ranges to find the appropriate color index\n    for i, range_max in enumerate(new_value_ranges):\n      if value <= range_max:\n        return colors[i]\n\n      # If the value is greater than the largest range, return the last color\n      return colors[-1]\n\n    # Map predicted_swe values to colors using the custom function\n  color_mapping = [map_value_to_color(value) for value in df_col.values]\n  return color_mapping, new_value_ranges\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  print(gridmet_var_df.head())\n  \n  colormaplist, value_ranges = create_color_maps_with_value_range(gridmet_var_df[var_name])\n  \n  # Create a scatter plot\n  plt.scatter(X, Y, label='Pressure', color=colormaplist, marker='o')\n\n  # Add labels and a legend\n  plt.xlabel('X-axis')\n  plt.ylabel('Y-axis')\n  plt.title('Scatter Plot Example')\n  plt.legend()\n  \n  res_png_path = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.png\"\n  plt.savefig(res_png_path)\n  print(f\"test image is saved at {res_png_path}\")\n\n  # Display the plot\n  plt.show()\n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/naGOx8w9sssG/gridmet_testing.py\", line 56, in <module>\n    custom_cmap = mcolors.ListedColormap(colors)\nNameError: name 'mcolors' is not defined\n",
  "history_begin_time" : 1695522243733,
  "history_end_time" : 1695522244561,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "hbTEsAdQUIho",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef plot_gridmet():\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  var_name = \"pr\"\n  test_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n  gridmet_var_df = pd.read_csv(test_csv)\n  print(gridmet_var_df.head())\n    \n  pass\n                \ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\nplot_gridmet()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\n",
  "history_begin_time" : 1695521970522,
  "history_end_time" : 1695521971463,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "u6zhhum2wnh",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-24\ntest start date:  2022-08-22\ntest end date:  2023-09-24\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n",
  "history_begin_time" : 1695515869062,
  "history_end_time" : 1695515872062,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kbte45habf0",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-23\ntest start date:  2022-08-22\ntest end date:  2023-09-23\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\nVariable name: etr\nVariable name: rmin\nVariable name: rmin\nVariable name: tmmn\nVariable name: tmmx\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmn\nVariable name: etr\nVariable name: pr\nVariable name: vs\nVariable name: tmmx\nVariable name: rmax\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv\nVariable name: pr\nVariable name: etr\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\nVariable name: etr\nVariable name: pr\nVariable name: tmmn\nVariable name: vs\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv\nVariable name: pr\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv\nVariable name: rmin\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: etr\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\nVariable name: rmin\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-22.csv already exists. Skipping..\nVariable name: etr\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-22.csv already exists. Skipping..\nVariable name: etr\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 233\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-22.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-22.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-22.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-22.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-22.csv already exists. Skipping..\n",
  "history_begin_time" : 1695506444307,
  "history_end_time" : 1695506578720,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8f4o9tuns5y",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-22\ntest start date:  2022-08-21\ntest end date:  2023-09-22\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\nVariable name: etr\nVariable name: rmin\nVariable name: rmin\nVariable name: tmmn\nVariable name: tmmx\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmn\nVariable name: etr\nVariable name: pr\nVariable name: vs\nVariable name: tmmx\nVariable name: rmax\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 232\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv\nVariable name: pr\nVariable name: etr\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 232\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: etr\nVariable name: pr\nVariable name: tmmn\nVariable name: vs\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 232\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv\nVariable name: pr\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 232\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-21.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 232\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-21.csv\nVariable name: rmin\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv already exists. Skipping..\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 232\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-21.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-21.csv already exists. Skipping..\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: rmin\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv already exists. Skipping..\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-21.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-21.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-21.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-21.csv already exists. Skipping..\nVariable name: rmin\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-21.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: rmin\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-08-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 232\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-21.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-08-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 232\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-08-21.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-21.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-08-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-08-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-08-21.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-08-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-08-21.csv already exists. Skipping..\n",
  "history_begin_time" : 1695418761535,
  "history_end_time" : 1695418860397,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "63kir2ersdy",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-22\ntest start date:  2022-03-21\ntest end date:  2023-09-22\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\nVariable name: etr\nVariable name: rmin\nVariable name: rmin\nVariable name: tmmn\nVariable name: tmmx\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmn\nVariable name: etr\nVariable name: pr\nVariable name: vs\nVariable name: tmmx\nVariable name: rmax\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 79\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv\nVariable name: pr\nVariable name: etr\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 79\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: etr\nVariable name: pr\nVariable name: tmmn\nVariable name: vs\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 79\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv\nVariable name: pr\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 79\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-21.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 79\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-21.csv\nVariable name: rmin\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv already exists. Skipping..\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 79\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-21.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-21.csv already exists. Skipping..\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: rmin\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv already exists. Skipping..\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-21.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-21.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-21.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-21.csv already exists. Skipping..\nVariable name: rmin\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-21.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: rmin\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 79\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-21.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-21.csv already exists. Skipping..\nVariable name: etr\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 79\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-21.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-21.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-21.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-21.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-21.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-21.csv already exists. Skipping..\n",
  "history_begin_time" : 1695417639385,
  "history_end_time" : 1695417737231,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zpd7kbil8d2",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name and file_name.endswith(\".nc\"):\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-22\ntest start date:  2022-03-20\ntest end date:  2023-09-22\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\nVariable name: etr\nVariable name: rmin\nVariable name: rmin\nVariable name: tmmn\nVariable name: tmmx\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmn\nVariable name: etr\nVariable name: pr\nVariable name: vs\nVariable name: tmmx\nVariable name: rmax\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 78\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv\nVariable name: pr\nVariable name: etr\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 78\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: etr\nVariable name: etr\nVariable name: pr\nVariable name: tmmn\nVariable name: vs\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 78\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv\nVariable name: pr\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 78\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-20.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 78\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-20.csv\nVariable name: rmin\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-20.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv already exists. Skipping..\nVariable name: etr\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv already exists. Skipping..\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 78\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-20.csv\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-20.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-20.csv already exists. Skipping..\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-20.csv already exists. Skipping..\nVariable name: etr\nVariable name: rmin\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv already exists. Skipping..\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-20.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-20.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-20.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-20.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-20.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-20.csv already exists. Skipping..\nVariable name: rmin\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-20.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: rmin\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-20.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-20.csv already exists. Skipping..\nVariable name: etr\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-20.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 78\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-20.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-20.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-20.csv already exists. Skipping..\nVariable name: etr\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 78\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-20.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-20.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-20.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-20.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-20.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-20.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-20.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-20.csv already exists. Skipping..\n",
  "history_begin_time" : 1695417175603,
  "history_end_time" : 1695417318349,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "e75w1fedsf6",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-22\ntest start date:  2022-03-20\ntest end date:  2023-09-22\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\nVariable name: etr\nVariable name: rmin\nVariable name: rmin\nVariable name: tmmn\nVariable name: tmmx\nVariable name: tmmx\nVariable name: vpd\nVariable name: tmmx\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.csv\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/e75w1fedsf6/gridmet_testing.py\", line 262, in <module>\n    turn_gridmet_nc_to_csv()\n  File \"/home/chetana/gw-workspace/e75w1fedsf6/gridmet_testing.py\", line 241, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n  File \"/home/chetana/gw-workspace/e75w1fedsf6/gridmet_testing.py\", line 185, in get_nc_csv_by_coords_and_variable\n    with nc.Dataset(nc_file) as nc_file:\n  File \"src/netCDF4/_netCDF4.pyx\", line 2307, in netCDF4._netCDF4.Dataset.__init__\n  File \"src/netCDF4/_netCDF4.pyx\", line 1925, in netCDF4._netCDF4._ensure_nc_success\nOSError: [Errno -51] NetCDF: Unknown file format: b'/home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.csv'\n",
  "history_begin_time" : 1695417072225,
  "history_end_time" : 1695417075308,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "5oreyjeyyhp",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-22\ntest start date:  2022-03-19\ntest end date:  2023-09-22\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: training\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-19.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-19.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-19.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-19.csv already exists. Skipping..\n",
  "history_begin_time" : 1695416939668,
  "history_end_time" : 1695416942016,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6VlsrKjBaVT8",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "Running",
  "history_begin_time" : 1695106615075,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "4mxu2cnbvh2",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-03-18\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-18.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-18.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-18.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-18.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-18.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-18.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-18.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-18.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-18.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-18.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-18.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-18.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-18.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-18.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-18.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-18.csv already exists. Skipping..\n",
  "history_begin_time" : 1695106493567,
  "history_end_time" : 1695106495860,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "in5brfkzaq5",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-03-18\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: rmax\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 76\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-03-18.csv\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 76\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-18.csv\nVariable name: etr\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 76\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-18.csv\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 76\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-18.csv\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 76\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-18.csv\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 76\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-18.csv\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-03-18.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-03-18.csv already exists. Skipping..\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 76\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-03-18.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-03-18.csv already exists. Skipping..\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 76\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-03-18.csv\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-03-18.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-03-18.csv already exists. Skipping..\n",
  "history_begin_time" : 1695106337131,
  "history_end_time" : 1695106437111,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "knRPvJ01tkJZ",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n      # drop useless columns\n      mapper_df = mapper_df[[\"dem_lat\", \"dem_lon\", var_name]]\n      mapper_df.rename(columns={\"dem_lat\": \"Latitude\",\n                               \"dem_lon\": \"Longitude\"}, inplace=True)\n\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: rmax\nVariable name: rmax\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 311\n   Latitude  Longitude rmax\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nVariable name: vpd\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 311\n   Latitude  Longitude vpd\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv\nVariable name: etr\nVariable name: vs\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 311\n   Latitude  Longitude  vs\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv\nVariable name: tmmn\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 311\n   Latitude  Longitude tmmn\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv\nVariable name: pr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 311\n   Latitude  Longitude  pr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv\nVariable name: tmmx\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 311\n   Latitude  Longitude tmmx\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv\nVariable name: rmin\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv already exists. Skipping..\nVariable name: rmin\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 311\n   Latitude  Longitude rmin\n0      49.0   -125.000   --\n1      49.0   -124.964   --\n2      49.0   -124.928   --\n3      49.0   -124.892   --\n4      49.0   -124.856   --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv already exists. Skipping..\nVariable name: etr\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nday_index: 311\n   Latitude  Longitude etr\n0      49.0   -125.000  --\n1      49.0   -124.964  --\n2      49.0   -124.928  --\n3      49.0   -124.892  --\n4      49.0   -124.856  --\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv already exists. Skipping..\n",
  "history_begin_time" : 1695104117021,
  "history_end_time" : 1695104215834,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "hoJbg50FW1TU",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      var_col = nc_file.variables[long_var_name][:]\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv already exists. Skipping..\nVariable name: rmax\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv already exists. Skipping..\nVariable name: pr\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv already exists. Skipping..\nVariable name: tmmn\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv already exists. Skipping..\nVariable name: rmin\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv already exists. Skipping..\nVariable name: vpd\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv already exists. Skipping..\nVariable name: etr\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv already exists. Skipping..\nVariable name: vs\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv already exists. Skipping..\nVariable name: tmmx\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv already exists. Skipping..\n",
  "history_begin_time" : 1695103712135,
  "history_end_time" : 1695103712946,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "PxWpziECHtjY",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv already exists. Skipping..\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv already exists. Skipping..\nfile_name:  vpd_2022.nc\nVariable name: vpd\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv already exists. Skipping..\nfile_name:  etr_2023.nc\nVariable name: etr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv already exists. Skipping..\nfile_name:  vs_2022.nc\nVariable name: vs\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv already exists. Skipping..\nfile_name:  tmmn_2022.nc\nVariable name: tmmn\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv already exists. Skipping..\nfile_name:  pr_2022.nc\nVariable name: pr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv already exists. Skipping..\nfile_name:  tmmx_2022.nc\nVariable name: tmmx\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv already exists. Skipping..\nfile_name:  rmin_2023.nc\nVariable name: rmin\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv already exists. Skipping..\nfile_name:  pr_2023.nc\nVariable name: pr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv already exists. Skipping..\nfile_name:  tmmn_2023.nc\nVariable name: tmmn\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv already exists. Skipping..\nfile_name:  rmin_2022.nc\nVariable name: rmin\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv already exists. Skipping..\nfile_name:  vpd_2023.nc\nVariable name: vpd\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv already exists. Skipping..\nfile_name:  etr_2022.nc\nVariable name: etr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv already exists. Skipping..\nfile_name:  vs_2023.nc\nVariable name: vs\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv already exists. Skipping..\nfile_name:  tmmx_2023.nc\nVariable name: tmmx\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv already exists. Skipping..\n",
  "history_begin_time" : 1695103664496,
  "history_end_time" : 1695103665332,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "YJAjXwXk7KPu",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv already exists. Skipping..\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv already exists. Skipping..\nfile_name:  vpd_2022.nc\nVariable name: vpd\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv already exists. Skipping..\nfile_name:  etr_2023.nc\nVariable name: etr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv\nfile_name:  vs_2022.nc\nVariable name: vs\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv already exists. Skipping..\nfile_name:  tmmn_2022.nc\nVariable name: tmmn\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile Name: tmmn_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: air_temperature, Shape: (365, 585, 1386)\nlong var name:  air_temperature\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\nday_index: 311\n   dem_lat  dem_lon  x  y  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx  tmmn\n0     49.0 -125.000  0  0  ...  -124.766667             10.0              0.0    --\n1     49.0 -124.964  1  0  ...  -124.766667             10.0              0.0    --\n2     49.0 -124.928  2  0  ...  -124.766667             10.0              0.0    --\n3     49.0 -124.892  3  0  ...  -124.766667             10.0              0.0    --\n4     49.0 -124.856  4  0  ...  -124.766667             10.0              0.0    --\n[5 rows x 10 columns]\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv\nfile_name:  pr_2022.nc\nVariable name: pr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nFile Name: pr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: precipitation_amount, Shape: (365, 585, 1386)\nlong var name:  precipitation_amount\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\nday_index: 311\n   dem_lat  dem_lon  x  y  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx  pr\n0     49.0 -125.000  0  0  ...  -124.766667             10.0              0.0  --\n1     49.0 -124.964  1  0  ...  -124.766667             10.0              0.0  --\n2     49.0 -124.928  2  0  ...  -124.766667             10.0              0.0  --\n3     49.0 -124.892  3  0  ...  -124.766667             10.0              0.0  --\n4     49.0 -124.856  4  0  ...  -124.766667             10.0              0.0  --\n[5 rows x 10 columns]\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv\nfile_name:  tmmx_2022.nc\nVariable name: tmmx\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nFile Name: tmmx_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: air_temperature, Shape: (365, 585, 1386)\nlong var name:  air_temperature\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\nday_index: 311\n   dem_lat  dem_lon  x  y  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx  tmmx\n0     49.0 -125.000  0  0  ...  -124.766667             10.0              0.0    --\n1     49.0 -124.964  1  0  ...  -124.766667             10.0              0.0    --\n2     49.0 -124.928  2  0  ...  -124.766667             10.0              0.0    --\n3     49.0 -124.892  3  0  ...  -124.766667             10.0              0.0    --\n4     49.0 -124.856  4  0  ...  -124.766667             10.0              0.0    --\n[5 rows x 10 columns]\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv\nfile_name:  rmin_2023.nc\nVariable name: rmin\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv\nfile_name:  pr_2023.nc\nVariable name: pr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_pr_2022-11-08.csv already exists. Skipping..\nfile_name:  tmmn_2023.nc\nVariable name: tmmn\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv already exists. Skipping..\nfile_name:  rmin_2022.nc\nVariable name: rmin\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nFile Name: rmin_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: relative_humidity, Shape: (365, 585, 1386)\nlong var name:  relative_humidity\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\nday_index: 311\n   dem_lat  dem_lon  x  y  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx  rmin\n0     49.0 -125.000  0  0  ...  -124.766667             10.0              0.0    --\n1     49.0 -124.964  1  0  ...  -124.766667             10.0              0.0    --\n2     49.0 -124.928  2  0  ...  -124.766667             10.0              0.0    --\n3     49.0 -124.892  3  0  ...  -124.766667             10.0              0.0    --\n4     49.0 -124.856  4  0  ...  -124.766667             10.0              0.0    --\n[5 rows x 10 columns]\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_rmin_2022-11-08.csv\nfile_name:  vpd_2023.nc\nVariable name: vpd\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv already exists. Skipping..\nfile_name:  etr_2022.nc\nVariable name: etr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nFile Name: etr_2022.nc\nFile /home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv already exists, skipping..\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: potential_evapotranspiration, Shape: (365, 585, 1386)\nlong var name:  potential_evapotranspiration\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\nday_index: 311\n   dem_lat  dem_lon  x  y  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx  etr\n0     49.0 -125.000  0  0  ...  -124.766667             10.0              0.0   --\n1     49.0 -124.964  1  0  ...  -124.766667             10.0              0.0   --\n2     49.0 -124.928  2  0  ...  -124.766667             10.0              0.0   --\n3     49.0 -124.892  3  0  ...  -124.766667             10.0              0.0   --\n4     49.0 -124.856  4  0  ...  -124.766667             10.0              0.0   --\n[5 rows x 10 columns]\ngridmet var saved:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv\nfile_name:  vs_2023.nc\nVariable name: vs\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv already exists. Skipping..\nfile_name:  tmmx_2023.nc\nVariable name: tmmx\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_tmmx_2022-11-08.csv already exists. Skipping..\n",
  "history_begin_time" : 1695103512463,
  "history_end_time" : 1695103582617,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ZkZA8WLuxK0J",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv():\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_folder_name):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv()\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv already exists. Skipping..\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv already exists. Skipping..\nfile_name:  vpd_2022.nc\nVariable name: vpd\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vpd_2022-11-08.csv already exists. Skipping..\nfile_name:  etr_2023.nc\nVariable name: etr\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_etr_2022-11-08.csv\nfile_name:  vs_2022.nc\nVariable name: vs\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv\n/home/chetana/gridmet_test_run/testing_output/2022_vs_2022-11-08.csv already exists. Skipping..\nfile_name:  tmmn_2022.nc\nVariable name: tmmn\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_tmmn_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nFile Name: tmmn_2022.nc\n   dem_lat  dem_lon  x  ...  gridmet_lon  gridmet_lat_idx  gridmet_lon_idx\n0     49.0 -125.000  0  ...  -124.766667             10.0              0.0\n1     49.0 -124.964  1  ...  -124.766667             10.0              0.0\n2     49.0 -124.928  2  ...  -124.766667             10.0              0.0\n3     49.0 -124.892  3  ...  -124.766667             10.0              0.0\n4     49.0 -124.856  4  ...  -124.766667             10.0              0.0\n[5 rows x 9 columns]\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: air_temperature, Shape: (365, 585, 1386)\nlong var name:  air_temperature\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/ZkZA8WLuxK0J/gridmet_testing.py\", line 276, in <module>\n    turn_gridmet_nc_to_csv()\n  File \"/home/chetana/gw-workspace/ZkZA8WLuxK0J/gridmet_testing.py\", line 255, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n  File \"/home/chetana/gw-workspace/ZkZA8WLuxK0J/gridmet_testing.py\", line 208, in get_nc_csv_by_coords_and_variable\n    print(western_us_dem_df.head())\nNameError: name 'western_us_dem_df' is not defined\n",
  "history_begin_time" : 1695103167959,
  "history_end_time" : 1695103407251,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "BGb85DELD9pL",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper(nc_file):\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    \n    create_gridmet_to_dem_mapper(nc_file)\n  \n    mapper_df = pd.read_csv(f'{work_dir}/gridmet_to_dem_mapper.csv')\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = int(row[\"gridmet_lat_idx\"])\n        lon_index = int(row[\"gridmet_lat_idx\"])\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = mapper_df.apply(get_gridmet_var_value, axis=1)\n      \n    print(mapper_df.head())\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv, index=False)\n                print(\"gridmet var saved: \", res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "",
  "history_begin_time" : 1695103088285,
  "history_end_time" : 1695103163281,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "jjWmftJRaDjF",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper():\n    #df[['Result1', 'Result2']] = df.apply(lambda row: pd.Series(my_function(row)), axis=1)\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n#     new_lat_data = []\n#     new_lon_data = []\n#     new_var_data = []\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    #data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    #df = pd.DataFrame(data)\n    print(western_us_dem_df.head())\n    return western_us_dem_df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "",
  "history_begin_time" : 1695102801890,
  "history_end_time" : 1695102854107,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "YiWzDZENddSY",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper():\n    #df[['Result1', 'Result2']] = df.apply(lambda row: pd.Series(my_function(row)), axis=1)\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n#     new_lat_data = []\n#     new_lon_data = []\n#     new_var_data = []\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    #data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    #df = pd.DataFrame(data)\n    print(western_us_dem_df.head())\n    return western_us_dem_df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "",
  "history_begin_time" : 1695102411140,
  "history_end_time" : 1695102546231,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "zbRAwclYNhdZ",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef create_gridmet_to_dem_mapper():\n    #df[['Result1', 'Result2']] = df.apply(lambda row: pd.Series(my_function(row)), axis=1)\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        gridmet_lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        gridmet_lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        return latitudes[gridmet_lat_index], longitudes[gridmet_lon_index], \n      \t\t   gridmet_lat_index, gridmet_lon_index\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[['gridmet_lat', 'gridmet_lon', \n                         'gridmet_lat_idx', 'gridmet_lon_idx',]] = western_us_dem_df.apply(lambda row: pd.Series(get_gridmet_var_value(row)), axis=1)\n      western_us_dem_df.rename(columns={\"Latitude\": \"dem_lat\", \n                                        \"Longitude\": \"dem_lon\"}, inplace=True)\n      \n    print(western_us_dem_df.head())\n    \n    # Save the new converted AMSR to CSV file\n    western_us_dem_df.to_csv(target_csv_path, index=False)\n    \n    return western_us_dem_df\n  \n  \ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n#     new_lat_data = []\n#     new_lon_data = []\n#     new_var_data = []\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    #data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    #df = pd.DataFrame(data)\n    print(western_us_dem_df.head())\n    return western_us_dem_df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/zbRAwclYNhdZ/gridmet_testing.py\", line 188\n    gridmet_lat_index, gridmet_lon_index\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1695102398034,
  "history_end_time" : 1695102398089,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "h225vq3hfylc",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n#     new_lat_data = []\n#     new_lon_data = []\n#     new_var_data = []\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = find_nearest_index(latitudes, float(row[\"Latitude\"]))\n        lon_index = find_nearest_index(longitudes, float(row[\"Longitude\"]))\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    #data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    #df = pd.DataFrame(data)\n    print(western_us_dem_df.head())\n    return western_us_dem_df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "",
  "history_begin_time" : 1695101555023,
  "history_end_time" : 1695101797503,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "b9iWmjJKZy3E",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n#     new_lat_data = []\n#     new_lon_data = []\n#     new_var_data = []\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = find_nearest_index(longitudes, float(row[\"Latitude\"]))\n        lon_index = find_nearest_index(latitudes, float(row[\"Longitude\"]))\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    #data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    #df = pd.DataFrame(data)\n    print(western_us_dem_df.head())\n    return western_us_dem_df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile Name: rmax_2022.nc\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: relative_humidity, Shape: (365, 585, 1386)\nlong var name:  relative_humidity\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\n   Latitude  Longitude  x  y  Elevation\n0      49.0   -125.000  0  0        NaN\n1      49.0   -124.964  1  0        NaN\n2      49.0   -124.928  2  0        NaN\n3      49.0   -124.892  3  0        NaN\n4      49.0   -124.856  4  0        NaN\nday_index: 311\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/b9iWmjJKZy3E/gridmet_testing.py\", line 267, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/b9iWmjJKZy3E/gridmet_testing.py\", line 247, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n  File \"/home/chetana/gw-workspace/b9iWmjJKZy3E/gridmet_testing.py\", line 190, in get_nc_csv_by_coords_and_variable\n    western_us_dem_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 9568, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\", line 764, in apply\n    return self.apply_standard()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\", line 891, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\", line 907, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/chetana/gw-workspace/b9iWmjJKZy3E/gridmet_testing.py\", line 186, in get_gridmet_var_value\n    var_value = var_col[day_index, lat_index, lon_index]\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/numpy/ma/core.py\", line 3216, in __getitem__\n    dout = self.data[indx]\nIndexError: index 1385 is out of bounds for axis 1 with size 585\n",
  "history_begin_time" : 1695101325059,
  "history_end_time" : 1695101332754,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "76DobbQydsM3",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n#     new_lat_data = []\n#     new_lon_data = []\n#     new_var_data = []\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      # Calculate the day of the year\n      day_of_year = selected_date.timetuple().tm_yday\n      day_index = day_of_year - 1\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lat_index = find_nearest_index(longitudes, float(row[\"Latitude\"]))\n        lon_index = find_nearest_index(latitudes, float(row[\"Longitutde\"]))\n        var_value = var_col[day_index, lat_index, lon_index]\n        return var_value\n    \n      # Use the apply function to apply the custom function to each row\n      western_us_dem_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    #data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    #df = pd.DataFrame(data)\n    print(western_us_dem_df.head())\n    return western_us_dem_df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile Name: rmax_2022.nc\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: relative_humidity, Shape: (365, 585, 1386)\nlong var name:  relative_humidity\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\n   Latitude  Longitude  x  y  Elevation\n0      49.0   -125.000  0  0        NaN\n1      49.0   -124.964  1  0        NaN\n2      49.0   -124.928  2  0        NaN\n3      49.0   -124.892  3  0        NaN\n4      49.0   -124.856  4  0        NaN\nday_index: 311\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'Longitutde'\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/76DobbQydsM3/gridmet_testing.py\", line 267, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/76DobbQydsM3/gridmet_testing.py\", line 247, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n  File \"/home/chetana/gw-workspace/76DobbQydsM3/gridmet_testing.py\", line 190, in get_nc_csv_by_coords_and_variable\n    western_us_dem_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 9568, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\", line 764, in apply\n    return self.apply_standard()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\", line 891, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\", line 907, in apply_series_generator\n    results[i] = self.f(v)\n  File \"/home/chetana/gw-workspace/76DobbQydsM3/gridmet_testing.py\", line 185, in get_gridmet_var_value\n    lon_index = find_nearest_index(latitudes, float(row[\"Longitutde\"]))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\", line 981, in __getitem__\n    return self._get_value(key)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\", line 1089, in _get_value\n    loc = self.index.get_loc(label)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'Longitutde'\n",
  "history_begin_time" : 1695101286399,
  "history_end_time" : 1695101297954,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "0s4rX38MioPJ",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #print(var_col)\n      print(western_us_dem_df.head())\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      def get_gridmet_var_value(row):\n        # Perform your custom calculation here\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        closest_flag = flag[closest_lat_idx, closest_lon_idx]\n        return closest_flag\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df[var_name] = western_us_dem_df.apply(get_gridmet_var_value, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    #data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    #df = pd.DataFrame(data)\n    return mapper_df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile Name: rmax_2022.nc\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: relative_humidity, Shape: (365, 585, 1386)\nlong var name:  relative_humidity\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\n   Latitude  Longitude  x  y  Elevation\n0      49.0   -125.000  0  0        NaN\n1      49.0   -124.964  1  0        NaN\n2      49.0   -124.928  2  0        NaN\n3      49.0   -124.892  3  0        NaN\n4      49.0   -124.856  4  0        NaN\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/0s4rX38MioPJ/gridmet_testing.py\", line 262, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/0s4rX38MioPJ/gridmet_testing.py\", line 242, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n  File \"/home/chetana/gw-workspace/0s4rX38MioPJ/gridmet_testing.py\", line 176, in get_nc_csv_by_coords_and_variable\n    print('day_index:', day_index)\nNameError: name 'day_index' is not defined\n",
  "history_begin_time" : 1695101022886,
  "history_end_time" : 1695101034033,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "0jZI3FrcIGfL",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      print(var_col)\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      def get_gridmet_value(row):\n        # Perform your custom calculation here\n        closest_lat_idx = int(row['amsr_lat_idx'])\n        closest_lon_idx = int(row['amsr_lon_idx'])\n        closest_flag = flag[closest_lat_idx, closest_lon_idx]\n        return closest_flag\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df['AMSR_SWE'] = mapper_df.apply(get_swe, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile Name: rmax_2022.nc\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: relative_humidity, Shape: (365, 585, 1386)\nlong var name:  relative_humidity\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\n[[[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n ...\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]\n [[-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  ...\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]\n  [-- -- -- ... -- -- --]]]\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/0jZI3FrcIGfL/gridmet_testing.py\", line 261, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/0jZI3FrcIGfL/gridmet_testing.py\", line 241, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n  File \"/home/chetana/gw-workspace/0jZI3FrcIGfL/gridmet_testing.py\", line 175, in get_nc_csv_by_coords_and_variable\n    print('day_index:', day_index)\nNameError: name 'day_index' is not defined\n",
  "history_begin_time" : 1695100717100,
  "history_end_time" : 1695100732299,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "mUgx0xInaBFL",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\n\ngridmet_var_mapping = {\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmn\":\"air_temperature\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      def get_gridmet_value(row):\n        # Perform your custom calculation here\n        closest_lat_idx = int(row['amsr_lat_idx'])\n        closest_lon_idx = int(row['amsr_lon_idx'])\n        closest_flag = flag[closest_lat_idx, closest_lon_idx]\n        return closest_flag\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df['AMSR_SWE'] = mapper_df.apply(get_swe, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n                                                       var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile Name: rmax_2022.nc\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: relative_humidity, Shape: (365, 585, 1386)\nlong var name:  relative_humidity\nlatitudes shape: (585,)\nlongitudes shape: (1386,)\nday shape: (365,)\nval col shape: (365, 585, 1386)\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/mUgx0xInaBFL/gridmet_testing.py\", line 259, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/mUgx0xInaBFL/gridmet_testing.py\", line 239, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, \n  File \"/home/chetana/gw-workspace/mUgx0xInaBFL/gridmet_testing.py\", line 173, in get_nc_csv_by_coords_and_variable\n    print('day_index:', day_index)\nNameError: name 'day_index' is not defined\n",
  "history_begin_time" : 1695100616002,
  "history_end_time" : 1695100648217,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "cxW9xtoTLNjX",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file,\n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    western_us_dem_df = pd.read_csv(western_us_coords)\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      def get_gridmet_value(row):\n        # Perform your custom calculation here\n        closest_lat_idx = int(row['amsr_lat_idx'])\n        closest_lon_idx = int(row['amsr_lon_idx'])\n        closest_flag = flag[closest_lat_idx, closest_lon_idx]\n        return closest_flag\n    \n      # Use the apply function to apply the custom function to each row\n      mapper_df['AMSR_SWE'] = mapper_df.apply(get_swe, axis=1)\n      \n#       for coord in coordinates:\n#         lon, lat = coord\n#         new_lat_data.append(lat)\n#         new_lon_data.append(lon)\n#         # Access the variables in the NetCDF file\n#         # Find the nearest indices for the given coordinates\n#         lon_index = find_nearest_index(longitudes, lon)\n#         lat_index = find_nearest_index(latitudes, lat)\n#         #day_index = find_nearest_index(day, day[day.shape[0]-1])\n#         #print(f\"last day: {day_index}\")\n\n#         # Get the value at the specified coordinates\n#         the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n#         if the_value == \"--\":\n#           the_value = -9999\n#         new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            print(\"file_name: \", file_name)\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nfile_name:  rmax_2023.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nfile_name:  rmax_2022.nc\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile Name: rmax_2022.nc\nVariable: lon, Shape: (1386,)\nVariable: lat, Shape: (585,)\nVariable: day, Shape: (365,)\nVariable: crs, Shape: (1,)\nVariable: relative_humidity, Shape: (365, 585, 1386)\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/cxW9xtoTLNjX/gridmet_testing.py\", line 246, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/cxW9xtoTLNjX/gridmet_testing.py\", line 227, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, var_name, test_start_date)\n  File \"/home/chetana/gw-workspace/cxW9xtoTLNjX/gridmet_testing.py\", line 149, in get_nc_csv_by_coords_and_variable\n    long_var_name = gridmet_var_mapping[var_name]\nNameError: name 'gridmet_var_mapping' is not defined\n",
  "history_begin_time" : 1695099728151,
  "history_end_time" : 1695099729432,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "oqXQPANsbqKp",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    \n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef prepare_gridmet_to_dem_mapper():\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(selected_date.year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nVariable name: rmax\nThe csv will be here:  /home/chetana/gridmet_test_run/testing_output/2022_rmax_2022-11-08.csv\nProcessing file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nFile Name: rmax_2022.nc\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/oqXQPANsbqKp/gridmet_testing.py\", line 266, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/oqXQPANsbqKp/gridmet_testing.py\", line 247, in turn_gridmet_nc_to_csv\n    df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\nNameError: name 'coordinates' is not defined\n",
  "history_begin_time" : 1695099356875,
  "history_end_time" : 1695099357704,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "dZxaRBh48lEc",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    \n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef prepare_gridmet_to_dem_mapper():\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    \n    #prepare_gridmet_to_dem_mapper(gridmet_nc_folder_path, dem_template_csv)\n    \n    #coordinates = get_coordinates_of_template_tif()\n    #target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    #mapper_df = pd.read_csv(target_mapper_csv_path)\n    #print(mapper_df.head())\n    \n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nVariable name: rmax\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/dZxaRBh48lEc/gridmet_testing.py\", line 266, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/dZxaRBh48lEc/gridmet_testing.py\", line 232, in turn_gridmet_nc_to_csv\n    res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\nNameError: name 'current_year' is not defined\n",
  "history_begin_time" : 1695099317683,
  "history_end_time" : 1695099318480,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "TbsmN5wOr4OT",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    \n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef prepare_gridmet_to_dem_mapper():\n    # Check if the CSV already exists\n    target_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    if os.path.exists(target_csv_path):\n        print(f\"File {target_csv_path} already exists, skipping..\")\n        return\n    \n    \n    pass\n  \ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    #coordinates = get_coordinates_of_template_tif()\n    target_mapper_csv_path = f'{work_dir}/gridmet_to_dem_mapper.csv'\n    mapper_df = pd.read_csv(target_mapper_csv_path)\n    print(mapper_df.head())\n    \n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/TbsmN5wOr4OT/gridmet_testing.py\", line 242, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/TbsmN5wOr4OT/gridmet_testing.py\", line 199, in turn_gridmet_nc_to_csv\n    mapper_df = pd.read_csv(target_mapper_csv_path)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n    self.handles = get_handle(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 856, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/gridmet_test_run/gridmet_to_dem_mapper.csv'\n",
  "history_begin_time" : 1695098345240,
  "history_end_time" : 1695098346060,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "TxbhL6mH0k55",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    #coordinates = get_coordinates_of_template_tif()\n    target_mapper_csv_path = f'{work_dir}/amsr_to_gridmet_mapper.csv'\n    mapper_df = pd.read_csv(target_mapper_csv_path)\n    print(mapper_df.head())\n    \n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/TxbhL6mH0k55/gridmet_testing.py\", line 230, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/TxbhL6mH0k55/gridmet_testing.py\", line 189, in turn_gridmet_nc_to_csv\n    coordinates = get_coordinates_of_template_tif()\n  File \"/home/chetana/gw-workspace/TxbhL6mH0k55/gridmet_testing.py\", line 114, in get_coordinates_of_template_tif\n    df = pd.read_csv(dem_csv)\nNameError: name 'dem_csv' is not defined\n",
  "history_begin_time" : 1695098051384,
  "history_end_time" : 1695098052198,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "hJ1Y7im7gvBH",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    coordinates = get_coordinates_of_template_tif()\n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-19\ntest start date:  2022-11-08\ntest end date:  2023-09-19\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/hJ1Y7im7gvBH/gridmet_testing.py\", line 226, in <module>\n    turn_gridmet_nc_to_csv(gridmet_folder_name,\n  File \"/home/chetana/gw-workspace/hJ1Y7im7gvBH/gridmet_testing.py\", line 185, in turn_gridmet_nc_to_csv\n    coordinates = get_coordinates_of_template_tif()\n  File \"/home/chetana/gw-workspace/hJ1Y7im7gvBH/gridmet_testing.py\", line 114, in get_coordinates_of_template_tif\n    df = pd.read_csv(dem_csv)\nNameError: name 'dem_csv' is not defined\n",
  "history_begin_time" : 1695095649874,
  "history_end_time" : 1695095652136,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "jur3er79xp1",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    coordinates = get_coordinates_of_template_tif()\n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\n#turn_gridmet_nc_to_csv(gridmet_folder_name,\n#                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-18\ntest start date:  2022-11-08\ntest end date:  2023-09-18\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\n",
  "history_begin_time" : 1695054050363,
  "history_end_time" : 1695054052637,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ie67lf7gfm8",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    coordinates = get_coordinates_of_template_tif()\n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\n#turn_gridmet_nc_to_csv(gridmet_folder_name,\n#                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-18\ntest start date:  2022-11-08\ntest end date:  2023-09-18\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\n",
  "history_begin_time" : 1695054020137,
  "history_end_time" : 1695054033327,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wi969oeveuq",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    coordinates = get_coordinates_of_template_tif()\n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\n#turn_gridmet_nc_to_csv(gridmet_folder_name,\n#                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-18\ntest start date:  2022-11-08\ntest end date:  2023-09-18\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\n",
  "history_begin_time" : 1695053980834,
  "history_end_time" : 1695054019274,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "oc3f4f9j10a",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(gridmet_folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    coordinates = get_coordinates_of_template_tif()\n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\n#turn_gridmet_nc_to_csv(gridmet_folder_name,\n#                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-18\ntest start date:  2022-11-06\ntest end date:  2023-09-18\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\n",
  "history_begin_time" : 1695053797965,
  "history_end_time" : 1695053800282,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "cldougml3cv",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    coordinates = get_coordinates_of_template_tif()\n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\n#turn_gridmet_nc_to_csv(gridmet_folder_name,\n#                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-18\ntest start date:  2022-11-06\ntest end date:  2023-09-18\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/cldougml3cv/gridmet_testing.py\", line 225, in <module>\n    download_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\n  File \"/home/chetana/gw-workspace/cldougml3cv/gridmet_testing.py\", line 88, in download_gridmet_of_specific_variables\n    target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\nNameError: name 'folder_name' is not defined\n",
  "history_begin_time" : 1695053741578,
  "history_end_time" : 1695053743891,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "BysmTY9hTECA",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    coordinates = get_coordinates_of_template_tif()\n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_date.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-17\ntest start date:  2022-11-06\ntest end date:  2023-09-17\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/BysmTY9hTECA/gridmet_testing.py\", line 225, in <module>\n    download_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\n  File \"/home/chetana/gw-workspace/BysmTY9hTECA/gridmet_testing.py\", line 88, in download_gridmet_of_specific_variables\n    target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\nNameError: name 'folder_name' is not defined\n",
  "history_begin_time" : 1694975925145,
  "history_end_time" : 1694975925936,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "df0hd3bWCtot",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n# Define the folder to store downloaded files\ngridmet_folder_name = f'{work_dir}/gridmet_climatology'\n\nwestern_us_coords = f'{work_dir}/dem_file.tif.csv'\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n\ndef get_file_name_from_path(file_path):\n    # Get the file name from the file path\n    file_name = os.path.basename(file_path)\n    return file_name\n\ndef get_var_from_file_name(file_name):\n    # Assuming the file name format is \"tmmm_year.csv\"\n    var_name = str(file_name.split('_')[0])\n    return var_name\n\ndef get_coordinates_of_template_tif():\n  \t# Load the CSV file and extract coordinates\n    coordinates = []\n    df = pd.read_csv(dem_csv)\n    for index, row in df.iterrows():\n        # Process each row here\n        lon, lat = float(row[\"Latitude\"]), float(row[\"Longitude\"])\n        coordinates.append((lon, lat))\n    return coordinates\n\ndef find_nearest_index(array, value):\n    # Find the index of the element in the array that is closest to the given value\n    return (abs(array - value)).argmin()\n\ndef get_nc_csv_by_coords_and_variable(nc_file, \n                                      coordinates, \n                                      var_name,\n                                      test_start_date):\n    coordinates = get_coordinates_of_template_tif()\n    # get the netcdf file and generate the csv file for every coordinate in the dem_template.csv\n    new_lat_data = []\n    new_lon_data = []\n    new_var_data = []\n    # Read the NetCDF file\n    with nc.Dataset(nc_file) as nc_file:\n      # Get a list of all variables in the NetCDF file\n      variables = nc_file.variables.keys()\n\n      # Print the variables and their shapes\n      for variable in variables:\n        shape = nc_file.variables[variable].shape\n        print(f\"Variable: {variable}, Shape: {shape}\")\n      \n      # Get the values at each coordinate using rasterio's sample function\n      latitudes = nc_file.variables['lat'][:]\n      longitudes = nc_file.variables['lon'][:]\n      day = nc_file.variables['day'][:]\n      long_var_name = gridmet_var_mapping[var_name]\n      print(\"long var name: \", long_var_name)\n      var_col = nc_file.variables[long_var_name][:]\n      \n      print(f\"latitudes shape: {latitudes.shape}\")\n      print(f\"longitudes shape: {longitudes.shape}\")\n      print(f\"day shape: {day.shape}\")\n      print(f\"val col shape: {var_col.shape}\")\n      \n      #day_index = convert_date_to_1900(test_start_date)\n      #day_index = day[day.shape[0]-1]\n      #day_index = 44998\n      print('day_index:', day_index)\n      \n      for coord in coordinates:\n        lon, lat = coord\n        new_lat_data.append(lat)\n        new_lon_data.append(lon)\n        # Access the variables in the NetCDF file\n        # Find the nearest indices for the given coordinates\n        lon_index = find_nearest_index(longitudes, lon)\n        lat_index = find_nearest_index(latitudes, lat)\n        #day_index = find_nearest_index(day, day[day.shape[0]-1])\n        #print(f\"last day: {day_index}\")\n\n        # Get the value at the specified coordinates\n        the_value = var_col[day.shape[0]-1, lat_index, lon_index]  # Assuming data_variable is a 3D variable (time, lat, lon)\n        if the_value == \"--\":\n          the_value = -9999\n        new_var_data.append(the_value)\n        #print(f\"lon - {lon} lat - {lat} lon-index {lon_index} lat-index {lat_index} day-index {day_index} value - {the_value}\")\n    # Create the DataFrame\n    data = { 'Latitude': new_lat_data, 'Longitude': new_lon_data, var_name: new_var_data}\n    df = pd.DataFrame(data)\n    return df\n\ndef turn_gridmet_nc_to_csv(gridmet_nc_folder_path, dem_template_csv):\n    coordinates = get_coordinates_of_template_tif()\n    selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    #current_year = get_current_year()\n    for root, dirs, files in os.walk(gridmet_nc_folder_path):\n        for file_name in files:\n            var_name = get_var_from_file_name(file_name)\n            print(\"Variable name:\", var_name)\n            res_csv = f\"{work_dir}/testing_output/{str(current_year)}_{var_name}_{test_start_date}.csv\"\n            print(\"The csv will be here: \", res_csv)\n            \n            if os.path.exists(res_csv):\n                #os.remove(res_csv)\n                print(f\"{res_csv} already exists. Skipping..\")\n                continue\n            \n            if str(selected_date.year) in file_name :\n                # Perform operations on each file here\n                netcdf_file_path = os.path.join(root, file_name)\n                print(\"Processing file:\", netcdf_file_path)\n                file_name = get_file_name_from_path(netcdf_file_path)\n                print(\"File Name:\", file_name)\n\n                df = get_nc_csv_by_coords_and_variable(netcdf_file_path, coordinates, var_name, test_start_date)\n                df.to_csv(res_csv)\n                \n\ndef prepare_folder_and_get_year_list():\n  # Check if the folder exists, if not, create it\n  if not os.path.exists(gridmet_folder_name):\n      os.makedirs(gridmet_folder_name)\n\n  selected_date = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n  year_list = [selected_date.year]\n\n  # Remove any existing files in the folder\n  if selected_yr.year == datetime.now().year:\n      remove_files_in_folder(gridmet_folder_name)  # only redownload when the year is the current year\n  return year_list\n\n# Run the download function\ndownload_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\nturn_gridmet_nc_to_csv(gridmet_folder_name,\n                       western_us_coords)\n",
  "history_output" : "today date = 2023-09-17\ntest start date:  2022-11-06\ntest end date:  2023-09-17\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/df0hd3bWCtot/gridmet_testing.py\", line 225, in <module>\n    download_gridmet_of_specific_variables(prepare_folder_and_get_year_list())\n  File \"/home/chetana/gw-workspace/df0hd3bWCtot/gridmet_testing.py\", line 220, in prepare_folder_and_get_year_list\n    if selected_yr.year == datetime.now().year:\nNameError: name 'selected_yr' is not defined\n",
  "history_begin_time" : 1694975895952,
  "history_end_time" : 1694975896772,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "dormtozi3qj",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif selected_yr.year == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-17\ntest start date:  2022-11-06\ntest end date:  2023-09-17\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc exists\n",
  "history_begin_time" : 1694971164062,
  "history_end_time" : 1694972839687,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "pkva39p0jhq",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif selected_yr.year == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-17\ntest start date:  2022-11-05\ntest end date:  2023-09-17\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc exists\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2022.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2022.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2022.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2022.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2022.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\n",
  "history_begin_time" : 1694970713083,
  "history_end_time" : 1694970735154,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ps8xbjp3r63",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif selected_yr.year == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "",
  "history_begin_time" : 1694970595170,
  "history_end_time" : 1694970612621,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "iyb3t8hbbs4",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif selected_yr.year == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-17\ntest start date:  2023-05-05\ntest end date:  2023-09-17\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694970131735,
  "history_end_time" : 1694970157710,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kqxmm8fsbgd",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif selected_yr.year == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-17\ntest start date:  2023-06-05\ntest end date:  2023-09-17\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694969350765,
  "history_end_time" : 1694969377073,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9tymsw4la8q",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif selected_yr.year == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-16\ntest start date:  2023-06-01\ntest end date:  2023-09-16\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694905308464,
  "history_end_time" : 1694905336830,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6p5UnDlivYPq",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif selected_yr.year == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-16\ntest start date:  2023-06-01\ntest end date:  2023-09-16\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694904061821,
  "history_end_time" : 1694904087001,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "fkDcfYAKxc4Q",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nprint(selected_yr, \" - \", datetime.now().year)\nif selected_yr == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-16\ntest start date:  2023-06-01\ntest end date:  2023-09-16\n/home/chetana\n2023-06-01 00:00:00  -  2023\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc exists\n",
  "history_begin_time" : 1694904041299,
  "history_end_time" : 1694904042396,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "iC5a48AhpsFp",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nprint(datetime.now().year)\nif selected_yr == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-16\ntest start date:  2023-06-01\ntest end date:  2023-09-16\n/home/chetana\n2023\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc exists\n",
  "history_begin_time" : 1694904018802,
  "history_end_time" : 1694904019949,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "aaTeOirn2e2p",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif selected_yr == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-16\ntest start date:  2023-06-01\ntest end date:  2023-09-16\n/home/chetana\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc exists\n",
  "history_begin_time" : 1694903898622,
  "history_end_time" : 1694903899717,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "PSc24UmAk5QH",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables(year_list):\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\nyear_list = [selected_yr.year]\n    \n# Remove any existing files in the folder\nif int(selected_yr) == datetime.now().year:\n    remove_files_in_folder(folder_name)  # only redownload when the year is the current year\n\n# Run the download function\ndownload_gridmet_of_specific_variables(year_list)\n",
  "history_output" : "today date = 2023-09-16\ntest start date:  2023-06-01\ntest end date:  2023-09-16\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/PSc24UmAk5QH/gridmet_testing.py\", line 100, in <module>\n    if int(selected_yr) == datetime.now().year:\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'datetime.datetime'\n",
  "history_begin_time" : 1694903875592,
  "history_end_time" : 1694903876746,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "s8wumfLWHQyg",
  "history_input" : "\"\"\"\nScript for downloading specific variables of GridMET climatology data.\n\nThis script downloads specific meteorological variables from the GridMET climatology dataset\nfor a specified year. It uses the netCDF4 library for handling NetCDF files, urllib for downloading files,\nand pandas for data manipulation. The script also removes existing files in the target folder before downloading.\n\n\nUsage:\n    Run this script to download specific meteorological variables for a specified year from the GridMET dataset.\n\n\"\"\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\ndef get_current_year():\n    \"\"\"\n    Get the current year.\n\n    Returns:\n        int: The current year.\n    \"\"\"\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\ndef remove_files_in_folder(folder_path):\n    \"\"\"\n    Remove all files in a specified folder.\n\n    Parameters:\n        folder_path (str): Path to the folder to remove files from.\n    \"\"\"\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    \"\"\"\n    Download a file from a URL and save it to a specified location.\n\n    Parameters:\n        url (str): URL of the file to download.\n        target_file_path (str): Path where the downloaded file should be saved.\n        variable (str): Name of the meteorological variable being downloaded.\n    \"\"\"\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\ndef download_gridmet_of_specific_variables():\n    \"\"\"\n    Download specific meteorological variables from the GridMET climatology dataset.\n    \"\"\"\n    # Make a directory to store the downloaded files\n    selected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n    year_list = [selected_yr.year]\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n# Define the folder to store downloaded files\nfolder_name = f'{work_dir}/gridmet_climatology'\n\n# Check if the folder exists, if not, create it\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\n# Remove any existing files in the folder\nremove_files_in_folder(folder_name)\n\n# Run the download function\ndownload_gridmet_of_specific_variables()\n",
  "history_output" : "today date = 2023-09-16\ntest start date:  2023-06-01\ntest end date:  2023-09-16\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694903668240,
  "history_end_time" : 1694903693799,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "HSnvzOQZA9Yq",
  "history_input" : "import os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = f'{work_dir}/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-09-16\ntest start date:  2023-06-01\ntest end date:  2023-09-16\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694902422003,
  "history_end_time" : 1694902450976,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kve0a1lkqm1",
  "history_input" : "import os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = f'{work_dir}/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "",
  "history_begin_time" : 1694897888090,
  "history_end_time" : 1694897919621,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "Uvclianah0dY",
  "history_input" : "import os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = f'{work_dir}/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-09-14\ntest start date:  2023-04-01\ntest end date:  2023-09-14\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694710389183,
  "history_end_time" : 1694710415302,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "V1GiGtWgYyqW",
  "history_input" : "import os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = f'{work_dir}/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-09-13\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694572730671,
  "history_end_time" : 1694572757196,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "RfdfCkqyxQrk",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date, work_dir\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = f'{work_dir}/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-09-12\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2019.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_merged.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2021.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2021.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2019.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2019.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2019.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_merged.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2021.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2021.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_merged.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_merged.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2019.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2021.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_merged.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/training_ready_gridmet.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2021.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2019.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2022.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_merged.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_merged.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2019.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2021.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2022.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2019.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2022.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_merged.csv\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2021.csv\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1694489683902,
  "history_end_time" : 1694489710405,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "lejo3nMz6D3U",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-08-10\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.nc\n",
  "history_begin_time" : 1691694047140,
  "history_end_time" : 1691694089461,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "77zokxvmku6",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-08-08\n/home/chetana\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.nc\n",
  "history_begin_time" : 1691531336108,
  "history_end_time" : 1691531369510,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Done"
},{
  "history_id" : "ssykx8rhtku",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-08-08\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\n",
  "history_begin_time" : 1691531294409,
  "history_end_time" : 1691531296470,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Done"
},{
  "history_id" : "58nyq52thog",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-08-08\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.nc\n",
  "history_begin_time" : 1691531255064,
  "history_end_time" : 1691531288342,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Done"
},{
  "history_id" : "qujk4ke6kwe",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%Y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-08-08\n/home/chetana\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2019.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2020.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2020.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2020.nc\n",
  "history_begin_time" : 1691531164667,
  "history_end_time" : 1691531199844,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Done"
},{
  "history_id" : "jc7ityigxr0",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "today date = 2023-08-08\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/jc7ityigxr0/gridmet_testing.py\", line 22, in <module>\n    selected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n  File \"/home/chetana/anaconda3/lib/python3.9/_strptime.py\", line 568, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File \"/home/chetana/anaconda3/lib/python3.9/_strptime.py\", line 349, in _strptime\n    raise ValueError(\"time data %r does not match format %r\" %\nValueError: time data '2020-01-01' does not match format '%y-%m-%d'\n",
  "history_begin_time" : 1691531121419,
  "history_end_time" : 1691531124564,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "fbf7cnqlvur",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "",
  "history_begin_time" : 1691531061539,
  "history_end_time" : 1691531065365,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Done"
},{
  "history_id" : "5338lplmisn",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/5338lplmisn/gridmet_testing.py\", line 13, in <module>\n    from snowcast_utils import test_start_date\n  File \"/home/chetana/gw-workspace/5338lplmisn/snowcast_utils.py\", line 5, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691530848527,
  "history_end_time" : 1691530851277,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "du1mkll78qt",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "",
  "history_begin_time" : 1691530718186,
  "history_end_time" : 1691530721105,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "859oavbtlr8",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/859oavbtlr8/gridmet_testing.py\", line 13, in <module>\n    from snowcast_utils import test_start_date\n  File \"/home/chetana/gw-workspace/859oavbtlr8/snowcast_utils.py\", line 5, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691530690660,
  "history_end_time" : 1691530716749,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "xcd2fkqskd5",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/xcd2fkqskd5/gridmet_testing.py\", line 13, in <module>\n    from snowcast_utils import test_start_date\n  File \"/home/chetana/gw-workspace/xcd2fkqskd5/snowcast_utils.py\", line 4, in <module>\n    import ee\nModuleNotFoundError: No module named 'ee'\n",
  "history_begin_time" : 1691530621271,
  "history_end_time" : 1691530624170,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "b4x1gi74qxh",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/b4x1gi74qxh/gridmet_testing.py\", line 13, in <module>\n    from snowcast_utils import test_start_date\n  File \"/home/chetana/gw-workspace/b4x1gi74qxh/snowcast_utils.py\", line 4, in <module>\n    import ee\nModuleNotFoundError: No module named 'ee'\n",
  "history_begin_time" : 1691530617560,
  "history_end_time" : 1691530620430,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "ubzomgb7edr",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import test_start_date\n\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nselected_yr = datetime.strptime(test_start_date, \"%y-%m-%d\")\n\n\nyear_list = [selected_yr.year]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/ubzomgb7edr/gridmet_testing.py\", line 13, in <module>\n    from snowcast_utils import test_start_date\n  File \"/home/chetana/gw-workspace/ubzomgb7edr/snowcast_utils.py\", line 4, in <module>\n    import ee\nModuleNotFoundError: No module named 'ee'\n",
  "history_begin_time" : 1691530600701,
  "history_end_time" : 1691530614283,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "vVDWbJAO15BS",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\n#year_list = [get_current_year()]\nyear_list = [2019]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Deleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2019.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2019.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2019.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2019.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2019.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2019.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2019.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2019.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2019.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2019.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2019.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2019.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2019.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2019.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2019.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2019.nc\n",
  "history_begin_time" : 1691529641808,
  "history_end_time" : 1691529690639,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "c4TQWsBWV7Ug",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\nyear_list = [get_current_year()]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Deleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2010.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2012.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2011.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2005.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2018.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2015.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2003.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2012.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2007.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2009.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2002.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2015.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2010.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2004.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2013.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2003.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2008.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2009.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2006.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2014.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2004.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2014.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2011.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2017.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2008.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2008.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2002.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2006.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2008.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2013.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2006.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2017.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2017.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2018.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2014.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2008.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2012.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2010.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2015.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2005.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2016.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2011.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2005.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2021.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2003.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2003.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2012.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2004.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2006.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2015.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2016.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2003.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2007.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2002.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2009.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2016.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2013.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2014.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2009.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2011.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2017.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2018.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2004.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2010.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2017.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2004.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2012.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2005.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2002.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2003.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2007.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2007.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2013.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2016.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2005.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2006.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2014.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2002.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2011.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2004.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2006.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2010.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2022.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2019.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2005.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2016.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2020.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2018.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2015.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2009.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2013.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2002.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2007.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2007.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2018.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1690644524904,
  "history_end_time" : 1690644548258,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "NcYvrEwh42ce",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\nyear_list = [get_current_year()]\n\ndef remove_files_in_folder(folder_path):\n    # Get a list of files in the folder\n    files = os.listdir(folder_path)\n\n    # Loop through the files and remove them\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n            print(f\"Deleted file: {file_path}\")\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    \n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\nfolder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\nremove_files_in_folder(folder_name)\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Deleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\nDeleted file: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmn_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/tmmx_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/pr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vpd_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/etr_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmax_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/rmin_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc\nDownloading http://www.northwestknowledge.net/metdata/data/vs_2023.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc\n",
  "history_begin_time" : 1690262093589,
  "history_end_time" : 1690262119735,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "IuGVTNO2Ngnp",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\nyear_list = [get_current_year()]\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\n\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "File /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc exists\n",
  "history_begin_time" : 1690261554238,
  "history_end_time" : 1690261555220,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "MtJXIiiNyq1m",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\nyear_list = [get_current_year()]\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\n\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "File /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc exists\n",
  "history_begin_time" : 1690184700781,
  "history_end_time" : 1690184702131,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "eNJBbNWKV1bp",
  "history_input" : "#############################################\n# Process Name: gridmet\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ngridmet_var_mapping = {\n  \"tmmn\": \"air_temperature\",\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\nstart_date = date(2001, 1, 1)\nend_date = date(2001, 12, 12)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('station_cell_mapping.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = 'gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_clim_cleaned.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['lat'], row['lon'], row['cell_id'], row['station_id']\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/eNJBbNWKV1bp/gridmet_testing.py\", line 32, in <module>\n    station = pd.read_csv('station_cell_mapping.csv')\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n    self.handles = get_handle(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 856, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: 'station_cell_mapping.csv'\n",
  "history_begin_time" : 1690184486114,
  "history_end_time" : 1690184488099,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "erKtLfRT7S7n",
  "history_input" : "#############################################\n# Process Name: gridmet\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ngridmet_var_mapping = {\n  \"tmmn\": \"air_temperature\",\n  \"etr\": \"potential_evapotranspiration\",\n  \"pr\":\"precipitation_amount\",\n  \"rmax\":\"relative_humidity\",\n  \"rmin\":\"relative_humidity\",\n  \"tmmx\":\"air_temperature\",\n  \"vpd\":\"mean_vapor_pressure_deficit\",\n  \"vs\":\"wind_speed\",\n}\n\nstart_date = date(2001, 1, 1)\nend_date = date(2001, 12, 12)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('station_cell_mapping.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = 'gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = 'testing_clim_cleaned.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['lat'], row['lon'], row['cell_id'], row['station_id']\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/erKtLfRT7S7n/gridmet_testing.py\", line 32, in <module>\n    station = pd.read_csv('station_cell_mapping.csv')\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 211, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 950, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 605, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1442, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1735, in _make_engine\n    self.handles = get_handle(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 856, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: 'station_cell_mapping.csv'\n",
  "history_begin_time" : 1690184362497,
  "history_end_time" : 1690184369213,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "XwmksVe9xqor",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\nyear_list = [get_current_year()]\n\ndef download_file(url, target_file_path, variable):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        save_path = target_file_path\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, target_file_path, var)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\n\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "File /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc exists\n",
  "history_begin_time" : 1690178113503,
  "history_end_time" : 1690178114024,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "53L0YQ3pKNVD",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\ndef get_current_year():\n    now = datetime.now()\n    current_year = now.year\n    return current_year\n\nyear_list = [get_current_year()]\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, folder_name)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\n\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "File /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2023.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2023.nc exists\n",
  "history_begin_time" : 1690172385250,
  "history_end_time" : 1690172385784,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "0ziymqp9AV8E",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\nfrom snowcast_utils import get_current_year\n\n\nyear_list = [get_current_year()]\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, folder_name)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\n\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/0ziymqp9AV8E/gridmet_testing.py\", line 13, in <module>\n    from snowcast_utils import get_current_year\n  File \"/home/chetana/gw-workspace/0ziymqp9AV8E/snowcast_utils.py\", line 8, in <module>\n    import geopandas as gpd\nModuleNotFoundError: No module named 'geopandas'\n",
  "history_begin_time" : 1690172326486,
  "history_end_time" : 1690172343481,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ntXPU2gYWkGB",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2001, 1, 1)\nend_date = date(2001, 2, 2)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n    current_date = start_date\n\n    while current_date <= end_date:\n        date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n        all_dates.append(date_string)\n        current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef download_gridmet_of_specific_variables():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, folder_name)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\n\ndownload_gridmet_of_specific_variables()\n\n",
  "history_output" : "File /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2001.nc exists\n",
  "history_begin_time" : 1690171772355,
  "history_end_time" : 1690171772886,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vX9O1Zl4JTWi",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2001, 1, 1)\nend_date = date(2001, 2, 2)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n    current_date = start_date\n\n    while current_date <= end_date:\n        date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n        all_dates.append(date_string)\n        current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, folder_name)\n            else:\n                print(f\"File {target_file_path} exists\")\n\n\n\ngridmet_climatology()\n\n",
  "history_output" : "File /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2001.nc exists\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2001.nc exists\n",
  "history_begin_time" : 1690171631380,
  "history_end_time" : 1690171631835,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "CHaHmAY4bUjy",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2001, 1, 1)\nend_date = date(2001, 2, 2)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n    current_date = start_date\n\n    while current_date <= end_date:\n        date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n        all_dates.append(date_string)\n        current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            target_file_path = os.path.join(folder_name, var + '_' + '%s' % y + '.nc')\n            if not os.path.exists(target_file_path):\n                download_file(download_link, folder_name)\n            else:\n                print(f\"File {target_file_path}\")\n\n\n\ngridmet_climatology()\n\n",
  "history_output" : "File /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2001.nc\nFile /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2001.nc\nFile /home/chetana/gridmet_test_run/gridmet_climatology/pr_2001.nc\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2001.nc\nFile /home/chetana/gridmet_test_run/gridmet_climatology/etr_2001.nc\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2001.nc\nFile /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2001.nc\nFile /home/chetana/gridmet_test_run/gridmet_climatology/vs_2001.nc\n",
  "history_begin_time" : 1690171621216,
  "history_end_time" : 1690171621777,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "GQpxCpWMi19u",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2001, 1, 1)\nend_date = date(2001, 2, 2)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/testing_western_us_lat_long_ext.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n    current_date = start_date\n\n    while current_date <= end_date:\n        date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n        all_dates.append(date_string)\n        current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            print(f\"Downloading {url}\")\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n            print(f\"saved to {file_content}\")\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data_ext.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['lat'], row['lon'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\n#get_climatology_data(year_list)\n\n",
  "history_output" : "",
  "history_begin_time" : 1690171497578,
  "history_end_time" : 1690171498077,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "MepCLBvU4yAg",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2001, 1, 1)\nend_date = date(2001, 2, 2)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/testing_western_us_lat_long_ext.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n    current_date = start_date\n\n    while current_date <= end_date:\n        date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n        all_dates.append(date_string)\n        current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data_ext.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['lat'], row['lon'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2001\nCompleted data retrieval for the year 2001\n",
  "history_begin_time" : 1690167436716,
  "history_end_time" : 1690167788070,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "26EtKEcNOgx0",
  "history_input" : "import numpy as np\nimport pandas as pd\nfrom osgeo import gdal\n\n\ndef lat_lon_to_pixel(lat, lon, geotransform):\n    x = int((lon - geotransform[0]) / geotransform[1])\n    y = int((lat - geotransform[3]) / geotransform[5])\n    return x, y\n\n\ndef calculate_slope_aspect(elevation_data, pixel_size_x, pixel_size_y):\n    # Calculate slope using the Sobel operator\n    slope_x = np.gradient(elevation_data, pixel_size_x, axis=1)\n    slope_y = np.gradient(elevation_data, pixel_size_y, axis=0)\n    slope_rad = np.arctan(np.sqrt(slope_x ** 2 + slope_y ** 2))\n    slope_deg = np.degrees(slope_rad)\n\n    # Calculate aspect (direction of the steepest descent)\n    aspect_rad = np.arctan2(slope_y, -slope_x)\n    aspect_deg = (np.degrees(aspect_rad) + 360) % 360\n\n    return slope_deg, aspect_deg\n\n\ndef calculate_curvature(elevation_data, pixel_size_x, pixel_size_y):\n    # Calculate curvature using the Laplacian operator\n    curvature_x = np.gradient(np.gradient(elevation_data, pixel_size_x, axis=1), pixel_size_x, axis=1)\n    curvature_y = np.gradient(np.gradient(elevation_data, pixel_size_y, axis=0), pixel_size_y, axis=0)\n    curvature = curvature_x + curvature_y\n\n    return curvature\n\n\ndef read_elevation_data(file_path, lat, lon, neighborhood_size=3):\n    dataset = gdal.Open(file_path)\n    if dataset is None:\n        print(\"Error: Could not open the file.\")\n        return None\n\n    # Get geotransform information\n    geotransform = dataset.GetGeoTransform()\n    pixel_size_x = geotransform[1]\n    pixel_size_y = geotransform[5]\n\n    # Convert latitude and longitude to pixel indices\n    x, y = lat_lon_to_pixel(lat, lon, geotransform)\n\n    # Read a small neighborhood of elevation data around the selected point\n    band = dataset.GetRasterBand(1)\n    elevation_data = band.ReadAsArray(x - neighborhood_size // 2, y - neighborhood_size // 2, neighborhood_size,\n                                      neighborhood_size)\n\n    # Calculate slope and aspect\n    slope_data, aspect_data = calculate_slope_aspect(elevation_data, pixel_size_x, pixel_size_y)\n\n    # Calculate curvature\n    curvature_data = calculate_curvature(elevation_data, pixel_size_x, pixel_size_y)\n\n    return {\n        'Latitude': lat,\n        'Longitude': lon,\n        'Elevation': elevation_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Slope': slope_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Aspect': aspect_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Curvature': curvature_data[neighborhood_size // 2, neighborhood_size // 2]\n    }\n\n\nclim_data = pd.read_csv('/home/chetana/gridmet_test_run/testing_clim_cleaned.csv')\n\n# Apply read_elevation_data function to calculate elevation, slope, aspect, and curvature\nelevation_data = clim_data.apply(lambda row: read_elevation_data(\"/home/chetana/gridmet_test_run/output_4km.tif\", row['lat'], row['lon']), axis=1,\n                                 result_type='expand')\n\n# Merge elevation data with the original DataFrame\nfinal_testing_df = pd.concat([clim_data, elevation_data], axis=1)\n\n# Save the updated DataFrame to a new CSV file\nfinal_testing_df.to_csv('/home/chetana/gridmet_test_run/final_testing.csv', index=False)\n",
  "history_output" : "",
  "history_begin_time" : 1690149254134,
  "history_end_time" : 1690149720607,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "aV7JKoja9LYq",
  "history_input" : "import numpy as np\nimport pandas as pd\nfrom osgeo import gdal\n\n\ndef lat_lon_to_pixel(lat, lon, geotransform):\n    x = int((lon - geotransform[0]) / geotransform[1])\n    y = int((lat - geotransform[3]) / geotransform[5])\n    return x, y\n\n\ndef calculate_slope_aspect(elevation_data, pixel_size_x, pixel_size_y):\n    # Calculate slope using the Sobel operator\n    slope_x = np.gradient(elevation_data, pixel_size_x, axis=1)\n    slope_y = np.gradient(elevation_data, pixel_size_y, axis=0)\n    slope_rad = np.arctan(np.sqrt(slope_x ** 2 + slope_y ** 2))\n    slope_deg = np.degrees(slope_rad)\n\n    # Calculate aspect (direction of the steepest descent)\n    aspect_rad = np.arctan2(slope_y, -slope_x)\n    aspect_deg = (np.degrees(aspect_rad) + 360) % 360\n\n    return slope_deg, aspect_deg\n\n\ndef calculate_curvature(elevation_data, pixel_size_x, pixel_size_y):\n    # Calculate curvature using the Laplacian operator\n    curvature_x = np.gradient(np.gradient(elevation_data, pixel_size_x, axis=1), pixel_size_x, axis=1)\n    curvature_y = np.gradient(np.gradient(elevation_data, pixel_size_y, axis=0), pixel_size_y, axis=0)\n    curvature = curvature_x + curvature_y\n\n    return curvature\n\n\ndef read_elevation_data(file_path, lat, lon, neighborhood_size=3):\n    dataset = gdal.Open(file_path)\n    if dataset is None:\n        print(\"Error: Could not open the file.\")\n        return None\n\n    # Get geotransform information\n    geotransform = dataset.GetGeoTransform()\n    pixel_size_x = geotransform[1]\n    pixel_size_y = geotransform[5]\n\n    # Convert latitude and longitude to pixel indices\n    x, y = lat_lon_to_pixel(lat, lon, geotransform)\n\n    # Read a small neighborhood of elevation data around the selected point\n    band = dataset.GetRasterBand(1)\n    elevation_data = band.ReadAsArray(x - neighborhood_size // 2, y - neighborhood_size // 2, neighborhood_size,\n                                      neighborhood_size)\n\n    # Calculate slope and aspect\n    slope_data, aspect_data = calculate_slope_aspect(elevation_data, pixel_size_x, pixel_size_y)\n\n    # Calculate curvature\n    curvature_data = calculate_curvature(elevation_data, pixel_size_x, pixel_size_y)\n\n    return {\n        'Latitude': lat,\n        'Longitude': lon,\n        'Elevation': elevation_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Slope': slope_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Aspect': aspect_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Curvature': curvature_data[neighborhood_size // 2, neighborhood_size // 2]\n    }\n\n\nclim_data = pd.read_csv('/home/chetana/gridmet_test_run/testing_clim_cleaned.csv')\n\n# Apply read_elevation_data function to calculate elevation, slope, aspect, and curvature\nelevation_data = clim_data.apply(lambda row: read_elevation_data(\"/home/chetana/gridmet_test_run/output_4km.tif\", row['lat'], row['lon']), axis=1,\n                                 result_type='expand')\n\n# Merge elevation data with the original DataFrame\nfinal_testing_df = pd.concat([clim_data, elevation_data], axis=1)\n\n# Save the updated DataFrame to a new CSV file\nfinal_testing_df.to_csv('/home/chetana/gridmet_test_run/final_testing.csv', index=False)\n",
  "history_output" : "sh: /home/chetana/anaconda3/conda/bin/python: No such file or directory\n",
  "history_begin_time" : 1690149237185,
  "history_end_time" : 1690149238163,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "awBjgGcfZmZS",
  "history_input" : "import numpy as np\nimport pandas as pd\nfrom osgeo import gdal\n\n\ndef lat_lon_to_pixel(lat, lon, geotransform):\n    x = int((lon - geotransform[0]) / geotransform[1])\n    y = int((lat - geotransform[3]) / geotransform[5])\n    return x, y\n\n\ndef calculate_slope_aspect(elevation_data, pixel_size_x, pixel_size_y):\n    # Calculate slope using the Sobel operator\n    slope_x = np.gradient(elevation_data, pixel_size_x, axis=1)\n    slope_y = np.gradient(elevation_data, pixel_size_y, axis=0)\n    slope_rad = np.arctan(np.sqrt(slope_x ** 2 + slope_y ** 2))\n    slope_deg = np.degrees(slope_rad)\n\n    # Calculate aspect (direction of the steepest descent)\n    aspect_rad = np.arctan2(slope_y, -slope_x)\n    aspect_deg = (np.degrees(aspect_rad) + 360) % 360\n\n    return slope_deg, aspect_deg\n\n\ndef calculate_curvature(elevation_data, pixel_size_x, pixel_size_y):\n    # Calculate curvature using the Laplacian operator\n    curvature_x = np.gradient(np.gradient(elevation_data, pixel_size_x, axis=1), pixel_size_x, axis=1)\n    curvature_y = np.gradient(np.gradient(elevation_data, pixel_size_y, axis=0), pixel_size_y, axis=0)\n    curvature = curvature_x + curvature_y\n\n    return curvature\n\n\ndef read_elevation_data(file_path, lat, lon, neighborhood_size=3):\n    dataset = gdal.Open(file_path)\n    if dataset is None:\n        print(\"Error: Could not open the file.\")\n        return None\n\n    # Get geotransform information\n    geotransform = dataset.GetGeoTransform()\n    pixel_size_x = geotransform[1]\n    pixel_size_y = geotransform[5]\n\n    # Convert latitude and longitude to pixel indices\n    x, y = lat_lon_to_pixel(lat, lon, geotransform)\n\n    # Read a small neighborhood of elevation data around the selected point\n    band = dataset.GetRasterBand(1)\n    elevation_data = band.ReadAsArray(x - neighborhood_size // 2, y - neighborhood_size // 2, neighborhood_size,\n                                      neighborhood_size)\n\n    # Calculate slope and aspect\n    slope_data, aspect_data = calculate_slope_aspect(elevation_data, pixel_size_x, pixel_size_y)\n\n    # Calculate curvature\n    curvature_data = calculate_curvature(elevation_data, pixel_size_x, pixel_size_y)\n\n    return {\n        'Latitude': lat,\n        'Longitude': lon,\n        'Elevation': elevation_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Slope': slope_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Aspect': aspect_data[neighborhood_size // 2, neighborhood_size // 2],\n        'Curvature': curvature_data[neighborhood_size // 2, neighborhood_size // 2]\n    }\n\n\nclim_data = pd.read_csv('/home/chetana/gridmet_test_run/testing_clim_cleaned.csv')\n\n# Apply read_elevation_data function to calculate elevation, slope, aspect, and curvature\nelevation_data = clim_data.apply(lambda row: read_elevation_data(\"/home/chetana/gridmet_test_run/output_4km.tif\", row['lat'], row['lon']), axis=1,\n                                 result_type='expand')\n\n# Merge elevation data with the original DataFrame\nfinal_testing_df = pd.concat([clim_data, elevation_data], axis=1)\n\n# Save the updated DataFrame to a new CSV file\nfinal_testing_df.to_csv('/home/chetana/gridmet_test_run/final_testing.csv', index=False)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/awBjgGcfZmZS/gridmet_testing.py\", line 3, in <module>\n    from osgeo import gdal\nModuleNotFoundError: No module named 'osgeo'\n",
  "history_begin_time" : 1690149210867,
  "history_end_time" : 1690149212349,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WwDDOuiU6WOz",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2001, 1, 1)\nend_date = date(2001, 2, 2)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/testing_western_us_lat_long_ext.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n    current_date = start_date\n\n    while current_date <= end_date:\n        date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n        all_dates.append(date_string)\n        current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data_ext.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['lat'], row['lon'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "File downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmn_2001.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/tmmx_2001.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/pr_2001.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vpd_2001.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/etr_2001.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmax_2001.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/rmin_2001.nc\nFile downloaded successfully and saved as: /home/chetana/gridmet_test_run/gridmet_climatology/vs_2001.nc\nStarting data retrieval for the year 2001\nCompleted data retrieval for the year 2001\n",
  "history_begin_time" : 1690125943839,
  "history_end_time" : 1690126320650,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "2Es7SmNPYJnR",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/testing_western_us_lat_long_ext.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data_ext.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['lat'], row['lon'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\n",
  "history_begin_time" : 1690055810223,
  "history_end_time" : 1690056024034,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "R5pmxHp0NBsA",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/testing_western_us_lat_long_ext.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data_ext.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\nTraceback (most recent call last):\n  File \"/home/chetana/gridmet_test_run/pycrate/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'Latitude'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/R5pmxHp0NBsA/gridmet_testing.py\", line 128, in <module>\n    get_climatology_data(year_list)\n  File \"/home/chetana/gw-workspace/R5pmxHp0NBsA/gridmet_testing.py\", line 97, in get_climatology_data\n    lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n  File \"/home/chetana/gridmet_test_run/pycrate/lib/python3.9/site-packages/pandas/core/series.py\", line 981, in __getitem__\n    return self._get_value(key)\n  File \"/home/chetana/gridmet_test_run/pycrate/lib/python3.9/site-packages/pandas/core/series.py\", line 1089, in _get_value\n    loc = self.index.get_loc(label)\n  File \"/home/chetana/gridmet_test_run/pycrate/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'Latitude'\n",
  "history_begin_time" : 1690055300357,
  "history_end_time" : 1690055307408,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "y5nVFx1Moy1e",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/lat_lon_coordinates.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\nCompleted data retrieval for the year 2002\nStarting data retrieval for the year 2003\nCompleted data retrieval for the year 2003\nStarting data retrieval for the year 2004\nCompleted data retrieval for the year 2004\nStarting data retrieval for the year 2005\nCompleted data retrieval for the year 2005\nStarting data retrieval for the year 2006\nCompleted data retrieval for the year 2006\nStarting data retrieval for the year 2007\nCompleted data retrieval for the year 2007\nStarting data retrieval for the year 2008\nCompleted data retrieval for the year 2008\nStarting data retrieval for the year 2009\nCompleted data retrieval for the year 2009\nStarting data retrieval for the year 2010\nCompleted data retrieval for the year 2010\nStarting data retrieval for the year 2011\nCompleted data retrieval for the year 2011\nStarting data retrieval for the year 2012\nCompleted data retrieval for the year 2012\nStarting data retrieval for the year 2013\nCompleted data retrieval for the year 2013\nStarting data retrieval for the year 2014\nCompleted data retrieval for the year 2014\nStarting data retrieval for the year 2015\nCompleted data retrieval for the year 2015\nStarting data retrieval for the year 2016\nCompleted data retrieval for the year 2016\nStarting data retrieval for the year 2017\nCompleted data retrieval for the year 2017\nStarting data retrieval for the year 2018\nCompleted data retrieval for the year 2018\nStarting data retrieval for the year 2019\nCompleted data retrieval for the year 2019\nStarting data retrieval for the year 2020\nCompleted data retrieval for the year 2020\nStarting data retrieval for the year 2021\nCompleted data retrieval for the year 2021\nStarting data retrieval for the year 2022\nCompleted data retrieval for the year 2022\nStarting data retrieval for the year 2023\nCompleted data retrieval for the year 2023\n",
  "history_begin_time" : 1689919626742,
  "history_end_time" : 1689926182741,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "K0s9pEbdDNDY",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/lat_lon_coordinates.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\n",
  "history_begin_time" : 1689919486426,
  "history_end_time" : 1689919626750,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "C8gaCg9sw8cN",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/lat_lon_coordinates.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\nCompleted data retrieval for the year 2002\nStarting data retrieval for the year 2003\n",
  "history_begin_time" : 1689919055083,
  "history_end_time" : 1689919486434,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "zFDRsmo85g4t",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/lat_lon_coordinates.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : null,
  "history_begin_time" : 1689919049305,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "vIvEVcl3v2jD",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/western_us_coordinates_4km_8step.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\n",
  "history_begin_time" : 1689914350975,
  "history_end_time" : 1689919049313,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "gbPYnXdc9Thr",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/western_us_coordinates_4km.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\n",
  "history_begin_time" : 1689911502175,
  "history_end_time" : 1689914323327,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "rRIoDjs9oNEb",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/testing_station_cell_mapping.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('/home/chetana/gridmet_test_run/gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\n",
  "history_begin_time" : 1689891672364,
  "history_end_time" : 1689911502188,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "fcgbSrs6zYu5",
  "history_input" : "#############################################\n# Process Name: gridmet_station_only\n# Person Assigned: Gokul Prathin A\n# Last Changes On: 1st July 2023\n#############################################\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport netCDF4 as nc\nimport urllib.request\nfrom datetime import datetime, timedelta, date\n\nstart_date = date(2002, 1, 1)\nend_date = date(2023, 1, 1)\n\n# start_date = date(2017, 1, 1)\n# end_date = date(2018, 1, 1)\n\nyear_list = [start_date.year + i for i in range(end_date.year - start_date.year + 1)]\nstation = pd.read_csv('/home/chetana/gridmet_test_run/testing_station_cell_mapping.csv')\n\n\ndef get_all_dates_in_year(years):\n    all_dates = []\n\n    for year in years:\n        tmp_start_date = datetime(year, 1, 1)\n        tmp_end_date = datetime(year, 12, 31)\n\n        current_date = tmp_start_date\n        while current_date <= tmp_end_date:\n            date_string = current_date.strftime('%Y-%m-%d %H:%M:%S')\n            all_dates.append(date_string)\n            current_date += timedelta(days=1)\n\n    return all_dates\n\n\ndef download_file(url, save_location):\n    try:\n        with urllib.request.urlopen(url) as response:\n            file_content = response.read()\n        file_name = os.path.basename(url)\n        save_path = os.path.join(save_location, file_name)\n        with open(save_path, 'wb') as file:\n            file.write(file_content)\n        print(f\"File downloaded successfully and saved as: {save_path}\")\n    except Exception as e:\n        print(f\"An error occurred while downloading the file: {str(e)}\")\n\n\ndef gridmet_climatology():\n    # make a directory to store the downloaded files\n    folder_name = '/home/chetana/gridmet_test_run/gridmet_climatology'\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    base_metadata_url = \"http://www.northwestknowledge.net/metdata/data/\"\n    variables_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'etr', 'rmax', 'rmin', 'vs']\n\n    for var in variables_list:\n        for y in year_list:\n            download_link = base_metadata_url + var + '_' + '%s' % y + '.nc'\n            if not os.path.exists(os.path.join(folder_name, var + '_' + '%s' % y + '.nc')):\n                download_file(download_link, folder_name)\n\n\ndef get_climatology_data(yr_lst):\n    all_dates = get_all_dates_in_year(yr_lst)\n    climatology_dataframe = pd.DataFrame(\n        columns=['date', 'lat', 'lon', 'cell_id', 'station_id', 'etr', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd', 'vs'])\n\n    reference_date = datetime(1900, 1, 1)\n\n    csv_file = '/home/chetana/gridmet_test_run/testing_climatology_data.csv'  # Specify the CSV file path\n\n    with open(csv_file, 'w') as f:\n        climatology_dataframe.to_csv(f, index=False)  # Write the header to the CSV file\n\n    for year in yr_lst:\n        print(f'Starting data retrieval for the year {year}')\n        etr_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"etr_{year}.nc\"))\n        pr_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"pr_{year}.nc\"))\n        rmax_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"rmax_{year}.nc\"))\n        rmin_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"rmin_{year}.nc\"))\n        tmmn_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"tmmn_{year}.nc\"))\n        tmmx_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"tmmx_{year}.nc\"))\n        vpd_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"vpd_{year}.nc\"))\n        vs_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"vs_{year}.nc\"))\n\n        latitudes = etr_nc_file.variables['lat'][:]\n        longitudes = etr_nc_file.variables['lon'][:]\n        day = etr_nc_file.variables['day'][:]\n\n        for index, row in station.iterrows():\n            lat, lon, cell_id, station_id = row['Latitude'], row['Longitude'], None, None\n            lat_index = np.abs(latitudes - lat).argmin()\n            lon_index = np.abs(longitudes - lon).argmin()\n\n            for date_str in get_all_dates_in_year([year]):\n                date_object = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n                days_since_1900 = (date_object - reference_date).days\n                time_index = np.abs(day - days_since_1900).argmin()\n                row_data = {\n                    'date': date_str.split(' ')[0],\n                    'lat': lat,\n                    'lon': lon,\n                    #'cell_id': cell_id,\n                    #'station_id': station_id,\n                    'etr': etr_nc_file.variables['potential_evapotranspiration'][time_index, lat_index, lon_index],\n                    'pr': pr_nc_file.variables['precipitation_amount'][time_index, lat_index, lon_index],\n                    'rmax': rmax_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'rmin': rmin_nc_file.variables['relative_humidity'][time_index, lat_index, lon_index],\n                    'tmmn': tmmn_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'tmmx': tmmx_nc_file.variables['air_temperature'][time_index, lat_index, lon_index],\n                    'vpd': vpd_nc_file.variables['mean_vapor_pressure_deficit'][time_index, lat_index, lon_index],\n                    'vs': vs_nc_file.variables['wind_speed'][time_index, lat_index, lon_index],\n                }\n                with open(csv_file, 'a') as f:\n                    pd.DataFrame(row_data, index=[0]).to_csv(f, header=False, index=False)  # Append row to the CSV file\n\n        print(f'Completed data retrieval for the year {year}')\n\n\n\ngridmet_climatology()\nget_climatology_data(year_list)\n\n",
  "history_output" : "Starting data retrieval for the year 2002\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/fcgbSrs6zYu5/gridmet_testing.py\", line 128, in <module>\n    get_climatology_data(year_list)\n  File \"/home/chetana/gw-workspace/fcgbSrs6zYu5/gridmet_testing.py\", line 83, in get_climatology_data\n    etr_nc_file = nc.Dataset(os.path.join('gridmet_climatology', f\"etr_{year}.nc\"))\n  File \"src/netCDF4/_netCDF4.pyx\", line 2464, in netCDF4._netCDF4.Dataset.__init__\n  File \"src/netCDF4/_netCDF4.pyx\", line 2027, in netCDF4._netCDF4._ensure_nc_success\nFileNotFoundError: [Errno 2] No such file or directory: 'gridmet_climatology/etr_2002.nc'\n",
  "history_begin_time" : 1689891559043,
  "history_end_time" : 1689891566624,
  "history_notes" : null,
  "history_process" : "drwmbo",
  "host_id" : null,
  "indicator" : "Done"
},]
