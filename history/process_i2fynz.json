[{
  "history_id" : "muoh37z56v1",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-09-16\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: importance_summary_plot_2023-02-12.png\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2023_pr_2023-02-12.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2023_predicted_swe_2023-02-12.png\nCopied: 2023_pr_2023-06-15.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2023_pr_2023-02-11.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: importance_summary_plot_2023-09-15.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-09-15.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: importance_summary_plot_2023-02-11.png\nCopied: 2023_predicted_swe_2023-02-11.png\nCopied: 2023_pr_2023-01-15.png\nCopied: importance_summary_plot_2023-06-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2023_predicted_swe_2023-06-15.png\nCopied: 2023_pr_2023-09-16.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-09-16.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: importance_summary_plot_2023-09-16.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2023_predicted_swe_2023-09-15.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696864262292,
  "history_end_time" : 1696864264800,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "md0gddfmafp",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-09-15\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: importance_summary_plot_2023-02-12.png\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2023_pr_2023-02-12.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2023_predicted_swe_2023-02-12.png\nCopied: 2023_pr_2023-06-15.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2023_pr_2023-02-11.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: importance_summary_plot_2023-09-15.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-09-15.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: importance_summary_plot_2023-02-11.png\nCopied: 2023_predicted_swe_2023-02-11.png\nCopied: 2023_pr_2023-01-15.png\nCopied: importance_summary_plot_2023-06-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2023_predicted_swe_2023-06-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2023_predicted_swe_2023-09-15.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696862761762,
  "history_end_time" : 1696862765220,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "x1297da3en8",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-06-15\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: importance_summary_plot_2023-02-12.png\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2023_pr_2023-02-12.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2023_predicted_swe_2023-02-12.png\nCopied: 2023_pr_2023-06-15.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2023_pr_2023-02-11.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: importance_summary_plot_2023-02-11.png\nCopied: 2023_predicted_swe_2023-02-11.png\nCopied: 2023_pr_2023-01-15.png\nCopied: importance_summary_plot_2023-06-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2023_predicted_swe_2023-06-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696832548979,
  "history_end_time" : 1696832551330,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l0NsZez8yo4y",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-12\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: importance_summary_plot_2023-02-12.png\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2023_pr_2023-02-12.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2023_predicted_swe_2023-02-12.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2023_pr_2023-02-11.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: importance_summary_plot_2023-02-11.png\nCopied: 2023_predicted_swe_2023-02-11.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696832170373,
  "history_end_time" : 1696832171284,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "yg8orw6jgt0",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-12\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2023_pr_2023-02-12.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2023_predicted_swe_2023-02-12.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2023_pr_2023-02-11.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: importance_summary_plot_2023-02-11.png\nCopied: 2023_predicted_swe_2023-02-11.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696832124179,
  "history_end_time" : 1696832126631,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "WKpSjoWW7X7w",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2023_pr_2023-02-11.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: importance_summary_plot_2023-02-11.png\nCopied: 2023_predicted_swe_2023-02-11.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696831808254,
  "history_end_time" : 1696831809239,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "D8zzNjQtIYw9",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2023_pr_2023-02-11.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_predicted_swe_2023-02-11.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696831339492,
  "history_end_time" : 1696831340353,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "h79o2r6peo7",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-11\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2023_pr_2023-02-11.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_predicted_swe_2023-02-11.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696830439400,
  "history_end_time" : 1696830441781,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "iLA1w4scqBef",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-09\ntest start date:  2023-02-10\ntest end date:  2023-10-09\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: importance_summary_plot_2023-02-10.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696830005855,
  "history_end_time" : 1696830007160,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "CL0ThoN0XZXO",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-02-10\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2023_predicted_swe_2023-02-10.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696787788115,
  "history_end_time" : 1696787789011,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "k9m6p42jqih",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-02-10\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: 2023_pr_2023-02-10.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696787750802,
  "history_end_time" : 1696787753179,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7dlepd8eht0",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696786928901,
  "history_end_time" : 1696786931219,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "gQK1yh70lLri",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696786368874,
  "history_end_time" : 1696786369779,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vGrVbF0L17ai",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: partial_dependence_summary_plot_2023-01-20.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: et-model-feature-importance-latest.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: importance_summary_plot_2023-01-20.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696785865259,
  "history_end_time" : 1696785866135,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "IPipQ4vPRqc7",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "X has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\nX has feature names, but ExtraTreesRegressor was fitted without feature names\ntest start date:  2023-01-20\n",
  "history_begin_time" : 1696782560802,
  "history_end_time" : 1696782561742,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "QlwOSlU1bzT9",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png\nCopied: 2022_predicted_swe_2022-12-29.png\nCopied: 2022_predicted_swe_2022-01-17.png\nCopied: 2022_predicted_swe_2022-12-30.png\nCopied: 2022_predicted_swe_2022-01-16.png\nCopied: 2022_predicted_swe_2022-04-17.png\nCopied: 2022_predicted_swe_2022-02-28.png\nCopied: 2022_pr_2022-06-15.png\nCopied: 2022_predicted_swe_2022-10-15.png\nCopied: 2022_predicted_swe_2022-02-22.png\nCopied: 2023_predicted_swe_2023-01-18.png\nCopied: 2023_predicted_swe_2023-01-19.png\nCopied: 2023_predicted_swe_2023-01-20.png\nCopied: 2023_pr_2023-01-19.png\nCopied: 2022_pr_2022-02-28.png\nCopied: 2023_pr_2023-01-20.png\nCopied: 2023_pr_2023-01-18.png\nCopied: 2023_pr_2023-01-15.png\nCopied: 2022_pr_2022-01-16.png\nCopied: 2023_predicted_swe_2023-01-15.png\nCopied: 2022_pr_2022-12-29.png\nCopied: 2022_pr_2022-10-15.png\nCopied: 2022_pr_2022-02-22.png\nCopied: 2022_pr_2022-10-16.png\nCopied: 2022_pr_2022-04-17.png\nCopied: 2022_predicted_swe_2022-06-15.png\nCopied: 2022_pr_2022-03-15.png\nCopied: 2022_predicted_swe_2022-10-16.png\nCopied: 2022_pr_2022-01-17.png\nCopied: 2022_pr_2022-12-30.png\n",
  "history_begin_time" : 1696773919735,
  "history_end_time" : 1696773920555,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WCbPlL9vshQq",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\nimport shutil\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename} to {destination_folder}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nCopied: 2022_predicted_swe_2022-03-15.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-12-29.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-01-17.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-12-30.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-01-16.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-04-17.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-02-28.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-06-15.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-10-15.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-02-22.png to /var/www/html/swe_forecasting/plots/\nCopied: 2023_predicted_swe_2023-01-18.png to /var/www/html/swe_forecasting/plots/\nCopied: 2023_predicted_swe_2023-01-19.png to /var/www/html/swe_forecasting/plots/\nCopied: 2023_predicted_swe_2023-01-20.png to /var/www/html/swe_forecasting/plots/\nCopied: 2023_pr_2023-01-19.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-02-28.png to /var/www/html/swe_forecasting/plots/\nCopied: 2023_pr_2023-01-20.png to /var/www/html/swe_forecasting/plots/\nCopied: 2023_pr_2023-01-18.png to /var/www/html/swe_forecasting/plots/\nCopied: 2023_pr_2023-01-15.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-01-16.png to /var/www/html/swe_forecasting/plots/\nCopied: 2023_predicted_swe_2023-01-15.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-12-29.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-10-15.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-02-22.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-10-16.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-04-17.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-06-15.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-03-15.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_predicted_swe_2022-10-16.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-01-17.png to /var/www/html/swe_forecasting/plots/\nCopied: 2022_pr_2022-12-30.png to /var/www/html/swe_forecasting/plots/\n",
  "history_begin_time" : 1696773900914,
  "history_end_time" : 1696773902208,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "fY5KsH9wnSiH",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\nimport os\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename} to {destination_folder}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/fY5KsH9wnSiH/deploy_images_to_website.py\", line 33, in <module>\n    shutil.copy(source_file, destination_file)\nNameError: name 'shutil' is not defined\n",
  "history_begin_time" : 1696773886204,
  "history_end_time" : 1696773887061,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "4r0o7wqnb5XH",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n\n\n# copy the png from testing_output to plots\nsource_folder = f\"{work_dir}/testing_output/\"\n\n# Ensure the destination folder exists, create it if necessary\nif not os.path.exists(destination_folder):\n    os.makedirs(destination_folder)\n\n# Loop through the files in the source folder\nfor filename in os.listdir(source_folder):\n    # Check if the file is a PNG file\n    if filename.endswith('.png'):\n        # Build the source and destination file paths\n        source_file = os.path.join(source_folder, filename)\n        destination_file = os.path.join(destination_folder, filename)\n        \n        # Copy the file from the source to the destination\n        shutil.copy(source_file, destination_file)\n        print(f'Copied: {filename} to {destination_folder}')\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/4r0o7wqnb5XH/deploy_images_to_website.py\", line 20, in <module>\n    if not os.path.exists(destination_folder):\nNameError: name 'os' is not defined\n",
  "history_begin_time" : 1696773878224,
  "history_end_time" : 1696773879046,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "y5QoVfL8tPpz",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\n",
  "history_begin_time" : 1696773730148,
  "history_end_time" : 1696773731008,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "6kretzr0t9j",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-20\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\n",
  "history_begin_time" : 1696772056809,
  "history_end_time" : 1696772059206,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "prBp4gm78w9n",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-19\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\n",
  "history_begin_time" : 1696732317586,
  "history_end_time" : 1696732318438,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "RxQ7P9fP52TR",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n",
  "history_output" : "today date = 2023-10-08\ntest start date:  2023-01-19\ntest end date:  2023-10-08\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\n",
  "history_begin_time" : 1696732183178,
  "history_end_time" : 1696732184010,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "CgwLW9W8bN8i",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\n",
  "history_begin_time" : 1696690706404,
  "history_end_time" : 1696690707269,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "HcqRyikLnHMw",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\n",
  "history_begin_time" : 1696690430032,
  "history_end_time" : 1696690430857,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "8Udf3GQjUpMl",
  "history_input" : "import distutils.dir_util\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Copy the folder with overwriting existing files/folders\ndistutils.dir_util.copy_tree(source_folder, destination_folder, update=1)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nmove the plots and the results into the http folder\nFolder '/home/chetana/gridmet_test_run/var_comparison/' copied to '/var/www/html/swe_forecasting/plots/' with overwriting.\n",
  "history_begin_time" : 1696690331572,
  "history_end_time" : 1696690332429,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WBPbzuabD5uh",
  "history_input" : "import shutil\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nsource_folder = f\"{work_dir}/var_comparison/\"\ndestination_folder = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Define a custom copy function to overwrite existing files\ndef custom_copy_function(src, dst, *, follow_symlinks=True):\n    # Function to copy files and overwrite if they already exist\n    shutil.copy2(src, dst)\n\n# Use shutil.copytree to copy the entire folder and overwrite existing files\n# Copy the folder with overwriting existing files\nshutil.copytree(source_folder, destination_folder, copy_function=custom_copy_function)\n\nprint(f\"Folder '{source_folder}' copied to '{destination_folder}' with overwriting.\")\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nmove the plots and the results into the http folder\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/WBPbzuabD5uh/deploy_images_to_website.py\", line 17, in <module>\n    shutil.copytree(source_folder, destination_folder, copy_function=custom_copy_function)\n  File \"/home/chetana/anaconda3/lib/python3.9/shutil.py\", line 568, in copytree\n    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n  File \"/home/chetana/anaconda3/lib/python3.9/shutil.py\", line 467, in _copytree\n    os.makedirs(dst, exist_ok=dirs_exist_ok)\n  File \"/home/chetana/anaconda3/lib/python3.9/os.py\", line 225, in makedirs\n    mkdir(name, mode)\nFileExistsError: [Errno 17] File exists: '/var/www/html/swe_forecasting/plots/'\n",
  "history_begin_time" : 1696690271090,
  "history_end_time" : 1696690271880,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "yh2ngpP4eXBA",
  "history_input" : "import shutil\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nvar_comparison_plot_path = f\"{work_dir}/var_comparison/\"\npublic_folder_path = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Use shutil.copytree to copy the entire folder and overwrite existing files\nshutil.copytree(var_comparison_plot_path, public_folder_path, dirs_exist_ok=True)\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nmove the plots and the results into the http folder\n",
  "history_begin_time" : 1696690189864,
  "history_end_time" : 1696690190651,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Z7tOX29nDBbi",
  "history_input" : "import shutil\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nvar_comparison_plot_path = f\"{work_dir}/var_comparison/\"\npublic_folder_path = f\"/var/www/html/swe_forecasting/plots/\"\n\n# Use shutil.copytree to copy the entire folder and overwrite existing files\nshutil.copytree(var_comparison_plot_path, public_folder_path, dirs_exist_ok=True)\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nmove the plots and the results into the http folder\n",
  "history_begin_time" : 1696690055222,
  "history_end_time" : 1696690056007,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "C3pHMPbajlva",
  "history_input" : "import shutil\nfrom snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nvar_comparison_plot_path = f\"{work_dir}/var_comparison/\"\npublic_folder_path = f\"/var/www/html/swe_forecasting/plots/\"\n\n\n# Use shutil.copytree to copy the entire folder\nshutil.copytree(var_comparison_plot_path, public_folder_path)\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nmove the plots and the results into the http folder\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/C3pHMPbajlva/deploy_images_to_website.py\", line 12, in <module>\n    shutil.copytree(var_comparison_plot_path, public_folder_path)\n  File \"/home/chetana/anaconda3/lib/python3.9/shutil.py\", line 568, in copytree\n    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n  File \"/home/chetana/anaconda3/lib/python3.9/shutil.py\", line 467, in _copytree\n    os.makedirs(dst, exist_ok=dirs_exist_ok)\n  File \"/home/chetana/anaconda3/lib/python3.9/os.py\", line 225, in makedirs\n    mkdir(name, mode)\nFileExistsError: [Errno 17] File exists: '/var/www/html/swe_forecasting/plots/'\n",
  "history_begin_time" : 1696689997450,
  "history_end_time" : 1696689998337,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "B2R3cZTrtogY",
  "history_input" : "from snowcast_utils import work_dir\n\n\nprint(\"move the plots and the results into the http folder\")\n\nvar_comparison_plot_path = f\"{work_dir}/var_comparison/\"\npublic_folder_path = f\"/var/www/html/swe_forecasting/plots/\"\n\n\n# Use shutil.copytree to copy the entire folder\nshutil.copytree(var_comparison_plot_path, public_folder_path)\n",
  "history_output" : "today date = 2023-10-07\ntest start date:  2023-01-19\ntest end date:  2023-10-07\n/home/chetana\nmove the plots and the results into the http folder\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/B2R3cZTrtogY/deploy_images_to_website.py\", line 11, in <module>\n    shutil.copytree(var_comparison_plot_path, public_folder_path)\nNameError: name 'shutil' is not defined\n",
  "history_begin_time" : 1696689975445,
  "history_end_time" : 1696689976213,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "cpysvfj5omm",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n\n\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1696603205884,
  "history_end_time" : 1696603207421,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "p9gl6b6ug0q",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1696432531702,
  "history_end_time" : 1696432533246,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "zmp8i7gv4yw",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695828153852,
  "history_end_time" : 1695828155416,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "czviyfartje",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695696682072,
  "history_end_time" : 1695696683607,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xmkiiwl0fo0",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695694446097,
  "history_end_time" : 1695694447627,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "42hj1alv1ol",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695693643903,
  "history_end_time" : 1695693645497,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l0cfud3zts6",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695693368183,
  "history_end_time" : 1695693369725,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hjgc2h8v07n",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695581108558,
  "history_end_time" : 1695581110114,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "to7wwmnskzq",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695576481441,
  "history_end_time" : 1695576482967,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yrwz6eu344g",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695576171450,
  "history_end_time" : 1695576172973,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5h5lmzlcd3l",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695535982867,
  "history_end_time" : 1695535984404,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hfj9tmbcq9g",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695535675918,
  "history_end_time" : 1695535677482,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "p23brbnejxi",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695535411572,
  "history_end_time" : 1695535413127,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "7yluzdwmhtl",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695535140105,
  "history_end_time" : 1695535141642,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "b7pjz5snsnh",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695534861809,
  "history_end_time" : 1695534863317,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "bhabltvuwib",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695533205274,
  "history_end_time" : 1695533206831,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "mjr3ef3peel",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695529381564,
  "history_end_time" : 1695529383145,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "yeqtcaskns3",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695528579271,
  "history_end_time" : 1695528580790,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "u8atlhfktzl",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695515936403,
  "history_end_time" : 1695515937942,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "p0t5whi4uo6",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695506626333,
  "history_end_time" : 1695506627847,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "otoej6oti3a",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695418937435,
  "history_end_time" : 1695418938944,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q71a7qxomfp",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695417811691,
  "history_end_time" : 1695417813204,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "fldkoed5fjg",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695417396700,
  "history_end_time" : 1695417398248,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jm28zragg4m",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695417100143,
  "history_end_time" : 1695417101679,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "srzcfn7buys",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695417023746,
  "history_end_time" : 1695417025277,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5nqd02ytakh",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695106538747,
  "history_end_time" : 1695106540325,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "cjclm29xcau",
  "history_input" : "print(\"move the plots and the results into the http folder\")\n",
  "history_output" : "move the plots and the results into the http folder\n",
  "history_begin_time" : 1695106473033,
  "history_end_time" : 1695106474555,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "clur6qyq87y",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1695054088341,
  "history_end_time" : 1695054091808,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "7peiokgrz3f",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1695053841153,
  "history_end_time" : 1695053844560,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "gj0zj2q7mmo",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1695053782362,
  "history_end_time" : 1695053786953,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "u51qmdozu9n",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1694970773425,
  "history_end_time" : 1694970777026,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "03046ugepr5",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1694970652987,
  "history_end_time" : 1694970656409,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "1jp96y1fou4",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1694970198731,
  "history_end_time" : 1694970202102,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "qrcbzgqtiof",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1694969417161,
  "history_end_time" : 1694969420625,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3ce5k2fgqv7",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/3ce5k2fgqv7/service_prediction.py\", line 17, in <module>\n    import geopandas as gpd\nModuleNotFoundError: No module named 'geopandas'\n",
  "history_begin_time" : 1694908995684,
  "history_end_time" : 1694908999321,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "o1cy22ikpuo",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/o1cy22ikpuo/service_prediction.py\", line 17, in <module>\n    import geopandas as gpd\nModuleNotFoundError: No module named 'geopandas'\n",
  "history_begin_time" : 1694901480397,
  "history_end_time" : 1694901489001,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ikpgmzfjst1",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/ikpgmzfjst1/service_prediction.py\", line 7, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691531390809,
  "history_end_time" : 1691531394261,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "z3aw4ndxbq4",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/z3aw4ndxbq4/service_prediction.py\", line 7, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691531317662,
  "history_end_time" : 1691531321094,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "i29jtqm9tan",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/i29jtqm9tan/service_prediction.py\", line 7, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691531222658,
  "history_end_time" : 1691531226048,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "yzddwew8dwh",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/yzddwew8dwh/service_prediction.py\", line 7, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691531148214,
  "history_end_time" : 1691531151654,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "3im4vcuhgyn",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/3im4vcuhgyn/service_prediction.py\", line 7, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691531090018,
  "history_end_time" : 1691531095401,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "stdf6v41llh",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/stdf6v41llh/service_prediction.py\", line 7, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691530872842,
  "history_end_time" : 1691530877500,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "i97u3ct5b3u",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/i97u3ct5b3u/service_prediction.py\", line 7, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691530716904,
  "history_end_time" : 1691530721495,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "xsg02cmqm0l",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/xsg02cmqm0l/service_prediction.py\", line 7, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1691530644097,
  "history_end_time" : 1691530649812,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "yqe6br3t7ym",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689632045253,
  "history_end_time" : 1689632046695,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "yby8pypp5na",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "  File \"service_prediction.py\", line 31\n    github_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n                                                      ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1689631652411,
  "history_end_time" : 1689631654690,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "uomra1kgsfr",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689135077553,
  "history_end_time" : 1689135079178,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4ag774nsqkh",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/Users/joe\n",
  "history_begin_time" : 1687547313481,
  "history_end_time" : 1687547315509,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "utpy8loakij",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1687463701393,
  "history_end_time" : 1687463702828,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "k7w6r3jci48",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1687463656563,
  "history_end_time" : 1687463657987,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "spmnv1chlyv",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit(1)  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "sh: /home/chetana/anaconda3/condabin/python: No such file or directory\n",
  "history_begin_time" : 1686235985620,
  "history_end_time" : 1686235987930,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Failed"
},{
  "history_id" : "yh00udot6x8",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "  File \"service_prediction.py\", line 31\n    github_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n                                                      ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1686235556505,
  "history_end_time" : 1686235558793,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Failed"
},{
  "history_id" : "1to0ojrq4we",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "  File \"service_prediction.py\", line 31\n    github_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n                                                      ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1686153694188,
  "history_end_time" : 1686153695281,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Done"
},{
  "history_id" : "vv712ycxzpd",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1681516938453,
  "history_end_time" : 1681516939922,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "14b58migwlu",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1681039721725,
  "history_end_time" : 1681039723155,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xyjfyq05rlp",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1681007831265,
  "history_end_time" : 1681007832707,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "7jbiozf2rsq",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\nimport json\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "  File \"service_prediction.py\", line 32\n    github_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n                                                      ^\n",
  "history_begin_time" : 1679442763341,
  "history_end_time" : 1679442765438,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Failed"
},{
  "history_id" : "5wce3atsl8g",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\nimport json\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "  File \"service_prediction.py\", line 32\n    github_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n                                                      ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1679332606910,
  "history_end_time" : 1679332609165,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Done"
},{
  "history_id" : "m9wljp5y7q3",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "  File \"service_prediction.py\", line 31\n    github_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n                                                      ^\n",
  "history_begin_time" : 1679191275421,
  "history_end_time" : 1679191277770,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "2jifky",
  "indicator" : "Failed"
},{
  "history_id" : "pr2rshl93cs",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1678748562990,
  "history_end_time" : 1678748564466,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "l7x85m1flq9",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678747874310,
  "history_end_time" : 1678747879485,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "cbgdsf12xc7",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678743795461,
  "history_end_time" : 1678743800923,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "i7nlll5x5e6",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678742679001,
  "history_end_time" : 1678742684244,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "8xyloxd26se",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678725463307,
  "history_end_time" : 1678725468710,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "z843yky350d",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678649634707,
  "history_end_time" : 1678649639916,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "bmrtzqtyu6w",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678648426596,
  "history_end_time" : 1678648432178,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "j6h9szh1ig0",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678565135358,
  "history_end_time" : 1678565140004,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "zqxa5tthxzt",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678564689797,
  "history_end_time" : 1678564694663,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "uf4gsgc7um4",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678557799690,
  "history_end_time" : 1678557898784,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "8rfv4h1d18t",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n''' \nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678497658170,
  "history_end_time" : 1678497663095,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "UobjTQktZkzY",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\n'''\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n'''",
  "history_output" : "/home/chetana\n",
  "history_begin_time" : 1678496864910,
  "history_end_time" : 1678496869175,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "8wMhEdHwNCQX",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\n'''\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\n'''\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/8wMhEdHwNCQX/service_prediction.py\", line 62, in <module>\n    random_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\nNameError: name 'best_random' is not defined\n",
  "history_begin_time" : 1678496831917,
  "history_end_time" : 1678496835998,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Bxy0d6KAUfIG",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\n  \nfolder_path = f\"{github_dir}/model\"\nfiles = os.listdir(folder_path)\n\n# Filter out directories and non-files\nfiles = [f for f in files if os.path.isfile(os.path.join(folder_path, f))]\n\n# Get the most recent file based on creation time\nmost_recent_file = max(files, key=lambda f: os.path.getctime(os.path.join(folder_path, f)))\nprint(most_recent_file)\nbest_random = joblib.load(f\"{github_dir}/model/{most_recent_file}\")\n\nbest_model = joblib.load(f\"{github_dir}/model/{most_recent_file}\")\n'''\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")'''\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nwormhole_XGBoostHole_20230903025852.joblib\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/Bxy0d6KAUfIG/service_prediction.py\", line 74, in <module>\n    random_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n  File \"/home/chetana/gw-workspace/Bxy0d6KAUfIG/service_prediction.py\", line 41, in evaluate\n    y_predicted = model.predict(test_features)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 981, in predict\n    X = self._validate_X_predict(X)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 602, in _validate_X_predict\n    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 569, in _validate_data\n    self._check_n_features(X, reset=reset)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 370, in _check_n_features\n    raise ValueError(\nValueError: X has 4 features, but ExtraTreesRegressor is expecting 22 features as input.\n",
  "history_begin_time" : 1678496177945,
  "history_end_time" : 1678496197831,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ct93jswlmbo",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/ct93jswlmbo/service_prediction.py\", line 56, in <module>\n    base_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib'\n",
  "history_begin_time" : 1678330793595,
  "history_end_time" : 1678330798471,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Failed"
},{
  "history_id" : "qfiuxk9hq1r",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/qfiuxk9hq1r/service_prediction.py\", line 56, in <module>\n    base_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib'\n",
  "history_begin_time" : 1678312632864,
  "history_end_time" : 1678312637979,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Failed"
},{
  "history_id" : "81rfkkml76n",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/81rfkkml76n/service_prediction.py\", line 56, in <module>\n    base_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib'\n",
  "history_begin_time" : 1678285605423,
  "history_end_time" : 1678285609719,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Failed"
},{
  "history_id" : "YRM6lD1lru07",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/YRM6lD1lru07/service_prediction.py\", line 56, in <module>\n    base_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib'\n",
  "history_begin_time" : 1678202367870,
  "history_end_time" : 1678202371507,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "v3ggx8adah8",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/v3ggx8adah8/service_prediction.py\", line 56, in <module>\n    base_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib'\n",
  "history_begin_time" : 1678202257080,
  "history_end_time" : 1678202262210,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Failed"
},{
  "history_id" : "7c3lnc2f67f",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/7c3lnc2f67f/service_prediction.py\", line 56, in <module>\n    base_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib'\n",
  "history_begin_time" : 1678155323898,
  "history_end_time" : 1678155328867,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Failed"
},{
  "history_id" : "fG4Xfhvhp7na",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/fG4Xfhvhp7na/service_prediction.py\", line 56, in <module>\n    base_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib'\n",
  "history_begin_time" : 1677959296739,
  "history_end_time" : 1677959300491,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ugwvl7g7zqh",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#exit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/ugwvl7g7zqh/service_prediction.py\", line 56, in <module>\n    base_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib'\n",
  "history_begin_time" : 1677791582075,
  "history_end_time" : 1677791587314,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Failed"
},{
  "history_id" : "uf47bs97958",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677784204220,
  "history_end_time" : 1677784272018,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "jl9n9cd6tn1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677782901796,
  "history_end_time" : 1677782901796,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "230wrlksxng",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677781745157,
  "history_end_time" : 1677781745157,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "oxucnn3dv6c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677719046568,
  "history_end_time" : 1677719046568,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "fby8o71433n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677718179082,
  "history_end_time" : 1677718179082,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "wl33brc26ve",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677679556254,
  "history_end_time" : 1677679556254,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "9aklv5u8bpe",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677679507357,
  "history_end_time" : 1677679549075,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "6c2om5x43df",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677636286813,
  "history_end_time" : 1677636286813,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "inh0j55tg3m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677636150347,
  "history_end_time" : 1677636150347,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "53b40u8gopm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677636137199,
  "history_end_time" : 1677636142807,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "6o2cgr8wifx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677636063736,
  "history_end_time" : 1677636063736,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "n3hnhu3s8ei",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677635881797,
  "history_end_time" : 1677635881797,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "YlPlGtgzNsxE",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1677634405055,
  "history_end_time" : 1677634408572,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ep1dz0ltw11",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677617762754,
  "history_end_time" : 1677617762754,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "f4cl61t6qlr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677606170854,
  "history_end_time" : 1677606170854,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "r1tebpbzkgc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677606114094,
  "history_end_time" : 1677606114094,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "vbtlzir6e0r",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/gokulprathin/gw-workspace/vbtlzir6e0r/service_prediction.py\", line 18, in <module>\n    import geojson\nModuleNotFoundError: No module named 'geojson'\n",
  "history_begin_time" : 1677582866877,
  "history_end_time" : 1677582869544,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "2fkmsvksu87",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677525425949,
  "history_end_time" : 1677525425949,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "msu3cmdbv3p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462325747,
  "history_end_time" : 1694185608907,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "q0yqeqo4v6h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311680,
  "history_end_time" : 1694185608624,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "6bacgorrfy9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462265121,
  "history_end_time" : 1677462265121,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "axl6915gb7t",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677428742692,
  "history_end_time" : 1677428742692,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "j3tlxwwivem",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677428687298,
  "history_end_time" : 1677428687298,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "aczy0a1c5vr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677426262713,
  "history_end_time" : 1677426262713,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "b24p6z5foc9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677379889770,
  "history_end_time" : 1677379889770,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "kgs31c4qnsj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677379837760,
  "history_end_time" : 1677379837760,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "wh6izefavac",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677352477938,
  "history_end_time" : 1677352477938,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "xxpmfofo97b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677352389872,
  "history_end_time" : 1677352389872,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "umuqaixuu47",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677352335816,
  "history_end_time" : 1677352335816,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "vrik88slxtq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677344119893,
  "history_end_time" : 1677344119893,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "4qn39lek953",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677282602578,
  "history_end_time" : 1677282602578,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "bg51d685z54",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273712205,
  "history_end_time" : 1677273712205,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ez4yd7auuzn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273698728,
  "history_end_time" : 1677273703950,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "s6gpw7bbcqx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273673895,
  "history_end_time" : 1677273679530,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "t4m5nfvgr7q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273657778,
  "history_end_time" : 1677273665446,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "7x9vyhwdclv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273535979,
  "history_end_time" : 1677273535979,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "aotqjjv73yk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273519084,
  "history_end_time" : 1677273525482,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "orz9os7g8ek",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273371284,
  "history_end_time" : 1677273371284,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "kwwoku143tf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273340413,
  "history_end_time" : 1677273345436,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "gqunoc4k5ql",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273323470,
  "history_end_time" : 1677273332226,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "lb0j3ixzkzg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273146622,
  "history_end_time" : 1677273146622,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "4s54x7rw7al",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273100198,
  "history_end_time" : 1677273134480,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "0ur8j6udrvy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677201275398,
  "history_end_time" : 1677201275398,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "f5jfq0kp4ve",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677192311032,
  "history_end_time" : 1677192311032,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "8zmtaa14rud",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677192268351,
  "history_end_time" : 1677192268351,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "zi94zqwjbkr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677191916703,
  "history_end_time" : 1677191916703,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "o1z8bk75rwp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677184296661,
  "history_end_time" : 1677184296661,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "0m7dcybdjtg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677184173515,
  "history_end_time" : 1677184173515,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "vqpxkggm0et",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677113476432,
  "history_end_time" : 1677113476432,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "gzqn4glzt4a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677108238576,
  "history_end_time" : 1677108238576,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ekawert88i2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677108212453,
  "history_end_time" : 1677108228695,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "7h88ju4q6zu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107869787,
  "history_end_time" : 1677107869787,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ghvvtbkmkv9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107757938,
  "history_end_time" : 1677107757938,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "sxozmq0chjx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107718283,
  "history_end_time" : 1677107718283,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "7x4slie4v91",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107637136,
  "history_end_time" : 1677107705671,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fu5ypamdvks",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107604001,
  "history_end_time" : 1677107608759,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "pvehcffn3yb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107556500,
  "history_end_time" : 1677107562714,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "1wf3xw9e8u6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107524969,
  "history_end_time" : 1677107538157,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "3pu9wn0jgvw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107501071,
  "history_end_time" : 1677107501071,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "hqclnd8uwhq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107474132,
  "history_end_time" : 1677107474132,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "i4b17v1pjq9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106516075,
  "history_end_time" : 1677106516075,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "urdoon1aluf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106477026,
  "history_end_time" : 1677106477026,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "4exwoys5etf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106431014,
  "history_end_time" : 1677106431014,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "dz1lt1joaxd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106134855,
  "history_end_time" : 1677106147545,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "io290dwy1cg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106010922,
  "history_end_time" : 1677106010922,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "i1sx6mvvz6o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677030843463,
  "history_end_time" : 1677030843463,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "od9vgp3c46x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677030771119,
  "history_end_time" : 1677030771119,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ub5zz0zoj2o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677030672611,
  "history_end_time" : 1677030672611,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "05pbft2lcqx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677030562316,
  "history_end_time" : 1677030562316,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "2zpo82usf6g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677025528628,
  "history_end_time" : 1677025528628,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "fr9kqxt3jie",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677025466414,
  "history_end_time" : 1677025466414,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "bhrl8tjt47j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677017826394,
  "history_end_time" : 1677017826394,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "2xldqy9gwsp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677017218399,
  "history_end_time" : 1677017218399,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "qqv9hfbgkrj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677016681286,
  "history_end_time" : 1677016681286,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "11ec53czal0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677016142977,
  "history_end_time" : 1677016142977,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "euxftphecre",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677016063938,
  "history_end_time" : 1677016063938,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ifdb8gvbfra",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677015787619,
  "history_end_time" : 1677015787619,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "gt1ngh7evdu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677015739919,
  "history_end_time" : 1677015739919,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "eqmqu863na2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677014884904,
  "history_end_time" : 1677014884904,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "y12ls7ucfhz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677014795547,
  "history_end_time" : 1677014795547,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ijqg5m5j5zc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677014227950,
  "history_end_time" : 1677014227950,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "yide64owho8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677013908390,
  "history_end_time" : 1677013908390,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "yg0b7cgk795",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677013832967,
  "history_end_time" : 1677013832967,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "xq0xpqkz2rw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677011873002,
  "history_end_time" : 1677011873002,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "b9ykkz3vtq2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677008198531,
  "history_end_time" : 1677008198531,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "q4r1phudk5m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677008162913,
  "history_end_time" : 1677008162913,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "tnzzb7cbfqq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677001999544,
  "history_end_time" : 1677001999544,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "yts034fkknb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677001732208,
  "history_end_time" : 1677001732208,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gsu1783xlld",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677001593752,
  "history_end_time" : 1677001593752,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "drc5jl0jw65",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677000536749,
  "history_end_time" : 1677000536749,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0544kbfqo62",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676999722067,
  "history_end_time" : 1676999722067,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "yb51al",
  "indicator" : "Skipped"
},{
  "history_id" : "th86wc224rg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676999599020,
  "history_end_time" : 1676999599020,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zv387pba0tw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676862212262,
  "history_end_time" : 1676862212262,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gickwymdj9a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676329536216,
  "history_end_time" : 1676329536216,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ht59qgvastx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676329491717,
  "history_end_time" : 1676329491717,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ywxyqhfrhsj",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/gokulprathin/gw-workspace/ywxyqhfrhsj/service_prediction.py\", line 18, in <module>\n    import geojson\nModuleNotFoundError: No module named 'geojson'\n",
  "history_begin_time" : 1676063639817,
  "history_end_time" : 1676063642515,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ts4qdiid4h0",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/gokulprathin/gw-workspace/ts4qdiid4h0/service_prediction.py\", line 17, in <module>\n    import geopandas as gpd\nModuleNotFoundError: No module named 'geopandas'\n",
  "history_begin_time" : 1675783806605,
  "history_end_time" : 1675783809510,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ibs2onjwuot",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1672015053151,
  "history_end_time" : 1672015054853,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "r5d4dl4rrmv",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1671944456857,
  "history_end_time" : 1671944458660,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "g5couhejfmh",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1670910687738,
  "history_end_time" : 1670910689640,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "b6s1nd8srke",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1670910572268,
  "history_end_time" : 1670910574160,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jghyd16dz5n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670910268431,
  "history_end_time" : 1670910268431,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nkv4zo04hnb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670019638822,
  "history_end_time" : 1670019638822,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "55n6ya1vgyg",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1667484738245,
  "history_end_time" : 1667484740429,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6p0qfuwxjby",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1667410810472,
  "history_end_time" : 1667410812401,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "aslw9nt7uom",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1654521117157,
  "history_end_time" : 1654521118961,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2k746nwjlmf",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1647826118938,
  "history_end_time" : 1647826120615,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "5j0bd9slqr6",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1647225953750,
  "history_end_time" : 1647225955516,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "u1c7tdtbguo",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1646693035831,
  "history_end_time" : 1646693037497,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0mng6wg8pce",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nexit()  # for now, the workflow is not ready yet\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "",
  "history_begin_time" : 1646604649427,
  "history_end_time" : 1646604651060,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "6kpcbdrlvyp",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "/Users/joe\nThe Base Model model performance for testing set\n--------------------------------------\nMAE is 7.792623252483023\nMSE is 145.6170249908291\nR2 score is -0.3497606523873109\nRMSE is 12.067187948765408\nThe Optimized model performance for testing set\n--------------------------------------\nMAE is 7.635033087628328\nMSE is 138.08187844135637\nR2 score is -0.2799154929831078\nRMSE is 11.750824585592126\n",
  "history_begin_time" : 1646272339511,
  "history_end_time" : 1646272347051,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "41zmy9i70ub",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"service_prediction.py\", line 3, in <module>\n    from sklearn.ensemble import RandomForestRegressor\nModuleNotFoundError: No module named 'sklearn'\n",
  "history_begin_time" : 1645977677449,
  "history_end_time" : 1645977679115,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "je29f6",
  "indicator" : "Done"
},{
  "history_id" : "0ld354sm3kh",
  "history_input" : "# Predict results using the model\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# read the grid geometry file\n\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nmodis_test_ready_file = f\"{github_dir}/data/ready_for_training/modis_test_ready.csv\"\nmodis_test_ready_pd = pd.read_csv(modis_test_ready_file, header=0, index_col=0)\n\npd_to_clean = modis_test_ready_pd[[\"year\", \"m\", \"doy\", \"ndsi\", \"swe\", \"station_id\", \"cell_id\"]].dropna()\n\nall_features = pd_to_clean[[\"year\", \"m\", \"doy\", \"ndsi\"]].to_numpy()\nall_labels = pd_to_clean[[\"swe\"]].to_numpy().ravel()\n\ndef evaluate(model, test_features, y_test, model_name):\n    y_predicted = model.predict(test_features)\n    mae = metrics.mean_absolute_error(y_test, y_predicted)\n    mse = metrics.mean_squared_error(y_test, y_predicted)\n    r2 = metrics.r2_score(y_test, y_predicted)\n    rmse = math.sqrt(mse)\n\n    print(\"The {} model performance for testing set\".format(model_name))\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    \n    return y_predicted\n\nbase_model = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest_basic.joblib\")\nbasic_predicted_values = evaluate(base_model, all_features, all_labels, \"Base Model\")\n\nbest_random = joblib.load(f\"{homedir}/Documents/GitHub/snowcast_trained_model/model/wormhole_random_forest.joblib\")\nrandom_predicted_values = evaluate(best_random, all_features, all_labels, \"Optimized\")\n",
  "history_output" : "Traceback (most recent call last):\n  File \"service_prediction.py\", line 3, in <module>\n    from sklearn.ensemble import RandomForestRegressor\nModuleNotFoundError: No module named 'sklearn'\n",
  "history_begin_time" : 1645977446839,
  "history_end_time" : 1645977448515,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "je29f6",
  "indicator" : "Done"
},{
  "history_id" : "rby4m0etw7q",
  "history_input" : "# Predict results using the model\n\nprint(\"feed data into the service and monitor the results\")\n\n",
  "history_output" : "feed data into the service and monitor the results\n",
  "history_begin_time" : 1642977868759,
  "history_end_time" : 1642977868857,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nvdos9yaf4j",
  "history_input" : "# Predict results using the model\n\nprint(\"feed data into the service and monitor the results\")\n\n",
  "history_output" : "feed data into the service and monitor the results\n",
  "history_begin_time" : 1642969783156,
  "history_end_time" : 1642969783288,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4yf68c43e6s",
  "history_input" : "# Predict results using the model\n\nprint(\"feed data into the service and monitor the results\")\n\n",
  "history_output" : "feed data into the service and monitor the results\n",
  "history_begin_time" : 1642455233709,
  "history_end_time" : 1642455233817,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pw8xdgyyboc",
  "history_input" : "# Predict results using the model\n\nprint(\"feed data into the service and monitor the results\")\n\n",
  "history_output" : "feed data into the service and monitor the results\n",
  "history_begin_time" : 1642454685029,
  "history_end_time" : 1642454685159,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "v338oc2fnib",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1667410703760,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wupclhxe7ou",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1681039697759,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "tnpl59wp76w",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809171449,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fiuz9cohp9l",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678201703957,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "y3yenxnvcty",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1694185611211,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "q6i4liuzn6q",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677785529412,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "k3icaasvvin",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677797113213,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "izyaltmb7ey",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809840718,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "7h0oqm5v8ub",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677959722602,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "lw4ljqa5sdz",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678154846156,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "el9ec72zhx8",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677959583116,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "w8jd4vdvr5o",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206143045,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "gjtotcqtxi5",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1694185586126,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "qj56s9rode2",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677867648064,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "5ae6qcpr8ev",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678201687041,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "0mgawcd2urp",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677958849869,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "p0fhbvf8io0",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809573411,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ajx9zaj4blc",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677786042625,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fr09lsz8jtn",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809306572,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "6c9fwjpn0p7",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677958952851,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "g688sgwmo2e",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677958291183,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "r8zjzrk3uo5",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678312065069,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "d3c1bidbxvh",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677785383323,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "lp2412e0tgs",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809554667,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "wy40r6dux5z",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677784516773,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "4d8f154mc0w",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677796528249,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "f7suez7hpu3",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677958754101,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "5kh6qrwo9qo",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678201516408,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "m034ssfu4jr",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378227,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "cc9gtcsmw52",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678888215691,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "sygrpmufexr",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678744167048,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "gdc8873c7zc",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678883775422,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "g26gwtm6hsz",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678557923632,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "d2zmndc67zm",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678884438322,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "n0yhzxo2cn3",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678648341602,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "k0kczfuzgs4",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678725408335,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "oygzksayso5",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678742571498,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "5wprhfx806l",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678743615530,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "kd5kkn1g787",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678746792982,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "oymxjqi5iew",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678749935968,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ooy6rhaqwll",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678756684679,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "8njqozuuglk",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678884042259,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "0jxdu62tf34",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678884140246,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fyy1ax8388b",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678884535323,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fbfu9qqqzdx",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678884986354,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "0au1b74pstu",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678887010620,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "9vi779fndo4",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678887836224,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "0f0laf339ed",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678887946441,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "1cc2mu3gqli",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1679091533637,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "yws217cevi0",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1679091744924,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "0nd2k7kwdlq",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1682984800278,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "4fillxk8s5y",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1686235423743,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "ayra6dj4hkq",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1686235482621,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "obdk0twfu7i",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1686237909482,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "br1jtxmugg4",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1688416572959,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "fp0s4tgn092",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1688416660663,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "yrqcxas0tc4",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1688416822944,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "gz4a0l4706r",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1688416848465,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "j1htr3dmpwo",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1688416907363,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "7lb02ma8lbu",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1691530614286,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "93m0o03zzf7",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1691530622442,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "c3z0snyagae",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1691530721107,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "lm7urqf0jwn",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1691531284902,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "a167j548jwi",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1694972839688,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "hm08yzerong",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1695054019277,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ij7x9bpc93t",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1695054033332,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "poz7kto09f8",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1695827867011,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "dk657p9h9lc",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1695827965226,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "e8qaoz0sujw",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1696432482235,
  "history_notes" : null,
  "history_process" : "i2fynz",
  "host_id" : "100001",
  "indicator" : "Stopped"
},]
