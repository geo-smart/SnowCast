[{
  "history_id" : "4P6F1vt01aqm",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\nzone = 12\nlatLabel = 'S'\nsquare = 'YJ'\nyear = '202*' #>=2020\ndate = '*' #all acquisitions\npolarization = 'VV'\ns3Path = f's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/{zone}/{latLabel}/{square}/{year}/{date}/Gamma0_{polarization}.tif'\n\n# Find imagery according to S3 path pattern\ns3 = s3fs.S3FileSystem(anon=True)\nkeys = s3.glob(s3Path[5:]) #strip s3://\nprint(f'Located {len(keys)} images matching {s3Path}:')\n\nvrtName = f'stack{zone}{latLabel}{square}.vrt'\nif not os.path.exists(vrtName):\n    with open('s3paths.txt', 'w') as f:\n        for key in keys:\n            f.write(\"/vsis3/%s\\n\" % key)\n    print(\"current working dir: \", os.getcwd())\n    cmd = f'gdalbuildvrt -overwrite -separate -input_file_list s3paths.txt {os.getcwd()}/{vrtName}'\n    print(cmd)\n    os.system(cmd)\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(os.getcwd() + \"/\" + vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "dyld[11507]: Library not loaded: @rpath/libpoppler.91.dylib\n  Referenced from: /Users/l21-n02609-comm/opt/anaconda3/lib/libgdal.26.dylib\n  Reason: tried: '/Users/l21-n02609-comm/opt/anaconda3/lib/libpoppler.91.dylib' (no such file), '/Users/l21-n02609-comm/opt/anaconda3/bin/../lib/libpoppler.91.dylib' (no such file), '/Users/l21-n02609-comm/opt/anaconda3/bin/../lib/libpoppler.91.dylib' (no such file), '/usr/local/lib/libpoppler.91.dylib' (no such file), '/usr/lib/libpoppler.91.dylib' (no such file)\nprepare Sentinel 1 into .csv\nLocated 109 images matching s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/202*/*/Gamma0_VV.tif:\ncurrent working dir:  /Users/joe/gw-workspace/uoiAVoLpa4BsSEcIp4Np2LWMcI\ngdalbuildvrt -overwrite -separate -input_file_list s3paths.txt /Users/joe/gw-workspace/uoiAVoLpa4BsSEcIp4Np2LWMcI/stack12SYJ.vrt\nTraceback (most recent call last):\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 199, in _acquire_with_cache_info\n    file = self._cache[self._key]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/lru_cache.py\", line 53, in __getitem__\n    value = self._cache[key]\nKeyError: [<function open at 0x7f8edf293b80>, ('/Users/joe/gw-workspace/uoiAVoLpa4BsSEcIp4Np2LWMcI/stack12SYJ.vrt',), 'r', (('overview_level', 3), ('sharing', False))]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 261, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_shim.pyx\", line 78, in rasterio._shim.open_dataset\n  File \"rasterio/_err.pyx\", line 216, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: /Users/joe/gw-workspace/uoiAVoLpa4BsSEcIp4Np2LWMcI/stack12SYJ.vrt: No such file or directory\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/uoiAVoLpa4BsSEcIp4Np2LWMcI/data_sentinel1.py\", line 56, in <module>\n    da3 = rioxarray.open_rasterio(os.getcwd() + \"/\" + vrtName, overview_level=3, chunks='auto')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rioxarray/_io.py\", line 833, in open_rasterio\n    riods = manager.acquire()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 181, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 205, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/env.py\", line 437, in wrapper\n    return f(*args, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/__init__.py\", line 220, in open\n    s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 263, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: /Users/joe/gw-workspace/uoiAVoLpa4BsSEcIp4Np2LWMcI/stack12SYJ.vrt: No such file or directory\n",
  "history_begin_time" : 1644593810133,
  "history_end_time" : 1644593850268,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "2BWPpOeC63sC",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\nzone = 12\nlatLabel = 'S'\nsquare = 'YJ'\nyear = '202*' #>=2020\ndate = '*' #all acquisitions\npolarization = 'VV'\ns3Path = f's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/{zone}/{latLabel}/{square}/{year}/{date}/Gamma0_{polarization}.tif'\n\n# Find imagery according to S3 path pattern\ns3 = s3fs.S3FileSystem(anon=True)\nkeys = s3.glob(s3Path[5:]) #strip s3://\nprint(f'Located {len(keys)} images matching {s3Path}:')\n\nvrtName = f'stack{zone}{latLabel}{square}.vrt'\nif not os.path.exists(vrtName):\n    with open('s3paths.txt', 'w') as f:\n        for key in keys:\n            f.write(\"/vsis3/%s\\n\" % key)\n    print(\"current working dir: \", os.getcwd())\n    cmd = f'gdalbuildvrt -overwrite -separate -input_file_list s3paths.txt {os.getcwd()}/{vrtName}'\n    print(cmd)\n    os.system(cmd)\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(os.getcwd() + \"/\" + vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "dyld[7218]: Library not loaded: @rpath/libpoppler.91.dylib\n  Referenced from: /Users/l21-n02609-comm/opt/anaconda3/lib/libgdal.26.dylib\n  Reason: tried: '/Users/l21-n02609-comm/opt/anaconda3/lib/libpoppler.91.dylib' (no such file), '/Users/l21-n02609-comm/opt/anaconda3/bin/../lib/libpoppler.91.dylib' (no such file), '/Users/l21-n02609-comm/opt/anaconda3/bin/../lib/libpoppler.91.dylib' (no such file), '/usr/local/lib/libpoppler.91.dylib' (no such file), '/usr/lib/libpoppler.91.dylib' (no such file)\nprepare Sentinel 1 into .csv\nLocated 109 images matching s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/202*/*/Gamma0_VV.tif:\ncurrent working dir:  /Users/joe/gw-workspace/Rn8Wlb722fx83kUIxR4Ptdolly\ngdalbuildvrt -overwrite -separate -input_file_list s3paths.txt /Users/joe/gw-workspace/Rn8Wlb722fx83kUIxR4Ptdolly/stack12SYJ.vrt\nTraceback (most recent call last):\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 199, in _acquire_with_cache_info\n    file = self._cache[self._key]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/lru_cache.py\", line 53, in __getitem__\n    value = self._cache[key]\nKeyError: [<function open at 0x7fa5deedbb80>, ('/Users/joe/gw-workspace/Rn8Wlb722fx83kUIxR4Ptdolly/stack12SYJ.vrt',), 'r', (('overview_level', 3), ('sharing', False))]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 261, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_shim.pyx\", line 78, in rasterio._shim.open_dataset\n  File \"rasterio/_err.pyx\", line 216, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: /Users/joe/gw-workspace/Rn8Wlb722fx83kUIxR4Ptdolly/stack12SYJ.vrt: No such file or directory\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/Rn8Wlb722fx83kUIxR4Ptdolly/data_sentinel1.py\", line 56, in <module>\n    da3 = rioxarray.open_rasterio(os.getcwd() + \"/\" + vrtName, overview_level=3, chunks='auto')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rioxarray/_io.py\", line 833, in open_rasterio\n    riods = manager.acquire()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 181, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 205, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/env.py\", line 437, in wrapper\n    return f(*args, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/__init__.py\", line 220, in open\n    s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 263, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: /Users/joe/gw-workspace/Rn8Wlb722fx83kUIxR4Ptdolly/stack12SYJ.vrt: No such file or directory\n",
  "history_begin_time" : 1644554734364,
  "history_end_time" : 1644554785405,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "mk3ijrTM5t5c",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\nzone = 12\nlatLabel = 'S'\nsquare = 'YJ'\nyear = '202*' #>=2020\ndate = '*' #all acquisitions\npolarization = 'VV'\ns3Path = f's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/{zone}/{latLabel}/{square}/{year}/{date}/Gamma0_{polarization}.tif'\n\n# Find imagery according to S3 path pattern\ns3 = s3fs.S3FileSystem(anon=True)\nkeys = s3.glob(s3Path[5:]) #strip s3://\nprint(f'Located {len(keys)} images matching {s3Path}:')\n\nvrtName = f'stack{zone}{latLabel}{square}.vrt'\nif not os.path.exists(vrtName):\n    with open('s3paths.txt', 'w') as f:\n        for key in keys:\n            f.write(\"/vsis3/%s\\n\" % key)\n    print(\"current working dir: \", os.getcwd())\n    cmd = f'gdalbuildvrt -overwrite -separate -input_file_list s3paths.txt {os.getcwd()}/{vrtName}'\n    print(cmd)\n    os.system(cmd)\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(os.getcwd() + \"/\" + vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "dyld[76909]: Library not loaded: @rpath/libpoppler.91.dylib\n  Referenced from: /Users/l21-n02609-comm/opt/anaconda3/lib/libgdal.26.dylib\n  Reason: tried: '/Users/l21-n02609-comm/opt/anaconda3/lib/libpoppler.91.dylib' (no such file), '/Users/l21-n02609-comm/opt/anaconda3/bin/../lib/libpoppler.91.dylib' (no such file), '/Users/l21-n02609-comm/opt/anaconda3/bin/../lib/libpoppler.91.dylib' (no such file), '/usr/local/lib/libpoppler.91.dylib' (no such file), '/usr/lib/libpoppler.91.dylib' (no such file)\nprepare Sentinel 1 into .csv\nLocated 109 images matching s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/202*/*/Gamma0_VV.tif:\ncurrent working dir:  /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS\ngdalbuildvrt -overwrite -separate -input_file_list s3paths.txt /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt\nTraceback (most recent call last):\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 199, in _acquire_with_cache_info\n    file = self._cache[self._key]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/lru_cache.py\", line 53, in __getitem__\n    value = self._cache[key]\nKeyError: [<function open at 0x7f897160bb80>, ('/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt',), 'r', (('overview_level', 3), ('sharing', False))]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 261, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_shim.pyx\", line 78, in rasterio._shim.open_dataset\n  File \"rasterio/_err.pyx\", line 216, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt: No such file or directory\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 56, in <module>\n    da3 = rioxarray.open_rasterio(os.getcwd() + \"/\" + vrtName, overview_level=3, chunks='auto')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rioxarray/_io.py\", line 833, in open_rasterio\n    riods = manager.acquire()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 181, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 205, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/env.py\", line 437, in wrapper\n    return f(*args, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/__init__.py\", line 220, in open\n    s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 263, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt: No such file or directory\n",
  "history_begin_time" : 1644012231077,
  "history_end_time" : 1644012273391,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "1bGen2hNePic",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\nzone = 12\nlatLabel = 'S'\nsquare = 'YJ'\nyear = '202*' #>=2020\ndate = '*' #all acquisitions\npolarization = 'VV'\ns3Path = f's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/{zone}/{latLabel}/{square}/{year}/{date}/Gamma0_{polarization}.tif'\n\n# Find imagery according to S3 path pattern\ns3 = s3fs.S3FileSystem(anon=True)\nkeys = s3.glob(s3Path[5:]) #strip s3://\nprint(f'Located {len(keys)} images matching {s3Path}:')\n\nvrtName = f'stack{zone}{latLabel}{square}.vrt'\nif not os.path.exists(vrtName):\n    with open('s3paths.txt', 'w') as f:\n        for key in keys:\n            f.write(\"/vsis3/%s\\n\" % key)\n    print(\"current working dir: \", os.getcwd())\n    cmd = f'gdalbuildvrt -overwrite -separate -input_file_list s3paths.txt {os.getcwd()}/{vrtName}'\n    print(cmd)\n    os.system(cmd)\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(os.getcwd() + \"/\" + vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "dyld[76083]: Library not loaded: @rpath/libpoppler.91.dylib\n  Referenced from: /Users/l21-n02609-comm/opt/anaconda3/lib/libgdal.26.dylib\n  Reason: tried: '/Users/l21-n02609-comm/opt/anaconda3/lib/libpoppler.91.dylib' (no such file), '/Users/l21-n02609-comm/opt/anaconda3/bin/../lib/libpoppler.91.dylib' (no such file), '/Users/l21-n02609-comm/opt/anaconda3/bin/../lib/libpoppler.91.dylib' (no such file), '/usr/local/lib/libpoppler.91.dylib' (no such file), '/usr/lib/libpoppler.91.dylib' (no such file)\nprepare Sentinel 1 into .csv\nLocated 109 images matching s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/202*/*/Gamma0_VV.tif:\ncurrent working dir:  /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS\ngdalbuildvrt -overwrite -separate -input_file_list s3paths.txt /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt\nTraceback (most recent call last):\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 199, in _acquire_with_cache_info\n    file = self._cache[self._key]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/lru_cache.py\", line 53, in __getitem__\n    value = self._cache[key]\nKeyError: [<function open at 0x7fc5997bcb80>, ('/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt',), 'r', (('overview_level', 3), ('sharing', False))]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 261, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_shim.pyx\", line 78, in rasterio._shim.open_dataset\n  File \"rasterio/_err.pyx\", line 216, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt: No such file or directory\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 56, in <module>\n    da3 = rioxarray.open_rasterio(os.getcwd() + \"/\" + vrtName, overview_level=3, chunks='auto')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rioxarray/_io.py\", line 833, in open_rasterio\n    riods = manager.acquire()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 181, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 205, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/env.py\", line 437, in wrapper\n    return f(*args, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/__init__.py\", line 220, in open\n    s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 263, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt: No such file or directory\n",
  "history_begin_time" : 1643992850807,
  "history_end_time" : 1643992896624,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "JTa8ZmONfs7I",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\nzone = 12\nlatLabel = 'S'\nsquare = 'YJ'\nyear = '202*' #>=2020\ndate = '*' #all acquisitions\npolarization = 'VV'\ns3Path = f's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/{zone}/{latLabel}/{square}/{year}/{date}/Gamma0_{polarization}.tif'\n\n# Find imagery according to S3 path pattern\ns3 = s3fs.S3FileSystem(anon=True)\nkeys = s3.glob(s3Path[5:]) #strip s3://\nprint(f'Located {len(keys)} images matching {s3Path}:')\n\nvrtName = f'stack{zone}{latLabel}{square}.vrt'\nif not os.path.exists(vrtName):\n    with open('s3paths.txt', 'w') as f:\n        for key in keys:\n            f.write(\"/vsis3/%s\\n\" % key)\n    print(\"current working dir: \", os.getcwd())\n    cmd = f'gdalbuildvrt -overwrite -separate -input_file_list s3paths.txt {os.getcwd()}/{vrtName}'\n    print(cmd)\n    os.system(cmd)\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "sh: gdalbuildvrt: command not found\nprepare Sentinel 1 into .csv\nLocated 109 images matching s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/202*/*/Gamma0_VV.tif:\ncurrent working dir:  /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS\ngdalbuildvrt -overwrite -separate -input_file_list s3paths.txt /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/stack12SYJ.vrt\nTraceback (most recent call last):\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 199, in _acquire_with_cache_info\n    file = self._cache[self._key]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/lru_cache.py\", line 53, in __getitem__\n    value = self._cache[key]\nKeyError: [<function open at 0x7ff50226bb80>, ('stack12SYJ.vrt',), 'r', (('overview_level', 3), ('sharing', False))]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 261, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_shim.pyx\", line 78, in rasterio._shim.open_dataset\n  File \"rasterio/_err.pyx\", line 216, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: stack12SYJ.vrt: No such file or directory\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 56, in <module>\n    da3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rioxarray/_io.py\", line 833, in open_rasterio\n    riods = manager.acquire()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 181, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 205, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/env.py\", line 437, in wrapper\n    return f(*args, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/__init__.py\", line 220, in open\n    s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 263, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: stack12SYJ.vrt: No such file or directory\n",
  "history_begin_time" : 1643991992815,
  "history_end_time" : 1643992030907,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Mma1ArRQRGUL",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\nzone = 12\nlatLabel = 'S'\nsquare = 'YJ'\nyear = '202*' #>=2020\ndate = '*' #all acquisitions\npolarization = 'VV'\ns3Path = f's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/{zone}/{latLabel}/{square}/{year}/{date}/Gamma0_{polarization}.tif'\n\n# Find imagery according to S3 path pattern\ns3 = s3fs.S3FileSystem(anon=True)\nkeys = s3.glob(s3Path[5:]) #strip s3://\nprint(f'Located {len(keys)} images matching {s3Path}:')\n\nvrtName = f'stack{zone}{latLabel}{square}.vrt'\nif not os.path.exists(vrtName):\n    with open('s3paths.txt', 'w') as f:\n        for key in keys:\n            f.write(\"/vsis3/%s\\n\" % key)\n    print(\"current working dir: \", os.getcwd())\n    cmd = f'gdalbuildvrt -overwrite -separate -input_file_list s3paths.txt {vrtName}'\n    print(cmd)\n    os.system(cmd)\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "sh: gdalbuildvrt: command not found\nprepare Sentinel 1 into .csv\nLocated 109 images matching s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/202*/*/Gamma0_VV.tif:\ncurrent working dir:  /Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS\ngdalbuildvrt -overwrite -separate -input_file_list s3paths.txt stack12SYJ.vrt\nTraceback (most recent call last):\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 199, in _acquire_with_cache_info\n    file = self._cache[self._key]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/lru_cache.py\", line 53, in __getitem__\n    value = self._cache[key]\nKeyError: [<function open at 0x7fae19c93b80>, ('stack12SYJ.vrt',), 'r', (('overview_level', 3), ('sharing', False))]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 261, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_shim.pyx\", line 78, in rasterio._shim.open_dataset\n  File \"rasterio/_err.pyx\", line 216, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: stack12SYJ.vrt: No such file or directory\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 56, in <module>\n    da3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rioxarray/_io.py\", line 833, in open_rasterio\n    riods = manager.acquire()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 181, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 205, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/env.py\", line 437, in wrapper\n    return f(*args, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/__init__.py\", line 220, in open\n    s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 263, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: stack12SYJ.vrt: No such file or directory\n",
  "history_begin_time" : 1643991887598,
  "history_end_time" : 1643991926109,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Nd7xGcYyPvYu",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\nzone = 12\nlatLabel = 'S'\nsquare = 'YJ'\nyear = '202*' #>=2020\ndate = '*' #all acquisitions\npolarization = 'VV'\ns3Path = f's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/{zone}/{latLabel}/{square}/{year}/{date}/Gamma0_{polarization}.tif'\n\n# Find imagery according to S3 path pattern\ns3 = s3fs.S3FileSystem(anon=True)\nkeys = s3.glob(s3Path[5:]) #strip s3://\nprint(f'Located {len(keys)} images matching {s3Path}:')\n\nvrtName = f'stack{zone}{latLabel}{square}.vrt'\nif not os.path.exists(vrtName):\n    with open('s3paths.txt', 'w') as f:\n        for key in keys:\n            f.write(\"/vsis3/%s\\n\" % key)\n\tprint(\"current working dir: \", os.getcwd())\n    cmd = f'gdalbuildvrt -overwrite -separate -input_file_list s3paths.txt {vrtName}'\n    print(cmd)\n    os.system(cmd)\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 50\n    print(\"current working dir: \", os.getcwd())\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1643991872085,
  "history_end_time" : 1643991872145,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "GjZ9aiM6nwGt",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\nzone = 12\nlatLabel = 'S'\nsquare = 'YJ'\nyear = '202*' #>=2020\ndate = '*' #all acquisitions\npolarization = 'VV'\ns3Path = f's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/{zone}/{latLabel}/{square}/{year}/{date}/Gamma0_{polarization}.tif'\n\n# Find imagery according to S3 path pattern\ns3 = s3fs.S3FileSystem(anon=True)\nkeys = s3.glob(s3Path[5:]) #strip s3://\nprint(f'Located {len(keys)} images matching {s3Path}:')\n\nvrtName = f'stack{zone}{latLabel}{square}.vrt'\nif not os.path.exists(vrtName):\n    with open('s3paths.txt', 'w') as f:\n        for key in keys:\n            f.write(\"/vsis3/%s\\n\" % key)\n\n    cmd = f'gdalbuildvrt -overwrite -separate -input_file_list s3paths.txt {vrtName}'\n    print(cmd)\n    os.system(cmd)\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "sh: gdalbuildvrt: command not found\nprepare Sentinel 1 into .csv\nLocated 109 images matching s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/202*/*/Gamma0_VV.tif:\ngdalbuildvrt -overwrite -separate -input_file_list s3paths.txt stack12SYJ.vrt\nTraceback (most recent call last):\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 199, in _acquire_with_cache_info\n    file = self._cache[self._key]\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/lru_cache.py\", line 53, in __getitem__\n    value = self._cache[key]\nKeyError: [<function open at 0x7fe27627bb80>, ('stack12SYJ.vrt',), 'r', (('overview_level', 3), ('sharing', False))]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"rasterio/_base.pyx\", line 261, in rasterio._base.DatasetBase.__init__\n  File \"rasterio/_shim.pyx\", line 78, in rasterio._shim.open_dataset\n  File \"rasterio/_err.pyx\", line 216, in rasterio._err.exc_wrap_pointer\nrasterio._err.CPLE_OpenFailedError: stack12SYJ.vrt: No such file or directory\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 56, in <module>\n    da3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rioxarray/_io.py\", line 833, in open_rasterio\n    riods = manager.acquire()\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 181, in acquire\n    file, _ = self._acquire_with_cache_info(needs_lock)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/file_manager.py\", line 205, in _acquire_with_cache_info\n    file = self._opener(*self._args, **kwargs)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/env.py\", line 437, in wrapper\n    return f(*args, **kwds)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/rasterio/__init__.py\", line 220, in open\n    s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n  File \"rasterio/_base.pyx\", line 263, in rasterio._base.DatasetBase.__init__\nrasterio.errors.RasterioIOError: stack12SYJ.vrt: No such file or directory\n",
  "history_begin_time" : 1643991659142,
  "history_end_time" : 1643991697596,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "q3jiv1C6PeTP",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "prepare Sentinel 1 into .csv\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 33, in <module>\n    da3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\nNameError: name 'vrtName' is not defined\n",
  "history_begin_time" : 1643991306302,
  "history_end_time" : 1643991314956,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Q5oL8XnCzlNk",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 15, in <module>\n    import s3fs \nModuleNotFoundError: No module named 's3fs'\n",
  "history_begin_time" : 1643991280527,
  "history_end_time" : 1643991288135,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "BvCFpZbG4z53",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 9, in <module>\n    import intake\nModuleNotFoundError: No module named 'intake'\n",
  "history_begin_time" : 1643991255601,
  "history_end_time" : 1643991262479,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "E4qECmnd7Yac",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\nda.hvplot.image(clim=(0,0.4), cmap='gray', \n                x='x', y='y', \n                aspect='equal', frame_width=400,\n                title='S1B_20161121_12SYJ_ASC',\n                rasterize=True # send rendered image to browser, rather than full array\n               )\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 6, in <module>\n    import hvplot.pandas\nModuleNotFoundError: No module named 'hvplot'\n",
  "history_begin_time" : 1643991195537,
  "history_end_time" : 1643991210720,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "WLmpLUwragxH",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\nda.hvplot.image(clim=(0,0.4), cmap='gray', \n                x='x', y='y', \n                aspect='equal', frame_width=400,\n                title='S1B_20161121_12SYJ_ASC',\n                rasterize=True # send rendered image to browser, rather than full array\n               )\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/DIK6UAHjB8nXdLy84mCHqN9paS/data_sentinel1.py\", line 4, in <module>\n    import geoviews as gv\nModuleNotFoundError: No module named 'geoviews'\n",
  "history_begin_time" : 1643991008547,
  "history_end_time" : 1643991013870,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "BiEJgUPZexA7",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\nda.hvplot.image(clim=(0,0.4), cmap='gray', \n                x='x', y='y', \n                aspect='equal', frame_width=400,\n                title='S1B_20161121_12SYJ_ASC',\n                rasterize=True # send rendered image to browser, rather than full array\n               )\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"data_sentinel1.py\", line 4, in <module>\n    import geoviews as gv\nModuleNotFoundError: No module named 'geoviews'\n",
  "history_begin_time" : 1643990976883,
  "history_end_time" : 1643990982452,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Bh0qtUyDxy9k",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\nda.hvplot.image(clim=(0,0.4), cmap='gray', \n                x='x', y='y', \n                aspect='equal', frame_width=400,\n                title='S1B_20161121_12SYJ_ASC',\n                rasterize=True # send rendered image to browser, rather than full array\n               )\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"data_sentinel1.py\", line 3, in <module>\n    import geopandas as gpd\nModuleNotFoundError: No module named 'geopandas'\n",
  "history_begin_time" : 1643990922610,
  "history_end_time" : 1643990922678,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "bdBUDx1DhtVM",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\nda.hvplot.image(clim=(0,0.4), cmap='gray', \n                x='x', y='y', \n                aspect='equal', frame_width=400,\n                title='S1B_20161121_12SYJ_ASC',\n                rasterize=True # send rendered image to browser, rather than full array\n               )\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"data_sentinel1.py\", line 3, in <module>\n    import geopandas as gpd\nModuleNotFoundError: No module named 'geopandas'\n",
  "history_begin_time" : 1643990892162,
  "history_end_time" : 1643990892327,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "8Y9GcM9Rq4Ge",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport xarray as xr\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "prepare Sentinel 1 into .csv\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/i1KgbwuxiNuMSBX4Kd3ZwBwvgx/data_sentinel1.py\", line 22, in <module>\n    da3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\nNameError: name 'vrtName' is not defined\n",
  "history_begin_time" : 1642978039861,
  "history_end_time" : 1642978041067,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kTcumlcajCWX",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/i1KgbwuxiNuMSBX4Kd3ZwBwvgx/data_sentinel1.py\", line 9, in <module>\n    import s3fs \nModuleNotFoundError: No module named 's3fs'\n",
  "history_begin_time" : 1642978021400,
  "history_end_time" : 1642978022835,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Misqed53nBtw",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/i1KgbwuxiNuMSBX4Kd3ZwBwvgx/data_sentinel1.py\", line 4, in <module>\n    import intake\nModuleNotFoundError: No module named 'intake'\n",
  "history_begin_time" : 1642978010174,
  "history_end_time" : 1642978010604,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "A36wz4SrGwSl",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/i1KgbwuxiNuMSBX4Kd3ZwBwvgx/data_sentinel1.py\", line 4, in <module>\n    import panel as pn\nModuleNotFoundError: No module named 'panel'\n",
  "history_begin_time" : 1642977995061,
  "history_end_time" : 1642977995769,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "uu5p8yh6nzr",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\nda.hvplot.image(clim=(0,0.4), cmap='gray', \n                x='x', y='y', \n                aspect='equal', frame_width=400,\n                title='S1B_20161121_12SYJ_ASC',\n                rasterize=True # send rendered image to browser, rather than full array\n               )\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/i1KgbwuxiNuMSBX4Kd3ZwBwvgx/data_sentinel1.py\", line 4, in <module>\n    import geoviews as gv\nModuleNotFoundError: No module named 'geoviews'\n",
  "history_begin_time" : 1642977852086,
  "history_end_time" : 1642977853305,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "eg6kd34wb1k",
  "history_input" : "# Data preparation for Sentinel 1\n\nimport geopandas as gpd\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport panel as pn\nimport intake\nimport numpy as np\nimport os\nimport pandas as pd\nimport rasterio\nimport rioxarray\nimport s3fs \nimport xarray as xr\nhv.extension('bokeh')\n\nprint(\"prepare Sentinel 1 into .csv\")\n\n# GDAL environment variables to efficiently read remote data\nos.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\nos.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\nos.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Default is 10 MB limit in the GeoTIFF driver for range request merging.\n\n# Data is stored in a public S3 Bucket\nurl = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/S/YJ/2016/S1B_20161121_12SYJ_ASC/Gamma0_VV.tif'\n\n# These Cloud-Optimized-Geotiff (COG) files have 'overviews', low-resolution copies for quick visualization\nda = rioxarray.open_rasterio(url, overview_level=3).squeeze('band')\nda.hvplot.image(clim=(0,0.4), cmap='gray', \n                x='x', y='y', \n                aspect='equal', frame_width=400,\n                title='S1B_20161121_12SYJ_ASC',\n                rasterize=True # send rendered image to browser, rather than full array\n               )\n\n# Load a time series we created a VRT with GDAL to facilitate this step\nda3 = rioxarray.open_rasterio(vrtName, overview_level=3, chunks='auto')\n\n# Need to add time coordinates to this data\ndatetimes = [pd.to_datetime(x[55:63]) for x in keys]\n    \n# add new coordinate to existing dimension \nda = da3.assign_coords(time=('band', datetimes))\n# make 'time' active coordinate instead of integer band\nda = da.swap_dims({'band':'time'})\n# Name the dataset (helpful for hvplot calls later on)\nda.name = 'Gamma0VV'\n\n#use a small bounding box over grand mesa (UTM coordinates)\nxmin,xmax,ymin,ymax = [739186, 742748, 4.325443e+06, 4.327356e+06]\ndaT = da.sel(x=slice(xmin, xmax), \n             y=slice(ymax, ymin))\n\n# NOTE: this can take a while on slow internet connections, we're reading over 100 images!\nall_points = daT.where(daT!=0).hvplot.scatter('time', groupby=[], dynspread=True, datashade=True) \nmean_trend = daT.where(daT!=0, drop=True).mean(dim=['x','y']).hvplot.line(title='North Grand Mesa', color='red')\n\npath = '/tmp/tutorial-data/sar/sentinel1/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2/S1AA_20201030T131820_20201111T131820_VVP012_INT80_G_ueF_EBD2_unw_phase.tif'\nda = rioxarray.open_rasterio(path, masked=True).squeeze('band')\n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/aoEFgxNxP9s6Yil9uLVnHwKUXb/data_sentinel1.py\", line 4, in <module>\n    import geoviews as gv\nModuleNotFoundError: No module named 'geoviews'\n",
  "history_begin_time" : 1642969771011,
  "history_end_time" : 1642969771672,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jvwqpcqy8q3",
  "history_input" : "# Data preparation for Sentinel 1\n\nprint(\"prepare Sentinel 1 into .csv\")\n",
  "history_output" : "prepare Sentinel 1 into .csv\n",
  "history_begin_time" : 1642455225117,
  "history_end_time" : 1642455225257,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "od39bpxjsp4",
  "history_input" : "# Data preparation for Sentinel 1\n\nprint(\"prepare Sentinel 1 into .csv\")\n",
  "history_output" : "prepare Sentinel 1 into .csv\n",
  "history_begin_time" : 1642454673129,
  "history_end_time" : 1642454673375,
  "history_notes" : null,
  "history_process" : "m3bqdb",
  "host_id" : "100001",
  "indicator" : "Done"
},]
