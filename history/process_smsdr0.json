[{
  "history_id" : "k5yiw2j4ixy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711771209398,
  "history_end_time" : 1711771209398,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "oh8ckk3dp67",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711684813505,
  "history_end_time" : 1711684813505,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d9mlcheinyr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711598414931,
  "history_end_time" : 1711598414931,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xbklsuhlv98",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711592280397,
  "history_end_time" : 1711592280397,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6jzxojlktl5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711592081734,
  "history_end_time" : 1711592081734,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "rhgsr5jtscz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711512016119,
  "history_end_time" : 1711512016119,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3wlves254ij",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711425614028,
  "history_end_time" : 1711425614028,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kkdxvyfifnz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711339212535,
  "history_end_time" : 1711339212535,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i1zwrk1k891",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711252813355,
  "history_end_time" : 1711252813355,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g6g523jtgxr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711166413845,
  "history_end_time" : 1711166413845,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "suxakh4r4n9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1711080008941,
  "history_end_time" : 1711080008941,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sbfel0gk61y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710993609560,
  "history_end_time" : 1710993609560,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kk67382751w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710907208989,
  "history_end_time" : 1710907208989,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sfbcx22dpni",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710820808645,
  "history_end_time" : 1710820808645,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wmumhj2lx0z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710734409410,
  "history_end_time" : 1710734409410,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ehjqal66xw6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710690214118,
  "history_end_time" : 1710690214118,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "do92e555clk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710648009094,
  "history_end_time" : 1710648009094,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ua9qp8vczbk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710561608570,
  "history_end_time" : 1710561608570,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wkvdrbsf5lo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710475209158,
  "history_end_time" : 1710475209158,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k9lwkg26lav",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710388809054,
  "history_end_time" : 1710388809054,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pniu9ylfy0c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710302409301,
  "history_end_time" : 1710302409301,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "c1w6rjrtwuh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710216009343,
  "history_end_time" : 1710216009343,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1t7d2vwg8sp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710172046508,
  "history_end_time" : 1710172046508,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "exdnshz0aqe",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710129609006,
  "history_end_time" : 1710129609006,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "06lknaz5uer",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710080234038,
  "history_end_time" : 1710080234038,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "kx4peckv8h2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1710043208705,
  "history_end_time" : 1710043208705,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r9t78g7w9aq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709998716223,
  "history_end_time" : 1709998716223,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bkia4bqgqex",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709956808837,
  "history_end_time" : 1709956808837,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "m1effe5oj3h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709924987502,
  "history_end_time" : 1709924987502,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "75tbieycpba",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709870409856,
  "history_end_time" : 1709870409856,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qr4zbt49vtq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709845595291,
  "history_end_time" : 1709845595291,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "knoithub56v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709844621898,
  "history_end_time" : 1709844621898,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mej0svp8mnv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709842923323,
  "history_end_time" : 1709842923323,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "c67nrxh9pra",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709827652583,
  "history_end_time" : 1709844621142,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "397efm72wse",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709826138642,
  "history_end_time" : 1709826138642,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "e9w5caoxvbo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709797240773,
  "history_end_time" : 1709797240773,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ozcpew8umzc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709791537986,
  "history_end_time" : 1709791537986,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6ssvc9u5e41",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709784009354,
  "history_end_time" : 1709784009354,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vlt4xb6rl9m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709778056633,
  "history_end_time" : 1709778056633,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "a0x00g6dyol",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709774843549,
  "history_end_time" : 1709774843549,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ijkn4ngwojt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709765244612,
  "history_end_time" : 1709774842931,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "0gqnt9jcapj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709763117594,
  "history_end_time" : 1709765243432,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "62og2t2mdyd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709751527341,
  "history_end_time" : 1709751527341,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9g9ykpjysd6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709751443122,
  "history_end_time" : 1709751495317,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "b1467qim5oa",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709697609208,
  "history_end_time" : 1709697609208,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jx0zito0yvz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709611208681,
  "history_end_time" : 1709611208681,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sf2w5rfrn73",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709524808742,
  "history_end_time" : 1709524808742,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "99s47gvaot9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709438408532,
  "history_end_time" : 1709438408532,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "cj7d7fbevy1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709352008951,
  "history_end_time" : 1709352008951,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fch7bir2hyq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709265609294,
  "history_end_time" : 1709265609294,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1h02koscgov",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709179209324,
  "history_end_time" : 1709179209324,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "unfdm6lpa0u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709137312884,
  "history_end_time" : 1709137312884,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "20fqvay4ou8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709092808924,
  "history_end_time" : 1709092808924,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rj1szql4slc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709085684146,
  "history_end_time" : 1709085684146,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "rqqvcx6pza3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709078942121,
  "history_end_time" : 1709085672801,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Stopped"
},{
  "history_id" : "04lk3hv0jie",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709038894835,
  "history_end_time" : 1709038894835,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "6zh3kgre6z3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709038872957,
  "history_end_time" : 1709038879058,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Stopped"
},{
  "history_id" : "16lre0e6rky",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1709006408404,
  "history_end_time" : 1709006408404,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3wiqhewumt7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708971826152,
  "history_end_time" : 1708971826152,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "p1hdvvnjf54",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708958410858,
  "history_end_time" : 1708958410858,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "irra25r9qjg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708954624159,
  "history_end_time" : 1708954624159,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "89d2pylexgi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708920009352,
  "history_end_time" : 1708920009352,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "djpx85uuzw1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708833608997,
  "history_end_time" : 1708833608997,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "efuupa8andw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708747208709,
  "history_end_time" : 1708747208709,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "iikqm0q91in",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708660808941,
  "history_end_time" : 1708660808941,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "m8c2p5hm67d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708574409572,
  "history_end_time" : 1708574409572,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w9ttox3mzma",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708488009988,
  "history_end_time" : 1708488009988,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3t2oqosqmxc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708401608834,
  "history_end_time" : 1708401608834,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "co7emxx83uy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708352215489,
  "history_end_time" : 1708352215489,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "gbi0oclc2bo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708348193267,
  "history_end_time" : 1708352214865,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Stopped"
},{
  "history_id" : "idppyw2nw1o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708315208985,
  "history_end_time" : 1708315208985,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0biucufnviw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708312689875,
  "history_end_time" : 1708312689875,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "v3xj4xrx2zo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708305309895,
  "history_end_time" : 1708312689123,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Stopped"
},{
  "history_id" : "59x7nqv3q9k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708242679297,
  "history_end_time" : 1708242679297,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "1hypqtn9u7f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708240733508,
  "history_end_time" : 1708240733508,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "3qgjm313zjx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708238769926,
  "history_end_time" : 1708238769926,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "vr93ro1lfxc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708237144875,
  "history_end_time" : 1708237144875,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "t5ehr0ub3w4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708235187225,
  "history_end_time" : 1708235187225,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "giaoktemmcc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708233874629,
  "history_end_time" : 1708233874629,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "uxhutk39x1d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708228809075,
  "history_end_time" : 1708228809075,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xw2yhkebrpg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708227613796,
  "history_end_time" : 1708227613796,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "08fxnzef52l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708142409245,
  "history_end_time" : 1708142409245,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0ljmrep4cyx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1708056009056,
  "history_end_time" : 1708056009056,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pjxcrgg8ikj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707969608932,
  "history_end_time" : 1707969608932,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ix2eb71t9cj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707883208784,
  "history_end_time" : 1707883208784,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0bqtmazs6r5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707796809215,
  "history_end_time" : 1707796809215,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t23w3kb16fx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707750669713,
  "history_end_time" : 1707750669713,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "3egfob7rsv8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707710409289,
  "history_end_time" : 1707710409289,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ecptflyatqt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707624009263,
  "history_end_time" : 1707624009263,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "35xhu763rxo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707537608462,
  "history_end_time" : 1707537608462,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k03qbq94imv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707491746685,
  "history_end_time" : 1707491746685,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "rc9tqrlwhm3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707484657886,
  "history_end_time" : 1707484657886,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "4mxrgewaqv2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707451209562,
  "history_end_time" : 1707451209562,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "48201somn3e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707434644167,
  "history_end_time" : 1707434644167,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "2a6nfa73dvq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707432571791,
  "history_end_time" : 1707432571791,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Skipped"
},{
  "history_id" : "0k0ithxblgd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707431129229,
  "history_end_time" : 1707432053948,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "8drjlv",
  "indicator" : "Stopped"
},{
  "history_id" : "5pscf3fj9nr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707418188623,
  "history_end_time" : 1707418188623,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "mahjd7",
  "indicator" : "Skipped"
},{
  "history_id" : "hzy4v01tbj5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707413610261,
  "history_end_time" : 1707413610261,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "mahjd7",
  "indicator" : "Skipped"
},{
  "history_id" : "cmd00h3l42x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707364808555,
  "history_end_time" : 1707364808555,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wxl82x0epqv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707278408808,
  "history_end_time" : 1707278408808,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "f9ve03tk16e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707192718849,
  "history_end_time" : 1707192718849,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7f0uquz116b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707192008928,
  "history_end_time" : 1707448888637,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "s4yjny0bfnn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707189399005,
  "history_end_time" : 1707189399005,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "02vae8c49jr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707105609004,
  "history_end_time" : 1707750639180,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "vijpxt3xc90",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1707019209061,
  "history_end_time" : 1707750639652,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "4u9tc0dnhbq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706932808934,
  "history_end_time" : 1707750640195,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "dm05zpdfkcm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706846409403,
  "history_end_time" : 1707750640629,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "xgoq2gukn37",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706760009662,
  "history_end_time" : 1707750643268,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "1jvjrxhw76z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706673609200,
  "history_end_time" : 1707750643787,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ke44q54g069",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706587209135,
  "history_end_time" : 1707750644970,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "hil8bsh1nnh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706500808742,
  "history_end_time" : 1707750645647,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "inwtciaoak5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706414409069,
  "history_end_time" : 1707750646092,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "0ed4i7ky0xn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706366105878,
  "history_end_time" : 1706366105878,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "s6k4iwhl7lg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706364888427,
  "history_end_time" : 1706364888427,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vxuob3qyifb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706328009225,
  "history_end_time" : 1707750646891,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "myxbzfqz5bv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706280497901,
  "history_end_time" : 1706280497901,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "esnci5uab9u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706244881208,
  "history_end_time" : 1706244881208,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uo9nzehde45",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706241609447,
  "history_end_time" : 1706244810642,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "tbvyw21wciv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706155209321,
  "history_end_time" : 1706244801306,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "l1brukwryhc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1706068808774,
  "history_end_time" : 1706244800326,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "zhvbem0rk5i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705982408739,
  "history_end_time" : 1706244799959,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "nsxbgevyjc4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705896758907,
  "history_end_time" : 1706244798996,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "4b4w1cyihye",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705896009499,
  "history_end_time" : 1706244798514,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "vzqow40d5vu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705849063758,
  "history_end_time" : 1706244798003,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "6knavw3hwkh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705809608659,
  "history_end_time" : 1705849649588,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "yyrg80e9ifs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705793526799,
  "history_end_time" : 1705849647045,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "cnwya9dtmwe",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705790835041,
  "history_end_time" : 1705790835041,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ejvprd4ukbo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705770627692,
  "history_end_time" : 1705849642234,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "nwqtfomngdm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705762760543,
  "history_end_time" : 1705849640878,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "jp39jhvq7iy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705723209181,
  "history_end_time" : 1705789738430,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "6v7cso31r9f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705636808570,
  "history_end_time" : 1705770636196,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "lxowxjaeltt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705550409006,
  "history_end_time" : 1705770635522,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "h5bpx0b6bym",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705464008508,
  "history_end_time" : 1705770635025,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "hq82l1d4fks",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705422422452,
  "history_end_time" : 1705422422452,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t9qb96jt4zq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705377609109,
  "history_end_time" : 1705770633016,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "mpjh5f7m9sb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705291208714,
  "history_end_time" : 1705770632122,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "idk5qxfkcz4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705278850558,
  "history_end_time" : 1705278850558,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gwljs1irfkz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705270952729,
  "history_end_time" : 1705270952729,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xdrr5pki74r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705204809221,
  "history_end_time" : 1705789661988,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "c2yg90w3sqb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705169057177,
  "history_end_time" : 1705169057177,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "a3jbpjd330w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705118409335,
  "history_end_time" : 1705789660753,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "3bi45f5v221",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705072448057,
  "history_end_time" : 1705072448057,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vdaujqj8ipq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1705032009141,
  "history_end_time" : 1705789659525,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "psfel9vz9ve",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704979918281,
  "history_end_time" : 1704979918281,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9im8zyz6tjr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704945609350,
  "history_end_time" : 1705789658790,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "4vq6eejn0yc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704918977575,
  "history_end_time" : 1704918977575,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5cyzxjgvvaf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704908919566,
  "history_end_time" : 1704908919566,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tcz2un839aq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704859207399,
  "history_end_time" : 1705789668241,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ijddsev8gjo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704775840731,
  "history_end_time" : 1704775840731,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "w570m15hfoi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704772806603,
  "history_end_time" : 1705789667269,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "yrl4fiysg0b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704726161230,
  "history_end_time" : 1704727049020,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "nafyg9dgrjp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704686408143,
  "history_end_time" : 1705789666633,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "bprdsb6qwn1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704644803683,
  "history_end_time" : 1704644803683,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vjwmvp5qb3x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704600007947,
  "history_end_time" : 1705789665902,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "me0opnpan7m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704566156606,
  "history_end_time" : 1704566156606,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g1qt0tzbi1c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704565587362,
  "history_end_time" : 1704565587362,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "50ah1t8h4mu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704564424144,
  "history_end_time" : 1704564424144,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3oplq78axmy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704562992155,
  "history_end_time" : 1704562992155,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lf16bzk4na4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704561889777,
  "history_end_time" : 1704561889777,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gbv9ii0oh1u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704561861147,
  "history_end_time" : 1704561887030,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "3wphmvj6dds",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704555479187,
  "history_end_time" : 1704555479187,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3k34vvoz7nw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704555028177,
  "history_end_time" : 1704555028177,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xgis8egb8sv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704553241751,
  "history_end_time" : 1704553241751,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j25ecttbpty",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704552254592,
  "history_end_time" : 1704552254592,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dttef3n37yw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704513607180,
  "history_end_time" : 1705789671083,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gqqvqfnkmb6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704427207287,
  "history_end_time" : 1705789671857,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "puaxp9awwul",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704340807355,
  "history_end_time" : 1705789673099,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "jvbdj3tullu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704330109271,
  "history_end_time" : 1704330109271,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "32z942to6yo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704329364830,
  "history_end_time" : 1704329364830,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tta21lc90bc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704254407292,
  "history_end_time" : 1705789675626,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ofkqop2rf49",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704208947942,
  "history_end_time" : 1704208947942,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t04o6ft9j5v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704207352002,
  "history_end_time" : 1704207352002,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "78ntu5fyb7o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704205859351,
  "history_end_time" : 1704205859351,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6hronfuwuv0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704168007204,
  "history_end_time" : 1705789676812,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "e1ouxzgt7x5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1704081607255,
  "history_end_time" : 1705789677598,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "csxrnlzw6q9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703995208041,
  "history_end_time" : 1705789678791,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "lfznewr7vao",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703962871386,
  "history_end_time" : 1703962871386,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1b9jzbu0hqi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703960265428,
  "history_end_time" : 1703960265428,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rv806jlxhxz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703959737821,
  "history_end_time" : 1703959737821,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i0bi6qujugl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703958611568,
  "history_end_time" : 1703958611568,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pjcbdqrjgmr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703955838205,
  "history_end_time" : 1703955838205,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lft1u2g1y5m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703954150333,
  "history_end_time" : 1703954150333,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lh1s1n9n6ky",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703915768053,
  "history_end_time" : 1703915768053,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sah5htxkwhd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703915283467,
  "history_end_time" : 1703915283467,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "f2ipq4bn6z4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703914476620,
  "history_end_time" : 1703914476620,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g8yybl5gzql",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703912302152,
  "history_end_time" : 1703912302152,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k14lsdhdzxo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703908806873,
  "history_end_time" : 1705789681218,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "a395vr3u4cy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703906215359,
  "history_end_time" : 1703906215359,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d8a76sxq7a9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703900919124,
  "history_end_time" : 1703900919124,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x0q9bbsvnru",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703899837746,
  "history_end_time" : 1703899837746,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i43y40ji3ru",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703897422930,
  "history_end_time" : 1703897422930,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ijl7ix6ym8a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703896125562,
  "history_end_time" : 1703896125562,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7drldop3c5w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703890275971,
  "history_end_time" : 1703890275971,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g6l4f6ujg1v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703886800789,
  "history_end_time" : 1703886800789,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8lkyqkr0o57",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703885997745,
  "history_end_time" : 1703885997745,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kml9czp7mtb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703880194695,
  "history_end_time" : 1703880194695,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "06da8stvxza",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703872753014,
  "history_end_time" : 1703872753014,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ip0jeyv07zx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703869828220,
  "history_end_time" : 1703869828220,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tecvvsdl3x6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703868616909,
  "history_end_time" : 1703868616909,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rf1bvx8bvki",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703867114027,
  "history_end_time" : 1703867114027,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gdhmejcbe0h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703864885424,
  "history_end_time" : 1703864885424,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fen7ellyme5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703862637326,
  "history_end_time" : 1703862637326,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g3djdpdayv2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703827227300,
  "history_end_time" : 1703827227300,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eg095dsamq2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703822411218,
  "history_end_time" : 1703822411218,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "n8hvckgnm7e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703786924618,
  "history_end_time" : 1703789718816,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gr1092obuzk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703786053471,
  "history_end_time" : 1703786917607,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ofky33t8v8y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703778395373,
  "history_end_time" : 1703778395373,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "88qf65dko2p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703739034256,
  "history_end_time" : 1703739034256,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "m2z6wdvn67w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703738754296,
  "history_end_time" : 1703792459272,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "dpqkbkn8u1a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703736166888,
  "history_end_time" : 1703737316872,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "08pnnewr5sz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703694763535,
  "history_end_time" : 1703694763535,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1codtokee68",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703659541187,
  "history_end_time" : 1703659541187,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vk8pg3o2j9x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703658144664,
  "history_end_time" : 1703658144664,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "97uvpzykrs1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703650855756,
  "history_end_time" : 1703650855756,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bue2avb5bmy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703646751513,
  "history_end_time" : 1703650812430,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "c6yhhq1spjz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703642120881,
  "history_end_time" : 1703646749617,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "yixcuhxptj2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703641988907,
  "history_end_time" : 1703642074624,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "frmwm9mg0xk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703629665490,
  "history_end_time" : 1703629665490,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "z8mw2qdyndb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703626687964,
  "history_end_time" : 1703627783047,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "lws7exejn7o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703625782075,
  "history_end_time" : 1703625782075,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "e0lt117d8l2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1703624783796,
  "history_end_time" : 1703624783796,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "zcxxog6irld",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702875592802,
  "history_end_time" : 1702875592802,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p5n2etq8f2m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702871264361,
  "history_end_time" : 1702871264361,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3ulwwiqaj70",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702867996373,
  "history_end_time" : 1702867996373,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "we8nwc2qjbv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702866593370,
  "history_end_time" : 1702866593370,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "es0johjl7ce",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702866137583,
  "history_end_time" : 1702866137583,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fcxh0cxihl8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702657305591,
  "history_end_time" : 1702657305591,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pxbaahk6dq9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702633223029,
  "history_end_time" : 1702633223029,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1b2p3k6ejv5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702633156891,
  "history_end_time" : 1702633163892,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "7fh6wpra2dd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702274520867,
  "history_end_time" : 1702274520867,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "y46csrde4tx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702257109183,
  "history_end_time" : 1702257109183,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "97v9n1c9740",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702253506484,
  "history_end_time" : 1702253506484,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6judldt7qnl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702047800877,
  "history_end_time" : 1702047800877,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7tsyxniavew",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1702046671810,
  "history_end_time" : 1702047789477,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "v37sgzax8t4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701838623982,
  "history_end_time" : 1701838623982,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8npfn0qtkis",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701272631458,
  "history_end_time" : 1701272875102,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "hwnmuj3bed0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701272152688,
  "history_end_time" : 1701272363345,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "8998h44wflk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701269761306,
  "history_end_time" : 1701269761306,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "45n29c9envs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701245471999,
  "history_end_time" : 1701245471999,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "99ivw9b4oli",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701234300603,
  "history_end_time" : 1701234300603,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xxsfbygy23i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701232375258,
  "history_end_time" : 1701234158036,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "6wbntifm5sb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701231048654,
  "history_end_time" : 1701231048654,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bvlifnqvo9i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701230933449,
  "history_end_time" : 1701230952339,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "xl4arndgf9j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701230796318,
  "history_end_time" : 1701230932245,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "4sm2r7d1z0y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701230384868,
  "history_end_time" : 1701230384868,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6hksq5apwe3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701229983494,
  "history_end_time" : 1701229983494,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nfn5qtxoj00",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228899357,
  "history_end_time" : 1701228899357,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g5ljyj8edo6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228374787,
  "history_end_time" : 1701228374787,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qhyshrsoq49",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228236328,
  "history_end_time" : 1701228236328,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "403xnu9p1y4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228118490,
  "history_end_time" : 1701228118490,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1xr3pdk8qs4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701228056513,
  "history_end_time" : 1701228056513,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mi2c7cy4ob2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701227912491,
  "history_end_time" : 1701227912491,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fwnlvg0wx9p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1701013937392,
  "history_end_time" : 1701015920034,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wb079ih83ts",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700974688678,
  "history_end_time" : 1700974688678,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "221ugjet5z2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700885116787,
  "history_end_time" : 1700885116787,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "aj154vbnsqs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700471590167,
  "history_end_time" : 1700471590167,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tykesc6lxjy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700468936392,
  "history_end_time" : 1700468936392,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "oda1wmilkuv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700461922961,
  "history_end_time" : 1700462913665,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "9aag1kwiw78",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700448500125,
  "history_end_time" : 1700448500125,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vbni1gymf42",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700447319832,
  "history_end_time" : 1700447319832,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tkzd4ii869p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700230067230,
  "history_end_time" : 1700230067230,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "l7t8pfqvasu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700229012355,
  "history_end_time" : 1700229012355,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pcdia3y6gd0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700210213797,
  "history_end_time" : 1700210213797,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "54bre0cq1l7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700209780150,
  "history_end_time" : 1700209780150,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "q91r91foxqy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700209729235,
  "history_end_time" : 1700209729235,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2i23r8ck6d5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700203478635,
  "history_end_time" : 1700204245678,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "jn3f7zh6ty4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700201828250,
  "history_end_time" : 1700201828250,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mn4y21fq8mk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700200332843,
  "history_end_time" : 1700200332843,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i2liphrf7ts",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700145667860,
  "history_end_time" : 1700145667860,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7vzeeeqh20n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700143295294,
  "history_end_time" : 1700143295294,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dbyr4ppf7ph",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700141615802,
  "history_end_time" : 1700141615802,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mqw8rtk78br",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700134126826,
  "history_end_time" : 1700134126826,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "oou5vignluc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1700133783688,
  "history_end_time" : 1700133783688,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qtfwx8ro1dt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699992839746,
  "history_end_time" : 1699992839746,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xi4yb7pe2d9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699982145385,
  "history_end_time" : 1699982145385,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "miki0nwg65c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699941614790,
  "history_end_time" : 1699941614790,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tvxlg7gmrpn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699939440531,
  "history_end_time" : 1699939440531,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2dbst4r61yq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699937910455,
  "history_end_time" : 1699937910455,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lk2k9t0et5k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699805634594,
  "history_end_time" : 1699806085188,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "2pbbzgmls4u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699684154046,
  "history_end_time" : 1705789690220,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "7covhditnnj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1699681071320,
  "history_end_time" : 1699681071320,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k7hcp9y5ze6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698762678664,
  "history_end_time" : 1698762678664,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "dvekb05r03m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698762637951,
  "history_end_time" : 1698762637951,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1au0k18w8ly",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698276496947,
  "history_end_time" : 1698276496947,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eumo3mg098p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698252277353,
  "history_end_time" : 1698252277353,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hnnn1r3y41z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698251392454,
  "history_end_time" : 1698251392454,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ufpvl2dk4kc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698228210927,
  "history_end_time" : 1698228210927,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tckn94k5w1a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698227897126,
  "history_end_time" : 1698227897126,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "welt07t2ygy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698163737279,
  "history_end_time" : 1698163737279,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "lxf9hhlpjsv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698163445814,
  "history_end_time" : 1698163445814,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x4r960jzgx7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698163121527,
  "history_end_time" : 1698163121527,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "e7u6142iedi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698160809334,
  "history_end_time" : 1698160809334,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sz8zqk5q59x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698157805157,
  "history_end_time" : 1698157805157,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i80tpkqdz6k",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698152099722,
  "history_end_time" : 1698152099722,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d9opggyge75",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698095495703,
  "history_end_time" : 1698095495703,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "a8owvx62vw9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1698075453535,
  "history_end_time" : 1698075453535,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j1iraebu5ty",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697349529983,
  "history_end_time" : 1697349529983,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xd52wmqla77",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697348852237,
  "history_end_time" : 1697348852237,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mo0m89gfpbx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697189923529,
  "history_end_time" : 1697189923529,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k1kby1ia1lw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697188523272,
  "history_end_time" : 1697188523272,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0yuxsidg6lm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697187892235,
  "history_end_time" : 1697187892235,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vbkpcuqyra0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1697187367937,
  "history_end_time" : 1697187367937,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i0hx20urzn4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696863953144,
  "history_end_time" : 1696863953144,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "psy9wmypa0w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696862402871,
  "history_end_time" : 1696862402871,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wa2yd3qxdcf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696832263631,
  "history_end_time" : 1696832263631,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "hnb11xo2u5m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696831867305,
  "history_end_time" : 1696831867305,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kyjquehmo4f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696830174236,
  "history_end_time" : 1696830174236,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "511n722rt20",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696787541860,
  "history_end_time" : 1696787541860,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "f147shfqzcy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696786838144,
  "history_end_time" : 1696786838144,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vhkst3kna4x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696771780801,
  "history_end_time" : 1696771780801,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7afoh5q4b0q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696602943916,
  "history_end_time" : 1696602943916,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d1fa63oaii9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696432484307,
  "history_end_time" : 1696432484307,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u60lleu4iwl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1696432299737,
  "history_end_time" : 1696432482228,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ui4alv5bqjp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827991067,
  "history_end_time" : 1695827991067,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "o1e1n92wjn2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827889162,
  "history_end_time" : 1695827964211,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "6ahdx218qnw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695827855630,
  "history_end_time" : 1695827867002,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "42twpexa7ea",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695696616101,
  "history_end_time" : 1695696616101,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bqsnoc9lwuz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695694257314,
  "history_end_time" : 1695694257314,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ly98wxkw5j6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695693585733,
  "history_end_time" : 1695693585733,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fu51ijdi7hi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695693149344,
  "history_end_time" : 1695693149344,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5fadv4qud47",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695580915827,
  "history_end_time" : 1695580915827,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ktx3mqq79zk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695576291636,
  "history_end_time" : 1695576291636,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4xxtnm1yvl0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695575930990,
  "history_end_time" : 1695575930990,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4uhr5s3lqz5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535769183,
  "history_end_time" : 1695535769183,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p3mgc94o264",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535478672,
  "history_end_time" : 1695535478672,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d6ibbuexg3v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695535214011,
  "history_end_time" : 1695535214011,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5ybxk2gkdkj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695534943573,
  "history_end_time" : 1695534943573,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "660wfn6zvv0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695534671812,
  "history_end_time" : 1695534671812,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vmz1v6ojkpd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695533024076,
  "history_end_time" : 1695533024076,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "fbgh62jvuae",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695529187850,
  "history_end_time" : 1695529187850,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mzt67a14e7d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695528505137,
  "history_end_time" : 1695528505137,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "i3r61zxc8nf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695515862371,
  "history_end_time" : 1695515862371,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "d6r4e45ifyr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695506423823,
  "history_end_time" : 1695506423823,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gedjv06wc7r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695418741259,
  "history_end_time" : 1695418741259,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jpdbbqghu51",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417619662,
  "history_end_time" : 1695417619662,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "en6hv2x1u9x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417171265,
  "history_end_time" : 1695417171265,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ulq519blwzm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695417052720,
  "history_end_time" : 1695417052720,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1b1l65uvbm5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695416915971,
  "history_end_time" : 1695416915971,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ariyijttd97",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695106488934,
  "history_end_time" : 1695106488934,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "siejrveuiip",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695106316167,
  "history_end_time" : 1695106316167,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rbc5cigwdtd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695054045012,
  "history_end_time" : 1695054045012,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gi4asthvh7y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695054019745,
  "history_end_time" : 1695054032319,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "msduvt878jv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053979877,
  "history_end_time" : 1695054019270,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "qyfw43kq3ld",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053793360,
  "history_end_time" : 1695053793360,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "46929tweckb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1695053733355,
  "history_end_time" : 1695053733355,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r5m9t75dysq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694971144773,
  "history_end_time" : 1694972839683,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "sqhsho0ig74",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970707905,
  "history_end_time" : 1694970707905,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bcnfavfmyrb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970594745,
  "history_end_time" : 1694970594745,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1uc23pdm1zp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694970131468,
  "history_end_time" : 1694970131468,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rd24srgdkui",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694969349980,
  "history_end_time" : 1694969349980,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8cpv6r61ixu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694905307641,
  "history_end_time" : 1694905307641,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g27njygl4x8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1694897887110,
  "history_end_time" : 1694897887110,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "uzwpsrwr6eu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531335739,
  "history_end_time" : 1691531335739,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "a7360lql9s1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531292623,
  "history_end_time" : 1691531292623,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "0rssr5ggibf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531254447,
  "history_end_time" : 1691531284896,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "giers4alrug",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531163675,
  "history_end_time" : 1691531163675,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "l7ydpos103f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531120773,
  "history_end_time" : 1691531120773,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "qqhrll5rsey",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691531060766,
  "history_end_time" : 1691531060766,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "dwxm0lh5hx7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530848255,
  "history_end_time" : 1691530848255,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "lvwj4ki566g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530717580,
  "history_end_time" : 1691530721101,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "mri6a949z69",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530690015,
  "history_end_time" : 1691530716744,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "cqxg2g3ix67",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530620937,
  "history_end_time" : 1691530622433,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "1nrhyapsui0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530617009,
  "history_end_time" : 1691530617009,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Skipped"
},{
  "history_id" : "9yuaf5r6pcd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1691530599615,
  "history_end_time" : 1691530614279,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Stopped"
},{
  "history_id" : "a6q3o8fmgpf",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689632034054,
  "history_end_time" : 1689632035554,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "cju8xah43gf",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "  File \"data_gee_gridmet_real_time.py\", line 21\n    print(f'downloading {t.get(\"href\")}')\n                                       ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1689631636494,
  "history_end_time" : 1689631638767,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "tq3z35",
  "indicator" : "Failed"
},{
  "history_id" : "cexwcen0iwq",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1689135058206,
  "history_end_time" : 1689135060494,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "i1ex2sr7to9",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1688416893627,
  "history_end_time" : 1688416907375,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "38u6dzjhe70",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1688416837896,
  "history_end_time" : 1688416848467,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "fjvqftmrnsc",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1688416668733,
  "history_end_time" : 1688416822955,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "fk09paq8em0",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1688416629055,
  "history_end_time" : 1688416660673,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "z1dywo0h79m",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1688416567435,
  "history_end_time" : 1688416575013,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "jhtjit5fagi",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-06-23\n/Users/joe\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/jhtjit5fagi/data_gee_gridmet_real_time.py\", line 13, in <module>\n    from snowcast_utils import *\n  File \"/Users/joe/gw-workspace/jhtjit5fagi/snowcast_utils.py\", line 84, in <module>\n    findLastStopDate(f\"/home/chetana/Documents/GitHub/SnowCast/data/sim_training/gridmet/\", \"%Y-%m-%d %H:%M:%S\")\n  File \"/Users/joe/gw-workspace/jhtjit5fagi/snowcast_utils.py\", line 69, in findLastStopDate\n    for filename in os.listdir(target_testing_dir):\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/Documents/GitHub/SnowCast/data/sim_training/gridmet/'\n",
  "history_begin_time" : 1687546867484,
  "history_end_time" : 1687546870666,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "cb7bwhzt8it",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1687463685039,
  "history_end_time" : 1687463686606,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "nwv64w0wu7i",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1687463635644,
  "history_end_time" : 1687463637549,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "g1e0tz88ghd",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1686236147068,
  "history_end_time" : 1686237909494,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "v2dnmp9g9ap",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "sh: /home/chetana/anaconda3/condabin/python: No such file or directory\n",
  "history_begin_time" : 1686235961069,
  "history_end_time" : 1686235985412,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "nq2b268v1wi",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "  File \"data_gee_gridmet_real_time.py\", line 21\n    print(f'downloading {t.get(\"href\")}')\n                                       ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1686235530140,
  "history_end_time" : 1686235532386,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Failed"
},{
  "history_id" : "xber62qtgzl",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "",
  "history_begin_time" : 1686235448519,
  "history_end_time" : 1686235482627,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "iqhikwfve2t",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "usage: conda [-h] [-V] command ...\nconda: error: argument command: invalid choice: 'data_gee_gridmet_real_time.py' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'notices')\n",
  "history_begin_time" : 1686235402229,
  "history_end_time" : 1686235424779,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Stopped"
},{
  "history_id" : "gipn6lzenkz",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "  File \"data_gee_gridmet_real_time.py\", line 21\n    print(f'downloading {t.get(\"href\")}')\n                                       ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1686153657086,
  "history_end_time" : 1686153658298,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Done"
},{
  "history_id" : "1Dtuf8O7I4JK",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "downloading bi_1979.nc\ndownloading bi_1980.nc\ndownloading bi_1981.nc\ndownloading bi_1982.nc\ndownloading bi_1983.nc\ndownloading bi_1984.nc\ndownloading bi_1985.nc\ndownloading bi_1986.nc\ndownloading bi_1987.nc\ndownloading bi_1988.nc\ndownloading bi_1989.nc\ndownloading bi_1990.nc\ndownloading bi_1991.nc\ndownloading bi_1992.nc\ndownloading bi_1993.nc\ndownloading bi_1994.nc\ndownloading bi_1995.nc\ndownloading bi_1996.nc\ndownloading bi_1997.nc\ndownloading bi_1998.nc\ndownloading bi_1999.nc\ndownloading bi_2000.nc\ndownloading bi_2001.nc\ndownloading bi_2002.nc\ndownloading bi_2003.nc\ndownloading bi_2004.nc\ndownloading bi_2005.nc\ndownloading bi_2006.nc\ndownloading bi_2007.nc\ndownloading bi_2008.nc\ndownloading bi_2009.nc\ndownloading bi_2010.nc\ndownloading bi_2011.nc\ndownloading bi_2012.nc\ndownloading bi_2013.nc\ndownloading bi_2014.nc\ndownloading bi_2015.nc\ndownloading bi_2016.nc\ndownloading bi_2017.nc\ndownloading bi_2018.nc\ndownloading bi_2019.nc\ndownloading bi_2020.nc\ndownloading bi_2021.nc\ndownloading bi_2022.nc\ndownloading bi_2023.nc\ndownloading erc_1979.nc\ndownloading erc_1980.nc\ndownloading erc_1981.nc\ndownloading erc_1982.nc\ndownloading erc_1983.nc\ndownloading erc_1984.nc\ndownloading erc_1985.nc\ndownloading erc_1986.nc\ndownloading erc_1987.nc\ndownloading erc_1988.nc\ndownloading erc_1989.nc\ndownloading erc_1990.nc\ndownloading erc_1991.nc\ndownloading erc_1992.nc\ndownloading erc_1993.nc\ndownloading erc_1994.nc\ndownloading erc_1995.nc\ndownloading erc_1996.nc\ndownloading erc_1997.nc\ndownloading erc_1998.nc\ndownloading erc_1999.nc\ndownloading erc_2000.nc\ndownloading erc_2001.nc\ndownloading erc_2002.nc\ndownloading erc_2003.nc\ndownloading erc_2004.nc\ndownloading erc_2005.nc\ndownloading erc_2006.nc\ndownloading erc_2007.nc\ndownloading erc_2008.nc\ndownloading erc_2009.nc\ndownloading erc_2010.nc\ndownloading erc_2011.nc\ndownloading erc_2012.nc\ndownloading erc_2013.nc\ndownloading erc_2014.nc\ndownloading erc_2015.nc\ndownloading erc_2016.nc\ndownloading erc_2017.nc\ndownloading erc_2018.nc\ndownloading erc_2019.nc\ndownloading erc_2020.nc\ndownloading erc_2021.nc\ndownloading erc_2022.nc\ndownloading erc_2023.nc\ndownloading etr_1979.nc\ndownloading etr_1980.nc\ndownloading etr_1981.nc\ndownloading etr_1982.nc\ndownloading etr_1983.nc\ndownloading etr_1984.nc\ndownloading etr_1985.nc\ndownloading etr_1986.nc\ndownloading etr_1987.nc\ndownloading etr_1988.nc\ndownloading etr_1989.nc\ndownloading etr_1990.nc\ndownloading etr_1991.nc\ndownloading etr_1992.nc\ndownloading etr_1993.nc\ndownloading etr_1994.nc\ndownloading etr_1995.nc\ndownloading etr_1996.nc\ndownloading etr_1997.nc\ndownloading etr_1998.nc\ndownloading etr_1999.nc\ndownloading etr_2000.nc\ndownloading etr_2001.nc\ndownloading etr_2002.nc\ndownloading etr_2003.nc\ndownloading etr_2004.nc\ndownloading etr_2005.nc\ndownloading etr_2006.nc\ndownloading etr_2007.nc\ndownloading etr_2008.nc\ndownloading etr_2009.nc\ndownloading etr_2010.nc\ndownloading etr_2011.nc\ndownloading etr_2012.nc\ndownloading etr_2013.nc\ndownloading etr_2014.nc\ndownloading etr_2015.nc\ndownloading etr_2016.nc\ndownloading etr_2017.nc\ndownloading etr_2018.nc\ndownloading etr_2019.nc\ndownloading etr_2020.nc\ndownloading etr_2021.nc\ndownloading etr_2022.nc\ndownloading etr_2023.nc\ndownloading fm1000_1979.nc\ndownloading fm1000_1980.nc\ndownloading fm1000_1981.nc\ndownloading fm1000_1982.nc\ndownloading fm1000_1983.nc\ndownloading fm1000_1984.nc\ndownloading fm1000_1985.nc\ndownloading fm1000_1986.nc\ndownloading fm1000_1987.nc\ndownloading fm1000_1988.nc\ndownloading fm1000_1989.nc\ndownloading fm1000_1990.nc\ndownloading fm1000_1991.nc\ndownloading fm1000_1992.nc\ndownloading fm1000_1993.nc\ndownloading fm1000_1994.nc\ndownloading fm1000_1995.nc\ndownloading fm1000_1996.nc\ndownloading fm1000_1997.nc\ndownloading fm1000_1998.nc\ndownloading fm1000_1999.nc\ndownloading fm1000_2000.nc\ndownloading fm1000_2001.nc\ndownloading fm1000_2002.nc\ndownloading fm1000_2003.nc\ndownloading fm1000_2004.nc\ndownloading fm1000_2005.nc\ndownloading fm1000_2006.nc\ndownloading fm1000_2007.nc\ndownloading fm1000_2008.nc\ndownloading fm1000_2009.nc\ndownloading fm1000_2010.nc\ndownloading fm1000_2011.nc\ndownloading fm1000_2012.nc\ndownloading fm1000_2013.nc\ndownloading fm1000_2014.nc\ndownloading fm1000_2015.nc\ndownloading fm1000_2016.nc\ndownloading fm1000_2017.nc\ndownloading fm1000_2018.nc\ndownloading fm1000_2019.nc\ndownloading fm1000_2020.nc\ndownloading fm1000_2021.nc\ndownloading fm1000_2022.nc\ndownloading fm1000_2023.nc\ndownloading fm100_1979.nc\ndownloading fm100_1980.nc\ndownloading fm100_1981.nc\ndownloading fm100_1982.nc\ndownloading fm100_1983.nc\ndownloading fm100_1984.nc\ndownloading fm100_1985.nc\ndownloading fm100_1986.nc\ndownloading fm100_1987.nc\ndownloading fm100_1988.nc\ndownloading fm100_1989.nc\ndownloading fm100_1990.nc\ndownloading fm100_1991.nc\ndownloading fm100_1992.nc\ndownloading fm100_1993.nc\ndownloading fm100_1994.nc\ndownloading fm100_1995.nc\ndownloading fm100_1996.nc\ndownloading fm100_1997.nc\ndownloading fm100_1998.nc\ndownloading fm100_1999.nc\ndownloading fm100_2000.nc\ndownloading fm100_2001.nc\ndownloading fm100_2002.nc\ndownloading fm100_2003.nc\ndownloading fm100_2004.nc\ndownloading fm100_2005.nc\ndownloading fm100_2006.nc\ndownloading fm100_2007.nc\ndownloading fm100_2008.nc\ndownloading fm100_2009.nc\ndownloading fm100_2010.nc\ndownloading fm100_2011.nc\ndownloading fm100_2012.nc\ndownloading fm100_2013.nc\ndownloading fm100_2014.nc\ndownloading fm100_2015.nc\ndownloading fm100_2016.nc\ndownloading fm100_2017.nc\ndownloading fm100_2018.nc\ndownloading fm100_2019.nc\ndownloading fm100_2020.nc\ndownloading fm100_2021.nc\ndownloading fm100_2022.nc\ndownloading fm100_2023.nc\ndownloading pdsi.nc\ndownloading pet_1979.nc\ndownloading pet_1980.nc\ndownloading pet_1981.nc\ndownloading pet_1982.nc\ndownloading pet_1983.nc\ndownloading pet_1984.nc\ndownloading pet_1985.nc\ndownloading pet_1986.nc\ndownloading pet_1987.nc\ndownloading pet_1988.nc\ndownloading pet_1989.nc\ndownloading pet_1990.nc\ndownloading pet_1991.nc\ndownloading pet_1992.nc\ndownloading pet_1993.nc\ndownloading pet_1994.nc\ndownloading pet_1995.nc\ndownloading pet_1996.nc\ndownloading pet_1997.nc\ndownloading pet_1998.nc\ndownloading pet_1999.nc\ndownloading pet_2000.nc\ndownloading pet_2001.nc\ndownloading pet_2002.nc\ndownloading pet_2003.nc\ndownloading pet_2004.nc\ndownloading pet_2005.nc\ndownloading pet_2006.nc\ndownloading pet_2007.nc\ndownloading pet_2008.nc\ndownloading pet_2009.nc\ndownloading pet_2010.nc\ndownloading pet_2011.nc\ndownloading pet_2012.nc\ndownloading pet_2013.nc\ndownloading pet_2014.nc\ndownloading pet_2015.nc\ndownloading pet_2016.nc\ndownloading pet_2017.nc\ndownloading pet_2018.nc\ndownloading pet_2019.nc\ndownloading pet_2020.nc\ndownloading pet_2021.nc\ndownloading pet_2022.nc\ndownloading pet_2023.nc\ndownloading pr_1979.nc\ndownloading pr_1980.nc\ndownloading pr_1981.nc\ndownloading pr_1982.nc\ndownloading pr_1983.nc\ndownloading pr_1984.nc\ndownloading pr_1985.nc\ndownloading pr_1986.nc\ndownloading pr_1987.nc\ndownloading pr_1988.nc\ndownloading pr_1989.nc\ndownloading pr_1990.nc\ndownloading pr_1991.nc\ndownloading pr_1992.nc\ndownloading pr_1993.nc\ndownloading pr_1994.nc\ndownloading pr_1995.nc\ndownloading pr_1996.nc\ndownloading pr_1997.nc\ndownloading pr_1998.nc\ndownloading pr_1999.nc\ndownloading pr_2000.nc\ndownloading pr_2001.nc\ndownloading pr_2002.nc\ndownloading pr_2003.nc\ndownloading pr_2004.nc\ndownloading pr_2005.nc\ndownloading pr_2006.nc\ndownloading pr_2007.nc\ndownloading pr_2008.nc\ndownloading pr_2009.nc\ndownloading pr_2010.nc\ndownloading pr_2011.nc\ndownloading pr_2012.nc\ndownloading pr_2013.nc\ndownloading pr_2014.nc\ndownloading pr_2015.nc\ndownloading pr_2016.nc\ndownloading pr_2017.nc\ndownloading pr_2018.nc\ndownloading pr_2019.nc\ndownloading pr_2020.nc\ndownloading pr_2021.nc\ndownloading pr_2022.nc\ndownloading pr_2023.nc\ndownloading rmax_1979.nc\ndownloading rmax_1980.nc\ndownloading rmax_1981.nc\ndownloading rmax_1982.nc\ndownloading rmax_1983.nc\ndownloading rmax_1984.nc\ndownloading rmax_1985.nc\ndownloading rmax_1986.nc\ndownloading rmax_1987.nc\ndownloading rmax_1988.nc\ndownloading rmax_1989.nc\ndownloading rmax_1990.nc\ndownloading rmax_1991.nc\ndownloading rmax_1992.nc\ndownloading rmax_1993.nc\ndownloading rmax_1994.nc\ndownloading rmax_1995.nc\ndownloading rmax_1996.nc\ndownloading rmax_1997.nc\ndownloading rmax_1998.nc\ndownloading rmax_1999.nc\ndownloading rmax_2000.nc\ndownloading rmax_2001.nc\ndownloading rmax_2002.nc\ndownloading rmax_2003.nc\ndownloading rmax_2004.nc\ndownloading rmax_2005.nc\ndownloading rmax_2006.nc\ndownloading rmax_2007.nc\ndownloading rmax_2008.nc\ndownloading rmax_2009.nc\ndownloading rmax_2010.nc\ndownloading rmax_2011.nc\ndownloading rmax_2012.nc\ndownloading rmax_2013.nc\ndownloading rmax_2014.nc\ndownloading rmax_2015.nc\ndownloading rmax_2016.nc\ndownloading rmax_2017.nc\ndownloading rmax_2018.nc\ndownloading rmax_2019.nc\ndownloading rmax_2020.nc\ndownloading rmax_2021.nc\ndownloading rmax_2022.nc\ndownloading rmax_2023.nc\ndownloading rmin_1979.nc\ndownloading rmin_1980.nc\ndownloading rmin_1981.nc\ndownloading rmin_1982.nc\ndownloading rmin_1983.nc\ndownloading rmin_1984.nc\ndownloading rmin_1985.nc\ndownloading rmin_1986.nc\ndownloading rmin_1987.nc\ndownloading rmin_1988.nc\ndownloading rmin_1989.nc\ndownloading rmin_1990.nc\ndownloading rmin_1991.nc\ndownloading rmin_1992.nc\ndownloading rmin_1993.nc\ndownloading rmin_1994.nc\ndownloading rmin_1995.nc\ndownloading rmin_1996.nc\ndownloading rmin_1997.nc\ndownloading rmin_1998.nc\ndownloading rmin_1999.nc\ndownloading rmin_2000.nc\ndownloading rmin_2001.nc\ndownloading rmin_2002.nc\ndownloading rmin_2003.nc\ndownloading rmin_2004.nc\ndownloading rmin_2005.nc\ndownloading rmin_2006.nc\ndownloading rmin_2007.nc\ndownloading rmin_2008.nc\ndownloading rmin_2009.nc\ndownloading rmin_2010.nc\ndownloading rmin_2011.nc\ndownloading rmin_2012.nc\ndownloading rmin_2013.nc\ndownloading rmin_2014.nc\ndownloading rmin_2015.nc\ndownloading rmin_2016.nc\ndownloading rmin_2017.nc\ndownloading rmin_2018.nc\ndownloading rmin_2019.nc\ndownloading rmin_2020.nc\n",
  "history_begin_time" : 1682985614778,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "Ay1V33CNyw8n",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/Ay1V33CNyw8n/data_gee_gridmet_real_time.py\", line 3, in <module>\n    import requests\nModuleNotFoundError: No module named 'requests'\n",
  "history_begin_time" : 1682984900616,
  "history_end_time" : 1682984901760,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "vQkRjMjyHiiw",
  "history_input" : "!pip3 install requests beautifulsoup4\n\nimport os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/vQkRjMjyHiiw/data_gee_gridmet_real_time.py\", line 1\n    !pip3 install requests beautifulsoup4\n    ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1682984890905,
  "history_end_time" : 1682984892290,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "35ouqaImfOyE",
  "history_input" : "!pip3 install requests beautifulsoup4\n\nimport os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/35ouqaImfOyE/data_gee_gridmet_real_time.py\", line 1\n    !pip3 install requests beautifulsoup4\n    ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1682984865474,
  "history_end_time" : 1682984866708,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "0gQMfjx9p8Pv",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/0gQMfjx9p8Pv/data_gee_gridmet_real_time.py\", line 3, in <module>\n    import requests\nModuleNotFoundError: No module named 'requests'\n",
  "history_begin_time" : 1682984832032,
  "history_end_time" : 1682984834000,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ux04mjavxi1",
  "history_input" : "import os\nimport urllib\nimport requests\nfrom bs4 import BeautifulSoup\n\n# download the NetCDF file from Idaho http site daily or the time period matching the MODIS period\n# download site: https://www.northwestknowledge.net/metdata/data/\n\ndownload_source = \"https://www.northwestknowledge.net/metdata/data/\"\ngridmet_download_dir = \"/home/chetana/terrian_data/\"\n\n\ndef download_gridmet():\n    if not os.path.exists(gridmet_download_dir):\n        os.makedirs(gridmet_download_dir)\n\n    soup = BeautifulSoup(requests.get(download_source).text, \"html.parser\")\n    tag_links = soup.find_all('a')\n    for t in tag_links:\n        if '.nc' in t.text and not 'eddi' in t.text and not os.path.isfile(gridmet_download_dir + t.get(\"href\")):\n            print(f'downloading {t.get(\"href\")}')\n            urllib.request.urlretrieve(download_source + t.get('href'), gridmet_download_dir + t.get(\"href\"))\n\n\ndownload_gridmet()\n",
  "history_output" : "sh: /home/chetana/anaconda3/condabin/python: No such file or directory\n",
  "history_begin_time" : 1682984798278,
  "history_end_time" : 1682984801622,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "jf7wuu",
  "indicator" : "Failed"
},{
  "history_id" : "plzgwvpru0h",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1681039708113,
  "history_end_time" : 1681039709659,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "njdewhh3zug",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1681039689574,
  "history_end_time" : 1681039697765,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "3zoj8lc3zsu",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1681007820686,
  "history_end_time" : 1681007822223,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "KJ4VRVa8yBwM",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport os\nimport geopandas as gpd\nimport numpy as np\nimport concurrent.futures\nimport eeauth as e\n\n# Initialize the Earth Engine\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(\n    service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n\n# Set the parameters\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = '2022-04-06'\nend_date = '2022-04-18'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\nhomedir = os.path.expanduser('~')\ngithub_dir = os.path.join(homedir, 'Documents', 'GitHub', 'SnowCast')\nsubmission_format_file = os.path.join(github_dir, 'data', 'snowcast_provided', 'submission_format_eval.csv')\nall_cell_coords_file = os.path.join(github_dir, 'data', 'snowcast_provided', 'all_cell_coords_file.csv')\ndfolder = os.path.join(github_dir, 'data', 'sim_testing', org_name)\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Read the cell coordinates and submission format files\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\n\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\n# Define the function to get data for all cells\ndef get_all_cells_data_in_batches(batch_size=4):\n    # Create a geometry object from the cell coordinates\n    geometry = ee.Geometry.MultiPoint(all_cell_coords_pd[['lon', 'lat']].values.tolist())\n\n    # Initialize an empty DataFrame to store the results\n    df_all = pd.DataFrame()\n\n    # Split the date range into smaller intervals of batch_size\n    date_range = pd.date_range(start=start_date, end=end_date, freq=f\"{batch_size}D\")\n\n    for i in range(len(date_range)-1):\n        # Get the start and end dates for the current batch\n        start = date_range[i].strftime(\"%Y-%m-%d\")\n        end = date_range[i+1].strftime(\"%Y-%m-%d\")\n\n        # Create an ImageCollection object and filter it by date range and geometry\n        ic = ee.ImageCollection(product_name).select(var_list).filterDate(start, end).filterBounds(geometry)\n\n        # Get the pixel values for all cells and time intervals\n        data = ic.getRegion(geometry, scale=1000).getInfo()\n\n        # Convert the data to a Pandas DataFrame\n        df = pd.DataFrame(data[1:], columns=data[0])\n\n        # Convert the date column to a datetime object and set it as the index\n        df['time'] = pd.to_datetime(df['time'], unit='ms')\n        df = df.set_index(['time', 'longitude', 'latitude'])\n\n        # Stack the columns and reset the index to create a multi-level index DataFrame\n        df = df.stack().reset_index()\n        df = df.rename(columns={'level_3': 'variable', 0: 'value'})\n\n        # Pivot the variable column to create a wide format DataFrame\n        df = df.pivot_table(index=['time', 'latitude', 'longitude'], columns='variable', values='value')\n\n        # Reset the index to create a flat DataFrame\n        df = df.reset_index()\n\n        # Merge with the submission format DataFrame to add the cell IDs\n        df = pd.merge(df, submission_format_df[['cell_id', 'lat', 'lon']], on=['lat', 'lon'])\n\n        # Append the results to the final DataFrame\n        df_all = pd.concat([df_all, df[['cell_id', 'time'] + var_list]])\n\n    # Save the results to a CSV file\n    filename = f\"{org_name}/all_vars{start_date}_{end_date}.csv\"\n    df_all.to_csv(filename)\n\n# Get the data for all cells and save it to a CSV file\nall_cell_df = get_all_cells_data_in_batches(batch_size=4)\nfilename = f\"{org_name}/all_vars{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(filename)",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/KJ4VRVa8yBwM/data_gee_gridmet_real_time.py\", line 89, in <module>\n    all_cell_df = get_all_cells_data_in_batches(batch_size=4)\n  File \"/home/chetana/gw-workspace/KJ4VRVa8yBwM/data_gee_gridmet_real_time.py\", line 79, in get_all_cells_data_in_batches\n    df = pd.merge(df, submission_format_df[['cell_id', 'lat', 'lon']], on=['lat', 'lon'])\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3511, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 5796, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 5856, in _raise_if_missing\n    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\nKeyError: \"None of [Index(['cell_id', 'lat', 'lon'], dtype='object')] are in the [columns]\"\n",
  "history_begin_time" : 1679989192305,
  "history_end_time" : 1679989258193,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "axU9b8X7fKhn",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport os\nimport geopandas as gpd\nimport numpy as np\nimport concurrent.futures\nimport eeauth as e\n\n# Initialize the Earth Engine\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(\n    service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n\n# Set the parameters\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = '2022-04-06'\nend_date = '2022-04-18'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\nhomedir = os.path.expanduser('~')\ngithub_dir = os.path.join(homedir, 'Documents', 'GitHub', 'SnowCast')\nsubmission_format_file = os.path.join(github_dir, 'data', 'snowcast_provided', 'submission_format_eval.csv')\nall_cell_coords_file = os.path.join(github_dir, 'data', 'snowcast_provided', 'all_cell_coords_file.csv')\ndfolder = os.path.join(github_dir, 'data', 'sim_testing', org_name)\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Read the cell coordinates and submission format files\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\n\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\n# Define the function to get data for all cells\ndef get_all_cells_data_in_batches(batch_size=4):\n    # Create a geometry object from the cell coordinates\n    geometry = ee.Geometry.MultiPoint(all_cell_coords_pd[['lon', 'lat']].values.tolist())\n\n    # Initialize an empty DataFrame to store the results\n    df_all = pd.DataFrame()\n\n    # Split the date range into smaller intervals of batch_size\n    date_range = pd.date_range(start=start_date, end=end_date, freq=f\"{batch_size}D\")\n\n    for i in range(len(date_range)-1):\n        # Get the start and end dates for the current batch\n        start = date_range[i].strftime(\"%Y-%m-%d\")\n        end = date_range[i+1].strftime(\"%Y-%m-%d\")\n\n        # Create an ImageCollection object and filter it by date range and geometry\n        ic = ee.ImageCollection(product_name).select(var_list).filterDate(start, end).filterBounds(geometry)\n\n        # Get the pixel values for all cells and time intervals\n        data = ic.getRegion(geometry, scale=1000).getInfo()\n\n        # Convert the data to a Pandas DataFrame\n        df = pd.DataFrame(data[1:], columns=data[0])\n\n        # Convert the date column to a datetime object and set it as the index\n        df['time'] = pd.to_datetime(df['time'], unit='ms')\n        df = df.set_index(['time', 'longitude', 'latitude'])\n\n        # Stack the columns and reset the index to create a multi-level index DataFrame\n        df = df.stack().reset_index()\n        df = df.rename(columns={'level_3': 'variable', 0: 'value'})\n\n        # Pivot the variable column to create a wide format DataFrame\n        df = df.pivot_table(index=['time', 'latitude', 'longitude'], columns='variable', values='value')\n\n        # Reset the index to create a flat DataFrame\n        df = df.reset_index()\n\n        # Merge with the submission format DataFrame to add the cell IDs\n        df = pd.merge(df, submission_format_df[['cell_id', 'lat', 'lon']], on=['lat', 'lon'])\n\n        # Append the results to the final DataFrame\n        df_all = pd.concat([df_all, df[['cell_id', 'time'] + var_list]])\n\n    # Save the results to a CSV file\n    filename = f\"{org_name}/all_vars{start_date}_{end_date}.csv\"\n    df_all.to_csv(filename)\n\n# Get the data for all cells and save it to a CSV file\nall_cell_df = get_all_cells_data()\nfilename = f\"{org_name}/all_vars{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(filename)",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/axU9b8X7fKhn/data_gee_gridmet_real_time.py\", line 89, in <module>\n    all_cell_df = get_all_cells_data()\nNameError: name 'get_all_cells_data' is not defined\n",
  "history_begin_time" : 1679989141975,
  "history_end_time" : 1679989144727,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "YLVc9wCylrs6",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport os\nimport geopandas as gpd\nimport numpy as np\nimport concurrent.futures\nimport eeauth as e\n\n# Initialize the Earth Engine\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(\n    service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n\n# Set the parameters\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = '2022-04-06'\nend_date = '2022-04-18'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\nhomedir = os.path.expanduser('~')\ngithub_dir = os.path.join(homedir, 'Documents', 'GitHub', 'SnowCast')\nsubmission_format_file = os.path.join(github_dir, 'data', 'snowcast_provided', 'submission_format_eval.csv')\nall_cell_coords_file = os.path.join(github_dir, 'data', 'snowcast_provided', 'all_cell_coords_file.csv')\ndfolder = os.path.join(github_dir, 'data', 'sim_testing', org_name)\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Read the cell coordinates and submission format files\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\n\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\n# Define the function to get data for all cells\ndef get_all_cells_data():\n    # Create a geometry object from the cell coordinates\n    geometry = ee.Geometry.MultiPoint(all_cell_coords_pd[['lon', 'lat']].values.tolist())\n\n    # Create an ImageCollection object and filter it by date range and geometry\n    ic = ee.ImageCollection(product_name).select(var_list).filterDate(start_date, end_date).filterBounds(geometry)\n\n    # Get the pixel values for all cells and time intervals\n    data = ic.getRegion(geometry, scale=1000).getInfo()\n\n    # Convert the data to a Pandas DataFrame\n    df = pd.DataFrame(data[1:], columns=data[0])\n\n    # Convert the date column to a datetime object and set it as the index\n    df['time'] = pd.to_datetime(df['time'], unit='ms')\n    df = df.set_index(['time', 'longitude', 'latitude'])\n\n    # Stack the columns and reset the index to create a multi-level index DataFrame\n    df = df.stack().reset_index()\n    df = df.rename(columns={'level_3': 'variable', 0: 'value'})\n\n    # Pivot the variable column to create a wide format DataFrame\n    df = df.pivot_table(index=['time', 'latitude', 'longitude'], columns='variable', values='value')\n\n    # Reset the index to create a flat DataFrame\n    df = df.reset_index()\n\n    # Merge with the submission format DataFrame to add the cell IDs\n    df = pd.merge(df, submission_format_df[['cell_id', 'lat', 'lon']], on=['lat', 'lon'])\n\n    return df[['cell_id', 'time'] + var_list]\n\n# Get the data for all cells and save it to a CSV file\nall_cell_df = get_all_cells_data()\nfilename = f\"{org_name}/all_vars{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(filename)",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 915, in execute\n    raise HttpError(resp, content, uri=self.uri)\ngoogleapiclient.errors.HttpError: <HttpError 400 when requesting https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"ImageCollection.getRegion: Too many values: 20759 points x 8 bands x 12 images > 1048576.\". Details: \"ImageCollection.getRegion: Too many values: 20759 points x 8 bands x 12 images > 1048576.\">\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/YLVc9wCylrs6/data_gee_gridmet_real_time.py\", line 73, in <module>\n    all_cell_df = get_all_cells_data()\n  File \"/home/chetana/gw-workspace/YLVc9wCylrs6/data_gee_gridmet_real_time.py\", line 48, in get_all_cells_data\n    data = ic.getRegion(geometry, scale=1000).getInfo()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 330, in _execute_cloud_call\n    raise _translate_cloud_exception(e)\nee.ee_exception.EEException: ImageCollection.getRegion: Too many values: 20759 points x 8 bands x 12 images > 1048576.\n",
  "history_begin_time" : 1679988850241,
  "history_end_time" : 1679988854697,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "PHB0Vyjc6psn",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport os\nimport geopandas as gpd\nimport numpy as np\nimport concurrent.futures\nimport eeauth as e\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n    \norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = '2022-04-06'\nend_date = '2022-04-18'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\nhomedir = os.path.expanduser('~')\ngithub_dir = os.path.join(homedir, 'Documents', 'GitHub', 'SnowCast')\nsubmission_format_file = os.path.join(github_dir, 'data', 'snowcast_provided', 'submission_format_eval.csv')\nall_cell_coords_file = os.path.join(github_dir, 'data', 'snowcast_provided', 'all_cell_coords_file.csv')\ndfolder = os.path.join(github_dir, 'data', 'sim_testing', org_name)\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\ndef get_cell_data(args):\n    cell_id, longitude, latitude = args\n    print(f'Running cell data for lat: {latitude}, long:{longitude}')\n    try:\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(len(var_list) + 1), ['system:index'] + var_list).values().get(0)\n\n        # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n        df = pd.DataFrame(nested_list.getInfo(), columns=['date'] + var_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(f'Failed for cell_id: {cell_id}, Error: {e}')\n        return None\n\ncell_args = [(cell_id, all_cell_coords_pd.loc[cell_id, 'lon'], all_cell_coords_pd.loc[cell_id, 'lat']) for cell_id in submission_format_df.index]\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n    results = list(executor.map(get_cell_data, cell_args))\nall_cell_df = pd.concat(results)\nfilename = f\"{org_name}/all_vars{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(filename)",
  "history_output" : null,
  "history_begin_time" : 1679988204652,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "P6yuUBEleyg3",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(\n    service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ndef retrieve_cell_data(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(\n            start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(\n                reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(\n            ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n        # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        global all_cell_df\n        all_cell_df = pd.concat([all_cell_df, df])\n\n    except Exception as e:\n        print(f\"Error processing cell {current_cell_id}: {e}\")\n        traceback.print_exc()\n\n# define a ThreadPoolExecutor with 10 threads\nexecutor = ThreadPoolExecutor(max_workers=10)\n\n# create a list of all cell IDs to retrieve data for\ncell_id_list = submission_format_df.index.to_list()\n\n# submit retrieval jobs to the executor\nfuture_list = []\nfor cell_id in cell_id_list:\n    future = executor.submit(retrieve_cell_data, cell_id)\n    future_list.append(future)\n\n# wait for all jobs to complete before continuing\nfor future in as_completed(future_list):\n    pass\n\n# save the results to a CSV file\nall_cell_df.to_csv(f\"{dfolder}/{org_name}_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n",
  "history_begin_time" : 1679987415126,
  "history_end_time" : 1679988204663,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kr6Zv6Nnnet1",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(\n    service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ndef retrieve_cell_data(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(\n            start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(\n                reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(\n            ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n        # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        global all_cell_df\n        all_cell_df = pd.concat([all_cell_df, df])\n\n    except Exception as e:\n        print(f\"Error processing cell {current_cell_id}: {e}\")\n        traceback.print_exc()\n\n# define a ThreadPoolExecutor with 10 threads\nexecutor = ThreadPoolExecutor(max_workers=10)\n\n# create a list of all cell IDs to retrieve data for\ncell_id_list = submission_format_df.index.to_list()\n\n# submit retrieval jobs to the executor\nfuture_list = []\nfor cell_id in cell_id_list:\n    future = executor.submit(retrieve_cell_data, cell_id)\n    future_list.append(future)\n\n# wait for all jobs to complete before continuing\nfor future in as_completed(future_list):\n    pass\n\n# save the results to a CSV file\nall_cell_df.to_csv(f\"{dfolder}/{org_name}_{start_date}_{end_date}.csv\")\n",
  "history_output" : null,
  "history_begin_time" : 1679987409820,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "acx5iKgcVQj8",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(\n    service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ndef retrieve_cell_data(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(\n            start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(\n                reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(\n            ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n        # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        global all_cell_df\n        all_cell_df = pd.concat([all_cell_df, df])\n\n    except Exception as e:\n        print(f\"Error processing cell {current_cell_id}: {e}\")\n        traceback.print_exc()\n\n# define a ThreadPoolExecutor with 10 threads\nexecutor = ThreadPoolExecutor(max_workers=10)\n\n# create a list of all cell IDs to retrieve data for\ncell_id_list = submission_format_df.index.to_list()\n\n# submit retrieval jobs to the executor\nfuture_list = []\nfor cell_id in cell_id_list:\n    future = executor.submit(retrieve_cell_data, cell_id)\n    future_list.append(future)\n\n# wait for all jobs to complete before continuing\nfor future in as_completed(future_list):\n    pass\n\n# save the results to a CSV file\nall_cell_df.to_csv(f\"{dfolder}/{org_name}_{start_date}_{end_date}.csv\")\n",
  "history_output" : "/home/chetana\n/home/chetana\n",
  "history_begin_time" : 1679987371156,
  "history_end_time" : 1679987409830,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "KKcAWgTIS6NR",
  "history_input" : "import ee\nimport json\nimport numpy as np\nimport os\nimport pandas as pd\nimport traceback\n\nfrom datetime import date\nfrom snowcast_utils import *\n\n# Authenticate and initialize Google Earth Engine\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# Read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n# Define necessary variables\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\n# Read grid cell coordinates and submission format\n# all_cell_coords_pd = pd.read_csv(\"data/snowcast_provided/all_cell_coords_file.csv\", header=0, index_col=0)\n# submission_format_df = pd.read_csv(\"data/snowcast_provided/submission_format_eval.csv\", header=0, index_col=0)\n\n# Create empty dataframe to hold all data\nall_cell_df = pd.DataFrame(columns=column_list)\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n# Loop through each cell in submission format and retrieve data from Google Earth Engine\nfor current_cell_id in submission_format_df.index:\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # Identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n\n        # Filter and select desired variables from image collection\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        # Define function to reduce each image in the collection to a point mean\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        # Map function over the image collection and retrieve data as a nested list\n        poi_reduced_imgs = viirs.map(poi_mean)\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(len(var_list)+1), reduced_column_list).values().get(0)\n        \n        # Convert nested list to dataframe and append to master dataframe\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n#         df = df[column_list]\n        all_cell_df = pd.concat([all_cell_df, df])\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        pass\n\n# Save master dataframe to CSV file\nall_cell_df.to_csv(f\"data/sim_testing/{org_name}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\n",
  "history_begin_time" : 1679986426745,
  "history_end_time" : 1679987289274,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "OMUz3QEnr6aK",
  "history_input" : "import ee\nimport json\nimport numpy as np\nimport os\nimport pandas as pd\nimport traceback\n\nfrom datetime import date\nfrom snowcast_utils import *\n\n# Authenticate and initialize Google Earth Engine\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# Read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n# Define necessary variables\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\n# Read grid cell coordinates and submission format\n# all_cell_coords_pd = pd.read_csv(\"data/snowcast_provided/all_cell_coords_file.csv\", header=0, index_col=0)\n# submission_format_df = pd.read_csv(\"data/snowcast_provided/submission_format_eval.csv\", header=0, index_col=0)\n\n# Create empty dataframe to hold all data\nall_cell_df = pd.DataFrame(columns=column_list)\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n# Loop through each cell in submission format and retrieve data from Google Earth Engine\nfor current_cell_id in submission_format_df.index:\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # Identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n\n        # Filter and select desired variables from image collection\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        # Define function to reduce each image in the collection to a point mean\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        # Map function over the image collection and retrieve data as a nested list\n        poi_reduced_imgs = viirs.map(poi_mean)\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(len(var_list)+1), reduced_column_list).values().get(0)\n        \n        # Convert nested list to dataframe and append to master dataframe\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n#         df = df[column_list]\n        all_cell_df = pd.concat([all_cell_df, df])\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        pass\n\n# Save master dataframe to CSV file\nall_cell_df.to_csv(f\"data/sim_testing/{org_name}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : null,
  "history_begin_time" : 1679986419867,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "PeKS7tkKv1ub",
  "history_input" : "import ee\nimport json\nimport numpy as np\nimport os\nimport pandas as pd\nimport traceback\n\nfrom datetime import date\nfrom snowcast_utils import *\n\n# Authenticate and initialize Google Earth Engine\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n# Define necessary variables\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\"data/sim_testing/gridmet/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\n# Read grid cell coordinates and submission format\nall_cell_coords_pd = pd.read_csv(\"data/snowcast_provided/all_cell_coords_file.csv\", header=0, index_col=0)\nsubmission_format_df = pd.read_csv(\"data/snowcast_provided/submission_format_eval.csv\", header=0, index_col=0)\n\n# Create empty dataframe to hold all data\nall_cell_df = pd.DataFrame(columns=column_list)\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n# Loop through each cell in submission format and retrieve data from Google Earth Engine\nfor current_cell_id in submission_format_df.index:\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # Identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n\n        # Filter and select desired variables from image collection\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        # Define function to reduce each image in the collection to a point mean\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        # Map function over the image collection and retrieve data as a nested list\n        poi_reduced_imgs = viirs.map(poi_mean)\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(len(var_list)+1), reduced_column_list).values().get(0)\n        \n        # Convert nested list to dataframe and append to master dataframe\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n        df = df[column_list]\n        all_cell_df = pd.concat([all_cell_df, df])\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        pass\n\n# Save master dataframe to CSV file\nall_cell_df.to_csv(f\"data/sim_testing/{org_name}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/PeKS7tkKv1ub/data_gee_gridmet_real_time.py\", line 26, in <module>\n    start_date = findLastStopDate(\"data/sim_testing/gridmet/\", \"%Y-%m-%d %H:%M:%S\")\n  File \"/home/chetana/gw-workspace/PeKS7tkKv1ub/snowcast_utils.py\", line 69, in findLastStopDate\n    for filename in os.listdir(target_testing_dir):\nFileNotFoundError: [Errno 2] No such file or directory: 'data/sim_testing/gridmet/'\n",
  "history_begin_time" : 1679986030725,
  "history_end_time" : 1679986058265,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "hacrOTFgHIRH",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(len(submission_format_df.index), ': length of evalutaion')\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\nprint(nested_dict, 'nested_dict')\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\n# Convert the nested list to a pandas DataFrame\n\ndf['date'] = pd.to_datetime(df['date'])\n# df = df.set_index('date')\n\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\nprint(f'cell_ids: {len(submission_format_df.index)}, lat: {len(all_cell_coords_pd)}')\n\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n20759 : length of evalutaion\n2023-03-14 06:00:00\n[['2022-04-06T06:00:00', 271.19920513013517, 284.70377032564625, 0.06158667090932103, 0.7782283700588044, 3.8249363091382413, 55.045164569320995, 22.282732087198195, 5.238387852916292], ['2022-04-07T06:00:00', 273.6590596199716, 288.9221084269741, 0.1003770506960238, 1.0265331694192505, 4.106221342850907, 50.668908591130986, 17.64268826835809, 3.7030622634661254], ['2022-04-08T06:00:00', 274.80669012704317, 290.34381432388943, 0.10850912089724674, 0.9707744824648333, 4.245128906342301, 57.691964698374775, 20.439259139670032, 3.6092224574946705], ['2022-04-09T06:00:00', 271.50956374654027, 285.72084489039275, 0.4133190672131327, 0.6579965345245844, 3.837435035862034, 65.31953532316993, 25.458402136445326, 4.908646694116972], ['2022-04-10T06:00:00', 269.65426462753265, 280.29622442948516, 0.5340364819441344, 0.5176592267100457, 3.2387903766032937, 55.50510035219098, 28.114073168644662, 5.256557630475819], ['2022-04-11T06:00:00', 265.60383129051843, 276.2171252320742, 8.704402317201023, 0.18750789756646072, 1.676694179747759, 88.82748396758893, 52.16973910093137, 7.96188219337304], ['2022-04-12T06:00:00', 261.9588709276993, 273.71444541054933, 1.3123968204041692, 0.20395342919652457, 1.8754764047269001, 88.15255269495997, 42.49878730499864, 6.267140526721981], ['2022-04-13T06:00:00', 263.9880260691832, 274.10480989778637, 2.7974727400384474, 0.2503816363106835, 1.972781000438116, 77.00392341847014, 39.91387444923476, 5.699408949903546], ['2022-04-14T06:00:00', 268.1111893070275, 276.86986630613814, 11.043610527432683, 0.22955925820337836, 1.947696926952028, 82.5305054587933, 50.82985836790447, 6.247992465088616], ['2022-04-15T06:00:00', 271.03826072783835, 280.48400073438734, 4.839539389169375, 0.37225109509820786, 2.7635789225981724, 73.98791401609543, 41.995944144309604, 4.89435951810941], ['2022-04-16T06:00:00', 271.29472630966404, 280.73304287179536, 12.398150419169678, 0.33887088511987246, 2.634439003436582, 78.16378783314742, 45.391169860556644, 6.455227765846991], ['2022-04-17T06:00:00', 271.629450882877, 283.203281657212, 0.5451340051169523, 0.5822154281021811, 3.4326811332373666, 60.25470293657891, 29.166437385352662, 4.558937122737257]] nested_dict\ncell_ids: 20759, lat: 20759\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/hacrOTFgHIRH/data_gee_gridmet_real_time.py\", line 99, in <module>\n    df['cell_id'] = submission_format_df.index.values\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 4538, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (20759) does not match length of index (12)\n",
  "history_begin_time" : 1679985322524,
  "history_end_time" : 1679985384983,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "EQBPjizYsPau",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(len(submission_format_df.index), ': length of evalutaion')\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\n# Convert the nested list to a pandas DataFrame\n\ndf['date'] = pd.to_datetime(df['date'])\n# df = df.set_index('date')\n\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\nprint(f'cell_ids: {len(submission_format_df.index)}, lat: {len(all_cell_coords_pd)}')\n\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n20759 : length of evalutaion\n2023-03-14 06:00:00\ncell_ids: 20759, lat: 20759\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/EQBPjizYsPau/data_gee_gridmet_real_time.py\", line 98, in <module>\n    df['cell_id'] = submission_format_df.index.values\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 4538, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (20759) does not match length of index (12)\n",
  "history_begin_time" : 1679985185178,
  "history_end_time" : 1679985247993,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "e5ApcwZpbbAt",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(len(submission_format_df.index), ': length of evalutaion')\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\n# Convert the nested list to a pandas DataFrame\n\ndf['date'] = pd.to_datetime(df['date'])\n# df = df.set_index('date')\n\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\nprint(f'cell_ids: {len(submission_format_df.index)}, lat: {len(all_cell_coords_pd['lat'])}')\n\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/e5ApcwZpbbAt/data_gee_gridmet_real_time.py\", line 96\n    print(f'cell_ids: {len(submission_format_df.index)}, lat: {len(all_cell_coords_pd['lat'])}')\n                                                                                       ^\nSyntaxError: f-string: unmatched '['\n",
  "history_begin_time" : 1679985163499,
  "history_end_time" : 1679985164611,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ok5mfwa4YOND",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(len(submission_format_df.index), ': length of evalutaion')\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\n# Convert the nested list to a pandas DataFrame\n\ndf['date'] = pd.to_datetime(df['date'])\n# df = df.set_index('date')\n\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\nprint(f'cell_ids: {len(submission_format_df.index)}, lat: {len(all_cell_coords_pd['lat'])}')\n\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/ok5mfwa4YOND/data_gee_gridmet_real_time.py\", line 96\n    print(f'cell_ids: {len(submission_format_df.index)}, lat: {len(all_cell_coords_pd['lat'])}')\n                                                                                       ^\nSyntaxError: f-string: unmatched '['\n",
  "history_begin_time" : 1679985088050,
  "history_end_time" : 1679985089138,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "PwTz0x0t5XG9",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(len(submission_format_df.index), ': length of evalutaion')\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\n# Convert the nested list to a pandas DataFrame\n\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\n# df['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n20759 : length of evalutaion\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/PwTz0x0t5XG9/data_gee_gridmet_real_time.py\", line 97, in <module>\n    df['latitude'] = all_cell_coords_pd['lat'].values\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 4538, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (20759) does not match length of index (12)\n",
  "history_begin_time" : 1679984848136,
  "history_end_time" : 1679984910607,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ly5lYYwJ9mkI",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(len(submission_format_df.index), ': length of evalutaion')\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\ndf['cell_id'] = submission_format_df.index.values\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\n# Convert the nested list to a pandas DataFrame\n\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\n\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n20759 : length of evalutaion\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/ly5lYYwJ9mkI/data_gee_gridmet_real_time.py\", line 42, in <module>\n    df = pd.DataFrame(nested_dict, columns=reduced_column_list)\nNameError: name 'nested_dict' is not defined\n",
  "history_begin_time" : 1679984654769,
  "history_end_time" : 1679984705905,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cY5Kfk3LNAvw",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(len(submission_format_df.index), ': length of evalutaion')\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n20759 : length of evalutaion\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/cY5Kfk3LNAvw/data_gee_gridmet_real_time.py\", line 95, in <module>\n    df['cell_id'] = submission_format_df.index.values\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 4538, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (20759) does not match length of index (12)\n",
  "history_begin_time" : 1679984120236,
  "history_end_time" : 1679984184897,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "NhSww8KRWx7o",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/NhSww8KRWx7o/data_gee_gridmet_real_time.py\", line 93, in <module>\n    df['cell_id'] = submission_format_df.index.values\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 4538, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (20759) does not match length of index (12)\n",
  "history_begin_time" : 1679984012450,
  "history_end_time" : 1679984080419,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "S4BL5URmfPFe",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# Convert the list to a nested list\nnested_dict = poi_reduced_imgs.reduceColumns(\n    reducer=ee.Reducer.toList(len(reduced_column_list)), \n    selectors=reduced_column_list\n).get('list').getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/S4BL5URmfPFe/data_gee_gridmet_real_time.py\", line 93, in <module>\n    df['cell_id'] = submission_format_df.index.values\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 4538, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (20759) does not match length of index (12)\n",
  "history_begin_time" : 1679983674787,
  "history_end_time" : 1679983736686,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "5tXKG5cDa8fE",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n# start_date = \"2022-04-06\"\n# end_date = \"2022-04-18\"\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean).toList(viirs.size())\n\n# Convert the list to a nested list\nnested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_list, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/5tXKG5cDa8fE/data_gee_gridmet_real_time.py\", line 46, in <module>\n    column_list.extend(var_list)\nNameError: name 'var_list' is not defined\n",
  "history_begin_time" : 1679983548912,
  "history_end_time" : 1679983599961,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cdJBeTN31Afr",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean).toList(viirs.size())\n\n# Convert the list to a nested list\nnested_dict = [img.toDictionary(reduced_column_list) for img in poi_reduced_imgs.getInfo()]\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_dict, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/cdJBeTN31Afr/data_gee_gridmet_real_time.py\", line 82, in <module>\n    nested_dict = [img.toDictionary(reduced_column_list) for img in poi_reduced_imgs.getInfo()]\n  File \"/home/chetana/gw-workspace/cdJBeTN31Afr/data_gee_gridmet_real_time.py\", line 82, in <listcomp>\n    nested_dict = [img.toDictionary(reduced_column_list) for img in poi_reduced_imgs.getInfo()]\nAttributeError: 'dict' object has no attribute 'toDictionary'\n",
  "history_begin_time" : 1679983310584,
  "history_end_time" : 1679983372849,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "OmlvR9EqgIV1",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean).toList(viirs.size())\n\n# Convert the list to a nested list\nnested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_list, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/OmlvR9EqgIV1/data_gee_gridmet_real_time.py\", line 82, in <module>\n    nested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/apifunction.py\", line 205, in <lambda>\n    return lambda *args, **kwargs: func.call(*args, **kwargs)  # pylint: disable=unnecessary-lambda\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 67, in call\n    return self.apply(self.nameArgs(args, kwargs))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 261, in _Promote\n    return CustomFunction.create(arg, 'Object', ['Object'] * args_count)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/customfunction.py\", line 125, in create\n    return CustomFunction(signature, func)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/customfunction.py\", line 43, in __init__\n    if body(*variables) is None:\n  File \"/home/chetana/gw-workspace/OmlvR9EqgIV1/data_gee_gridmet_real_time.py\", line 82, in <lambda>\n    nested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\nAttributeError: 'ComputedObject' object has no attribute 'toDictionary'\n",
  "history_begin_time" : 1679983120815,
  "history_end_time" : 1679983175172,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "1W9XsXGWldSP",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n# start_date = \"2022-04-06\"\n# end_date = \"2022-04-18\"\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\n\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean).toList(viirs.size())\n\n# Convert the list to a nested list\nnested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_list, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/1W9XsXGWldSP/data_gee_gridmet_real_time.py\", line 46, in <module>\n    column_list.extend(var_list)\nNameError: name 'var_list' is not defined\n",
  "history_begin_time" : 1679983018915,
  "history_end_time" : 1679983069538,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "LgINOUdlWXBP",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n# start_date = \"2022-04-06\"\n# end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean).toList(viirs.size())\n\n# Convert the list to a nested list\nnested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_list, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/LgINOUdlWXBP/data_gee_gridmet_real_time.py\", line 71, in <module>\n    nested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/apifunction.py\", line 205, in <lambda>\n    return lambda *args, **kwargs: func.call(*args, **kwargs)  # pylint: disable=unnecessary-lambda\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 67, in call\n    return self.apply(self.nameArgs(args, kwargs))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 261, in _Promote\n    return CustomFunction.create(arg, 'Object', ['Object'] * args_count)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/customfunction.py\", line 125, in create\n    return CustomFunction(signature, func)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/customfunction.py\", line 43, in __init__\n    if body(*variables) is None:\n  File \"/home/chetana/gw-workspace/LgINOUdlWXBP/data_gee_gridmet_real_time.py\", line 71, in <lambda>\n    nested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\nAttributeError: 'ComputedObject' object has no attribute 'toDictionary'\n",
  "history_begin_time" : 1679982798892,
  "history_end_time" : 1679982861905,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "GHifaWH2Tn3n",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n# start_date = \"2022-04-06\"\n# end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean).toList(viirs.size())\n\n# Convert the list to a nested list\nnested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_list, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : null,
  "history_begin_time" : 1679982750783,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "SvXppXviwqA1",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n# start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n# start_date = \"2022-04-06\"\n# end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of all the point coordinates\ncoords_list = []\nfor current_cell_id in submission_format_df.index:\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n    coords_list.append([longitude, latitude])\n\n# Convert the list of coordinates to an Earth Engine feature collection\nfeatures = [ee.Feature(ee.Geometry.Point(coords)) for coords in coords_list]\nfc = ee.FeatureCollection(features)\n\n# Filter the image collection based on date and the feature collection\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(fc).select(var_list)\n\n# Define the function for reducing the region\ndef poi_mean(img):\n    reducer = img.reduceRegion(\n        reducer=ee.Reducer.mean(), geometry=fc, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return img\n\n# Map the poi_mean function over the image collection and reduce to a list\npoi_reduced_imgs = viirs.map(poi_mean).toList(viirs.size())\n\n# Convert the list to a nested list\nnested_list = poi_reduced_imgs.map(lambda img: img.toDictionary(reduced_column_list)).getInfo()\n\n# Convert the nested list to a pandas DataFrame\ndf = pd.DataFrame(nested_list, columns=reduced_column_list)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\n\n# Add cell_id, latitude, and longitude columns to the DataFrame\ndf['cell_id'] = submission_format_df.index.values\ndf['latitude'] = all_cell_coords_pd['lat'].values\ndf['longitude'] = all_cell_coords_pd['lon'].values\n\n# Save the DataFrame to a CSV file\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n",
  "history_output" : "today date = 2023-03-28\n2023-03-14 06:00:00\n",
  "history_begin_time" : 1679982709725,
  "history_end_time" : 1679982750829,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "uOhSMmdyiuDb",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport os\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n# Authenticate and initialize Earth Engine\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n# Set up file paths and variables\ngithub_dir = os.path.expanduser('~/Documents/GitHub/SnowCast')\nsubmission_format_file = f'{github_dir}/data/snowcast_provided/submission_format_eval.csv'\nall_cell_coords_file = f'{github_dir}/data/snowcast_provided/all_cell_coords_file.csv'\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ndfolder = f'{github_dir}/data/sim_testing/{org_name}/'\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Read in dataframes\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n# Define function to collect data for all cells\ndef collect_all_cells_data():\n    cell_coords = all_cell_coords_pd[['lon', 'lat']].values.tolist()\n    cell_data = ee.ImageCollection(product_name).filterDate(start_date, end_date).getRegion(cell_coords, scale=30)\n    cell_data = pd.DataFrame(cell_data[1:], columns=cell_data[0])\n    cell_data['date'] = pd.to_datetime(cell_data['time'], unit='ms').dt.date.astype(str)\n    cell_data['cell_id'] = all_cell_coords_pd.index.values.repeat(len(var_list))\n    cell_data['latitude'] = all_cell_coords_pd['lat'].values.repeat(len(var_list))\n    cell_data['longitude'] = all_cell_coords_pd['lon'].values.repeat(len(var_list))\n    return cell_data[column_list]\n\n# Collect data for all cells\nall_cell_data = collect_all_cells_data()\n\n# Save data to file\nall_cell_data.to_csv(f'{dfolder}/gridmet_cell_data.csv', index=False)\n\nprint(\"Data collection and export complete.\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/uOhSMmdyiuDb/data_gee_gridmet_real_time.py\", line 57, in <module>\n    all_cell_data = collect_all_cells_data()\n  File \"/home/chetana/gw-workspace/uOhSMmdyiuDb/data_gee_gridmet_real_time.py\", line 48, in collect_all_cells_data\n    cell_data = ee.ImageCollection(product_name).filterDate(start_date, end_date).getRegion(cell_coords, scale=30)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/apifunction.py\", line 205, in <lambda>\n    return lambda *args, **kwargs: func.call(*args, **kwargs)  # pylint: disable=unnecessary-lambda\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 67, in call\n    return self.apply(self.nameArgs(args, kwargs))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 240, in _Promote\n    return Geometry(arg)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n    return type.__call__(cls, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 87, in __init__\n    raise ee_exception.EEException('Invalid GeoJSON geometry.')\nee.ee_exception.EEException: Invalid GeoJSON geometry.\n",
  "history_begin_time" : 1679979679185,
  "history_end_time" : 1679979707513,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "4aSTcAh8zPMV",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport os\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n# Authenticate and initialize Earth Engine\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n# Set up file paths and variables\ngithub_dir = os.path.expanduser('~/Documents/GitHub/SnowCast')\nsubmission_format_file = f'{github_dir}/data/snowcast_provided/submission_format_eval.csv'\nall_cell_coords_file = f'{github_dir}/data/snowcast_provided/all_cell_coords_file.csv'\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\ndfolder = f'{github_dir}/data/sim_testing/{org_name}/'\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Read in dataframes\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n# Define function to collect data for all cells\ndef collect_all_cells_data():\n    cell_coords = all_cell_coords_pd[['lon', 'lat']].values.tolist()\n    cell_data = ee.ImageCollection(product_name).filterDate(start_date, end_date).getRegion(cell_coords, scale=30)\n    cell_data = pd.DataFrame(cell_data[1:], columns=cell_data[0])\n    cell_data['date'] = pd.to_datetime(cell_data['time'], unit='ms').dt.date.astype(str)\n    cell_data['cell_id'] = all_cell_coords_pd.index.values.repeat(len(var_list))\n    cell_data['latitude'] = all_cell_coords_pd['lat'].values.repeat(len(var_list))\n    cell_data['longitude'] = all_cell_coords_pd['lon'].values.repeat(len(var_list))\n    return cell_data[column_list]\n\n# Collect data for all cells\nall_cell_data = collect_all_cells_data()\n\n# Save data to file\nall_cell_data.to_csv(f'{dfolder}/gridmet_cell_data.csv', index=False)\n\nprint(\"Data collection and export complete.\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/4aSTcAh8zPMV/data_gee_gridmet_real_time.py\", line 57, in <module>\n    all_cell_data = collect_all_cells_data()\n  File \"/home/chetana/gw-workspace/4aSTcAh8zPMV/data_gee_gridmet_real_time.py\", line 48, in collect_all_cells_data\n    cell_data = ee.ImageCollection(product_name).filterDate(start_date, end_date).getRegion(cell_coords, scale=30)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/apifunction.py\", line 205, in <lambda>\n    return lambda *args, **kwargs: func.call(*args, **kwargs)  # pylint: disable=unnecessary-lambda\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 67, in call\n    return self.apply(self.nameArgs(args, kwargs))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 240, in _Promote\n    return Geometry(arg)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n    return type.__call__(cls, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 87, in __init__\n    raise ee_exception.EEException('Invalid GeoJSON geometry.')\nee.ee_exception.EEException: Invalid GeoJSON geometry.\n",
  "history_begin_time" : 1679978044866,
  "history_end_time" : 1679978072793,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "uOeVqK8LGZIk",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport multiprocessing\n\n# Initialize GEE\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\n# Read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# Read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n# Set the variables\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of cell IDs and their coordinates\ncell_coords = [(cell_id, all_cell_coords_pd['lon'][cell_id], all_cell_coords_pd['lat'][cell_id]) for cell_id in submission_format_df.index]\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Define a function to retrieve data for a batch of cells\ndef get_batch_data(batch):\n    cell_data_list = []\n    for cell_id, longitude, latitude in batch:\n        try:\n            print(f\"=> Collected GridMet data for {cell_id}\")\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            viirs = ee.ImageCollection(product_name).filterDate(\n                start_date, end_date).filterBounds(poi).select(var_list)\n\n            def poi_mean(img):\n                reducer = img.reduceRegion(\n                    reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n                img = img.set('date', img.date().format())\n                for var in var_list:\n                    column_name = var\n                    mean = reducer.get(column_name)\n                    img = img.set(column_name, mean)\n                return img\n\n            poi_reduced_imgs = viirs.map(poi_mean)\n\n            nested_list = poi_reduced_imgs.reduceColumns(\n                ee.Reducer.toList(var_list), ['date']).get('list')\n\n            df = pd.DataFrame.from_records(nested_list.getInfo(), index='date')\n            df.index = pd.to_datetime(df.index, format='%Y-%m-%d')\n            df['cell_id'] = cell_id\n            df['latitude'] = latitude\n            df['longitude'] = longitude\n\n            cell_data_list.append(df)\n        except Exception as e:\n            print(f\"=> Error collecting data for cell {cell_id}\")\n            print(traceback.format_exc())\n\n    return pd.concat(cell_data_list)\n\n\n# Define a function to collect data for all cells using multiple processes\ndef collect_all_data(cell_coords, num_processes=4):\n    with multiprocessing.Pool(num_processes) as p:\n        results = p.map(get_batch_data, np.array_split(cell_coords, num_processes))\n        return pd.concat(results)\n        \nnum_processes = 4\ncollect_all_data(cell_coords, num_processes=4)\n\n# try:\n#     print(\"Collecting data for all cells...\")\n#     cell_data = collect_all_data(cell_coords, num_processes=num_processes)\n#     print(\"Data collection complete!\")\n# except Exception as e:\n#     print(f\"Error collecting data for all cells: {e}\")\n#     print(traceback.format_exc())\n# output_dir = f\"{github_dir}/data/sim_testing/{org_name}/\"\n# output_filename = f\"{output_dir}/{start_date.strftime('%Y-%m-%d_%H:%M:%S')}{end_date.strftime('%Y-%m-%d%H:%M:%S')}.csv\"\n\n# try:\n#     if not os.path.exists(output_dir):\n#         os.makedirs(output_dir)\n#         cell_data.to_csv(output_filename)\n#         print(f\"Data saved to {output_filename}\")\n# except Exception as e:\n#     print(f\"Error saving data to {output_filename}: {e}\")\n#     print(traceback.format_exc())",
  "history_output" : "2023-03-14 06:00:00\n=> Collected GridMet data for 0001daba-dd41-4787-84ab-f7956f7829a8\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -121.3016095\n=> Collected GridMet data for 0027a004-df14-4d66-a3e4-e987336b8814\nTraceback (most recent call last):\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 002a9f10-203c-4feb-9ea4-19bcbe9a7686\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -121.3105925\n=> Collected GridMet data for 0038be33-f5ba-4274-93b9-c7b6ea003519\nTraceback (most recent call last):\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return List(arg)\n    return type.__call__(cls, *args, **kwargs)\n    raise ee_exception.EEException(\n\nTraceback (most recent call last):\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -119.9631195\nTraceback (most recent call last):\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return List(arg)\n    raise ee_exception.EEException(\n=> Error collecting data for cell 0043c28e-7f7d-49e9-8be3-139f93b281a7\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 00481126-761a-4d70-8775-c449bf498ecd\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -106.102115\nTraceback (most recent call last):\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return List(arg)\n    raise ee_exception.EEException(\n=> Error collecting data for cell 004e5e03-f6b6-470b-96e2-911992c8ffb4\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -106.982464\n=> Collected GridMet data for 004f4c46-e664-414b-ad56-feaee010eee8\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -118.6964955\nTraceback (most recent call last):\n    init = Geometry._parseArgs(\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 0050f3a5-e24d-45d7-9ce1-f046a54adb96\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -121.4363565\n=> Error collecting data for cell 0051069d-cdc3-467b-9034-31f5e0eeb005\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n\nTraceback (most recent call last):\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return List(arg)\n    raise ee_exception.EEException(\n=> Error collecting data for cell 0057c657-ac2f-4141-881c-3593859ef092\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 0057dca9-9c70-4708-9697-909e5711a7f0\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n\nTraceback (most recent call last):\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return List(arg)\n    raise ee_exception.EEException(\n=> Error collecting data for cell 005f3676-e3dd-416a-af7b-696067815dfa\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 00656c12-2000-4cb7-97b0-6d51bafb5db2\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -121.2207615\nTraceback (most recent call last):\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return List(arg)\n    raise ee_exception.EEException(\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n=> Collected GridMet data for 0072f5ac-ec83-4183-8757-47a7e26a8d86\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Error collecting data for cell 008e79fa-7265-404f-ab62-48f59d0e0f4c\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -109.1743535\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Collected GridMet data for 0095d99e-2c21-40ff-bb09-467a12da25d2\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -118.3910685\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 00c0b91c-9aa7-4d9b-a44f-abb91acd49d2\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -118.79531\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 00c4db22-a423-41a4-ada6-a8b1b04153a4\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -121.9394135\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 00cbc9d7-ce7c-46e8-87fd-774fcd1ad03e\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -120.9422835\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 00d3626b-3696-49ae-97d2-165f56187953\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -118.8492085\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 00df85af-2836-4229-a654-876cf2a1767e\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -109.0665555\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n=> Collected GridMet data for 00e1b8d6-84f5-4b79-a5a7-ce7f8fe13773\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -119.8283725\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n\n=> Error collecting data for cell 40049bd2-119f-4913-81c8-67ebf4c213b4\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n    raise ee_exception.EEException(\n=> Error collecting data for cell 00ec51da-dae3-4624-960b-e0cc9a911718\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -118.974973\nTraceback (most recent call last):\n    init = Geometry._parseArgs(\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return List(arg)\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -121.3105925\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Collected GridMet data for 00f1ff7a-6c24-44ae-9d47-d78533773a93\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -120.6727885\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n=> Collected GridMet data for 00fd6873-2601-45b8-9704-8bb6a53bb62c\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 011091ab-0823-4e6c-ad70-a9f3e8ec5118\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -105.6709235\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Error collecting data for cell 0113dc17-2d90-4541-89cd-f209b30405f2\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -108.8689265\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Error collecting data for cell 4023d30e-108c-4be9-9688-64404c599345\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -109.3270665\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Collected GridMet data for 011df06d-650c-40e7-bd56-d2f305c1bff9\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Collected GridMet data for 011e46e4-00bc-4fb3-be3b-d31e22e880f2\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Collected GridMet data for 0125850a-5d2f-46d2-9873-0066edcfe334\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Error collecting data for cell 012ea03b-8472-4adc-abf5-6352a2e9c04d\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n=> Collected GridMet data for 402cba2e-55ad-41e5-8142-999446d04cb3\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n=> Collected GridMet data for 0136d669-a167-44d6-8c65-dbcbc4f71e5b\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -107.7190825\n=> Error collecting data for cell 402dd439-c8d0-4179-a097-5fdd1abe28ef\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -105.9583845\n=> Collected GridMet data for 01387dab-ab55-490d-9451-1d15bf4d9b0e\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n    raise ee_exception.EEException(\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n    raise ee_exception.EEException(\n=> Collected GridMet data for 0138b557-850c-43a9-a5d6-7c7e96d096e1\n=> Error collecting data for cell 0138b557-850c-43a9-a5d6-7c7e96d096e1\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n    return type.__call__(cls, *args, **kwargs)\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -121.2207615\n=> Collected GridMet data for 0139bb4f-9f2b-420c-b5ea-34db9a5d0d65\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n=> Error collecting data for cell 40375e8a-02b2-4042-a7ea-73a19b1bc4d7\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n    return type.__call__(cls, *args, **kwargs)\n  File \"/home/chetana/gw-workspace/uOeVqK8LGZIk/data_gee_gridmet_real_time.py\", line 65, in get_batch_data\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 014ce464-ac95-43ad-a614-5f017f8656ed\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -105.922452\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Error collecting data for cell 015e2c22-7766-4d19-bde1-33f6a22824ba\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -119.442097\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Error collecting data for cell 40490fc4-6675-4b73-afaa-642f2ed93ecb\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -120.0619345\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Collected GridMet data for 0161a423-ba7f-405d-b129-273fadc00911\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 01620fe7-3c4a-4b71-b45d-a3805eeaf509\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -109.4438475\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n=> Error collecting data for cell 404b416b-32eb-49e4-bfcb-5c2c0189a550\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -109.9289385\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Error collecting data for cell 404cc7ef-b080-4973-8410-98d6dd0af9d1\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -120.2865135\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 404d4e53-ad4d-4faa-b271-6b8599681f80\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -119.5139625\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 404f057c-bb53-41e0-baa3-3d39dbc2ea40\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n    return apifunction.ApiFunction.lookup(server_name).apply(result)\n    return List(arg)\n\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -119.0468385\n=> Collected GridMet data for 40547fa3-e7f3-4cbb-81d1-728e7413c61c\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    init = Geometry._parseArgs(\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    return type.__call__(cls, *args, **kwargs)\n=> Error collecting data for cell 01867838-b8c1-45b2-bf01-a262d18c95ec\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 755, in _parseArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 281, in _Promote\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\nee.ee_exception.EEException: Invalid argument specified for ee.List(): -119.9631195\nTraceback (most recent call last):\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 80, in apply\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n=> Collected GridMet data for 0186f113-1650-4e47-8de0-70cee5863d66\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n    return type.__call__(cls, *args, **kwargs)\n=> Collected GridMet data for 01881a4a-6136-4d0f-834e-8cd0c9085733\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Error collecting data for cell 4060281e-b9f9-4d97-90bf-611744a728db\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n=> Error collecting data for cell 4068cf08-3eaa-4d7b-9049-d8e4462b9e7c\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n=> Error collecting data for cell 018cf1a1-f945-4097-9c47-0c4690538bb5\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n=> Error collecting data for cell 018d455b-a485-499f-858d-b2f09c0dc75f\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n    init = Geometry._parseArgs(\n    promoted_args[name] = Function._promoter(args[name], spec['type'])\n    raise ee_exception.EEException(\n=> Error collecting data for cell 018e1f62-069b-48e1-b440-f6eacaa54520\n    init = Geometry._parseArgs(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 407548c9-ffd6-46cb-9374-58c9a7257a56\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n=> Collected GridMet data for 4077b0a0-f033-440c-83fe-04abe036b621\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 186, in Point\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/function.py\", line 107, in promoteArgs\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 44, in __init__\n",
  "history_begin_time" : 1679977624354,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "kZrjKYA4e16N",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport multiprocessing\n\n# Initialize GEE\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\n# Read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# Read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n# Set the variables\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of cell IDs and their coordinates\ncell_coords = [(cell_id, all_cell_coords_pd['lon'][cell_id], all_cell_coords_pd['lat'][cell_id]) for cell_id in submission_format_df.index]\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Define a function to retrieve data for a batch of cells\ndef get_batch_data(batch):\n    cell_data_list = []\n    for cell_id, longitude, latitude in batch:\n        try:\n            print(f\"=> Collected GridMet data for {cell_id}\")\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            viirs = ee.ImageCollection(product_name).filterDate(\n                start_date, end_date).filterBounds(poi).select(var_list)\n\n            def poi_mean(img):\n                reducer = img.reduceRegion(\n                    reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n                img = img.set('date', img.date().format())\n                for var in var_list:\n                    column_name = var\n                    mean = reducer.get(column_name)\n                    img = img.set(column_name, mean)\n                return img\n\n            poi_reduced_imgs = viirs.map(poi_mean)\n\n            nested_list = poi_reduced_imgs.reduceColumns(\n                ee.Reducer.toList(var_list), ['date']).get('list')\n\n            df = pd.DataFrame.from_records(nested_list.getInfo(), index='date')\n            df.index = pd.to_datetime(df.index, format='%Y-%m-%d')\n            df['cell_id'] = cell_id\n            df['latitude'] = latitude\n            df['longitude'] = longitude\n\n            cell_data_list.append(df)\n        except Exception as e:\n            print(f\"=> Error collecting data for cell {cell_id}\")\n            print(traceback.format_exc())\n\n    return pd.concat(cell_data_list)\n\n\n# Define a function to collect data for all cells using multiple processes\ndef collect_all_data(cell_coords, num_processes=4):\n    with multiprocessing.Pool(num_processes) as p:\n        p.map(get_batch_data, cell_coords)\n        \nnum_processes = 4\ntry:\n    print(\"Collecting data for all cells...\")\n    cell_data = collect_all_data(cell_coords, num_processes=num_processes)\n    print(\"Data collection complete!\")\nexcept Exception as e:\n    print(f\"Error collecting data for all cells: {e}\")\n    print(traceback.format_exc())\noutput_dir = f\"{github_dir}/data/sim_testing/{org_name}/\"\noutput_filename = f\"{output_dir}/{start_date.strftime('%Y-%m-%d_%H:%M:%S')}{end_date.strftime('%Y-%m-%d%H:%M:%S')}.csv\"\n\ntry:\n    if not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n    cell_data.to_csv(output_filename)\n    print(f\"Data saved to {output_filename}\")\nexcept Exception as e:\n    print(f\"Error saving data to {output_filename}: {e}\")\n    print(traceback.format_exc())",
  "history_output" : "  File \"/home/chetana/gw-workspace/kZrjKYA4e16N/data_gee_gridmet_real_time.py\", line 114\n    os.makedirs(output_dir)\n    ^\nIndentationError: expected an indented block\n",
  "history_begin_time" : 1679975676897,
  "history_end_time" : 1679975678024,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "UwkKwMwQgm9w",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport multiprocessing\n\n# Initialize GEE\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\n# Read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# Read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n# Set the variables\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of cell IDs and their coordinates\ncell_coords = [(cell_id, all_cell_coords_pd['lon'][cell_id], all_cell_coords_pd['lat'][cell_id]) for cell_id in submission_format_df.index]\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Define a function to retrieve data for a batch of cells\ndef get_batch_data(batch):\n    cell_data_list = []\n    for cell_id, longitude, latitude in batch:\n        try:\n            print(f\"=> Collected GridMet data for {cell_id}\")\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            viirs = ee.ImageCollection(product_name).filterDate(\n                start_date, end_date).filterBounds(poi).select(var_list)\n\n            def poi_mean(img):\n                reducer = img.reduceRegion(\n                    reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n                img = img.set('date', img.date().format())\n                for var in var_list:\n                    column_name = var\n                    mean = reducer.get(column_name)\n                    img = img.set(column_name, mean)\n                return img\n\n            poi_reduced_imgs = viirs.map(poi_mean)\n\n            nested_list = poi_reduced_imgs.reduceColumns(\n                ee.Reducer.toList(var_list), ['date']).get('list')\n\n            df = pd.DataFrame.from_records(nested_list.getInfo(), index='date')\n            df.index = pd.to_datetime(df.index, format='%Y-%m-%d')\n            df['cell_id'] = cell_id\n            df['latitude'] = latitude\n            df['longitude'] = longitude\n\n            cell_data_list.append(df)\n        except Exception as e:\n            print(f\"=> Error collecting data for cell {cell_id}\")\n            print(traceback.format_exc())\n\n    return pd.concat(cell_data_list)\n\n\n# Define a function to collect data for all cells using multiple processes\ndef collect_all_data(cell_coords, num_processes=4):\n    with multiprocessing.Pool(num_processes) as p:\n        p.map(get_batch_data, cell_coords)\n        \nnum_processes = 4\ntry:\n    print(\"Collecting data for all cells...\")\n    cell_data = collect_all_data(cell_coords, num_processes=num_processes)\n    print(\"Data collection complete!\")\nexcept Exception as e:\n    print(f\"Error collecting data for all cells: {e}\")\n    print(traceback.format_exc())\noutput_dir = f\"{github_dir}/data/sim_testing/{org_name}/\"\noutput_filename = f\"{output_dir}/{start_date.strftime('%Y-%m-%d_%H:%M:%S')}{end_date.strftime('%Y-%m-%d%H:%M:%S')}.csv\"\n\ntry:\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n        cell_data.to_csv(output_filename)\n        print(f\"Data saved to {output_filename}\")\nexcept Exception as e:\n    print(f\"Error saving data to {output_filename}: {e}\")\n    print(traceback.format_exc())",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n(20759, 25)\n2023-03-14 06:00:00\nCollecting data for all cells...\nError collecting data for all cells: too many values to unpack (expected 3)\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/chetana/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/home/chetana/gw-workspace/UwkKwMwQgm9w/data_gee_gridmet_real_time.py\", line 60, in get_batch_data\n    for cell_id, longitude, latitude in batch:\nValueError: too many values to unpack (expected 3)\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/UwkKwMwQgm9w/data_gee_gridmet_real_time.py\", line 104, in <module>\n    cell_data = collect_all_data(cell_coords, num_processes=num_processes)\n  File \"/home/chetana/gw-workspace/UwkKwMwQgm9w/data_gee_gridmet_real_time.py\", line 99, in collect_all_data\n    p.map(get_batch_data, cell_coords)\n  File \"/home/chetana/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 364, in map\n    return self._map_async(func, iterable, mapstar, chunksize).get()\n  File \"/home/chetana/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 771, in get\n    raise self._value\nValueError: too many values to unpack (expected 3)\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/UwkKwMwQgm9w/data_gee_gridmet_real_time.py\", line 110, in <module>\n    output_filename = f\"{output_dir}/{start_date.strftime('%Y-%m-%d_%H:%M:%S')}{end_date.strftime('%Y-%m-%d%H:%M:%S')}.csv\"\nAttributeError: 'str' object has no attribute 'strftime'\n",
  "history_begin_time" : 1679975491592,
  "history_end_time" : 1679975542567,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "f2P9mr0jLWGR",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport multiprocessing\n\n# Initialize GEE\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\n# Read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n\n# Read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n# Set the variables\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# Create a list of cell IDs and their coordinates\ncell_coords = [(cell_id, all_cell_coords_pd['lon'][cell_id], all_cell_coords_pd['lat'][cell_id]) for cell_id in submission_format_df.index]\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Define a function to retrieve data for a batch of cells\ndef get_batch_data(batch):\n    cell_data_list = []\n    for cell_id, longitude, latitude in batch:\n        try:\n            print(f\"=> Collected GridMet data for {cell_id}\")\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            viirs = ee.ImageCollection(product_name).filterDate(\n                start_date, end_date).filterBounds(poi).select(var_list)\n\n            def poi_mean(img):\n                reducer = img.reduceRegion(\n                    reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n                img = img.set('date', img.date().format())\n                for var in var_list:\n                    column_name = var\n                    mean = reducer.get(column_name)\n                    img = img.set(column_name, mean)\n                return img\n\n            poi_reduced_imgs = viirs.map(poi_mean)\n\n            nested_list = poi_reduced_imgs.reduceColumns(\n                ee.Reducer.toList(var_list), ['date']).get('list')\n\n            df = pd.DataFrame.from_records(nested_list.getInfo(), index='date')\n            df.index = pd.to_datetime(df.index, format='%Y-%m-%d')\n            df['cell_id'] = cell_id\n            df['latitude'] = latitude\n            df['longitude'] = longitude\n\n            cell_data_list.append(df)\n        except Exception as e:\n            print(f\"=> Error collecting data for cell {cell_id}\")\n            print(traceback.format_exc())\n\n    return pd.concat(cell_data_list)\n\n\n# Define a function to collect data for all cells using multiple processes\ndef collect_all_data(cell_coords, num_processes=4):\n    with multiprocessing.Pool(num_processes) as p:\n        p.map(get_batch_data, cell_coords)\n        \nnum_processes = 4\ntry:\n    print(\"Collecting data for all cells...\")\n    cell_data = collect_all_data(cell_coords, num_processes=num_processes)\n    print(\"Data collection complete!\")\nexcept Exception as e:\n    print(f\"Error collecting data for all cells: {e}\")\n    print(traceback.format_exc())\noutput_dir = f\"{github_dir}/data/sim_testing/{org_name}/\"\noutput_filename = f\"{output_dir}/{start_date.strftime('%Y-%m-%d_%H:%M:%S')}{end_date.strftime('%Y-%m-%d%H:%M:%S')}.csv\"\n\ntry:\n    if not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n    cell_data.to_csv(output_filename)\n    print(f\"Data saved to {output_filename}\")\nexcept Exception as e:\n    print(f\"Error saving data to {output_filename}: {e}\")\n    print(traceback.format_exc())",
  "history_output" : "  File \"/home/chetana/gw-workspace/f2P9mr0jLWGR/data_gee_gridmet_real_time.py\", line 114\n    os.makedirs(output_dir)\n    ^\nIndentationError: expected an indented block\n",
  "history_begin_time" : 1679975464587,
  "history_end_time" : 1679975465707,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "rYdKvBjCLMRw",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport threading\n\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ncount = 0\n\n# Create a list of all cell IDs\ncell_ids = submission_format_df.index.tolist()\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Identify a 500 meter buffer around our Point Of Interest (POI)\npoi = ee.Geometry.Point(all_cell_coords_pd['lon'][cell_ids[0]], all_cell_coords_pd['lat'][cell_ids[0]]).buffer(1000)\n\n# Filter Image Collection based on time range and POI\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n# Define function to calculate mean for each image and return as a list\ndef poi_mean(img):\n    reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n    img = img.set('date', img.date().format())\n    props = {var: reducer.get(var) for var in var_list}\n    return ee.Feature(poi, props).set('date', img.date().format())\n\n# Map poi_mean function over Image Collection and convert to a feature collection\npoi_reduced_feats = ee.FeatureCollection(viirs.map(poi_mean))\n\n# Convert feature collection to a dataframe\nall_cell_df = pd.DataFrame([x['properties'] for x in poi_reduced_feats.getInfo()['features']])\n\n# Add latitude\n# Add latitude and longitude to the dataframe\nall_cell_df['latitude'] = all_cell_coords_pd.loc[cell_ids, 'lat'].reindex(cell_ids).tolist()\nall_cell_df['longitude'] = all_cell_coords_pd.loc[cell_ids, 'lon'].reindex(cell_ids).tolist()\n\n# Rearrange columns and sort by date and cell ID\nall_cell_df = all_cell_df[column_list].sort_values(by=['date', 'cell_id'])\n\n# Rename columns for submission format\nall_cell_df = all_cell_df.rename(columns={'cell_id': 'ID'})\nall_cell_df = all_cell_df.rename(columns={'tmmn': 'tmin', 'tmmx': 'tmax', 'pr': 'precip'})\n\n# Convert date column to datetime format\nall_cell_df['date'] = pd.to_datetime(all_cell_df['date'], format='%Y-%m-%d')\n\n# Reorder columns for submission format\nreduced_column_list.remove('eto')\nreduced_column_list.remove('rmax')\nreduced_column_list.remove('rmin')\nreduced_column_list.remove('vs')\nall_cell_df = all_cell_df[reduced_column_list]\n\n# Set index to ID for submission format\nall_cell_df = all_cell_df.set_index('ID')\n\n# Write to file\nsubmission_file = f\"{dfolder}{org_name}_{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(submission_file)\n\nprint(f\"File saved: {submission_file}\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/rYdKvBjCLMRw/data_gee_gridmet_real_time.py\", line 88, in <module>\n    all_cell_df['latitude'] = all_cell_coords_pd.loc[cell_ids, 'lat'].reindex(cell_ids).tolist()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 4538, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (20759) does not match length of index (93)\n",
  "history_begin_time" : 1679974758954,
  "history_end_time" : 1679974810579,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "okIWzKEMYlpV",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport threading\n\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ncount = 0\n\n# Create a list of all cell IDs\ncell_ids = submission_format_df.index.tolist()\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Identify a 500 meter buffer around our Point Of Interest (POI)\npoi = ee.Geometry.Point(all_cell_coords_pd['lon'][cell_ids[0]], all_cell_coords_pd['lat'][cell_ids[0]]).buffer(1000)\n\n# Filter Image Collection based on time range and POI\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n# Define function to calculate mean for each image and return as a list\ndef poi_mean(img):\n    reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n    img = img.set('date', img.date().format())\n    props = {var: reducer.get(var) for var in var_list}\n    return ee.Feature(poi, props).set('date', img.date().format())\n\n# Map poi_mean function over Image Collection and convert to a feature collection\npoi_reduced_feats = ee.FeatureCollection(viirs.map(poi_mean))\n\n# Convert feature collection to a dataframe\nall_cell_df = pd.DataFrame([x['properties'] for x in poi_reduced_feats.getInfo()['features']])\n\n# Add latitude\n# Add latitude and longitude to the dataframe\nall_cell_df['latitude'] = all_cell_coords_pd.loc[cell_ids, 'lat'].tolist()\nall_cell_df['longitude'] = all_cell_coords_pd.loc[cell_ids, 'lon'].tolist()\n\n# Rearrange columns and sort by date and cell ID\nall_cell_df = all_cell_df[column_list].sort_values(by=['date', 'cell_id'])\n\n# Rename columns for submission format\nall_cell_df = all_cell_df.rename(columns={'cell_id': 'ID'})\nall_cell_df = all_cell_df.rename(columns={'tmmn': 'tmin', 'tmmx': 'tmax', 'pr': 'precip'})\n\n# Convert date column to datetime format\nall_cell_df['date'] = pd.to_datetime(all_cell_df['date'], format='%Y-%m-%d')\n\n# Reorder columns for submission format\nreduced_column_list.remove('eto')\nreduced_column_list.remove('rmax')\nreduced_column_list.remove('rmin')\nreduced_column_list.remove('vs')\nall_cell_df = all_cell_df[reduced_column_list]\n\n# Set index to ID for submission format\nall_cell_df = all_cell_df.set_index('ID')\n\n# Write to file\nsubmission_file = f\"{dfolder}{org_name}_{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(submission_file)\n\nprint(f\"File saved: {submission_file}\")\n",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/okIWzKEMYlpV/data_gee_gridmet_real_time.py\", line 88, in <module>\n    all_cell_df['latitude'] = all_cell_coords_pd.loc[cell_ids, 'lat'].tolist()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3655, in __setitem__\n    self._set_item(key, value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3832, in _set_item\n    value = self._sanitize_column(value)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 4538, in _sanitize_column\n    com.require_length_match(value, self.index)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/common.py\", line 557, in require_length_match\n    raise ValueError(\nValueError: Length of values (20759) does not match length of index (93)\n",
  "history_begin_time" : 1679974554862,
  "history_end_time" : 1679974608653,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "IqZBxSrfr2k2",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport threading\n\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ncount = 0\n\n# Create a list of all cell IDs\ncell_ids = submission_format_df.index.tolist()\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Identify a 500 meter buffer around our Point Of Interest (POI)\npoi = ee.Geometry.Point(all_cell_coords_pd['lon'][cell_ids[0]], all_cell_coords_pd['lat'][cell_ids[0]]).buffer(1000)\n\n# Filter Image Collection based on time range and POI\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n# Define function to calculate mean for each image and return as a list\ndef poi_mean(img):\n    reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n    img = img.set('date', img.date().format())\n    for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n    return ee.List([img.date().millis(), img.toDictionary()])\n\n# Map poi_mean function over Image Collection and convert to a feature collection\npoi_reduced_feats = ee.FeatureCollection(viirs.map(poi_mean))\n\n# Convert feature collection to a dataframe\nall_cell_df = pd.DataFrame([x['properties'] for x in poi_reduced_feats.getInfo()['features']])\n\n# Add latitude\n# Add latitude and longitude to the dataframe\nall_cell_df['latitude'] = all_cell_coords_pd.loc[cell_ids, 'lat'].tolist()\nall_cell_df['longitude'] = all_cell_coords_pd.loc[cell_ids, 'lon'].tolist()\n\n# Rearrange columns and sort by date and cell ID\nall_cell_df = all_cell_df[column_list].sort_values(by=['date', 'cell_id'])\n\n# Rename columns for submission format\nall_cell_df = all_cell_df.rename(columns={'cell_id': 'ID'})\nall_cell_df = all_cell_df.rename(columns={'tmmn': 'tmin', 'tmmx': 'tmax', 'pr': 'precip'})\n\n# Convert date column to datetime format\nall_cell_df['date'] = pd.to_datetime(all_cell_df['date'], format='%Y-%m-%d')\n\n# Reorder columns for submission format\nreduced_column_list.remove('eto')\nreduced_column_list.remove('rmax')\nreduced_column_list.remove('rmin')\nreduced_column_list.remove('vs')\nall_cell_df = all_cell_df[reduced_column_list]\n\n# Set index to ID for submission format\nall_cell_df = all_cell_df.set_index('ID')\n\n# Write to file\nsubmission_file = f\"{dfolder}{org_name}_{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(submission_file)\n\nprint(f\"File saved: {submission_file}\")\n",
  "history_output" : "/home/chetana\n/home/chetana\nTraceback (most recent call last):\n",
  "history_begin_time" : 1679974373397,
  "history_end_time" : 1679974426593,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "rtNofeomWaMQ",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nee.Initialize(creds)\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ncount = 0\n\n# Create a list of all cell IDs\ncell_ids = submission_format_df.index.tolist()\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Create a function to fetch data for a single cell ID\ndef fetch_data(current_cell_id):\n    global all_cell_df\n    global count\n    \n    try:\n        print(f\"=> Collected GridMet data for {count} cells\")\n        print(\"collecting \", current_cell_id)\n\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(\n            start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(\n                reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(\n            ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n        all_cell_df = all_cell_df.append(df.reset_index()[column_list], ignore_index=True)\n        count += 1\n        print(f\"=> Collected GridMet data for {count} cells\")\n    except Exception as e:\n        print(traceback.format_exc())\n        \nnum_threads = 10\nthreads = []\nfor i in range(num_threads):\n    # Create a thread for each chunk of cell IDs\n    thread = threading.Thread(target=lambda cell_ids_chunk: [\n    fetch_data(cell_id) for cell_id in cell_ids_chunk], args=(cell_ids[i::num_threads],))\n    thread.start()\n    threads.append(thread)\n    \nfor thread in threads:\n    thread.join()\n    \nfilename = f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(filename)",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n2023-03-14 06:00:00\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/rtNofeomWaMQ/data_gee_gridmet_real_time.py\", line 116, in <module>\n    thread = threading.Thread(target=lambda cell_ids_chunk: [\nNameError: name 'threading' is not defined\n",
  "history_begin_time" : 1679973451618,
  "history_end_time" : 1679973503153,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "X5LdvWKysDU5",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n# try:\n#     ee.Initialize()\n# except Exception as e:\n#     ee.Authenticate()\n#     ee.Initialize()\n\nservice_account = 'eartheginegcloud@earthengine58.iam.gserviceaccount.com'\ncreds = ee.ServiceAccountCredentials(service_account, '/home/chetana/bhargavi-creds.json')\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ncount = 0\n\n# Create a list of all cell IDs\ncell_ids = submission_format_df.index.tolist()\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Create a function to fetch data for a single cell ID\ndef fetch_data(current_cell_id):\n    global all_cell_df\n    global count\n    \n    try:\n        print(f\"=> Collected GridMet data for {count} cells\")\n        print(\"collecting \", current_cell_id)\n\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(\n            start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(\n                reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(\n            ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n        all_cell_df = all_cell_df.append(df.reset_index()[column_list], ignore_index=True)\n        count += 1\n        print(f\"=> Collected GridMet data for {count} cells\")\n    except Exception as e:\n        print(traceback.format_exc())\n        \nnum_threads = 10\nthreads = []\nfor i in range(num_threads):\n    # Create a thread for each chunk of cell IDs\n    thread = threading.Thread(target=lambda cell_ids_chunk: [\n    fetch_data(cell_id) for cell_id in cell_ids_chunk], args=(cell_ids[i::num_threads],))\n    thread.start()\n    threads.append(thread)\n    \nfor thread in threads:\n    thread.join()\n    \nfilename = f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(filename)",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n/home/chetana\n",
  "history_begin_time" : 1679973402773,
  "history_end_time" : 1679973451629,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cUCoXAwjacbN",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ncount = 0\n\n# Create a list of all cell IDs\ncell_ids = submission_format_df.index.tolist()\n\n# change this\nstart_date = '2022-01-01'\nend_date = '2022-04-04'\n#\n\n# Create a function to fetch data for a single cell ID\ndef fetch_data(current_cell_id):\n    global all_cell_df\n    global count\n    \n    try:\n        print(f\"=> Collected GridMet data for {count} cells\")\n        print(\"collecting \", current_cell_id)\n\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(\n            start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(\n                reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(\n            ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n        all_cell_df = all_cell_df.append(df.reset_index()[column_list], ignore_index=True)\n        count += 1\n        print(f\"=> Collected GridMet data for {count} cells\")\n    except Exception as e:\n        print(traceback.format_exc())\n        \nnum_threads = 10\nthreads = []\nfor i in range(num_threads):\n    # Create a thread for each chunk of cell IDs\n    thread = threading.Thread(target=lambda cell_ids_chunk: [\n    fetch_data(cell_id) for cell_id in cell_ids_chunk], args=(cell_ids[i::num_threads],))\n    thread.start()\n    threads.append(thread)\n    \nfor thread in threads:\n    thread.join()\n    \nfilename = f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(filename)",
  "history_output" : "today date = 2023-03-28\n/home/chetana\n2023-03-14 06:00:00\n['gcloud', 'auth', 'application-default', 'login', '--scopes=https://www.googleapis.com/auth/earthengine,https://www.googleapis.com/auth/devstorage.full_control', '--client-id-file=/home/chetana/.config/earthengine/credentials-client-id.json']\nFetching credentials using gcloud\norig_exe:  gcloud\nenum 2 No such file or directory gcloud\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/cUCoXAwjacbN/data_gee_gridmet_real_time.py\", line 16, in <module>\n    ee.Initialize()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 132, in Initialize\n    data.initialize(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 201, in initialize\n    _install_cloud_api_resource()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 260, in _install_cloud_api_resource\n    _cloud_api_resource = _cloud_api_utils.build_cloud_resource(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/_cloud_api_utils.py\", line 166, in build_cloud_resource\n    resource = build()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/_cloud_api_utils.py\", line 146, in build\n    return discovery.build(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/discovery.py\", line 270, in build\n    content = _retrieve_discovery_doc(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/discovery.py\", line 376, in _retrieve_discovery_doc\n    resp, content = req.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 209, in request\n    self.credentials.before_request(self._request, method, uri, request_headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google/auth/credentials.py\", line 133, in before_request\n    self.refresh(request)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google/oauth2/credentials.py\", line 228, in refresh\n    ) = reauth.refresh_grant(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google/oauth2/reauth.py\", line 338, in refresh_grant\n    _client._handle_error_response(response_data)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google/oauth2/_client.py\", line 60, in _handle_error_response\n    raise exceptions.RefreshError(error_details, response_data)\ngoogle.auth.exceptions.RefreshError: ('invalid_grant: Bad Request', {'error': 'invalid_grant', 'error_description': 'Bad Request'})\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 299, in _load_app_default_credentials\n    subprocess.run(command, check=True)\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 505, in run\n    with Popen(*popenargs, **kwargs) as process:\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 951, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/home/chetana/anaconda3/lib/python3.9/subprocess.py\", line 1825, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'gcloud'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/cUCoXAwjacbN/data_gee_gridmet_real_time.py\", line 18, in <module>\n    ee.Authenticate()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/__init__.py\", line 104, in Authenticate\n    return oauth.authenticate(authorization_code, quiet, code_verifier, auth_mode,\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 401, in authenticate\n    _load_app_default_credentials(auth_mode == 'gcloud', scopes, quiet)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/oauth.py\", line 302, in _load_app_default_credentials\n    raise Exception('gcloud command not found. ' + tip) from e\nException: gcloud command not found. Please ensure that gcloud is installed.\nMore information: https://developers.google.com/earth-engine/guides/python_install\n\n",
  "history_begin_time" : 1679964684327,
  "history_end_time" : 1679964736206,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "usn4kyAhj6jd",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(\n    submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = findLastStopDate(\n    f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ncount = 0\n\n# Create a list of all cell IDs\ncell_ids = submission_format_df.index.tolist()\n\n# Create a function to fetch data for a single cell ID\ndef fetch_data(current_cell_id):\n    global all_cell_df\n    global count\n    \n    try:\n        print(f\"=> Collected GridMet data for {count} cells\")\n        print(\"collecting \", current_cell_id)\n\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(\n            start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(\n                reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format())\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(\n            ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n        all_cell_df = all_cell_df.append(df.reset_index()[column_list], ignore_index=True)\n        count += 1\n        print(f\"=> Collected GridMet data for {count} cells\")\n    except Exception as e:\n        print(traceback.format_exc())\n        \nnum_threads = 10\nthreads = []\nfor i in range(num_threads):\n    # Create a thread for each chunk of cell IDs\n    thread = threading.Thread(target=lambda cell_ids_chunk: [\n    fetch_data(cell_id) for cell_id in cell_ids_chunk], args=(cell_ids[i::num_threads],))\n    thread.start()\n    threads.append(thread)\n    \nfor thread in threads:\n    thread.join()\n    \nfilename = f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\"\nall_cell_df.to_csv(filename)",
  "history_output" : "usage: conda [-h] [-V] command ...\nconda: error: argument command: invalid choice: 'data_gee_gridmet_real_time.py' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'notices')\n",
  "history_begin_time" : 1679964600881,
  "history_end_time" : 1679964607226,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "bOlmRHGddJBK",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\n'''for current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass'''\ncoords_list = all_cell_coords_pd.apply(lambda row: [row['lon'], row['lat']], axis=1).tolist()\nmultipoint = ee.Geometry.MultiPoint(coords_list)\n\n# filter the VIIRS image collection by location and date\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(multipoint).select(var_list)\n\n# define a new poi_mean function\ndef poi_mean(img):\n  reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=multipoint, scale=1000)\n  img = img.set('date', img.date().format());\n  for var in var_list:\n    column_name = var\n    mean = reducer.get(column_name)\n    img = img.set(column_name,mean)\n  return img\n\n# apply poi_mean to the entire image collection\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# convert the resulting FeatureCollection to a Pandas DataFrame\nnested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\ndf = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n# merge the resulting DataFrame with all_cell_coords_pd\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\ndf = df.reset_index()\ndf = df.merge(all_cell_coords_pd, on='cell_id')\ndf = df.rename(columns={'lat': 'latitude', 'lon': 'longitude'})\n\n\n\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n",
  "history_output" : "today date = 2023-03-19\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/bOlmRHGddJBK/data_gee_gridmet_real_time.py\", line 117, in <module>\n    df = df.merge(all_cell_coords_pd, on='cell_id')\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 9354, in merge\n    return merge(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\", line 107, in merge\n    op = _MergeOperation(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\", line 700, in __init__\n    ) = self._get_merge_keys()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\", line 1110, in _get_merge_keys\n    left_keys.append(left._get_label_or_level_values(lk))\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 1840, in _get_label_or_level_values\n    raise KeyError(key)\nKeyError: 'cell_id'\n",
  "history_begin_time" : 1679463317798,
  "history_end_time" : 1679463346140,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "PXa41PQ56OjL",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\n'''for current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass'''\ncoords_list = all_cell_coords_pd.apply(lambda row: [row['lon'], row['lat']], axis=1).tolist()\nmultipoint = ee.Geometry.MultiPoint(coords_list)\n\n# filter the VIIRS image collection by location and date\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(multipoint).select(var_list)\n\n# define a new poi_mean function\ndef poi_mean(img):\n  reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=multipoint, scale=1000)\n  img = img.set('date', img.date().format());\n  for var in var_list:\n    column_name = var\n    mean = reducer.get(column_name)\n    img = img.set(column_name,mean)\n  return img\n\n# apply poi_mean to the entire image collection\npoi_reduced_imgs = viirs.map(poi_mean)\n\n# convert the resulting FeatureCollection to a Pandas DataFrame\nnested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\ndf = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n# merge the resulting DataFrame with all_cell_coords_pd\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.set_index('date')\ndf = df.merge(all_cell_coords_pd, left_index=True, right_on='cell_id')\n\n# rename the columns as needed\ndf = df.rename(columns={'lat': 'latitude', 'lon': 'longitude'})\n\n\n\ndf.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n",
  "history_output" : "today date = 2023-03-19\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/PXa41PQ56OjL/data_gee_gridmet_real_time.py\", line 116, in <module>\n    df = df.merge(all_cell_coords_pd, left_index=True, right_on='cell_id')\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 9354, in merge\n    return merge(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\", line 107, in merge\n    op = _MergeOperation(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\", line 704, in __init__\n    self._maybe_coerce_merge_keys()\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\", line 1265, in _maybe_coerce_merge_keys\n    raise ValueError(msg)\nValueError: You are trying to merge on datetime64[ns] and object columns. If you wish to proceed you should use pd.concat\n",
  "history_begin_time" : 1679463096028,
  "history_end_time" : 1679463124642,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "1wlSucpKEomj",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n",
  "history_output" : "today date = 2023-03-19\n/home/chetana\n/home/chetana/Documents/GitHub/SnowCast/data/sim_testing/gridmet//all_vars_2023-03-01_2023-03-14.csv\nDONE\n",
  "history_begin_time" : 1679462808005,
  "history_end_time" : 1679462834240,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "S6wWyzHqCq9z",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nimport pandas as pd\nimport os\nimport datetime\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\n# Define function to get data from Google Earth Engine\n# Define a function to get data for a single cell\ndef get_data_for_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # Identify a 1000 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n        # Don't forget we need to call the callback method \"getInfo\" to retrieve the data\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n\n    except Exception as e:\n        print(f\"Failed to collect GridMet data for cell {current_cell_id}: {e}\")\n        return None\n\n# Define a function to collect data for all cells using multithreading\ndef collect_data_for_all_cells():\n    all_cell_dfs = []\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        futures = [executor.submit(get_data_for_cell, current_cell_id) for current_cell_id in submission_format_df.index]\n\n        for future in concurrent.futures.as_completed(futures):\n            df = future.result()\n            if df is not None:\n                all_cell_dfs.append(df)\n\n    all_cell_df = pd.concat(all_cell_dfs)\n\n    return all_cell_df\n\n# Call the function to collect data for all cells using multithreading\nall_cell_df = collect_data_for_all_cells()\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint(\"DONE\")",
  "history_output" : "Fetching credentials using gcloud\n",
  "history_begin_time" : 1679462428860,
  "history_end_time" : 1679462458236,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "5NNjVTGBK5l6",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nimport pandas as pd\nimport os\nimport datetime\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\niter_count = 0\n# Define function to get data from Google Earth Engine\ndef get_data(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        # Identify a 1000 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        # Define a function to calculate mean for each variable over the buffer\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name,mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        # Convert Earth Engine object to a Pandas DataFrame\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(len(var_list)), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\t\tprint(iter_count)\n        iter_count = iter_count + 1\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        pass\n\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n# Use multiprocessing to speed up data retrieval\npool = Pool(processes=cpu_count())\ndf_list = pool.map(get_data, submission_format_df.index)\npool.close()\n\n# Merge all dataframes into one\nall_cell_df = pd.concat(df_list)\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint(\"DONE\")",
  "history_output" : "  File \"/home/chetana/gw-workspace/5NNjVTGBK5l6/data_gee_gridmet_real_time.py\", line 42\n    print(iter_count)\nTabError: inconsistent use of tabs and spaces in indentation\n",
  "history_begin_time" : 1679459712080,
  "history_end_time" : 1679459713200,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "110K1qESucua",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n# define the buffer size in meters\nBUFFER_SIZE = 1000\n\n# define the number of threads to use for parallel processing\nNUM_THREADS = cpu_count()\n\n# define the Earth Engine credentials\nee.Initialize(e.creds())\n\n# define the directory for saving the data\ndfolder = f\"{os.path.expanduser('~')}/Documents/GitHub/SnowCast/data/sim_testing/gridmet\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n\n# define the list of variables to retrieve from Earth Engine\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n# define the function to retrieve data for a single cell\ndef retrieve_data(cell_id):\n  try:\n    # get the coordinates of the cell\n    longitude = all_cell_coords_pd['lon'][cell_id]\n    latitude = all_cell_coords_pd['lat'][cell_id]\n\n    # identify a buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(BUFFER_SIZE)\n\n    # retrieve the image collection for the given time period and location\n    viirs = ee.ImageCollection('IDAHO_EPSCOR/GRIDMET').filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    # define a function to compute the mean values for the variables of interest\n    def compute_means(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format())\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name, mean)\n      return img\n\n    # apply the function to each image in the collection\n    poi_reduced_imgs = viirs.map(compute_means)\n\n    # reduce the collection to a list and convert it to a Pandas dataframe\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), var_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=['date'] + var_list)\n\n    # convert the date column to a Pandas datetime object and set it as the index\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    # add the cell ID and coordinates as columns\n    df['cell_id'] = cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n\n    return df\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    return None\n\n# retrieve the data for all cells using parallel processing\nwith Pool(NUM_THREADS) as pool:\n  dfs = pool.map(retrieve_data, submission_format_df.index)\n\n# concatenate the dataframes for all cells into a single dataframe\nall_cell_df = pd.concat([df for df in dfs if df is not None], ignore_index=True)\n\n# save the dataframe to a CSV file\nfilename = f\"all_vars_{start_date}_{end_date}.csv\"\nfilepath = os.path.join(dfolder, filename)\nall_cell_df.to_csv(filepath)\n\nprint(f\"Data saved to {filepath}\")\nprint(\"DONE\")\n",
  "history_output" : "today date = 2023-03-19\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/110K1qESucua/data_gee_gridmet_real_time.py\", line 72, in <module>\n    dfs = pool.map(retrieve_data, submission_format_df.index)\nNameError: name 'submission_format_df' is not defined\n",
  "history_begin_time" : 1679453635172,
  "history_end_time" : 1679453660898,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "BBySrBFcy2ZG",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nimport pandas as pd\n\n# Authenticate with Earth Engine\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\n# Set up input parameters\nstart_date = '2023-03-01'\nend_date = '2023-03-14'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nbuffer_size_m = 1000\n\n# Set up file paths\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Load cell coordinates\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n# Set up the Point Of Interest (POI) buffer\nbuffer_size_deg = buffer_size_m / 111319.9  # conversion factor from meters to degrees\npoi_buffer = ee.Geometry.Point(all_cell_coords_pd['lon'], all_cell_coords_pd['lat']).buffer(buffer_size_deg)\n\n# Filter the image collection and retrieve data for all cells at once\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi_buffer).select(var_list)\n\ndef process_image(img):\n    \"\"\"Process a single image, returning a list of values for each cell.\"\"\"\n    lon = img.get('longitude').getInfo()\n    lat = img.get('latitude').getInfo()\n    data = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=ee.Geometry.Point(lon, lat), scale=1000).getInfo()\n    row = [img.date().format('YYYY-MM-dd'), lon, lat] + [data.get(var, None) for var in var_list]\n    return row\n\nimage_list = viirs.toList(viirs.size())\nrows = [process_image(ee.Image(image_list.get(i))) for i in range(viirs.size().getInfo())]\n\n# Build the output dataframe and write to file\ncolumn_list = ['date', 'longitude', 'latitude'] + var_list\nall_cell_df = pd.DataFrame(rows, columns=column_list)\nall_cell_df.set_index('date', inplace=True)\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n\nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')",
  "history_output" : "today date = 2023-03-19\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/BBySrBFcy2ZG/data_gee_gridmet_real_time.py\", line 35, in <module>\n    poi_buffer = ee.Geometry.Point(all_cell_coords_pd['lon'], all_cell_coords_pd['lat']).buffer(buffer_size_deg)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 188, in Point\n    Geometry._GetSpecifiedArgs((coords, proj) + args, ('lon', 'lat'),\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 840, in _GetSpecifiedArgs\n    return [i for i in args if i != _UNSPECIFIED]\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 840, in <listcomp>\n    return [i for i in args if i != _UNSPECIFIED]\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 1527, in __nonzero__\n    raise ValueError(\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
  "history_begin_time" : 1679452795906,
  "history_end_time" : 1679452822096,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "eh2fNQEW93eT",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nimport pandas as pd\n\n# Authenticate with Earth Engine\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\n# Set up input parameters\nstart_date = '2023-03-01'\nend_date = '2023-03-14'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nbuffer_size_m = 1000\n\n# Set up file paths\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Load cell coordinates\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n# Set up the Point Of Interest (POI) buffer\nbuffer_size_deg = buffer_size_m / 111319.9  # conversion factor from meters to degrees\npoi_buffer = ee.Geometry.Point(all_cell_coords_pd['lon'], all_cell_coords_pd['lat']).buffer(buffer_size_deg)\n\n# Filter the image collection and retrieve data for all cells at once\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi_buffer).select(var_list)\n\ndef process_image(img):\n    \"\"\"Process a single image, returning a list of values for each cell.\"\"\"\n    lon = img.get('longitude').getInfo()\n    lat = img.get('latitude').getInfo()\n    data = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=ee.Geometry.Point(lon, lat), scale=1000).getInfo()\n    row = [img.date().format('YYYY-MM-dd'), lon, lat] + [data.get(var, None) for var in var_list]\n    return row\n\nimage_list = viirs.toList(viirs.size())\nrows = [process_image(ee.Image(image_list.get(i))) for i in range(viirs.size().getInfo())]\n\n# Build the output dataframe and write to file\ncolumn_list = ['date', 'longitude', 'latitude'] + var_list\nall_cell_df = pd.DataFrame(rows, columns=column_list)\nall_cell_df.set_index('date', inplace=True)\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n\nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')",
  "history_output" : "today date = 2023-03-19\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/eh2fNQEW93eT/data_gee_gridmet_real_time.py\", line 35, in <module>\n    poi_buffer = ee.Geometry.Point(all_cell_coords_pd['lon'], all_cell_coords_pd['lat']).buffer(buffer_size_deg)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 188, in Point\n    Geometry._GetSpecifiedArgs((coords, proj) + args, ('lon', 'lat'),\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 840, in _GetSpecifiedArgs\n    return [i for i in args if i != _UNSPECIFIED]\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/geometry.py\", line 840, in <listcomp>\n    return [i for i in args if i != _UNSPECIFIED]\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 1527, in __nonzero__\n    raise ValueError(\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
  "history_begin_time" : 1679452666744,
  "history_end_time" : 1679452725069,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "EheIez68Kykr",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nimport pandas as pd\n\n# Authenticate with Earth Engine\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\n# Set up input parameters\nstart_date = '2023-03-01'\nend_date = '2023-03-14'\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nbuffer_size_m = 1000\n\n# Set up file paths\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n\n# Load cell coordinates\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n# Set up the Point Of Interest (POI) buffer\nbuffer_size_deg = buffer_size_m / 111319.9  # conversion factor from meters to degrees\npoi_buffer = ee.Geometry.Point(all_cell_coords_pd['lon'], all_cell_coords_pd['lat']).buffer(buffer_size_deg)\n\n# Filter the image collection and retrieve data for all cells at once\nviirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi_buffer).select(var_list)\n\ndef process_image(img):\n    \"\"\"Process a single image, returning a list of values for each cell.\"\"\"\n    lon = img.get('longitude').getInfo()\n    lat = img.get('latitude').getInfo()\n    data = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=ee.Geometry.Point(lon, lat), scale=1000).getInfo()\n    row = [img.date().format('YYYY-MM-dd'), lon, lat] + [data.get(var, None) for var in var_list]\n    return row\n\nimage_list = viirs.toList(viirs.size())\nrows = [process_image(ee.Image(image_list.get(i))) for i in range(viirs.size().getInfo())]\n\n# Build the output dataframe and write to file\ncolumn_list = ['date', 'longitude', 'latitude'] + var_list\nall_cell_df = pd.DataFrame(rows, columns=column_list)\nall_cell_df.set_index('date', inplace=True)\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n\nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')",
  "history_output" : "usage: conda [-h] [-V] command ...\nconda: error: argument command: invalid choice: 'data_gee_gridmet_real_time.py' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'notices')\n",
  "history_begin_time" : 1679452627883,
  "history_end_time" : 1679452633942,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "qlco3nnizri",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : "  File \"data_gee_gridmet_real_time.py\", line 16\n    github_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n                                                      ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1679191258669,
  "history_end_time" : 1679191264548,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "2jifky",
  "indicator" : "Failed"
},{
  "history_id" : "1rPHW6iffgR1",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n'''\n\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        # Get cell coordinates\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # Identify a buffer around our Point Of Interest (POI)\n        buffer_radius = 500  # reduce the buffer size for better performance\n        poi = ee.Geometry.Point(longitude, latitude).buffer(buffer_radius)\n\n        # Get data for the cell and filter by date\n        viirs_all = ee.ImageCollection(product_name).select(var_list).filterBounds(poi)\n        viirs_cell = viirs_all.filterDate(start_date, end_date)\n\n        # Define the function to reduce image to the mean value of pixels within the buffer\n        def poi_mean(img):\n            reducer = ee.Reducer.mean().unweighted().setOutputs(var_list)\n            img = img.set('date', img.date().format());\n            mean_values = img.reduceRegion(reducer=reducer, geometry=poi, scale=1000).values()\n            mean_values_dict = {var_list[i]: mean_values[i] for i in range(len(var_list))}\n            img = img.setMulti(mean_values_dict)\n            return img\n\n        # Reduce the images to mean values within the buffer and convert to a pandas dataframe\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(len(reduced_column_list)), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        # Add cell coordinates and ID to the dataframe\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    # Use Dask to parallelize the processing of cells\n    import dask.dataframe as dd\n    from dask.distributed import Client\n    client = Client()\n\n    # Create a Dask dataframe of cell IDs and process each cell in parallel\n    cell_ids = pd.Series(submission_format_df.index)\n    ddf = dd.from_pandas(cell_ids, npartitions=client.nthreads)\n    dfs = ddf.map(process_cell).compute()\n\n    # Concatenate the resulting dataframes and save to a CSV file\n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\", index=False)\n\n    # Print the path to the saved CSV file and shutdown the Dask client\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    client.shutdown()\n    print('DONE')\n\n# Call the main function\nif __name__ == '__main__':\n    process_all_cells()\n",
  "history_output" : "today date = 2023-03-15\n/home/chetana\ntoday date = 2023-03-15\n/home/chetana\ntoday date = 2023-03-15\n/home/chetana\ntoday date = 2023-03-15\n/home/chetana\ntoday date = 2023-03-15\n/home/chetana\ntoday date = 2023-03-15\n/home/chetana\ntoday date = 2023-03-15\n/home/chetana\ntoday date = 2023-03-15\n/home/chetana\ntoday date = 2023-03-15\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/1rPHW6iffgR1/data_gee_gridmet_real_time.py\", line 218, in <module>\n    process_all_cells()\n  File \"/home/chetana/gw-workspace/1rPHW6iffgR1/data_gee_gridmet_real_time.py\", line 203, in process_all_cells\n    ddf = dd.from_pandas(cell_ids, npartitions=client.nthreads)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/dask/dataframe/io/io.py\", line 236, in from_pandas\n    raise TypeError(\nTypeError: Please provide npartitions as an int, or possibly as None if you specify chunksize.\n",
  "history_begin_time" : 1679166933448,
  "history_end_time" : 1679167039693,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "9WQyMAikfWu0",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()'''\n# Initialize GEE\nimport ee\nee.Initialize()\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        # Compute the mean values for each variable using GEE's built-in functions\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.select(var_list)\n            return img.setMulti(reducer)\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        # Map the nested list obtained from GEE to the desired column names\n        nested_list = poi_reduced_imgs.getInfo()[\"features\"]\n        df = pd.DataFrame(nested_list)\n        df = df[\"properties\"].apply(pd.Series)\n        df = df.rename(columns={\"system:index\": \"date\"})\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    cell_ids = submission_format_df.index.tolist()\n\n    # Use GEE batch processing to process multiple cells at once\n    batch_size = 100\n    for i in range(0, len(cell_ids), batch_size):\n        batch = cell_ids[i:i+batch_size]\n        dfs = ee.batch.Export.table.toDrive(\n            collection=ee.FeatureCollection([ee.Feature(None, {\"id\": cell_id}) for cell_id in batch]),\n            description=\"Batch Export\",\n            folder=dfolder,\n            fileNamePrefix=f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}\",\n            fileFormat=\"CSV\"\n        ).start().result()\n\n        # Read the exported CSV files and concatenate the dataframes\n        batch_dfs = [pd.read_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}.csv\") for i in range(len(batch))]\n        dfs.extend(batch_dfs)\n\n    all_cell_df = pd.concat(dfs)\n\n    # Remove unnecessary data and operations before exporting the data to a CSV file\n    all_cell_df = all_cell_df.rename(columns={\"id\": \"cell_id\"})\n    all_cell_df = all_cell_df.drop(columns=[\".geo\"])\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprocess_all_cells()",
  "history_output" : null,
  "history_begin_time" : 1679166572279,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "tb6UkiJv7iOi",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()'''\n# Initialize GEE\nimport ee\nee.Initialize()\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        # Compute the mean values for each variable using GEE's built-in functions\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.select(var_list)\n            return img.setMulti(reducer)\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        # Map the nested list obtained from GEE to the desired column names\n        nested_list = poi_reduced_imgs.getInfo()[\"features\"]\n        df = pd.DataFrame(nested_list)\n        df = df[\"properties\"].apply(pd.Series)\n        df = df.rename(columns={\"system:index\": \"date\"})\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    cell_ids = submission_format_df.index.tolist()\n\n    # Use GEE batch processing to process multiple cells at once\n    batch_size = 100\n    for i in range(0, len(cell_ids), batch_size):\n        batch = cell_ids[i:i+batch_size]\n        dfs = ee.batch.Export.table.toDrive(\n            collection=ee.FeatureCollection([ee.Feature(None, {\"id\": cell_id}) for cell_id in batch]),\n            description=\"Batch Export\",\n            folder=dfolder,\n            fileNamePrefix=f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}\",\n            fileFormat=\"CSV\"\n        ).start().result()\n\n        # Read the exported CSV files and concatenate the dataframes\n        batch_dfs = [pd.read_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}.csv\") for i in range(len(batch))]\n        dfs.extend(batch_dfs)\n\n    all_cell_df = pd.concat(dfs)\n\n    # Remove unnecessary data and operations before exporting the data to a CSV file\n    all_cell_df = all_cell_df.rename(columns={\"id\": \"cell_id\"})\n    all_cell_df = all_cell_df.drop(columns=[\".geo\"])\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n\n process_all_cells()",
  "history_output" : "  File \"/home/chetana/gw-workspace/tb6UkiJv7iOi/data_gee_gridmet_real_time.py\", line 218\n    process_all_cells()\n                       ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1679166569949,
  "history_end_time" : 1679166573225,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "q4NbuppUVLUe",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()'''\n# Initialize GEE\nimport ee\nee.Initialize()\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        # Compute the mean values for each variable using GEE's built-in functions\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.select(var_list)\n            return img.setMulti(reducer)\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        # Map the nested list obtained from GEE to the desired column names\n        nested_list = poi_reduced_imgs.getInfo()[\"features\"]\n        df = pd.DataFrame(nested_list)\n        df = df[\"properties\"].apply(pd.Series)\n        df = df.rename(columns={\"system:index\": \"date\"})\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    cell_ids = submission_format_df.index.tolist()\n\n    # Use GEE batch processing to process multiple cells at once\n    batch_size = 100\n    for i in range(0, len(cell_ids), batch_size):\n        batch = cell_ids[i:i+batch_size]\n        dfs = ee.batch.Export.table.toDrive(\n            collection=ee.FeatureCollection([ee.Feature(None, {\"id\": cell_id}) for cell_id in batch]),\n            description=\"Batch Export\",\n            folder=dfolder,\n            fileNamePrefix=f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}\",\n            fileFormat=\"CSV\"\n        ).start().result()\n\n        # Read the exported CSV files and concatenate the dataframes\n        batch_dfs = [pd.read_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}.csv\") for i in range(len(batch))]\n        dfs.extend(batch_dfs)\n\n    all_cell_df = pd.concat(dfs)\n\n    # Remove unnecessary data and operations before exporting the data to a CSV file\n    all_cell_df = all_cell_df.rename(columns={\"id\": \"cell_id\"})\n    all_cell_df = all_cell_df.drop(columns=[\".geo\"])\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n\n process_all_cells()",
  "history_output" : "  File \"/home/chetana/gw-workspace/q4NbuppUVLUe/data_gee_gridmet_real_time.py\", line 218\n    process_all_cells()\n                       ^\nIndentationError: unindent does not match any outer indentation level\n",
  "history_begin_time" : 1679166538186,
  "history_end_time" : 1679166539403,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "UWcraFb4j8uR",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()'''\n# Initialize GEE\nimport ee\nee.Initialize()\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        # Compute the mean values for each variable using GEE's built-in functions\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.select(var_list)\n            return img.setMulti(reducer)\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        # Map the nested list obtained from GEE to the desired column names\n        nested_list = poi_reduced_imgs.getInfo()[\"features\"]\n        df = pd.DataFrame(nested_list)\n        df = df[\"properties\"].apply(pd.Series)\n        df = df.rename(columns={\"system:index\": \"date\"})\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    cell_ids = submission_format_df.index.tolist()\n\n    # Use GEE batch processing to process multiple cells at once\n    batch_size = 100\n    for i in range(0, len(cell_ids), batch_size):\n        batch = cell_ids[i:i+batch_size]\n        dfs = ee.batch.Export.table.toDrive(\n            collection=ee.FeatureCollection([ee.Feature(None, {\"id\": cell_id}) for cell_id in batch]),\n            description=\"Batch Export\",\n            folder=dfolder,\n            fileNamePrefix=f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}\",\n            fileFormat=\"CSV\"\n        ).start().result()\n\n        # Read the exported CSV files and concatenate the dataframes\n        batch_dfs = [pd.read_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}.csv\") for i in range(len(batch))]\n        dfs.extend(batch_dfs)\n\n    all_cell_df = pd.concat(dfs)\n\n    # Remove unnecessary data and operations before exporting the data to a CSV file\n    all_cell_df = all_cell_df.rename(columns={\"id\": \"cell_id\"})\n    all_cell_df = all_cell_df.drop(columns=[\".geo\"])\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv)\n\n process_all_cells()",
  "history_output" : "  File \"/home/chetana/gw-workspace/UWcraFb4j8uR/data_gee_gridmet_real_time.py\", line 216\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv)\n                                                                        ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1679166522845,
  "history_end_time" : 1679166524057,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "T4Qdjrq3VSLX",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()'''\n# Initialize GEE\nimport ee\nee.Initialize()\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        # Compute the mean values for each variable using GEE's built-in functions\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.select(var_list)\n            return img.setMulti(reducer)\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        # Map the nested list obtained from GEE to the desired column names\n        nested_list = poi_reduced_imgs.getInfo()[\"features\"]\n        df = pd.DataFrame(nested_list)\n        df = df[\"properties\"].apply(pd.Series)\n        df = df.rename(columns={\"system:index\": \"date\"})\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    cell_ids = submission_format_df.index.tolist()\n\n    # Use GEE batch processing to process multiple cells at once\n    batch_size = 100\n    for i in range(0, len(cell_ids), batch_size):\n        batch = cell_ids[i:i+batch_size]\n        dfs = ee.batch.Export.table.toDrive(\n            collection=ee.FeatureCollection([ee.Feature(None, {\"id\": cell_id}) for cell_id in batch]),\n            description=\"Batch Export\",\n            folder=dfolder,\n            fileNamePrefix=f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}\",\n            fileFormat=\"CSV\"\n        ).start().result()\n\n        # Read the exported CSV files and concatenate the dataframes\n        batch_dfs = [pd.read_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}_{i//batch_size}.csv\") for i in range(len(batch))]\n        dfs.extend(batch_dfs)\n\n    all_cell_df = pd.concat(dfs)\n\n    # Remove unnecessary data and operations before exporting the data to a CSV file\n    all_cell_df = all_cell_df.rename(columns={\"id\": \"cell_id\"})\n    all_cell_df = all_cell_df.drop(columns=[\".geo\"])\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\n\n process_all_cells()",
  "history_output" : "  File \"/home/chetana/gw-workspace/T4Qdjrq3VSLX/data_gee_gridmet_real_time.py\", line 216\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\n                                                                       ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1679166463473,
  "history_end_time" : 1679166464661,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "nA1RBzB18EQD",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : null,
  "history_begin_time" : 1679107043266,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "zTB3xUBV7a58",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nend_date_s = datetime.datetime.strptime('2023-03-14', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : "today date = 2023-03-14\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\n\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nTraceback (most recent call last):\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nhttp.client.RemoteDisconnected: Remote end closed connection without response\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/zTB3xUBV7a58/data_gee_gridmet_real_time.py\", line 121, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 757, in computeValue\n    return _execute_cloud_call(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 328, in _execute_cloud_call\n    return call.execute(num_retries=num_retries)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 900, in execute\n    resp, content = _retry_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/googleapiclient/http.py\", line 177, in _retry_request\n    resp, content = http.request(uri, method, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/google_auth_httplib2.py\", line 218, in request\n    response, content = self.http.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1720, in request\n    (response, content) = self._request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2/__init__.py\", line 1440, in _request\n    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 154, in _conn_request\n    raise _map_exception(e)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/httplib2shim/__init__.py\", line 140, in _conn_request\n    urllib3_response = self.pool.request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 78, in request\n    return self.request_encode_body(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/request.py\", line 170, in request_encode_body\n    return self.urlopen(method, url, **extra_kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/poolmanager.py\", line 376, in urlopen\n    response = conn.urlopen(method, u.request_uri, **kw)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    retries = retries.increment(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 525, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"<string>\", line 3, in raise_from\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n    response.begin()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n    version, status, reason = self._read_status()\n  File \"/home/chetana/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n    raise RemoteDisconnected(\"Remote end closed connection without\"\nurllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\n\n\n\n\n\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n\n\n\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\nFailed:  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
  "history_begin_time" : 1679093401258,
  "history_end_time" : 1679107147320,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "uSvliVA3LylO",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\nend_date_s = datetime.datetime.strptime('{end_date}', '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : "today date = 2023-03-14\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/uSvliVA3LylO/data_gee_gridmet_real_time.py\", line 28, in <module>\n    end_date_s = datetime.datetime.strptime('{end_date}', '%Y-%m-%d')\n  File \"/home/chetana/anaconda3/lib/python3.9/_strptime.py\", line 568, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File \"/home/chetana/anaconda3/lib/python3.9/_strptime.py\", line 349, in _strptime\n    raise ValueError(\"time data %r does not match format %r\" %\nValueError: time data '{end_date}' does not match format '%Y-%m-%d'\n",
  "history_begin_time" : 1679093286891,
  "history_end_time" : 1679093318700,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cQ46c5DubRAz",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\nend_date_s = datetime.datetime.strptime(end_date, '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : "today date = 2023-03-14\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/cQ46c5DubRAz/data_gee_gridmet_real_time.py\", line 28, in <module>\n    end_date_s = datetime.datetime.strptime(end_date, '%Y-%m-%d')\nTypeError: strptime() argument 1 must be str, not datetime.date\n",
  "history_begin_time" : 1679093222025,
  "history_end_time" : 1679093254202,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "jo11Spt0LRgi",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\nend_date_s = datetime.strptime(end_date, '%Y-%m-%d')\nend_date = end_date_s.strftime('%Y-%m-%d')\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : "today date = 2023-03-14\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/jo11Spt0LRgi/data_gee_gridmet_real_time.py\", line 28, in <module>\n    end_date_s = datetime.strptime(end_date, '%Y-%m-%d')\nAttributeError: module 'datetime' has no attribute 'strptime'\n",
  "history_begin_time" : 1679093129502,
  "history_end_time" : 1679093161367,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "6IycKBfmUUEy",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\nes=end_date\nend_date = ee.Date(es)\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : "today date = 2023-03-14\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/6IycKBfmUUEy/data_gee_gridmet_real_time.py\", line 29, in <module>\n    end_date = ee.Date(es)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 32, in __call__\n    return type.__call__(cls, *args, **kwargs)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_date.py\", line 71, in __init__\n    raise ee_exception.EEException(\nee.ee_exception.EEException: Invalid argument specified for ee.Date(): 2023-03-14\n",
  "history_begin_time" : 1679092589234,
  "history_end_time" : 1679092788936,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ykJQ6YEQyUhI",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : "/home/chetana\nTraceback (most recent call last):\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 298, in encode\n    return self._encode_for_cloud_api(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 74, in encode_cloud_value\n    return super(List, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/dictionary.py\", line 74, in encode_cloud_value\n    return super(Dictionary, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 265, in _encode_cloud_object\n    raise ee_exception.EEException('Can\\'t encode object: %s' % obj)\nee.ee_exception.EEException: Can't encode object: 2023-03-14\n\nFailed:  Can't encode object: 2023-03-14\n",
  "history_begin_time" : 1679091772129,
  "history_end_time" : 1679091816776,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "5yuthNbkStkR",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()\n",
  "history_output" : "today date = 2023-03-14\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/5yuthNbkStkR/data_gee_gridmet_real_time.py\", line 118, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 752, in computeValue\n    body = {'expression': serializer.encode(obj, for_cloud_api=True)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 298, in encode\n    return serializer._encode(obj)  # pylint: disable=protected-access\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 80, in _encode\n    return self._encode_for_cloud_api(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 98, in _encode_for_cloud_api\n    value = self._encode_cloud_object(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 74, in encode_cloud_value\n    return super(List, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/dictionary.py\", line 74, in encode_cloud_value\n    return super(Dictionary, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 265, in _encode_cloud_object\n    raise ee_exception.EEException('Can\\'t encode object: %s' % obj)\nee.ee_exception.EEException: Can't encode object: 2023-03-14\n\nFailed:  Can't encode object: 2023-03-14\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/5yuthNbkStkR/data_gee_gridmet_real_time.py\", line 118, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 752, in computeValue\n    body = {'expression': serializer.encode(obj, for_cloud_api=True)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 298, in encode\n    return serializer._encode(obj)  # pylint: disable=protected-access\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 80, in _encode\n    return self._encode_for_cloud_api(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 98, in _encode_for_cloud_api\n    value = self._encode_cloud_object(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 74, in encode_cloud_value\n    return super(List, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/dictionary.py\", line 74, in encode_cloud_value\n    return super(Dictionary, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 265, in _encode_cloud_object\n    raise ee_exception.EEException('Can\\'t encode object: %s' % obj)\nee.ee_exception.EEException: Can't encode object: 2023-03-14\n\nFailed:  Can't encode object: 2023-03-14\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/5yuthNbkStkR/data_gee_gridmet_real_time.py\", line 118, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 752, in computeValue\n    body = {'expression': serializer.encode(obj, for_cloud_api=True)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 298, in encode\n    return serializer._encode(obj)  # pylint: disable=protected-access\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 80, in _encode\n    return self._encode_for_cloud_api(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 98, in _encode_for_cloud_api\n    value = self._encode_cloud_object(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 74, in encode_cloud_value\n    return super(List, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/dictionary.py\", line 74, in encode_cloud_value\n    return super(Dictionary, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 265, in _encode_cloud_object\n    raise ee_exception.EEException('Can\\'t encode object: %s' % obj)\nee.ee_exception.EEException: Can't encode object: 2023-03-14\n\nFailed:  Can't encode object: 2023-03-14\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/5yuthNbkStkR/data_gee_gridmet_real_time.py\", line 118, in process_cell\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 98, in getInfo\n    return data.computeValue(self)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/data.py\", line 752, in computeValue\n    body = {'expression': serializer.encode(obj, for_cloud_api=True)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 298, in encode\n    return serializer._encode(obj)  # pylint: disable=protected-access\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 80, in _encode\n    return self._encode_for_cloud_api(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 98, in _encode_for_cloud_api\n    value = self._encode_cloud_object(obj)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/ee_list.py\", line 74, in encode_cloud_value\n    return super(List, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/dictionary.py\", line 74, in encode_cloud_value\n    return super(Dictionary, self).encode_cloud_value(opt_encoder)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/serializer.py\", line 221, in _encode_cloud_object\n    result = obj.encode_cloud_value(self._encode_cloud_object)\n  File \"/home/chetana/anaconda3/lib/python3.9/site-packages/ee/computedobject.py\", line 152, in encode_cloud_value\n    encoded_args[name] = {'valueReference': encoder(value)}\n",
  "history_begin_time" : 1679091731768,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Running"
},{
  "history_id" : "9iDTlDQrjlW4",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n\n# Define the function for processing a single cell\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd.loc[current_cell_id, 'lon']\n        latitude = all_cell_coords_pd.loc[current_cell_id, 'lat']\n\n        # identify a 500 meter buffer around our Point Of Interest (POI)\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        \n        # get data for the entire area and filter to the specific cell\n        viirs_all = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_list)\n        viirs_cell = viirs_all.filterBounds(poi)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name, mean)\n            return img\n\n        poi_reduced_imgs = viirs_cell.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\n# Define the main function for processing all cells\ndef process_all_cells():\n    with Pool() as p:\n        dfs = p.map(process_cell, submission_format_df.index)\n    \n    dfs = [df for df in dfs if df is not None]\n    all_cell_df = pd.concat(dfs)\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n# Call the main function\nprocess_all_cells()",
  "history_output" : null,
  "history_begin_time" : 1679011083288,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "ltU2LRQpAuuK",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n'''\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\n\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name,mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\nif __name__ == '__main__':\n    pool = Pool(processes=cpu_count()-1)\n    results = pool.map(process_cell, submission_format_df.index)\n    pool.close()\n    pool.join()\n\n    for df in results:\n        if df is not None:\n            all_cell_df = pd.concat([all_cell_df, df])\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n\n",
  "history_output" : null,
  "history_begin_time" : 1679010722120,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "2gkHGTvesAjK",
  "history_input" : "'''from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n'''\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name,mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\nif __name__ == '__main__':\n    pool = Pool(processes=cpu_count()-1)\n    results = pool.map(process_cell, submission_format_df.index)\n    pool.close()\n    pool.join()\n\n    for df in results:\n        if df is not None:\n            all_cell_df = pd.concat([all_cell_df, df])\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n\n",
  "history_output" : "today date = 2023-03-16\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/2gkHGTvesAjK/data_gee_gridmet_real_time.py\", line 163, in <module>\n    pool = Pool(processes=cpu_count()-1)\nNameError: name 'Pool' is not defined\n",
  "history_begin_time" : 1679010424237,
  "history_end_time" : 1679010452738,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "JTfK4gVU6Mjc",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n\n\n\n",
  "history_output" : "today date = 2023-03-16\n/home/chetana\n/home/chetana/Documents/GitHub/SnowCast/data/sim_testing/gridmet//all_vars_2023-03-01_2023-03-16.csv\nDONE\n",
  "history_begin_time" : 1679010332726,
  "history_end_time" : 1679010362480,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "K9wrnHNPSeh5",
  "history_input" : "'''from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n    \n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')'''\n\n\nimport traceback\nimport eeauth as ee\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name,mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\nif __name__ == '__main__':\n    pool = Pool(processes=cpu_count()-1)\n    results = pool.map(process_cell, submission_format_df.index)\n    pool.close()\n    pool.join()\n\n    for df in results:\n        if df is not None:\n            all_cell_df = pd.concat([all_cell_df, df])\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1679010331420,
  "history_end_time" : 1679010332753,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "UsqMOQIp69c7",
  "history_input" : "'''from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n    \n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')'''\n\n\nimport traceback\nimport eeauth as ee\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name,mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\nif __name__ == '__main__':\n    pool = Pool(processes=cpu_count()-1)\n    results = pool.map(process_cell, submission_format_df.index)\n    pool.close()\n    pool.join()\n\n    for df in results:\n        if df is not None:\n            all_cell_df = pd.concat([all_cell_df, df])\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n\n\n\n",
  "history_output" : "today date = 2023-03-16\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/UsqMOQIp69c7/data_gee_gridmet_real_time.py\", line 100, in <module>\n    ee.Initialize(e.creds())\nAttributeError: module 'eeauth' has no attribute 'Initialize'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/UsqMOQIp69c7/data_gee_gridmet_real_time.py\", line 102, in <module>\n    ee.Authenticate()\nAttributeError: module 'eeauth' has no attribute 'Authenticate'\n",
  "history_begin_time" : 1679010271355,
  "history_end_time" : 1679010298681,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "C9psG0cPI1ya",
  "history_input" : "'''from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n    \n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')'''\n\n\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name,mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\nif __name__ == '__main__':\n    pool = Pool(processes=cpu_count()-1)\n    results = pool.map(process_cell, submission_format_df.index)\n    pool.close()\n    pool.join()\n\n    for df in results:\n        if df is not None:\n            all_cell_df = pd.concat([all_cell_df, df])\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n\n\n\n",
  "history_output" : "today date = 2023-03-16\n/home/chetana\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/C9psG0cPI1ya/data_gee_gridmet_real_time.py\", line 100, in <module>\n    ee.Initialize(e.creds())\nNameError: name 'ee' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/C9psG0cPI1ya/data_gee_gridmet_real_time.py\", line 102, in <module>\n    ee.Authenticate()\nNameError: name 'ee' is not defined\n",
  "history_begin_time" : 1679010182685,
  "history_end_time" : 1679010249128,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "0cG8lt4uVmnd",
  "history_input" : "''from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n    \n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')'''\n\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom multiprocessing import Pool, cpu_count\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n    os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns=column_list)\n\ndef process_cell(current_cell_id):\n    try:\n        longitude = all_cell_coords_pd['lon'][current_cell_id]\n        latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n        poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n        viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n        def poi_mean(img):\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            img = img.set('date', img.date().format());\n            for var in var_list:\n                column_name = var\n                mean = reducer.get(column_name)\n                img = img.set(column_name,mean)\n            return img\n\n        poi_reduced_imgs = viirs.map(poi_mean)\n\n        nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n        df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n\n        df['cell_id'] = current_cell_id\n        df['latitude'] = latitude\n        df['longitude'] = longitude\n\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n        print(\"Failed: \", e)\n        return None\n\nif __name__ == '__main__':\n    pool = Pool(processes=cpu_count()-1)\n    results = pool.map(process_cell, submission_format_df.index)\n    pool.close()\n    pool.join()\n\n    for df in results:\n        if df is not None:\n            all_cell_df = pd.concat([all_cell_df, df])\n\n    all_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\n    print('DONE')\n\n\n\n\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/0cG8lt4uVmnd/data_gee_gridmet_real_time.py\", line 1\n    ''from snowcast_utils import *\n      ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1679010084769,
  "history_end_time" : 1679010087871,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "aNV1Gy5mdbga",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")\nprint('DONE')\n\n\n\n\n",
  "history_output" : "today date = 2023-03-15\n/home/chetana\n/home/chetana/Documents/GitHub/SnowCast/data/sim_testing/gridmet//all_vars_2023-03-01_2023-03-15.csv\nDONE\n",
  "history_begin_time" : 1678888700377,
  "history_end_time" : 1678888735163,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "eLsFR2Yd90nz",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n\n",
  "history_output" : "today date = 2023-03-15\n/home/chetana\nDONE\n",
  "history_begin_time" : 1678888592426,
  "history_end_time" : 1678888620220,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "UQazT0taWzsH",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    break\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n\n",
  "history_output" : null,
  "history_begin_time" : 1678888586646,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "3vCDnEvPsJcc",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n\n",
  "history_output" : "today date = 2023-03-15\n/home/chetana\n",
  "history_begin_time" : 1678888245525,
  "history_end_time" : 1678888586666,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "98jfb32za9r",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n\n",
  "history_output" : "today date = 2023-03-15\n/home/chetana\n",
  "history_begin_time" : 1678887944964,
  "history_end_time" : 1678888533109,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "YoMmt6J7LmjI",
  "history_input" : "from snowcast_utils import *\nimport traceback\nimport eeauth as e\nfrom snowcast_utils import test_start_date as start_date, test_end_date as end_date\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n\n# start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n# end_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count += 1\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n\n",
  "history_output" : "today date = 2023-03-15\n/home/chetana\n",
  "history_begin_time" : 1678885084678,
  "history_end_time" : 1678888245547,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "enqh4xlkon9",
  "history_input" : "null",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/enqh4xlkon9/data_gee_gridmet_real_time.py\", line 1, in <module>\n    null\nNameError: name 'null' is not defined\n",
  "history_begin_time" : 1678884592177,
  "history_end_time" : 1678884986356,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "hpcz2wvy6wz",
  "history_input" : "null",
  "history_output" : "Traceback (most recent call last):\n",
  "history_begin_time" : 1678884241455,
  "history_end_time" : 1678884438328,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "tGrcRyp7TAxv",
  "history_input" : "null",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/tGrcRyp7TAxv/data_gee_gridmet_real_time.py\", line 1, in <module>\n    null\nNameError: name 'null' is not defined\n",
  "history_begin_time" : 1678884171080,
  "history_end_time" : 1678884172343,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "suehrkspxn8",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-15\n/home/chetana\n",
  "history_begin_time" : 1678883377994,
  "history_end_time" : 1678883775439,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "phf4hczdwc0",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-14\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678756814033,
  "history_end_time" : 1678756812645,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Running"
},{
  "history_id" : "stkd509vod2",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1678756683911,
  "history_end_time" : 1678756694595,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Failed"
},{
  "history_id" : "74kbn1eaqjl",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678749632389,
  "history_end_time" : 1678749936005,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "v90ym2y9bx3",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1678748547029,
  "history_end_time" : 1678748550741,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "d92n0kodbby",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678747246154,
  "history_end_time" : 1678747298916,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "ss9dlqd5zc7",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678746481648,
  "history_end_time" : 1678746793031,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "rfixxvm3uti",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n",
  "history_begin_time" : 1678743869419,
  "history_end_time" : 1678744167082,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "t4y395u8afx",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n",
  "history_begin_time" : 1678743629903,
  "history_end_time" : 1678743637885,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "1w1fl63oo95",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n",
  "history_begin_time" : 1678743145298,
  "history_end_time" : 1678743615532,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "l3l42719irn",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678742585186,
  "history_end_time" : 1678742583845,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Running"
},{
  "history_id" : "m0dj1c9mhze",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678742210200,
  "history_end_time" : 1678742571507,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "tu32v0wd9lc",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : 1678738747362,
  "history_end_time" : 1678738747362,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Running"
},{
  "history_id" : "alfyrlaegti",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678725457439,
  "history_end_time" : 1678725455516,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Running"
},{
  "history_id" : "e95cyizlh0p",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-13\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678723156063,
  "history_end_time" : 1678725408347,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "vv631hshxmt",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-12\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678649015033,
  "history_end_time" : 1678649554003,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "2wwtrzdz9zj",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-12\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678648420069,
  "history_end_time" : 1678648418701,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Running"
},{
  "history_id" : "4bkpoti0dpi",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-11\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678564569173,
  "history_end_time" : 1678564567765,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Running"
},{
  "history_id" : "k8x2hn8mvyl",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-11\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678564540104,
  "history_end_time" : 1678564538635,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Running"
},{
  "history_id" : "rb5azwdcnfd",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-11\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678557923933,
  "history_end_time" : 1678557923646,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Running"
},{
  "history_id" : "m3lmy5ozdhw",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-11\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678557706480,
  "history_end_time" : 1678557898790,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "m8qiyiq966m",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-11\n/home/chetana\n",
  "history_begin_time" : 1678497028911,
  "history_end_time" : 1678497042885,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "armq7jm2ao9",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-09\n/home/chetana\n",
  "history_begin_time" : 1678330214710,
  "history_end_time" : 1678330227060,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "utrv7uzf9ld",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-09\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678326966996,
  "history_end_time" : 1694185584773,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "q8pbv8epwp4",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-08\n/home/chetana\n",
  "history_begin_time" : 1678312068380,
  "history_end_time" : 1678312076830,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "wilxukedzfc",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-08\n/home/chetana\n",
  "history_begin_time" : 1678312031596,
  "history_end_time" : 1678312065295,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "oj41r9jzzjt",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-08\n/home/chetana\n",
  "history_begin_time" : 1678312002133,
  "history_end_time" : 1694185586238,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "w9qwvvohk5d",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-08\n/home/chetana\n",
  "history_begin_time" : 1678283570153,
  "history_end_time" : 1678283603956,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "z6shot26hzx",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-08\n/home/chetana\n",
  "history_begin_time" : 1678242412727,
  "history_end_time" : 1694185588506,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "jwa24t3z8cn",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-07\n/home/chetana\n",
  "history_begin_time" : 1678201952472,
  "history_end_time" : 1678201981484,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "12gmotm7blv",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-07\n/home/chetana\n",
  "history_begin_time" : 1678201381438,
  "history_end_time" : 1678201516415,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "hvk8qv0108y",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-07\n/home/chetana\n",
  "history_begin_time" : 1678155226341,
  "history_end_time" : 1678155254650,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Done"
},{
  "history_id" : "tkh4zkq4tsu",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-06\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1678144784419,
  "history_end_time" : 1678154846233,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fCGUJjd7H4OD",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : "today date = 2023-03-04\n/home/chetana\n",
  "history_begin_time" : 1677956517969,
  "history_end_time" : 1677956530427,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "YBCUn4sPLHRV",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\n\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nprint('DONE')\n\n\n\n",
  "history_output" : null,
  "history_begin_time" : 1677956512783,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "dE4UwI6zIrFk",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\nprint('--------------------------------')\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n\n",
  "history_output" : "today date = 2023-03-04\n/home/chetana\n/home/chetana\n--------------------------------\n(20759, 25)\n",
  "history_begin_time" : 1677954868928,
  "history_end_time" : 1677954960078,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Jq57NFVz5S2U",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n\n",
  "history_output" : "today date = 2023-03-04\n/home/chetana\n",
  "history_begin_time" : 1677954843617,
  "history_end_time" : 1677954868941,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ZRsZbAMg3R7J",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n\n",
  "history_output" : "today date = 2023-03-04\n/home/chetana\n",
  "history_begin_time" : 1677954819471,
  "history_end_time" : 1677954843632,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kfub1xvp9hi",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n\n",
  "history_output" : "today date = 2023-03-03\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1677858834302,
  "history_end_time" : 1694185596810,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "vl8r9tjxk2w",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\") #uncomment to print\n    #print(\"collecting \", current_cell_id) #uncomment to print\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n\n",
  "history_output" : "today date = 2023-03-03\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1677809469964,
  "history_end_time" : 1694185620802,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "kotFVMxGqxn9",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\")\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n\n",
  "history_output" : "today date = 2023-03-03\n/home/chetana\n/home/chetana\n(20759, 25)\n",
  "history_begin_time" : 1677801759294,
  "history_end_time" : 1677804339842,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "naZu7zJhixmb",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\")\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n\n",
  "history_output" : null,
  "history_begin_time" : 1677801747040,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : null
},{
  "history_id" : "38ChWBV5SAFN",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\")\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n\n",
  "history_output" : "today date = 2023-03-02\n/home/chetana\n/home/chetana\n(20759, 25)\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  4.213151\n2023-02-25 06:00:00  NaN  ...  5.706575\n2023-02-26 06:00:00  NaN  ...  4.000000\n2023-02-27 06:00:00  NaN  ...  3.800000\n2023-02-28 06:00:00  NaN  ...  4.500000\n\n[1249 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  5.700000\n2023-02-25 06:00:00  NaN  ...  5.504515\n2023-02-26 06:00:00  NaN  ...  4.500000\n2023-02-27 06:00:00  NaN  ...  5.300000\n2023-02-28 06:00:00  NaN  ...  5.400000\n\n[2498 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.900000\n2023-02-25 06:00:00  NaN  ...  9.800000\n2023-02-26 06:00:00  NaN  ...  3.900000\n2023-02-27 06:00:00  NaN  ...  7.300000\n2023-02-28 06:00:00  NaN  ...  7.000000\n\n[3747 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  9.547553\n2023-02-25 06:00:00  NaN  ...  9.400000\n2023-02-26 06:00:00  NaN  ...  3.700000\n2023-02-27 06:00:00  NaN  ...  7.300000\n2023-02-28 06:00:00  NaN  ...  6.700000\n\n[4996 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  6.600000\n2023-02-25 06:00:00  NaN  ...  7.600000\n2023-02-26 06:00:00  NaN  ...  5.300000\n2023-02-27 06:00:00  NaN  ...  3.700000\n2023-02-28 06:00:00  NaN  ...  5.100000\n\n[6245 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  5.800000\n2023-02-25 06:00:00  NaN  ...  6.300000\n2023-02-26 06:00:00  NaN  ...  4.700000\n2023-02-27 06:00:00  NaN  ...  4.900000\n2023-02-28 06:00:00  NaN  ...  5.400000\n\n[7494 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  9.000000\n2023-02-25 06:00:00  NaN  ...  6.400000\n2023-02-26 06:00:00  NaN  ...  6.200000\n2023-02-27 06:00:00  NaN  ...  7.000000\n2023-02-28 06:00:00  NaN  ...  6.900000\n\n[8743 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  6.314271\n2023-02-25 06:00:00  NaN  ...  7.507136\n2023-02-26 06:00:00  NaN  ...  3.200000\n2023-02-27 06:00:00  NaN  ...  7.296432\n2023-02-28 06:00:00  NaN  ...  5.100000\n\n[9992 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.730678\n2023-02-25 06:00:00  NaN  ...  7.861357\n2023-02-26 06:00:00  NaN  ...  5.792331\n2023-02-27 06:00:00  NaN  ...  7.800000\n2023-02-28 06:00:00  NaN  ...  7.400000\n\n[11241 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.100000\n2023-02-25 06:00:00  NaN  ...  9.800000\n2023-02-26 06:00:00  NaN  ...  3.700000\n2023-02-27 06:00:00  NaN  ...  7.100000\n2023-02-28 06:00:00  NaN  ...  6.400000\n\n[12490 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.793028\n2023-02-25 06:00:00  NaN  ...  9.800000\n2023-02-26 06:00:00  NaN  ...  3.900000\n2023-02-27 06:00:00  NaN  ...  7.300000\n2023-02-28 06:00:00  NaN  ...  7.100000\n\n[13739 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.084262\n2023-02-25 06:00:00  NaN  ...  6.126393\n2023-02-26 06:00:00  NaN  ...  6.300000\n2023-02-27 06:00:00  NaN  ...  7.000000\n2023-02-28 06:00:00  NaN  ...  6.900000\n\n[14988 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.572800\n2023-02-25 06:00:00  NaN  ...  8.020079\n2023-02-26 06:00:00  NaN  ...  5.000000\n2023-02-27 06:00:00  NaN  ...  2.352720\n2023-02-28 06:00:00  NaN  ...  4.800000\n\n[16237 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.309312\n2023-02-25 06:00:00  NaN  ...  8.109312\n2023-02-26 06:00:00  NaN  ...  5.195344\n2023-02-27 06:00:00  NaN  ...  3.495344\n2023-02-28 06:00:00  NaN  ...  4.895344\n\n[17486 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.659558\n2023-02-25 06:00:00  NaN  ...  7.578674\n2023-02-26 06:00:00  NaN  ...  6.200000\n2023-02-27 06:00:00  NaN  ...  6.900000\n2023-02-28 06:00:00  NaN  ...  6.800000\n\n[18735 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.500000\n2023-02-25 06:00:00  NaN  ...  8.300000\n2023-02-26 06:00:00  NaN  ...  5.100000\n2023-02-27 06:00:00  NaN  ...  3.400000\n2023-02-28 06:00:00  NaN  ...  4.800000\n\n[19984 rows x 12 columns]\n                    date  ...         vs\n2019-09-29 06:00:00  NaN  ...   5.606575\n2019-09-30 06:00:00  NaN  ...   2.106575\n2019-10-01 06:00:00  NaN  ...   1.800000\n2019-10-02 06:00:00  NaN  ...   4.106575\n2019-10-03 06:00:00  NaN  ...   3.100000\n...                  ...  ...        ...\n2023-02-24 06:00:00  NaN  ...  10.337379\n2023-02-25 06:00:00  NaN  ...   7.707476\n2023-02-26 06:00:00  NaN  ...   3.600000\n2023-02-27 06:00:00  NaN  ...   8.000000\n2023-02-28 06:00:00  NaN  ...   8.107476\n\n[21233 rows x 12 columns]\n                    date  ...         vs\n2019-09-29 06:00:00  NaN  ...   5.606575\n2019-09-30 06:00:00  NaN  ...   2.106575\n2019-10-01 06:00:00  NaN  ...   1.800000\n2019-10-02 06:00:00  NaN  ...   4.106575\n2019-10-03 06:00:00  NaN  ...   3.100000\n...                  ...  ...        ...\n2023-02-24 06:00:00  NaN  ...  11.593643\n2023-02-25 06:00:00  NaN  ...  10.582745\n2023-02-26 06:00:00  NaN  ...   4.500000\n2023-02-27 06:00:00  NaN  ...   2.887689\n2023-02-28 06:00:00  NaN  ...   5.736731\n\n[22482 rows x 12 columns]\n                    date  ...         vs\n2019-09-29 06:00:00  NaN  ...   5.606575\n2019-09-30 06:00:00  NaN  ...   2.106575\n2019-10-01 06:00:00  NaN  ...   1.800000\n2019-10-02 06:00:00  NaN  ...   4.106575\n2019-10-03 06:00:00  NaN  ...   3.100000\n...                  ...  ...        ...\n2023-02-24 06:00:00  NaN  ...  11.379760\n2023-02-25 06:00:00  NaN  ...  10.265803\n2023-02-26 06:00:00  NaN  ...   4.400000\n2023-02-27 06:00:00  NaN  ...   2.693121\n2023-02-28 06:00:00  NaN  ...   5.599701\n\n[23731 rows x 12 columns]\n                    date  ...         vs\n2019-09-29 06:00:00  NaN  ...   5.606575\n2019-09-30 06:00:00  NaN  ...   2.106575\n2019-10-01 06:00:00  NaN  ...   1.800000\n2019-10-02 06:00:00  NaN  ...   4.106575\n2019-10-03 06:00:00  NaN  ...   3.100000\n...                  ...  ...        ...\n2023-02-24 06:00:00  NaN  ...  12.204696\n2023-02-25 06:00:00  NaN  ...  11.257043\n2023-02-26 06:00:00  NaN  ...   4.452348\n2023-02-27 06:00:00  NaN  ...   2.500000\n2023-02-28 06:00:00  NaN  ...   5.300000\n\n[24980 rows x 12 columns]\n                    date  ...         vs\n2019-09-29 06:00:00  NaN  ...   5.606575\n2019-09-30 06:00:00  NaN  ...   2.106575\n2019-10-01 06:00:00  NaN  ...   1.800000\n2019-10-02 06:00:00  NaN  ...   4.106575\n2019-10-03 06:00:00  NaN  ...   3.100000\n...                  ...  ...        ...\n2023-02-24 06:00:00  NaN  ...  10.147420\n2023-02-25 06:00:00  NaN  ...  10.147420\n2023-02-26 06:00:00  NaN  ...   5.500000\n2023-02-27 06:00:00  NaN  ...   2.586855\n2023-02-28 06:00:00  NaN  ...   4.600000\n\n[26229 rows x 12 columns]\n                    date  ...         vs\n2019-09-29 06:00:00  NaN  ...   5.606575\n2019-09-30 06:00:00  NaN  ...   2.106575\n2019-10-01 06:00:00  NaN  ...   1.800000\n2019-10-02 06:00:00  NaN  ...   4.106575\n2019-10-03 06:00:00  NaN  ...   3.100000\n...                  ...  ...        ...\n2023-02-24 06:00:00  NaN  ...  10.074143\n2023-02-25 06:00:00  NaN  ...   6.778453\n2023-02-26 06:00:00  NaN  ...   3.600000\n2023-02-27 06:00:00  NaN  ...   7.800000\n2023-02-28 06:00:00  NaN  ...   7.895691\n\n[27478 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.100000\n2023-02-25 06:00:00  NaN  ...  5.795682\n2023-02-26 06:00:00  NaN  ...  4.900000\n2023-02-27 06:00:00  NaN  ...  2.400000\n2023-02-28 06:00:00  NaN  ...  4.904318\n\n[28727 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  4.716565\n2023-02-25 06:00:00  NaN  ...  7.593838\n2023-02-26 06:00:00  NaN  ...  3.100000\n2023-02-27 06:00:00  NaN  ...  7.007576\n2023-02-28 06:00:00  NaN  ...  4.607576\n\n[29976 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.838118\n2023-02-25 06:00:00  NaN  ...  8.590495\n2023-02-26 06:00:00  NaN  ...  5.047624\n2023-02-27 06:00:00  NaN  ...  7.900000\n2023-02-28 06:00:00  NaN  ...  7.600000\n\n[31225 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.500000\n2023-02-25 06:00:00  NaN  ...  5.800000\n2023-02-26 06:00:00  NaN  ...  6.200000\n2023-02-27 06:00:00  NaN  ...  6.800000\n2023-02-28 06:00:00  NaN  ...  6.700000\n\n[32474 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  9.014189\n2023-02-25 06:00:00  NaN  ...  6.214189\n2023-02-26 06:00:00  NaN  ...  5.004730\n2023-02-27 06:00:00  NaN  ...  7.800000\n2023-02-28 06:00:00  NaN  ...  7.595270\n\n[33723 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  3.900000\n2023-02-25 06:00:00  NaN  ...  6.700000\n2023-02-26 06:00:00  NaN  ...  3.300000\n2023-02-27 06:00:00  NaN  ...  7.300000\n2023-02-28 06:00:00  NaN  ...  5.500000\n\n[34972 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  9.900000\n2023-02-25 06:00:00  NaN  ...  8.400000\n2023-02-26 06:00:00  NaN  ...  5.700000\n2023-02-27 06:00:00  NaN  ...  7.700000\n2023-02-28 06:00:00  NaN  ...  7.400000\n\n[36221 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  9.045233\n2023-02-25 06:00:00  NaN  ...  9.351556\n2023-02-26 06:00:00  NaN  ...  5.347568\n2023-02-27 06:00:00  NaN  ...  7.800000\n2023-02-28 06:00:00  NaN  ...  7.500000\n\n[37470 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.200000\n2023-02-25 06:00:00  NaN  ...  9.300000\n2023-02-26 06:00:00  NaN  ...  3.500000\n2023-02-27 06:00:00  NaN  ...  3.700000\n2023-02-28 06:00:00  NaN  ...  4.652372\n\n[38719 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.495146\n2023-02-25 06:00:00  NaN  ...  6.390291\n2023-02-26 06:00:00  NaN  ...  6.200000\n2023-02-27 06:00:00  NaN  ...  7.052427\n2023-02-28 06:00:00  NaN  ...  6.952427\n\n[39968 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.895192\n2023-02-25 06:00:00  NaN  ...  6.000000\n2023-02-26 06:00:00  NaN  ...  6.100000\n2023-02-27 06:00:00  NaN  ...  7.252404\n2023-02-28 06:00:00  NaN  ...  7.000000\n\n[41217 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  5.400000\n2023-02-25 06:00:00  NaN  ...  7.000000\n2023-02-26 06:00:00  NaN  ...  3.400000\n2023-02-27 06:00:00  NaN  ...  7.500000\n2023-02-28 06:00:00  NaN  ...  5.900000\n\n[42466 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  6.748723\n2023-02-25 06:00:00  NaN  ...  4.231631\n2023-02-26 06:00:00  NaN  ...  6.300000\n2023-02-27 06:00:00  NaN  ...  7.200000\n2023-02-28 06:00:00  NaN  ...  7.000000\n\n[43715 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  5.723892\n2023-02-25 06:00:00  NaN  ...  5.913487\n2023-02-26 06:00:00  NaN  ...  4.500000\n2023-02-27 06:00:00  NaN  ...  5.295568\n2023-02-28 06:00:00  NaN  ...  5.423892\n\n[44964 rows x 12 columns]\n                    date  ...         vs\n2019-09-29 06:00:00  NaN  ...   5.606575\n2019-09-30 06:00:00  NaN  ...   2.106575\n2019-10-01 06:00:00  NaN  ...   1.800000\n2019-10-02 06:00:00  NaN  ...   4.106575\n2019-10-03 06:00:00  NaN  ...   3.100000\n...                  ...  ...        ...\n2023-02-24 06:00:00  NaN  ...  10.781518\n2023-02-25 06:00:00  NaN  ...   7.781518\n2023-02-26 06:00:00  NaN  ...   3.581517\n2023-02-27 06:00:00  NaN  ...   8.000000\n2023-02-28 06:00:00  NaN  ...   8.200000\n\n[46213 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.230435\n2023-02-25 06:00:00  NaN  ...  8.960474\n2023-02-26 06:00:00  NaN  ...  5.147628\n2023-02-27 06:00:00  NaN  ...  7.811759\n2023-02-28 06:00:00  NaN  ...  7.562945\n\n[47462 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.791876\n2023-02-25 06:00:00  NaN  ...  9.707021\n2023-02-26 06:00:00  NaN  ...  3.900000\n2023-02-27 06:00:00  NaN  ...  7.400000\n2023-02-28 06:00:00  NaN  ...  7.200000\n\n[48711 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  7.877833\n2023-02-25 06:00:00  NaN  ...  4.986699\n2023-02-26 06:00:00  NaN  ...  3.700000\n2023-02-27 06:00:00  NaN  ...  7.800000\n2023-02-28 06:00:00  NaN  ...  7.700000\n\n[49960 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.894933\n2023-02-25 06:00:00  NaN  ...  8.203537\n2023-02-26 06:00:00  NaN  ...  6.100000\n2023-02-27 06:00:00  NaN  ...  7.000000\n2023-02-28 06:00:00  NaN  ...  6.800000\n\n[51209 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  9.007915\n2023-02-25 06:00:00  NaN  ...  6.015830\n2023-02-26 06:00:00  NaN  ...  6.200000\n2023-02-27 06:00:00  NaN  ...  6.900000\n2023-02-28 06:00:00  NaN  ...  6.900000\n\n[52458 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  5.600000\n2023-02-25 06:00:00  NaN  ...  8.700000\n2023-02-26 06:00:00  NaN  ...  3.600000\n2023-02-27 06:00:00  NaN  ...  7.100000\n2023-02-28 06:00:00  NaN  ...  6.300000\n\n[53707 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.943615\n2023-02-25 06:00:00  NaN  ...  5.843615\n2023-02-26 06:00:00  NaN  ...  3.700000\n2023-02-27 06:00:00  NaN  ...  7.800000\n2023-02-28 06:00:00  NaN  ...  7.710314\n\n[54956 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.951873\n2023-02-25 06:00:00  NaN  ...  7.173967\n2023-02-26 06:00:00  NaN  ...  6.100000\n2023-02-27 06:00:00  NaN  ...  7.100000\n2023-02-28 06:00:00  NaN  ...  6.900000\n\n[56205 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  8.734774\n2023-02-25 06:00:00  NaN  ...  6.930452\n2023-02-26 06:00:00  NaN  ...  6.100000\n2023-02-27 06:00:00  NaN  ...  7.100000\n2023-02-28 06:00:00  NaN  ...  6.900000\n\n[57454 rows x 12 columns]\n                    date  ...        vs\n2019-09-29 06:00:00  NaN  ...  5.606575\n2019-09-30 06:00:00  NaN  ...  2.106575\n2019-10-01 06:00:00  NaN  ...  1.800000\n2019-10-02 06:00:00  NaN  ...  4.106575\n2019-10-03 06:00:00  NaN  ...  3.100000\n...                  ...  ...       ...\n2023-02-24 06:00:00  NaN  ...  2.998502\n2023-02-25 06:00:00  NaN  ...  5.370787\n2023-02-26 06:00:00  NaN  ...  3.709457\n2023-02-27 06:00:00  NaN  ...  4.692696\n2023-02-28 06:00:00  NaN  ...  5.805805\n\n[58703 rows x 12 columns]\n",
  "history_begin_time" : 1677801233594,
  "history_end_time" : 1677801747059,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "NHJYOktBtnWE",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\")\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n\n\n",
  "history_output" : "today date = 2023-03-02\n/home/chetana\n/home/chetana\n(20759, 25)\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/NHJYOktBtnWE/data_gee_gridmet_real_time.py\", line 46, in <module>\n    start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n  File \"/home/chetana/gw-workspace/NHJYOktBtnWE/snowcast_utils.py\", line 78, in findLastStopDate\n    latest_date = get_latest_date_from_an_array(date_list, data_format)\n  File \"/home/chetana/gw-workspace/NHJYOktBtnWE/snowcast_utils.py\", line 64, in get_latest_date_from_an_array\n    return max(arr, key=lambda x: datetime.datetime.strptime(x, date_format))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1677800987919,
  "history_end_time" : 1677801017620,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "Dewn0IAB4EWK",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(f\"=> Collected GridMet data for {count} cells\")\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n\n\n",
  "history_output" : "today date = 2023-03-02\n(20759, 25)\n  File \"/home/chetana/gw-workspace/Dewn0IAB4EWK/data_gee_gridmet_real_time.py\", line 46, in <module>\n  File \"/home/chetana/gw-workspace/Dewn0IAB4EWK/snowcast_utils.py\", line 78, in findLastStopDate\n  File \"/home/chetana/gw-workspace/Dewn0IAB4EWK/snowcast_utils.py\", line 64, in get_latest_date_from_an_array\n    return max(arr, key=lambda x: datetime.datetime.strptime(x, date_format))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1677800931476,
  "history_end_time" : 1677800959039,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "cRlGLOwd7s8T",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\n'''\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date'''\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\nprint(all_cell_df)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    print(all_cell_df)\n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date'\n\n",
  "history_output" : "  File \"/home/chetana/gw-workspace/cRlGLOwd7s8T/data_gee_gridmet_real_time.py\", line 129\n    end_date = test_end_date'\n                             ^\nSyntaxError: EOL while scanning string literal\n",
  "history_begin_time" : 1677800448721,
  "history_end_time" : 1677800450091,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ObfY9oug8zkS",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\nprint(all_cell_coords_pd)\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2023-03-02\n/home/chetana\n/home/chetana\n                                            lat         lon\ncell_id                                                    \n0001daba-dd41-4787-84ab-f7956f7829a8  43.510190 -109.318084\n0006d245-64c1-475f-a989-85f4787bae6a  40.329588 -105.949401\n000a9004-1462-4b8c-96ee-0601aff0fdf7  37.734259 -119.738541\n000ba8d9-d6d5-48da-84a2-1fa54951fae1  37.435274 -119.325316\n00118c37-43a4-4888-a95a-99a85218fda6  39.592862 -105.679907\n...                                         ...         ...\nffefd240-fae9-4ab2-8821-75ea2bad321d  40.089477 -120.906351\nfff08871-267e-466b-997b-3ceb3d420e75  37.648958 -119.522946\nfff54897-9676-4f7e-8e68-da7457517b7b  38.046192 -119.478030\nfffdfd4a-b421-4766-9df6-935ba7dfe029  37.776874 -108.042476\nfffeeca9-73ba-4e6c-a26e-af565d738d4f  37.826559 -108.249088\n\n[20759 rows x 2 columns]\n(20759, 25)\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/ObfY9oug8zkS/data_gee_gridmet_real_time.py\", line 46, in <module>\n    start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n  File \"/home/chetana/gw-workspace/ObfY9oug8zkS/snowcast_utils.py\", line 78, in findLastStopDate\n    latest_date = get_latest_date_from_an_array(date_list, data_format)\n  File \"/home/chetana/gw-workspace/ObfY9oug8zkS/snowcast_utils.py\", line 64, in get_latest_date_from_an_array\n    return max(arr, key=lambda x: datetime.datetime.strptime(x, date_format))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1677800165761,
  "history_end_time" : 1677800193079,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "MvnL5a8MRg11",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2023-03-02\n/home/chetana\n/home/chetana\n(20759, 25)\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/MvnL5a8MRg11/data_gee_gridmet_real_time.py\", line 46, in <module>\n    start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n  File \"/home/chetana/gw-workspace/MvnL5a8MRg11/snowcast_utils.py\", line 78, in findLastStopDate\n    latest_date = get_latest_date_from_an_array(date_list, data_format)\n  File \"/home/chetana/gw-workspace/MvnL5a8MRg11/snowcast_utils.py\", line 64, in get_latest_date_from_an_array\n    return max(arr, key=lambda x: datetime.datetime.strptime(x, date_format))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1677800061824,
  "history_end_time" : 1677800089962,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "rstgdgupvxr",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\nimport eeauth as e\n\n#exit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize(e.creds())\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1677786011742,
  "history_end_time" : 1677786042646,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "z5ck4wasug5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677784204251,
  "history_end_time" : 1677784272024,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "139nbq9h7dl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677782901813,
  "history_end_time" : 1677782901813,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "nm73dki789d",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677781745179,
  "history_end_time" : 1677781745179,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "u7rfqj18lwk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677719046595,
  "history_end_time" : 1677719046595,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "3ydo4cyxus0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677718179115,
  "history_end_time" : 1677718179115,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "i18i9xmfkqk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677679556268,
  "history_end_time" : 1677679556268,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "qqmlc70vm8w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677679507378,
  "history_end_time" : 1677679549085,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "tqac8anmhps",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677636286877,
  "history_end_time" : 1677636286877,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "btsks5eps1s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677636150377,
  "history_end_time" : 1677636150377,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "00hm3m0k0b4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677636137243,
  "history_end_time" : 1677636142812,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "47syuz3of6b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677636063779,
  "history_end_time" : 1677636063779,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "c30hf68idf0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677635881845,
  "history_end_time" : 1677635881845,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "eikzv1kicsy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677617762802,
  "history_end_time" : 1677617762802,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "v28cexsdy5w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677606170897,
  "history_end_time" : 1677606170897,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "w8xox95lqp2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677606114197,
  "history_end_time" : 1677606114197,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "brykd0sei1p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677582848569,
  "history_end_time" : 1677582848569,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gu0hoy4bxzp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677525426442,
  "history_end_time" : 1677525426442,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "qiqn6qzatt7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462325774,
  "history_end_time" : 1694185608915,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "0x3s23apols",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462312279,
  "history_end_time" : 1694185608676,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "c61no3nmtv0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677462311635,
  "history_end_time" : 1694185608624,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "02yxahxuuto",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677428742744,
  "history_end_time" : 1677428742744,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "44b7u51hvdw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677428687349,
  "history_end_time" : 1677428687349,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ocvr1cb6nei",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677426262892,
  "history_end_time" : 1677426262892,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "we00j4u9xs4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677379889810,
  "history_end_time" : 1705789703789,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "e1lpwyf1guf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677379837814,
  "history_end_time" : 1705789703166,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "aae3xunz91j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677352478002,
  "history_end_time" : 1677352478002,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "uk80m6dnzdh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677352389919,
  "history_end_time" : 1677352389919,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "x8wpqkwi4wi",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677352335866,
  "history_end_time" : 1677352335866,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "0vk13ergcau",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677344119964,
  "history_end_time" : 1705789707060,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "2ff2gysgh5a",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677282602832,
  "history_end_time" : 1677282602832,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "4f1ufv4hed6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273712232,
  "history_end_time" : 1677273712232,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "sfwyi8mm5vp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273698748,
  "history_end_time" : 1677273703950,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "oypihv9royd",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273673911,
  "history_end_time" : 1677273679535,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "rdjpg6aqnyr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273657801,
  "history_end_time" : 1677273665452,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "rry66ngau0e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273536009,
  "history_end_time" : 1677273536009,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "f4isx1nzfpe",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273519110,
  "history_end_time" : 1677273525488,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "sj33mmd14fh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273371300,
  "history_end_time" : 1677273371300,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ugq7gn6kyi9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273340437,
  "history_end_time" : 1677273345441,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "csrxlaijd2m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273323490,
  "history_end_time" : 1677273332233,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "7sny0yrs7rz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273146658,
  "history_end_time" : 1677273146658,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "hlf5zzx6658",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677273100232,
  "history_end_time" : 1677273134490,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "zgc2b9ax4tg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677201275717,
  "history_end_time" : 1677201275717,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "qm6368ru3ok",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677192311064,
  "history_end_time" : 1677192311064,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "m7p0op1zphw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677192268371,
  "history_end_time" : 1677192268371,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "rg9olhn0m13",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677191916736,
  "history_end_time" : 1677191916736,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "njr9ud76lvf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677184296690,
  "history_end_time" : 1677184296690,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "4se43ok58jb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677184173548,
  "history_end_time" : 1677184173548,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "oew2fohd1pu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677113476460,
  "history_end_time" : 1677113476460,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "fyco2zftffp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677108238616,
  "history_end_time" : 1677108238616,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "i9d0bh5w6ls",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677108212531,
  "history_end_time" : 1677108229730,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ci6vve1cwq4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107869807,
  "history_end_time" : 1677107869807,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ogxeh81cn9y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107757955,
  "history_end_time" : 1677107757955,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "860rn6nbwt2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107718301,
  "history_end_time" : 1677107718301,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "21bjhp94l3g",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107637160,
  "history_end_time" : 1677107705676,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "jpnkydezsz3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107604026,
  "history_end_time" : 1677107608762,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "i94697nv67o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107556522,
  "history_end_time" : 1677107562720,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "9nfqn9m86g0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107524994,
  "history_end_time" : 1677107538162,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "n5rb9vdpcrz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107501090,
  "history_end_time" : 1677107501090,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "x47r5phyods",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677107474159,
  "history_end_time" : 1677107474159,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "3k01n879xws",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106516100,
  "history_end_time" : 1677106516100,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "h8eyc2epbx8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106477055,
  "history_end_time" : 1677106477055,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "3klzmvp1x6u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106431046,
  "history_end_time" : 1677106431046,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "fi67gcfksdm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106134895,
  "history_end_time" : 1677106147561,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fjnjgfq9gt1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677106011020,
  "history_end_time" : 1677106011020,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "n5atihcmcle",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677030843616,
  "history_end_time" : 1677030843616,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "6bhzv8d3bx0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677030771152,
  "history_end_time" : 1677030771152,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "5gztfovs23x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677030672645,
  "history_end_time" : 1677030672645,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "ajmhw94eyqm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677030563219,
  "history_end_time" : 1677030563219,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "qcfehpgpz7s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677025528666,
  "history_end_time" : 1677025528666,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "fkgk6zw4c5o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677025467407,
  "history_end_time" : 1705789711439,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "36cfqsrz1yv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677017826418,
  "history_end_time" : 1677017826418,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "83ankw15ds6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677017218425,
  "history_end_time" : 1677017218425,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "icxffex9u05",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677016681317,
  "history_end_time" : 1677016681317,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "oxp3z6m4k3j",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677016142999,
  "history_end_time" : 1677016142999,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "gkc1bqf1xim",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677016063959,
  "history_end_time" : 1677016063959,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "6bjzlrx33sb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677015787645,
  "history_end_time" : 1677015787645,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "5sd9yc73c3z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677015739951,
  "history_end_time" : 1677015739951,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "66t57xh11ji",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677014884962,
  "history_end_time" : 1705789712275,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "q40zjgxl7an",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677014795625,
  "history_end_time" : 1705789714748,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "7734pqq8enr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677014228061,
  "history_end_time" : 1705789715531,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "98oiguyxz0f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677013908437,
  "history_end_time" : 1705789716207,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "kam5ot7b61o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677013833040,
  "history_end_time" : 1677013833040,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "lq0kyshf3lp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677011873078,
  "history_end_time" : 1705789717076,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "cisr8blj476",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677008198579,
  "history_end_time" : 1677008198579,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "shjvj2k4jev",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677008163853,
  "history_end_time" : 1677008163853,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Skipped"
},{
  "history_id" : "yplqrzjb922",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677001999588,
  "history_end_time" : 1705789717923,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "2e7khdc02p6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677001732249,
  "history_end_time" : 1677001732249,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3aujx4quw2t",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677001593843,
  "history_end_time" : 1677001593843,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "geylasxn5j7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677000536802,
  "history_end_time" : 1677000536802,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eb7rv6r0044",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676999722128,
  "history_end_time" : 1676999722128,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "yb51al",
  "indicator" : "Skipped"
},{
  "history_id" : "dk7iji9djml",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676999599130,
  "history_end_time" : 1676999599130,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "g3she27m7cw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676862212366,
  "history_end_time" : 1676862212366,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "eoy5f0fwzub",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676329536254,
  "history_end_time" : 1676329536254,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0fhv13dfeyh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676329491779,
  "history_end_time" : 1676329491779,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nodufxk2ud0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1676063613407,
  "history_end_time" : 1676063613407,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1d15zeatvcf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675783782325,
  "history_end_time" : 1675783782325,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1g2ym4dy6yz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1672014982957,
  "history_end_time" : 1672014982957,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pm1pd0lex4b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1671944382455,
  "history_end_time" : 1671944382455,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "v94al3sftu3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670910617279,
  "history_end_time" : 1670910617279,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "3jidn41e6dw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670910501159,
  "history_end_time" : 1670910501159,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ekha19vu0ei",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670910268467,
  "history_end_time" : 1670910268467,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "iiq2grrsqrp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670019638900,
  "history_end_time" : 1670019638900,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "5haf29oxnpm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667484654138,
  "history_end_time" : 1667484654138,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "6pe9iv6v3gg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667410736813,
  "history_end_time" : 1667410736813,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2141eobqezg",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1667410652793,
  "history_end_time" : 1667410704910,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "bsuoushlp98",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1667410544541,
  "history_end_time" : 1667410624023,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wTQgcFd33UnK",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-06-28\n\nStream closed",
  "history_begin_time" : 1656389249204,
  "history_end_time" : 1656396197341,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "kvbmjhoj22u",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "\nprocess hasn't exited",
  "history_begin_time" : 1654519481631,
  "history_end_time" : 1654519482100,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "BKF6e1lQ1XhP",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1653917337928,
  "history_end_time" : 1654519659838,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "UNsvw4Kh8sL9",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1653445087880,
  "history_end_time" : 1653917496354,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "txixOSz9XtM8",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1653418271221,
  "history_end_time" : 1653445079295,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "On1rIuLN64vH",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1652898265957,
  "history_end_time" : 1653404004587,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "6QGlWLDOvITa",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\n#start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n#end_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1652076461272,
  "history_end_time" : 1652076468571,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "jJQOU545tzqI",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\n#start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n#end_date = test_end_date\nstart_date = \"2022-04-06\"\nend_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1651966782578,
  "history_end_time" : 1651977920998,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "YQMVf8aWyLFz",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "*** Earth Engine *** Authenticate calls from this Earth Engine Python client will fail after 2022-05-09: please upgrade. https://developers.google.com/earth-engine/guides/python_install\ntoday date = 2022-05-03\n\nStream closed",
  "history_begin_time" : 1651626815160,
  "history_end_time" : 1651631018697,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "IczRTgdnHeB5",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-04-20\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "*** Earth Engine *** Please upgrade your Earth Engine Python client: authentication is changing! https://developers.google.com/earth-engine/guides/python_install\ntoday date = 2022-04-28\ncollecting  e377648a-4f6f-4d2f-9ae2-c3e73e9887f6\ncollecting  e379e919-14dd-47b7-b5b8-27e92cc11305\n=> Collected GridMet data for 18483 cells\ncollecting  e37ce606-432c-4e97-9057-18ffbadf13ad\n=> Collected GridMet data for 18484 cells\ncollecting  e3818737-2f32-4195-9ec0-cc95989539e3\n=> Collected GridMet data for 18491 cells\ncollecting  e3a104e4-fa7d-499e-b2c7-18c0242e9f72\ncollecting  e3a24119-634d-4aa6-a79c-3d6a7747e2d4\n=> Collected GridMet data for 18495 cells\ncollecting  e3a4c6b6-aea8-462c-b8c6-0b3e34a87a66\ncollecting  e3a731b8-1c49-418a-8513-0f7b03e2e780\n=> Collected GridMet data for 18497 cells\ncollecting  e3a8f833-9875-4961-9c61-d99017c97288\n=> Collected GridMet data for 18498 cells\ncollecting  e3b0f61d-484d-4504-91d2-9f802cf15f02\n=> Collected GridMet data for 18499 cells\ncollecting  e3b36d3f-fc83-4a15-a889-a0eca419d9b4\n=> Collected GridMet data for 18500 cells\ncollecting  e3b3a9cf-0c95-491d-9c4c-b108eeb1ab6b\n=> Collected GridMet data for 18501 cells\ncollecting  e3d8ec43-b309-4cca-be43-8a5808e32689\n=> Collected GridMet data for 18512 cells\ncollecting  e3da76f0-5516-4a3d-88d7-3fc0bc4f70d7\n=> Collected GridMet data for 18513 cells\ncollecting  e3dd6e0c-51a1-4d60-bbf6-8e77f05b5992\n=> Collected GridMet data for 18514 cells\ncollecting  e3df0587-7935-4421-b74f-5238b42bc412\n=> Collected GridMet data for 18515 cells\ncollecting  e3e0bd95-55fe-4783-b4c7-809f001b934f\n=> Collected GridMet data for 18516 cells\ncollecting  e3e30659-c933-4583-a5b6-f1875006a3ea\n=> Collected GridMet data for 18517 cells\ncollecting  e3e4ba54-44bc-42f1-be5f-f8b2a6b8b409\n=> Collected GridMet data for 18518 cells\n=> Collected GridMet data for 18521 cells\n=> Collected GridMet data for 18522 cells\n=> Collected GridMet data for 18524 cells\ncollecting  e415afaf-81ee-4140-a2f0-4b2a68726914\n=> Collected GridMet data for 18525 cells\ncollecting  e41d87a8-6f4e-47d1-babf-7feecbe4069b\n=> Collected GridMet data for 18526 cells\ncollecting  e41ebcc9-5172-4e02-9ee6-351c930ef7b2\n=> Collected GridMet data for 18527 cells\n=> Collected GridMet data for 18528 cells\ncollecting  e423f76c-280c-4008-8e9f-c0d12d0dfd10\n=> Collected GridMet data for 18529 cells\ncollecting  e425b3c1-6f16-4195-affc-167309e965ba\n=> Collected GridMet data for 18530 cells\ncollecting  e426151f-8d98-4c0d-8956-143f71119ef9\n=> Collected GridMet data for 18534 cells\ncollecting  e4542ac6-b803-4f18-ba25-e61f9dd34e00\n=> Collected GridMet data for 18552 cells\n=> Collected GridMet data for 18557 cells\n=> Collected GridMet data for 18558 cells\ncollecting  e4786f10-67f3-4837-9a7d-a147bf03d890\n=> Collected GridMet data for 18559 cells\ncollecting  e47903fe-0424-4d9d-a231-c9bdaeb22727\n=> Collected GridMet data for 18560 cells\ncollecting  e47bdc7f-53c6-4501-af65-a78e5543a64d\n=> Collected GridMet data for 18561 cells\n=> Collected GridMet data for 18575 cells\ncollecting  e4bbbdd1-aa99-41bf-bbd7-583e1f071346\ncollecting  e4bc6f04-bdf0-4c62-a8d3-fb87f180c629\n=> Collected GridMet data for 18579 cells\ncollecting  e4bd1bc9-46ea-4d1e-a390-9bc543d4f993\n=> Collected GridMet data for 18580 cells\ncollecting  e4c54067-8c5c-490e-8231-e16bf93f64c3\n=> Collected GridMet data for 18581 cells\ncollecting  e4c5bba2-61fc-442b-b2a9-fdd2aaa343e1\n=> Collected GridMet data for 18582 cells\n=> Collected GridMet data for 18584 cells\ncollecting  e4eec6e6-6536-4e1e-a9a5-92ccbab0bd5d\n=> Collected GridMet data for 18592 cells\n=> Collected GridMet data for 18593 cells\ncollecting  e4fb9348-9bc7-4bb3-8d37-eaf0dfa2fbbf\n=> Collected GridMet data for 18594 cells\ncollecting  e528bffa-0e10-4b30-a8cd-9d9c0a623400\n=> Collected GridMet data for 18603 cells\ncollecting  e52b8285-8ffd-4733-bbc3-ab95938a7199\ncollecting  e5315bdf-3db8-43e2-ac57-e23dd5f796f7\n=> Collected GridMet data for 18605 cells\ncollecting  e532145e-da4a-4010-9c1b-df76cbd53f40\n=> Collected GridMet data for 18606 cells\ncollecting  e5384aff-cf98-4aef-85c9-993e35dd87fa\n=> Collected GridMet data for 18607 cells\ncollecting  e5396cc3-90b6-4c17-9358-fcd94fc5760c\n=> Collected GridMet data for 18608 cells\ncollecting  e53a10d4-99c6-4a4c-8f45-865531d467ef\n=> Collected GridMet data for 18609 cells\ncollecting  e53b56ee-e87b-431c-99c9-960db9c08ccd\n=> Collected GridMet data for 18610 cells\ncollecting  e540e8fe-e3c4-4fcb-9025-51346e3af35c\n=> Collected GridMet data for 18611 cells\ncollecting  e5435e23-41f1-4822-8eb0-726edcaae59f\n=> Collected GridMet data for 18612 cells\ncollecting  e54d7a46-8af8-46c1-b4c7-efb3e6a3272e\n=> Collected GridMet data for 18613 cells\ncollecting  e553a58f-11c9-48ea-88bf-80a454057fde\n=> Collected GridMet data for 18627 cells\ncollecting  e573bd59-8cfa-4ed5-a899-029bf009991b\ncollecting  e58106a8-1fc1-4c03-9c4b-f99f14439b23\n=> Collected GridMet data for 18640 cells\ncollecting  e59d5aa3-63e4-4ac3-957d-beb76380abe7\n=> Collected GridMet data for 18642 cells\ncollecting  e5a0585a-b814-4f3c-9586-15dca856557f\n=> Collected GridMet data for 18643 cells\ncollecting  e5a33fa1-a2ed-4328-99bc-876a7151d2f6\n=> Collected GridMet data for 18644 cells\n=> Collected GridMet data for 18646 cells\ncollecting  e5b04057-1bac-48fb-bc63-850eb57a7f56\n=> Collected GridMet data for 18647 cells\ncollecting  e5b22525-0fae-4143-8a23-432ccfbc90d7\n=> Collected GridMet data for 18648 cells\ncollecting  e5b5cda1-8033-43e2-bc97-d8d9bf2476dc\n=> Collected GridMet data for 18649 cells\n=> Collected GridMet data for 18662 cells\ncollecting  e5cdeb26-a497-4759-ae6c-df50ab82bc73\ncollecting  e5d0726d-d590-4d85-b8e2-7cd69f2a667c\n=> Collected GridMet data for 18666 cells\ncollecting  e5d5c5d5-fa21-401c-a2f9-60b613afb6de\n=> Collected GridMet data for 18667 cells\ncollecting  e5def2e8-c59d-4127-818c-58d6d8202d47\n=> Collected GridMet data for 18669 cells\n=> Collected GridMet data for 18671 cells\ncollecting  e5e9a95b-ce39-4f52-9b8a-d3542e200e41\n=> Collected GridMet data for 18673 cells\ncollecting  e5fb6b6b-1841-444f-a33d-58bb654bfd37\n=> Collected GridMet data for 18674 cells\n=> Collected GridMet data for 18677 cells\n=> Collected GridMet data for 18682 cells\n=> Collected GridMet data for 18686 cells\n=> Collected GridMet data for 18688 cells\ncollecting  e631c721-f932-4b2a-bbd8-52503b5509a4\n=> Collected GridMet data for 18689 cells\ncollecting  e634c60f-f23d-45e5-bc11-45975c592fe0\n=> Collected GridMet data for 18690 cells\ncollecting  e6393ead-2473-4b19-8b13-26a9b2fd3ac5\n=> Collected GridMet data for 18691 cells\n=> Collected GridMet data for 18697 cells\ncollecting  e65363e7-6d06-4b09-8fed-022ab45287e0\n=> Collected GridMet data for 18698 cells\ncollecting  e656f13c-794a-41a3-b65f-caccace44055\n=> Collected GridMet data for 18699 cells\n=> Collected GridMet data for 18700 cells\ncollecting  e65922a7-2af1-4ccc-925d-b9af980074ba\n=> Collected GridMet data for 18702 cells\ncollecting  e65e406c-0627-4a46-a2c3-b994ac918296\n=> Collected GridMet data for 18703 cells\ncollecting  e67533d9-4894-4308-8a31-75c42610a395\n=> Collected GridMet data for 18711 cells\n=> Collected GridMet data for 18714 cells\n=> Collected GridMet data for 18715 cells\ncollecting  e69eca81-1e40-4da5-b793-e508a5f4a7a3\n=> Collected GridMet data for 18722 cells\ncollecting  e6a378a3-01e8-4bb2-b975-862dd0fd7429\n=> Collected GridMet data for 18723 cells\ncollecting  e6a5147a-5b4f-4134-92ec-f26b93a43daa\n=> Collected GridMet data for 18724 cells\ncollecting  e6af0ae7-38a2-4670-9815-0475eec8b12c\ncollecting  e6b54311-24c2-47a5-9118-41e6e710b4d9\n=> Collected GridMet data for 18727 cells\n=> Collected GridMet data for 18734 cells\ncollecting  e6d22d6d-2b48-4800-a833-7c055db17e2c\n=> Collected GridMet data for 18735 cells\ncollecting  e6d48180-814d-494b-99cc-0be5cd1a0eaf\n=> Collected GridMet data for 18736 cells\ncollecting  e6d6c4e9-f294-454f-9ebb-567b80f27c8e\n=> Collected GridMet data for 18737 cells\ncollecting  e6d6ca5d-5b43-4bb1-b1d7-5bf2e35d6ee3\n=> Collected GridMet data for 18740 cells\ncollecting  e6f3ebb3-1c34-45f5-a0ee-c509cb101e38\n=> Collected GridMet data for 18746 cells\ncollecting  e6f457fb-05df-4193-90c5-42e12f5d1cd6\n=> Collected GridMet data for 18747 cells\ncollecting  e6fbe795-2c4c-453b-9b60-bc6e48338af0\n=> Collected GridMet data for 18748 cells\ncollecting  e7024775-3fe1-4e9d-837d-085ceb3a40da\n=> Collected GridMet data for 18749 cells\ncollecting  e7024e3d-3eef-467c-bf0c-bea6f955c8dd\n=> Collected GridMet data for 18750 cells\ncollecting  e706a23f-027c-43a2-aa5d-f9c269be8029\n=> Collected GridMet data for 18751 cells\ncollecting  e708d21a-8bec-4482-8400-3867e7cfcba7\n=> Collected GridMet data for 18752 cells\n=> Collected GridMet data for 18754 cells\ncollecting  e71a34c1-b727-4214-9b30-b6052216273a\ncollecting  e72bc39f-b0d3-44c3-b1fb-25e336cde088\n=> Collected GridMet data for 18762 cells\ncollecting  e72e5cb8-4aab-4dea-bf67-22dbb3943808\n=> Collected GridMet data for 18763 cells\ncollecting  e72fc735-35f0-4eca-bd52-fd13fdc3f7cf\n=> Collected GridMet data for 18764 cells\ncollecting  e7357a09-61ac-4db0-affa-9b34790990a7\n=> Collected GridMet data for 18770 cells\n=> Collected GridMet data for 18773 cells\ncollecting  e74b404c-da01-492e-ad71-d239cac6d988\n=> Collected GridMet data for 18774 cells\ncollecting  e750eb72-559b-41b5-a1c3-865fed777d89\ncollecting  e7603ef1-4d69-4e00-81db-a27944d88c56\n=> Collected GridMet data for 18780 cells\ncollecting  e760b2e0-cc67-4857-9bb9-8859ff4621c5\n=> Collected GridMet data for 18781 cells\ncollecting  e7686ed4-7425-4b81-a383-80cbd0896ab2\n=> Collected GridMet data for 18783 cells\ncollecting  e768aebb-bb38-4c32-90b6-17d8f39a68ae\n=> Collected GridMet data for 18784 cells\ncollecting  e7691790-cda9-4319-bc4b-9180d583e0d4\n=> Collected GridMet data for 18785 cells\ncollecting  e76db545-2fc8-4cc5-b8e0-d627418b9bc9\n=> Collected GridMet data for 18786 cells\n=> Collected GridMet data for 18791 cells\ncollecting  e7876b26-258a-4f5e-9e0a-66656ca7e40e\n=> Collected GridMet data for 18795 cells\ncollecting  e78e6b20-ccff-4875-91f1-8cb7d735a88c\n=> Collected GridMet data for 18797 cells\ncollecting  e78ec7ef-b95a-47ca-baf2-b64ca32d31a7\n=> Collected GridMet data for 18798 cells\ncollecting  e7937c18-4903-4f6f-87fa-372974541373\n=> Collected GridMet data for 18799 cells\ncollecting  e7958acc-4239-4e24-86d1-c8131b3b5457\n=> Collected GridMet data for 18800 cells\ncollecting  e796f5a3-0f9e-4e6b-ba43-699fc4d470fe\n=> Collected GridMet data for 18801 cells\ncollecting  e797e1c2-91f4-4010-801d-ec7bfdcd7ef5\n=> Collected GridMet data for 18802 cells\ncollecting  e79d8886-1e89-4aa5-b373-fcc2c5abe6d2\n=> Collected GridMet data for 18803 cells\ncollecting  e79f7e47-c81f-4273-ace5-193b9935d54f\n=> Collected GridMet data for 18804 cells\ncollecting  e7ac7911-a024-4871-8c36-bc32db4d94d9\n=> Collected GridMet data for 18805 cells\ncollecting  e7b0bbe0-151f-475f-96d5-081dab83c7a5\n=> Collected GridMet data for 18806 cells\ncollecting  e7b85908-b9e9-4d18-9c1a-3c0c9bac3c64\n=> Collected GridMet data for 18807 cells\n=> Collected GridMet data for 18812 cells\ncollecting  e7cb9a81-118e-4805-a3f1-f2e0302e8fce\n=> Collected GridMet data for 18813 cells\ncollecting  e7cf80a2-01ea-4670-a5db-f95e06a35966\ncollecting  e7d11081-0b19-4474-87ff-3a8549e2dd73\n=> Collected GridMet data for 18815 cells\ncollecting  e7d185c2-99e4-4687-b159-0baf66af6947\n=> Collected GridMet data for 18816 cells\ncollecting  e7d4f24a-be35-4730-ab2b-5887709e21cc\n=> Collected GridMet data for 18818 cells\ncollecting  e7eac7a1-60a6-4089-b887-e3bf828688bc\n=> Collected GridMet data for 18824 cells\ncollecting  e7ebec51-7f68-4542-9236-037e5b8446b8\n=> Collected GridMet data for 18825 cells\ncollecting  e7f6383d-72b2-48ad-b77c-a75dd3533c9b\n=> Collected GridMet data for 18826 cells\ncollecting  e7f8b1bf-3918-4e7e-b8e9-d1571098fc43\n=> Collected GridMet data for 18827 cells\ncollecting  e7f917ea-6985-492b-96dc-48ba2bb829b7\ncollecting  e7fe9c97-5615-4c29-9d7b-52e87163a6f8\ncollecting  e7ff3de8-1db3-4b71-964c-1bba2618d0fd\n=> Collected GridMet data for 18831 cells\n=> Collected GridMet data for 18832 cells\n=> Collected GridMet data for 18835 cells\n=> Collected GridMet data for 18842 cells\n=> Collected GridMet data for 18845 cells\ncollecting  e8303e2b-ebb2-4294-8962-7000050839dd\n=> Collected GridMet data for 18846 cells\ncollecting  e83bda58-d924-431c-8035-306ea3af8d8e\ncollecting  e84c8459-3d2d-4143-b415-771ef2357394\n=> Collected GridMet data for 18859 cells\ncollecting  e8515b97-af72-43fb-9435-ebb35545518c\n=> Collected GridMet data for 18860 cells\ncollecting  e851c1d7-5ba1-4772-b1da-4c4a41274972\n=> Collected GridMet data for 18861 cells\ncollecting  e8521964-3cbb-4d6c-adf9-bd1834a43f2d\n=> Collected GridMet data for 18868 cells\ncollecting  e86ee953-11d6-471c-ba04-7249d7f3d118\n=> Collected GridMet data for 18869 cells\ncollecting  e8730b43-5af4-4285-96f8-60732819745d\n=> Collected GridMet data for 18870 cells\ncollecting  e875c2f8-8491-4777-b004-d986047ac1d7\ncollecting  e877c899-ac38-47a8-a1de-0880dae264d3\ncollecting  e8854bfb-c02b-46e5-9430-3e62a7f265b5\ncollecting  e88ff026-8598-415d-851e-294903403ddb\ncollecting  e8946301-b09b-4f0e-992e-a37161be0c26\n=> Collected GridMet data for 18882 cells\ncollecting  e8948f32-e11d-43c5-a58f-2133fb0d9e3f\n=> Collected GridMet data for 18883 cells\ncollecting  e8949699-8e66-4aec-85c8-569b406ff4a1\n=> Collected GridMet data for 18884 cells\ncollecting  e8963876-8fd8-4bd7-a9ee-b554a454a517\n=> Collected GridMet data for 18885 cells\ncollecting  e89a077c-2b2d-41d2-9521-03bffaa1b2b0\ncollecting  e89c6f54-cc91-4d1d-a269-cd1b9322fa88\n=> Collected GridMet data for 18898 cells\ncollecting  e8c7d731-5dd4-4b49-b133-82672f0040da\n=> Collected GridMet data for 18899 cells\ncollecting  e8cb4561-141a-4ab6-b748-7d9c642934d5\n=> Collected GridMet data for 18900 cells\ncollecting  e8d44c53-1191-4e74-93a5-049e10d66e17\ncollecting  e8d63e8b-bae7-4157-b1f9-98addfb563db\n=> Collected GridMet data for 18903 cells\ncollecting  e8d6fecc-e0fa-424d-9403-bb7f7f29e6eb\ncollecting  e8e9b8ca-26c4-4854-a45d-adf7fa632098\n=> Collected GridMet data for 18909 cells\ncollecting  e8ed15b5-a094-4844-8a09-21db8947ebb5\ncollecting  e8f1c910-dbea-494d-9757-842a84425b0f\n=> Collected GridMet data for 18911 cells\ncollecting  e8fccf62-df64-4c68-9a1d-d146aed66fc9\n=> Collected GridMet data for 18914 cells\ncollecting  e907d041-1af9-4464-8386-d8cc7e75bcf6\n=> Collected GridMet data for 18915 cells\ncollecting  e909ffcd-b607-4835-8bb0-456849f7b727\n=> Collected GridMet data for 18916 cells\ncollecting  e90c5237-3a9b-42de-afe2-4568b13630c3\n=> Collected GridMet data for 18917 cells\n=> Collected GridMet data for 18918 cells\n=> Collected GridMet data for 18920 cells\n=> Collected GridMet data for 18923 cells\ncollecting  e918b670-cc97-4f02-b300-c1f7ab2325a5\n=> Collected GridMet data for 18924 cells\ncollecting  e91aac7e-73fc-45a7-be5a-307d7551d157\n=> Collected GridMet data for 18925 cells\ncollecting  e91ac62b-28ee-4920-a366-9ff932e89043\n=> Collected GridMet data for 18926 cells\ncollecting  e920162f-9385-4f2e-9ad5-b17bc69fb0ff\n=> Collected GridMet data for 18927 cells\ncollecting  e924842e-7e5e-41e9-a8c8-f85726acdd61\n=> Collected GridMet data for 18928 cells\ncollecting  e9253834-a9db-4883-9517-1ea1abd0181c\n=> Collected GridMet data for 18929 cells\ncollecting  e9268924-2b6a-4379-afc7-2c9c7a48b148\n=> Collected GridMet data for 18930 cells\n=> Collected GridMet data for 18938 cells\ncollecting  e965e6b6-388e-4594-bbc8-e9c6c4a1d27f\n=> Collected GridMet data for 18946 cells\n=> Collected GridMet data for 18948 cells\ncollecting  e988cb5f-c890-4449-82b7-7aad01a36ee0\n=> Collected GridMet data for 18949 cells\ncollecting  e98c5839-044c-4cc4-a28d-d178cd4e1403\n=> Collected GridMet data for 18950 cells\ncollecting  e98d6ae6-56a1-4523-bab2-ed39824597a8\n=> Collected GridMet data for 18951 cells\ncollecting  e99370cc-60ca-4ae7-b221-4cfd4badf4b0\n=> Collected GridMet data for 18952 cells\ncollecting  e99b6746-e8b9-41fe-bed0-e775cb7648f8\n=> Collected GridMet data for 18956 cells\n=> Collected GridMet data for 18960 cells\ncollecting  e9c6f260-2aa0-4489-9712-781deda8f691\n=> Collected GridMet data for 18961 cells\ncollecting  e9e897a3-78ad-4e8b-a1b2-634cd438b3fd\n=> Collected GridMet data for 18969 cells\ncollecting  e9ee778d-d760-4b9d-978c-a4f1305376d6\n=> Collected GridMet data for 18970 cells\ncollecting  e9fa096b-3dbb-4553-86bb-2ffabccf883c\n=> Collected GridMet data for 18973 cells\n=> Collected GridMet data for 18974 cells\ncollecting  e9ffa2c0-d082-402c-be58-806b9611f1ec\ncollecting  ea00b771-2b06-45e6-b314-52c9e1b054c0\n=> Collected GridMet data for 18976 cells\n=> Collected GridMet data for 18979 cells\ncollecting  ea181826-2364-4884-8799-82c55ccc9213\n=> Collected GridMet data for 18980 cells\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\n=> Collected GridMet data for 18981 cells\ncollecting  ea18c395-3690-46d1-87ff-b41f63c7e7f9\n=> Collected GridMet data for 18982 cells\n=> Collected GridMet data for 18988 cells\ncollecting  ea24bd75-4e77-4c98-813f-3b94035e211e\n=> Collected GridMet data for 18994 cells\ncollecting  ea35ae81-40d8-4f30-b439-20737c02af97\ncollecting  ea4023d5-94d6-45fe-a6db-5c876368d3aa\n=> Collected GridMet data for 19009 cells\n=> Collected GridMet data for 19022 cells\ncollecting  eab6708a-2342-4616-b6bf-aa228b62c060\n=> Collected GridMet data for 19034 cells\n=> Collected GridMet data for 19035 cells\ncollecting  ead81900-d6fd-4697-b3c4-22f4cfac4abf\n=> Collected GridMet data for 19036 cells\ncollecting  eadb75e9-5b78-4603-a77f-fea1b6e7b33a\n=> Collected GridMet data for 19037 cells\ncollecting  eadfdb9d-1cbc-475d-9bf3-33ece9fde5c2\n=> Collected GridMet data for 19038 cells\n=> Collected GridMet data for 19039 cells\ncollecting  eae30ac2-e7d4-4d85-babf-9904bd80c265\n=> Collected GridMet data for 19040 cells\ncollecting  eae5446e-7bb4-4314-8414-2e3bcf5ccc28\n=> Collected GridMet data for 19041 cells\n=> Collected GridMet data for 19042 cells\n=> Collected GridMet data for 19044 cells\ncollecting  eaf45020-66a8-4c6f-8f68-41729fe4cc2b\n=> Collected GridMet data for 19045 cells\ncollecting  eaf63856-6550-4b87-920b-c9aca9406c27\n=> Collected GridMet data for 19046 cells\ncollecting  eaf85fc5-647b-4406-94ce-4177ec2b4830\n=> Collected GridMet data for 19047 cells\n=> Collected GridMet data for 19048 cells\ncollecting  eafc5993-e9e2-42c1-b9b2-10bade88d83d\n=> Collected GridMet data for 19049 cells\ncollecting  eafdf03f-3b01-4d7f-969b-ba029fc6b98e\n=> Collected GridMet data for 19051 cells\ncollecting  eb03b2ae-1bdd-4fa0-b923-630d2774b6fd\n=> Collected GridMet data for 19052 cells\ncollecting  eb0dc8a6-fe05-45bb-bc14-43e8e3507427\ncollecting  eb17afdc-cf5e-49aa-93c8-ada3d2e15d12\n=> Collected GridMet data for 19059 cells\ncollecting  eb1d889a-c427-49e1-95a1-fa6577002c9b\n=> Collected GridMet data for 19060 cells\n=> Collected GridMet data for 19062 cells\ncollecting  eb271b6e-6c18-4eeb-8b30-88423f6245bb\n=> Collected GridMet data for 19063 cells\ncollecting  eb2b7b71-ca31-4b42-89fa-478c562810af\n=> Collected GridMet data for 19067 cells\n=> Collected GridMet data for 19068 cells\ncollecting  eb4616d3-9416-4486-b730-a9eed20f3619\n=> Collected GridMet data for 19069 cells\ncollecting  eb46a598-624a-40e0-80d5-bed284fdeb7b\n=> Collected GridMet data for 19070 cells\ncollecting  eb4a4741-13fe-4b4a-bfec-39fffeb3c6cd\n=> Collected GridMet data for 19071 cells\ncollecting  eb55b17f-228f-4680-a4d9-85bd2b927440\n=> Collected GridMet data for 19076 cells\ncollecting  eb573220-feb0-4253-9a90-f36a7146d887\n=> Collected GridMet data for 19077 cells\ncollecting  eb5a03eb-b21f-4395-8205-6ccd9b4ab485\n=> Collected GridMet data for 19078 cells\ncollecting  eb712255-8afe-4f79-a748-3f8b2996a0af\n=> Collected GridMet data for 19085 cells\n=> Collected GridMet data for 19086 cells\ncollecting  eb78f307-887f-4627-b8d8-cb512a535f38\ncollecting  ebe686bd-1872-4ef6-a0d8-b1f95bbb03c8\ncollecting  ebe77e2c-8d9f-4326-b7bb-dcfd1b363568\n=> Collected GridMet data for 19115 cells\ncollecting  ec0a18f6-016f-4525-b70f-29dc96ddee2b\n=> Collected GridMet data for 19117 cells\ncollecting  ec0e1694-3cd5-4e0c-bfdf-a63c0348ddf0\n=> Collected GridMet data for 19119 cells\n=> Collected GridMet data for 19120 cells\ncollecting  ec1402fd-efd4-4942-9096-0b53fb7fce86\n=> Collected GridMet data for 19121 cells\ncollecting  ec15a352-b7eb-491f-b937-427c7d8df0a8\n=> Collected GridMet data for 19122 cells\ncollecting  ec21fccb-cbd4-423b-a327-b6ace0e08712\n=> Collected GridMet data for 19123 cells\ncollecting  ec233e5d-10b4-406c-80e1-171c36594983\n=> Collected GridMet data for 19124 cells\ncollecting  ec255922-42d7-4656-aaea-4fcfaae37fb1\n=> Collected GridMet data for 19125 cells\ncollecting  ec26fa06-08f9-43d1-ba15-57f3eeca7bbc\n=> Collected GridMet data for 19126 cells\ncollecting  ec2c5e52-acdc-4d8e-b254-8a7efda31a15\n=> Collected GridMet data for 19127 cells\ncollecting  ec2e575f-17c1-47df-b809-8ca35fedf98b\n=> Collected GridMet data for 19128 cells\ncollecting  ec30c97d-72e4-4b8e-8383-bf7a37e6865b\n=> Collected GridMet data for 19129 cells\ncollecting  ec31cec1-cda8-4ce5-9c45-11c260b27ff2\n=> Collected GridMet data for 19130 cells\ncollecting  ec327951-30b2-40c0-a267-6800d5b428bd\n=> Collected GridMet data for 19131 cells\ncollecting  ec35306d-7c35-46bf-b254-61d4abf78250\n=> Collected GridMet data for 19132 cells\ncollecting  ec387242-d0b2-4fc0-a923-d233e8faf175\n=> Collected GridMet data for 19133 cells\ncollecting  ec3b9384-fe19-41be-bbb2-04a988754bf4\n=> Collected GridMet data for 19134 cells\ncollecting  ec3d30df-cfaf-4237-9b78-d0e22289abee\ncollecting  ec5616b7-7b5d-40d6-8ddd-4ac4572c24c9\n=> Collected GridMet data for 19140 cells\n=> Collected GridMet data for 19143 cells\n=> Collected GridMet data for 19145 cells\ncollecting  ec6efe59-edfb-417f-97d3-bc7678568f97\ncollecting  ec73f6a4-7479-4d0f-b9a6-a464d90acd6c\n=> Collected GridMet data for 19148 cells\n=> Collected GridMet data for 19149 cells\n=> Collected GridMet data for 19150 cells\ncollecting  ec81e3e3-f25d-4ecc-af36-e15d50bfaa1c\ncollecting  ec84450e-916f-46c8-b2a6-5e257af5c695\n=> Collected GridMet data for 19152 cells\ncollecting  ec84df43-b360-45e5-b85e-07b914dba458\n=> Collected GridMet data for 19153 cells\ncollecting  ec85606d-3543-4f8d-b3a2-41e56b91397a\n=> Collected GridMet data for 19154 cells\ncollecting  ec868ec6-42df-46ac-912b-c4fb1ac8c10d\n=> Collected GridMet data for 19155 cells\ncollecting  ec8c4e25-aefe-458a-8524-dd20d57bcf76\ncollecting  ec8ed1b9-596d-43c2-b699-9e11c64cc893\n=> Collected GridMet data for 19159 cells\n=> Collected GridMet data for 19160 cells\n=> Collected GridMet data for 19162 cells\n=> Collected GridMet data for 19163 cells\n=> Collected GridMet data for 19164 cells\ncollecting  eca952d7-acc7-4c87-becd-0a79ffe55f23\n=> Collected GridMet data for 19170 cells\ncollecting  ecae26ef-4709-4e52-be97-5d7af6bb6e6d\n=> Collected GridMet data for 19171 cells\n=> Collected GridMet data for 19173 cells\ncollecting  ecbace99-8c9f-4ce6-b493-6acef544617d\n=> Collected GridMet data for 19174 cells\n=> Collected GridMet data for 19177 cells\ncollecting  ecc967fa-8964-4bd7-bc39-f1e594ba9c17\n=> Collected GridMet data for 19182 cells\ncollecting  ecd353de-7817-4f12-b1ce-989167c337be\n=> Collected GridMet data for 19183 cells\ncollecting  ecdb3a76-d1a6-4a57-b080-b62c24deb1e2\n=> Collected GridMet data for 19184 cells\ncollecting  ecdfb3b4-9045-4d63-bd13-f3c49dc22774\n=> Collected GridMet data for 19186 cells\ncollecting  ece9ba47-e7c8-42a0-be24-571adc336e2d\n=> Collected GridMet data for 19188 cells\ncollecting  eceaa9b0-9ab5-40d4-8c42-c64c6623f455\n=> Collected GridMet data for 19189 cells\ncollecting  ecec7d1b-ddc3-42d3-bd9a-6fbaac35ef26\n=> Collected GridMet data for 19190 cells\n=> Collected GridMet data for 19192 cells\ncollecting  ed01d416-6f62-4836-9ccc-acf2f1e9218d\n=> Collected GridMet data for 19198 cells\ncollecting  ed0d6ff8-4627-49e5-871a-a7c98cb29aa2\ncollecting  ed1193d9-d5d0-4a14-8fd1-8b2dfb1e2892\ncollecting  ed12ba63-f9d0-4bda-84bd-c9d8fd271def\n=> Collected GridMet data for 19203 cells\ncollecting  ed1f2c19-bdcc-442f-a102-4a1983fae604\n=> Collected GridMet data for 19204 cells\n=> Collected GridMet data for 19205 cells\n=> Collected GridMet data for 19206 cells\ncollecting  ed252823-829e-41d0-a707-07123fe5be00\n=> Collected GridMet data for 19207 cells\ncollecting  ed2862d9-fecf-4c9c-b587-e457d8c106d9\n=> Collected GridMet data for 19208 cells\ncollecting  ed2939f4-7319-4c52-93b1-8546db885a91\n=> Collected GridMet data for 19209 cells\ncollecting  ed2eeb49-1c76-472c-97fc-fd69ad677a9f\n=> Collected GridMet data for 19210 cells\ncollecting  ed330c4b-323f-4c96-b1eb-4d415e0a9369\n=> Collected GridMet data for 19211 cells\n=> Collected GridMet data for 19212 cells\ncollecting  ed3ce1f9-6b00-4a0f-b429-9945f6db85aa\n=> Collected GridMet data for 19213 cells\ncollecting  ed3f6cc6-f415-43fe-ab97-60de82ed86d1\ncollecting  ed3fa3b4-32ab-403a-8e07-73eae046b728\ncollecting  ed44da1d-034a-4ee0-88d1-ef6de615f6bb\n=> Collected GridMet data for 19217 cells\ncollecting  ed4cb203-2797-40fd-babc-f9acc284749c\ncollecting  ed51eae2-551c-4d2f-839a-99723955bd48\ncollecting  ed7d575d-1dc8-4512-960e-179fb1f7509b\ncollecting  ed8177f4-a83a-4966-9f43-ffc7f07d36f9\n=> Collected GridMet data for 19237 cells\n=> Collected GridMet data for 19238 cells\n=> Collected GridMet data for 19241 cells\n=> Collected GridMet data for 19242 cells\ncollecting  ed9384a7-cfb6-42c5-a56f-1f2d1349807e\n=> Collected GridMet data for 19243 cells\ncollecting  ed961733-8576-4d1c-9c17-bab89d906271\n=> Collected GridMet data for 19244 cells\ncollecting  ed969a49-978e-4b06-986b-1f118c8b724f\ncollecting  ed9d0cd8-7da2-42e6-96dd-c30e09fd8ff3\n=> Collected GridMet data for 19247 cells\n=> Collected GridMet data for 19253 cells\ncollecting  edb759ea-d069-4cc4-a07a-84d244fd55ad\n=> Collected GridMet data for 19254 cells\ncollecting  edb767c5-96e9-4035-ae3f-87dba28f8410\n=> Collected GridMet data for 19255 cells\n=> Collected GridMet data for 19257 cells\ncollecting  edbc57ab-b1e6-467b-9106-b180a5c81ec5\n=> Collected GridMet data for 19258 cells\ncollecting  edbf487d-3fbf-435c-b6bb-70903f510985\n=> Collected GridMet data for 19260 cells\ncollecting  edc3381c-cf8f-4747-ad40-1d9fdc071125\ncollecting  edc6216a-27d8-4ae2-aa23-18467389950d\n=> Collected GridMet data for 19265 cells\n=> Collected GridMet data for 19273 cells\ncollecting  edeb371a-d2ff-4f29-9b64-a5e51a1c6064\n=> Collected GridMet data for 19275 cells\ncollecting  edf98c25-601c-4ab7-bc1c-e36d08575e87\n=> Collected GridMet data for 19284 cells\ncollecting  ee011215-8bf3-4bb3-8a68-7d850af3d415\n=> Collected GridMet data for 19285 cells\ncollecting  ee01ca4b-9ca9-4e2d-9c77-54728b477342\n=> Collected GridMet data for 19286 cells\ncollecting  ee023af6-b074-4aeb-ad9d-27f869108a61\n=> Collected GridMet data for 19287 cells\ncollecting  ee08558d-a6ce-4fb0-8a7a-223eca00f42d\ncollecting  ee0c41bc-1d2f-416a-9dc6-f099c837c02c\n=> Collected GridMet data for 19289 cells\ncollecting  ee0e92d8-fe7d-41b7-9943-663f8d0a620e\n=> Collected GridMet data for 19290 cells\ncollecting  ee0f47ce-1c47-452b-9cdc-e9f35d29fb4f\n=> Collected GridMet data for 19291 cells\n=> Collected GridMet data for 19292 cells\ncollecting  ee1c1c7e-8053-4c4d-9063-4dd220808ff5\n=> Collected GridMet data for 19293 cells\n=> Collected GridMet data for 19295 cells\ncollecting  ee284f73-633d-47d2-bd3a-e7d134d2c836\n=> Collected GridMet data for 19296 cells\ncollecting  ee2e0533-a9dd-44ac-9263-df1be35d644c\ncollecting  ee2f4239-9849-4601-9cfc-5a272d3106c0\n=> Collected GridMet data for 19299 cells\n=> Collected GridMet data for 19307 cells\n=> Collected GridMet data for 19308 cells\ncollecting  ee440ed2-28f8-4328-8f91-549059889b1b\n=> Collected GridMet data for 19309 cells\ncollecting  ee444872-41bf-471e-bdd5-72977f74eaf5\n=> Collected GridMet data for 19310 cells\ncollecting  ee53f483-e1b4-420d-9e5a-b9ddeb390c0d\n=> Collected GridMet data for 19315 cells\ncollecting  ee55cd94-2bbe-4c26-b4ad-2e984d1ea933\n=> Collected GridMet data for 19316 cells\ncollecting  ee571951-0361-4496-8f59-054d571fb31f\n=> Collected GridMet data for 19317 cells\ncollecting  ee57bc9a-08c8-4de7-ac25-3f3520710fc8\n=> Collected GridMet data for 19318 cells\ncollecting  ee57e5fa-aa8c-419d-bb9b-8440d95905a4\n=> Collected GridMet data for 19319 cells\ncollecting  ee593c29-a295-4d8c-b706-dc0971336f51\n=> Collected GridMet data for 19320 cells\ncollecting  ee5e829c-1c75-43fb-84c2-ac1703bcb42e\n=> Collected GridMet data for 19321 cells\ncollecting  ee621596-6b65-4958-a397-33a70279dc7b\n=> Collected GridMet data for 19322 cells\ncollecting  ee64890d-1f97-4219-97ea-6e681f9d4c16\n=> Collected GridMet data for 19323 cells\ncollecting  ee68e76c-cf04-4e2c-a843-934be73fa56a\n=> Collected GridMet data for 19324 cells\ncollecting  ee69b465-415f-4bce-9bcd-e1e413605f4a\n=> Collected GridMet data for 19325 cells\ncollecting  ee6f34ce-b8eb-4659-84a9-e3b67f294060\ncollecting  ee7aa34f-fb1a-40a3-8e71-a1f78fe0415c\ncollecting  ee857e74-1473-4718-94ad-fa85295fc36f\ncollecting  ee899e39-265a-4e0a-90af-be1bcd28a611\ncollecting  ee8b1741-d3ff-4efd-9ae3-1ffff54c445c\n=> Collected GridMet data for 19338 cells\ncollecting  ee93f4b1-8dee-475a-8d41-7a82911f4c8f\n=> Collected GridMet data for 19341 cells\n=> Collected GridMet data for 19350 cells\ncollecting  eec102d7-8267-497a-ae1b-85febfa60eef\n=> Collected GridMet data for 19357 cells\ncollecting  eec5e06e-aeec-4f37-aa27-df92f33bc85d\n=> Collected GridMet data for 19358 cells\ncollecting  eec85f70-2250-4de1-9587-752c8a4c75ef\n=> Collected GridMet data for 19360 cells\ncollecting  eeca6e2c-c4c9-4be5-abd0-5f80ca2b9209\n=> Collected GridMet data for 19361 cells\ncollecting  eecac9b0-8d03-45f4-b866-8e8654339869\n=> Collected GridMet data for 19362 cells\ncollecting  eecd5d89-2123-4931-bb64-953c40bf75d8\n=> Collected GridMet data for 19363 cells\ncollecting  eecdc67c-2d59-444f-9f80-b6100115c1db\n=> Collected GridMet data for 19364 cells\ncollecting  eecef4c0-2fdd-4e5d-87f0-4dde9d2d84d9\n=> Collected GridMet data for 19365 cells\n=> Collected GridMet data for 19382 cells\ncollecting  ef0cf19f-faf5-4cc9-87cb-5f6cdf8530a2\ncollecting  ef35bdd6-d946-4cc0-bf37-81c295d4dbc7\ncollecting  ef45144e-6e07-4ea4-aba0-53c88e599b0b\ncollecting  ef463e68-a399-4aca-8c9d-4834ee75a93a\n=> Collected GridMet data for 19404 cells\ncollecting  ef6b4fd4-e8da-4198-9571-d62c0b4fe45e\n=> Collected GridMet data for 19414 cells\ncollecting  ef7dc31e-9ec5-4ab6-8e73-94e570dbcdfb\n=> Collected GridMet data for 19419 cells\ncollecting  efa1b615-3ad1-49b0-9376-a382693fdfdd\n=> Collected GridMet data for 19436 cells\ncollecting  efb97a8f-dad0-44c6-acb3-30181c74dcc7\ncollecting  efb9d500-430b-469e-a361-4daeb17e64f5\n=> Collected GridMet data for 19447 cells\ncollecting  efec013b-bbd9-435f-834e-a0700b77c978\n=> Collected GridMet data for 19448 cells\ncollecting  effb5c9b-5686-4697-8cbd-ea6a10db939c\n=> Collected GridMet data for 19452 cells\n=> Collected GridMet data for 19458 cells\ncollecting  f0181ada-e9ba-4b8b-bc25-86c997de6192\n=> Collected GridMet data for 19459 cells\ncollecting  f019f691-a179-4e77-b38d-dfff20e21c9b\n=> Collected GridMet data for 19460 cells\ncollecting  f01c8d00-6ff1-4cee-addb-32e23d3001b1\n=> Collected GridMet data for 19461 cells\n=> Collected GridMet data for 19469 cells\ncollecting  f05a3307-6228-4ca9-9eec-edcec070d93a\ncollecting  f05b4270-6823-4c97-9bd4-0a1b1ae2829d\ncollecting  f069851c-694b-42ef-b0fe-4e4163bbc31d\n=> Collected GridMet data for 19478 cells\ncollecting  f0738330-14c0-4301-b9c8-13680d0cd343\ncollecting  f0739e0d-ed73-4c56-a126-a45defcd4704\n=> Collected GridMet data for 19480 cells\ncollecting  f0746316-7a61-43d2-9b64-2884ac30a87a\n=> Collected GridMet data for 19481 cells\ncollecting  f079e6fb-c45f-432b-afbb-c34f0d3aafc5\n=> Collected GridMet data for 19482 cells\ncollecting  f07b4254-c2fe-41f0-8658-37509630d9fa\n=> Collected GridMet data for 19483 cells\ncollecting  f07bbac8-3866-4522-b917-5a11f46152cb\n=> Collected GridMet data for 19484 cells\ncollecting  f07ceced-9da7-446b-b330-1cf48b4b705a\n=> Collected GridMet data for 19497 cells\ncollecting  f0975d34-8fb1-4294-ac93-8c5d410fcee4\n=> Collected GridMet data for 19498 cells\ncollecting  f098a008-0f1c-484a-a2f7-cd59d4792e44\n=> Collected GridMet data for 19499 cells\ncollecting  f09fae48-48ee-4894-a8bd-079b523ca689\n=> Collected GridMet data for 19506 cells\ncollecting  f0ad6f80-40a9-4338-8bad-b9f29c185344\n=> Collected GridMet data for 19507 cells\ncollecting  f0b0b0ac-8867-4e58-94e0-8970205bbb96\n=> Collected GridMet data for 19508 cells\ncollecting  f0b19d3a-e682-4cdd-8fde-30bd3ba54229\n=> Collected GridMet data for 19509 cells\ncollecting  f0b72b2d-f542-4c7a-870d-77727dcef4e6\ncollecting  f0bfa8ff-e00d-42f1-92b4-bd4e4ed18816\ncollecting  f0d5400f-54c0-4e99-b589-bc6653216dd2\n=> Collected GridMet data for 19516 cells\ncollecting  f0d78a98-56d3-4bed-b730-00f6efa0d2ee\n=> Collected GridMet data for 19517 cells\n=> Collected GridMet data for 19518 cells\ncollecting  f0dd4683-714d-4bac-b9e8-bdc1672b64df\n=> Collected GridMet data for 19519 cells\ncollecting  f0e26bec-b280-4faa-94e3-fdbb70d95c44\n=> Collected GridMet data for 19520 cells\ncollecting  f0e297cb-93eb-4b10-b53d-e4edd296a1cc\n=> Collected GridMet data for 19521 cells\ncollecting  f0e362be-cf41-4c9f-91ca-3f1db6ad6ca0\n=> Collected GridMet data for 19522 cells\ncollecting  f0e683f8-7e5c-4a56-9d8d-054bd3dc5eb3\n=> Collected GridMet data for 19524 cells\ncollecting  f0e70752-78c6-4290-b267-c41c0b854e4e\n=> Collected GridMet data for 19525 cells\ncollecting  f0ecf9c7-f9ee-4e1e-a013-d63eaeb34301\n=> Collected GridMet data for 19526 cells\ncollecting  f0ed3550-f107-4d95-b034-85178f0d6ea0\n=> Collected GridMet data for 19527 cells\ncollecting  f0eed77c-2e2f-4a60-8bd8-22798e440127\n=> Collected GridMet data for 19528 cells\ncollecting  f0f5ea13-bb2b-4046-bfd1-57f0d63447c8\n=> Collected GridMet data for 19529 cells\n=> Collected GridMet data for 19534 cells\ncollecting  f11512ab-b246-48c7-b84b-1e19b20c3600\n=> Collected GridMet data for 19537 cells\ncollecting  f11515e9-f2a0-4f8c-9f2d-12b9e2dc8569\n=> Collected GridMet data for 19538 cells\ncollecting  f119adee-e8dc-4b61-aa8c-3fe0c70aca5a\n=> Collected GridMet data for 19540 cells\ncollecting  f11d6930-bb68-4bea-81d8-eaff4401cb3f\n=> Collected GridMet data for 19543 cells\ncollecting  f1241987-d931-4430-a670-515853c68978\n=> Collected GridMet data for 19553 cells\n=> Collected GridMet data for 19554 cells\n=> Collected GridMet data for 19557 cells\ncollecting  f1435fd0-e0e4-4820-8827-842bc443e134\ncollecting  f1468af8-8219-4bba-9c8e-5083096e1790\n=> Collected GridMet data for 19561 cells\ncollecting  f14ea4bc-80d1-4e61-888d-ae3e5baf7e0b\n=> Collected GridMet data for 19563 cells\ncollecting  f14fbd0f-f53b-4b03-a152-3616bb0a4dc6\n=> Collected GridMet data for 19564 cells\ncollecting  f1508b9c-95fe-46e5-bc0e-ba14c1c0d329\n=> Collected GridMet data for 19565 cells\ncollecting  f151a0f7-0423-4e3c-b6cd-4fbe1fb6aba4\n=> Collected GridMet data for 19566 cells\ncollecting  f153c733-258e-4399-86ac-d0878ab13a86\n=> Collected GridMet data for 19567 cells\ncollecting  f154a9e5-ffa9-4e0a-a541-38c6de9922ee\n=> Collected GridMet data for 19568 cells\ncollecting  f15749a7-5e63-4074-a979-5703f04143f3\n=> Collected GridMet data for 19569 cells\ncollecting  f1581647-4086-45ad-b946-c36651f20217\n=> Collected GridMet data for 19570 cells\ncollecting  f15c089f-0166-4898-9208-ef8103546c57\n=> Collected GridMet data for 19572 cells\n=> Collected GridMet data for 19573 cells\n=> Collected GridMet data for 19575 cells\ncollecting  f167fce5-2ee0-4c94-9457-b2ab2d5d7d77\ncollecting  f1724395-a895-44fb-a4ff-cf903f876571\ncollecting  f179f168-a83c-497a-9c20-df1209d9ffad\n=> Collected GridMet data for 19579 cells\n=> Collected GridMet data for 19580 cells\ncollecting  f180af69-4adf-4797-a283-2b31cd3eca93\ncollecting  f18232ba-f37f-46ce-a42c-8d5921cd010a\n=> Collected GridMet data for 19582 cells\ncollecting  f186179d-6b34-4e6f-b21f-b46eaef65028\ncollecting  f1863e5f-a956-4b5b-9fec-78c4e95c8196\n=> Collected GridMet data for 19587 cells\ncollecting  f18edc56-f326-4f31-ba7f-4bb4a804a439\n=> Collected GridMet data for 19588 cells\ncollecting  f18fc0ab-cbb6-46c5-91f8-c8153911d4b6\n=> Collected GridMet data for 19589 cells\ncollecting  f1902f3b-5a5c-44ea-aab9-0392ba7d842a\ncollecting  f19606d7-7be5-4f33-99fe-5a4ddf9206c1\n=> Collected GridMet data for 19591 cells\n=> Collected GridMet data for 19594 cells\n=> Collected GridMet data for 19598 cells\ncollecting  f1b1d054-e6d1-4001-a13b-7474d47f2d38\n=> Collected GridMet data for 19604 cells\ncollecting  f1bd5406-67e8-43cc-a0e3-e9111edcb1e6\n=> Collected GridMet data for 19605 cells\ncollecting  f1bfe6d3-3318-4ea7-8bf1-3739bf0c88d0\n=> Collected GridMet data for 19606 cells\ncollecting  f1c6c7ac-138a-4954-aea0-ff59f5e10a75\n=> Collected GridMet data for 19614 cells\ncollecting  f1ee9f15-f11e-4eb8-af49-fc648ca8cf30\ncollecting  f1ef65ac-461e-4495-bf2e-7f22a7d9bb1e\n=> Collected GridMet data for 19619 cells\ncollecting  f1f086d4-80d3-439b-9e17-0d05e59c500d\n=> Collected GridMet data for 19620 cells\ncollecting  f1f17cee-3fca-44bc-8974-b72d5f995a4a\ncollecting  f1f3f0e9-2c89-4ba5-aaae-ebbe5e87f573\n=> Collected GridMet data for 19622 cells\ncollecting  f1f44cf0-3813-4908-af4a-826e350834e4\n=> Collected GridMet data for 19623 cells\ncollecting  f1f67ef0-5f3e-45e6-bb60-8788ee87b4da\n=> Collected GridMet data for 19624 cells\n=> Collected GridMet data for 19628 cells\n=> Collected GridMet data for 19634 cells\ncollecting  f214b3da-cdf1-4222-aa64-f10af474236d\n=> Collected GridMet data for 19635 cells\ncollecting  f21a8b74-da60-4415-b284-438ef94a7d94\n=> Collected GridMet data for 19636 cells\ncollecting  f21b6816-1435-4986-82e6-0bbbfe1d5104\ncollecting  f21c91b9-7f9d-4550-bff4-7613aacdd7e0\ncollecting  f21dce76-f529-4047-a60b-da19b84658ce\n=> Collected GridMet data for 19642 cells\n=> Collected GridMet data for 19644 cells\ncollecting  f232b80c-1d57-4972-8273-22641b1ab51e\n=> Collected GridMet data for 19647 cells\n=> Collected GridMet data for 19648 cells\n=> Collected GridMet data for 19650 cells\n=> Collected GridMet data for 19651 cells\ncollecting  f23e90ec-5605-49e1-850d-6a7c1ed1398b\n=> Collected GridMet data for 19652 cells\n=> Collected GridMet data for 19655 cells\n=> Collected GridMet data for 19656 cells\ncollecting  f2576c32-207d-4652-89e4-2ea0089402df\n=> Collected GridMet data for 19663 cells\ncollecting  f257ece8-173e-4091-8749-547155f70449\n=> Collected GridMet data for 19664 cells\ncollecting  f2589c84-c6ae-4d23-beca-532601198cc1\n=> Collected GridMet data for 19665 cells\ncollecting  f25946e8-7329-416d-9f3a-ea78b9993e40\n=> Collected GridMet data for 19666 cells\ncollecting  f25b039d-7450-4baf-8603-d29146cd964d\n=> Collected GridMet data for 19667 cells\ncollecting  f25cdbec-2f14-42c5-a6ef-a60f3a90caff\n=> Collected GridMet data for 19668 cells\ncollecting  f25e943a-9eea-401f-a2b7-ea4923ba10cc\n=> Collected GridMet data for 19669 cells\ncollecting  f266da1a-787d-4bb7-9dd8-15efda27878b\ncollecting  f26dbfc0-3d72-484a-86a9-81a6b1faa4de\n=> Collected GridMet data for 19672 cells\n=> Collected GridMet data for 19673 cells\ncollecting  f26f26dc-a0cf-4289-8fc0-3a51dd2675cf\n=> Collected GridMet data for 19674 cells\ncollecting  f2714089-bc86-44d2-b93a-1d23066e0ab3\n=> Collected GridMet data for 19675 cells\ncollecting  f271af0f-bd4b-46fa-9413-47e3911a078e\n=> Collected GridMet data for 19676 cells\ncollecting  f277da70-13b7-4d10-b6ac-0deed186b2ea\n=> Collected GridMet data for 19677 cells\ncollecting  f279c715-944e-4cf9-914b-a384e35fcaa2\n=> Collected GridMet data for 19678 cells\n=> Collected GridMet data for 19682 cells\n=> Collected GridMet data for 19692 cells\ncollecting  f2b2ef54-bbec-44cf-a086-d3acd31be199\n=> Collected GridMet data for 19693 cells\ncollecting  f2b43b19-ceea-4ab1-ba81-8296cf60372d\n=> Collected GridMet data for 19694 cells\n=> Collected GridMet data for 19697 cells\ncollecting  f2c55a53-4182-4afd-b9a3-313e67e282de\ncollecting  f2c7a796-22be-4138-8427-b485e02a710d\ncollecting  f2cd7c81-5183-4334-9c93-66bf4d009884\ncollecting  f2d57b73-131f-4555-8740-fc96dba199f0\ncollecting  f2d60d39-44ff-4d8a-a96d-4eac0daf4360\n=> Collected GridMet data for 19708 cells\ncollecting  f2e1d0d9-c3d4-4536-8468-6ffd8e71ff8e\n=> Collected GridMet data for 19714 cells\ncollecting  f2ef5d1f-76db-447a-a01b-bb3be4112ee3\ncollecting  f301182c-7eb5-4ad6-bbb9-fb42bb19a07f\ncollecting  f31614c8-cc4d-47c1-9265-8ce10e0dc08d\n=> Collected GridMet data for 19724 cells\n=> Collected GridMet data for 19727 cells\n=> Collected GridMet data for 19739 cells\n=> Collected GridMet data for 19740 cells\ncollecting  f3601bb9-de2f-4810-819d-f1a75dd40179\n=> Collected GridMet data for 19741 cells\ncollecting  f3637f57-767e-4bdb-8ebc-24efe192290c\n=> Collected GridMet data for 19748 cells\n=> Collected GridMet data for 19752 cells\ncollecting  f3807d1c-c14f-4d6e-a6d3-3c0890130a16\ncollecting  f38dc9b5-2935-4e0e-b1d6-bb7a07353b79\ncollecting  f39e158a-1b4c-42a2-930d-14b25b6b23bc\n=> Collected GridMet data for 19765 cells\ncollecting  f39e9833-ae54-4085-a509-d3e04bf08876\n=> Collected GridMet data for 19766 cells\ncollecting  f39fe99f-77db-4642-8e9b-7451c4f04af3\n=> Collected GridMet data for 19767 cells\ncollecting  f3a2656f-51c0-46ad-b9eb-508a099f8f51\n=> Collected GridMet data for 19768 cells\ncollecting  f3aa124e-70ea-4489-ad62-d933a0d100a7\ncollecting  f3c67cf1-f09e-4cce-996d-62c64c79803e\n=> Collected GridMet data for 19779 cells\ncollecting  f3ce09d4-b8c7-4284-b7a3-26f2e636ed6b\n=> Collected GridMet data for 19781 cells\ncollecting  f3d1c481-ce87-46ee-b254-a2983d0d3aca\n=> Collected GridMet data for 19782 cells\ncollecting  f3d34c92-b617-4920-8482-6b1ff84ecda4\n=> Collected GridMet data for 19791 cells\n=> Collected GridMet data for 19796 cells\ncollecting  f407ee61-48de-4e0b-9278-b4d9f1bf97d6\n=> Collected GridMet data for 19797 cells\ncollecting  f40f0161-faf5-4219-8677-1876afd4bdb6\n=> Collected GridMet data for 19803 cells\n=> Collected GridMet data for 19805 cells\ncollecting  f41e2cbe-252e-4570-94a1-5a90dd29778e\n=> Collected GridMet data for 19806 cells\ncollecting  f42edfab-fcec-43d9-a9a2-5f190a6e8f47\n=> Collected GridMet data for 19807 cells\ncollecting  f43449b7-ac09-4824-9cc8-84120a11b598\n=> Collected GridMet data for 19808 cells\ncollecting  f43671f4-d5c8-4445-b08d-e26de6cb542c\n=> Collected GridMet data for 19810 cells\n=> Collected GridMet data for 19811 cells\n=> Collected GridMet data for 19814 cells\ncollecting  f44bf871-95f5-475b-8b8c-2706695ced82\n=> Collected GridMet data for 19818 cells\ncollecting  f45942d7-a3d8-4be7-b12d-79812c063dde\ncollecting  f4601cde-2ec8-4420-aa7f-dc29807783e0\n=> Collected GridMet data for 19824 cells\ncollecting  f464367f-df51-47c0-9339-ebd9899e26eb\n=> Collected GridMet data for 19825 cells\ncollecting  f4671817-1546-46f4-aa67-812c74491e30\n=> Collected GridMet data for 19826 cells\ncollecting  f478740f-fe47-4dc2-89eb-c6a0e5c61c29\n=> Collected GridMet data for 19837 cells\ncollecting  f47dfbac-cc3f-40b5-a798-444f0dd8c6c5\n=> Collected GridMet data for 19838 cells\ncollecting  f4832fbb-c1e9-4f54-8def-464720a9ebd7\n=> Collected GridMet data for 19839 cells\ncollecting  f48bff6a-72de-4200-9528-712fe58e849e\n=> Collected GridMet data for 19843 cells\ncollecting  f48d8ae0-fe2d-4acb-a02d-3b42abb592a3\n=> Collected GridMet data for 19849 cells\n=> Collected GridMet data for 19851 cells\n=> Collected GridMet data for 19863 cells\n=> Collected GridMet data for 19868 cells\ncollecting  f4d001b4-9661-4393-9324-b90e4879b91d\n=> Collected GridMet data for 19869 cells\n=> Collected GridMet data for 19873 cells\n=> Collected GridMet data for 19874 cells\ncollecting  f4f70560-6bf7-4a77-b1d6-b9ef3a233262\n=> Collected GridMet data for 19880 cells\n=> Collected GridMet data for 19887 cells\ncollecting  f5171ca5-da0f-4407-a09a-71290d4bb062\n=> Collected GridMet data for 19890 cells\ncollecting  f51a5ad4-a0db-4621-9ba5-230d9da662b5\ncollecting  f51d0c48-a1e1-44d2-8566-88ff2c3b9fbe\ncollecting  f51f58dd-a81c-416a-9f47-f0ed7e2f8df8\n=> Collected GridMet data for 19895 cells\ncollecting  f52bc0de-3d8e-4a71-97ba-e9f9753b0580\ncollecting  f52ded70-fc2a-4db9-b30f-6c27d38bd84c\n=> Collected GridMet data for 19899 cells\ncollecting  f52f472f-c7b5-4f32-972f-ecb028589e79\ncollecting  f558c0b8-62df-4d96-ba9a-92ea9c706af3\ncollecting  f55a640d-8101-40dd-91af-29549bcfa7ba\ncollecting  f55b7eb4-f103-403f-9002-dc87fce5fe94\n=> Collected GridMet data for 19908 cells\ncollecting  f55b99f3-1851-42d1-b794-2d9d424a0617\n=> Collected GridMet data for 19909 cells\ncollecting  f55dc5d9-97e1-4361-ba11-7788cbef0c4e\n=> Collected GridMet data for 19910 cells\ncollecting  f55f05d9-a9f1-4433-b8fe-dfc312cd50e0\n=> Collected GridMet data for 19911 cells\ncollecting  f5602a4e-d5da-4dc5-b003-3b507927852c\n=> Collected GridMet data for 19912 cells\ncollecting  f5611d90-2edd-4e6a-b95e-83a5c68a588f\n=> Collected GridMet data for 19916 cells\n=> Collected GridMet data for 19922 cells\n=> Collected GridMet data for 19927 cells\ncollecting  f5822769-f5b8-468f-9563-3375ad0f5fb8\n=> Collected GridMet data for 19928 cells\ncollecting  f5859574-bb61-4004-b92f-b4478bd62f1a\n=> Collected GridMet data for 19930 cells\ncollecting  f5944653-c01e-480f-8d1e-be43cb255ac1\n=> Collected GridMet data for 19935 cells\ncollecting  f5ab4b19-df53-4428-834b-e87a3d798fb1\n=> Collected GridMet data for 19942 cells\ncollecting  f5b14841-133a-4f3c-a4cd-b53ffafe1a1a\n=> Collected GridMet data for 19943 cells\ncollecting  f5b223b3-2c5a-4ec3-9fe1-85eb1dea33d9\n=> Collected GridMet data for 19944 cells\ncollecting  f5b6de04-c96f-477f-8538-d3eab7c7d882\n=> Collected GridMet data for 19945 cells\ncollecting  f5b89bd4-3835-4fc1-8095-5be528081657\n=> Collected GridMet data for 19946 cells\ncollecting  f5b8a3c6-348a-4ffd-bcfc-6c95610e9430\n=> Collected GridMet data for 19947 cells\ncollecting  f5bea682-58d3-487d-9a33-ccddcb04d90c\n=> Collected GridMet data for 19948 cells\ncollecting  f5c0114f-6ada-4007-9841-115393d5f22e\n=> Collected GridMet data for 19949 cells\ncollecting  f5d009c3-8342-4cf7-9ddb-7e79f9640d0c\n=> Collected GridMet data for 19950 cells\ncollecting  f5d0e6f5-0627-4de7-8d56-ee44816d8a71\n=> Collected GridMet data for 19951 cells\ncollecting  f5d1181a-10e0-4a36-8fab-f9b0bc9a0cee\n=> Collected GridMet data for 19952 cells\ncollecting  f5d409a8-5e05-44a3-aa15-9de8175f8498\n=> Collected GridMet data for 19954 cells\ncollecting  f5d40b9a-efb4-47ef-996b-f2fe186d5976\n=> Collected GridMet data for 19955 cells\ncollecting  f5d7403d-af52-4e79-b167-bcb5318619de\ncollecting  f5eaf74d-314e-4430-bc2b-9327db442d8f\ncollecting  f6043c09-1028-4e41-bece-72693523c75d\n=> Collected GridMet data for 19974 cells\ncollecting  f60ce3fc-4a94-4a87-80a6-e3d849419df4\n=> Collected GridMet data for 19975 cells\ncollecting  f60d08a9-b89a-4f78-a482-f97b5e340eac\n=> Collected GridMet data for 19976 cells\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\n=> Collected GridMet data for 19977 cells\ncollecting  f61f6fe8-d458-4489-ba62-b2b729b42cdd\n=> Collected GridMet data for 19989 cells\ncollecting  f6454a7c-78e8-4169-964e-c32351daf3bc\ncollecting  f6542394-1c6a-4171-8a06-9f4feae4ac6d\ncollecting  f65a918f-45e7-4b7e-ac14-ef0100cfda2d\ncollecting  f65d77a7-e556-435c-8870-80f3a0d39a0c\ncollecting  f65e9e9c-05f1-49be-a17e-d71e37025fad\n=> Collected GridMet data for 20005 cells\ncollecting  f6608f69-aeca-4ae0-86c8-a1e462001a9a\n=> Collected GridMet data for 20006 cells\ncollecting  f66325f5-64c8-423e-8361-81f9d8fa1071\n=> Collected GridMet data for 20007 cells\ncollecting  f6640a09-a368-40db-a145-e7ce27500834\n=> Collected GridMet data for 20008 cells\ncollecting  f66534e4-9b3d-4d8b-89aa-74c986d2a95a\n=> Collected GridMet data for 20009 cells\ncollecting  f6682a53-92f6-4599-a298-12fdb1c12468\ncollecting  f66cb2e5-e967-4123-9c4e-afddc01bda6f\n=> Collected GridMet data for 20011 cells\ncollecting  f66f3c90-f9e1-43cd-981c-d4285ffe9c78\n=> Collected GridMet data for 20012 cells\ncollecting  f674973f-0f50-4dc8-948b-1b565a100759\n=> Collected GridMet data for 20013 cells\ncollecting  f6753300-acaf-45b7-bd94-cdb0b20ca005\ncollecting  f67cdaef-aa64-4598-9b48-9980fda627a8\n=> Collected GridMet data for 20018 cells\ncollecting  f67db21e-b100-44ec-b2f4-bf53b39d42c2\n=> Collected GridMet data for 20020 cells\ncollecting  f68b8b71-8a32-4f3b-9d8d-2d6617af5fb5\ncollecting  f6ad6005-9d03-4eeb-8548-308db1fb0fce\n=> Collected GridMet data for 20032 cells\ncollecting  f6b2eda5-9bc0-4fe5-8922-4f3334161076\n=> Collected GridMet data for 20033 cells\ncollecting  f6b33c42-a1d0-4866-928f-2dc12972cb20\n=> Collected GridMet data for 20043 cells\ncollecting  f6d4b4a8-50ff-4855-a249-04f8c40a0e5e\ncollecting  f6e70ca6-cb93-403f-8523-b9e0c9d76ce3\n=> Collected GridMet data for 20048 cells\ncollecting  f6ebbe5c-e836-466c-b4d1-7a7b49f26ec5\n=> Collected GridMet data for 20049 cells\ncollecting  f6edd301-7099-4495-8858-2403c0c5cea7\n=> Collected GridMet data for 20050 cells\ncollecting  f6eea24a-8bfa-4adc-acbc-b66a1aac85ba\n=> Collected GridMet data for 20051 cells\n=> Collected GridMet data for 20058 cells\n=> Collected GridMet data for 20060 cells\ncollecting  f702f922-fa67-4ddd-aeec-9f8e1ac804e8\n=> Collected GridMet data for 20061 cells\ncollecting  f7032337-7fe7-4a47-bdb6-1efef1c441a7\n=> Collected GridMet data for 20062 cells\n=> Collected GridMet data for 20065 cells\ncollecting  f70fd2f2-64cf-4e65-ac24-b81cba12e742\n=> Collected GridMet data for 20066 cells\ncollecting  f7163384-10cb-4176-b38a-bddcc0040f13\n=> Collected GridMet data for 20067 cells\ncollecting  f71da383-8ac1-43f0-a35f-e9f6720ad16f\n=> Collected GridMet data for 20068 cells\ncollecting  f71f6051-9cd6-43bd-9393-9c0c9a05be25\ncollecting  f758d0f4-7706-4b60-aa4d-89c6091a4f5e\ncollecting  f76302e6-4300-40a0-b4de-76da14adaaf7\n=> Collected GridMet data for 20085 cells\ncollecting  f77c3740-b9c6-4f3a-970c-2793eb11e5a9\n=> Collected GridMet data for 20086 cells\ncollecting  f77e0497-175a-4263-8155-d1e3ffbd7e43\n=> Collected GridMet data for 20087 cells\ncollecting  f77e4232-9906-4294-8ee0-d4220dc095c0\n=> Collected GridMet data for 20088 cells\ncollecting  f77e69b6-fc31-4aa2-a23a-d3d632a37f5b\n=> Collected GridMet data for 20093 cells\n=> Collected GridMet data for 20095 cells\n=> Collected GridMet data for 20096 cells\ncollecting  f79a9395-e00c-4f88-9cbf-9372259d3f71\n=> Collected GridMet data for 20097 cells\n=> Collected GridMet data for 20102 cells\ncollecting  f7a5bbee-9a79-4344-8399-f76d7fe7e329\n=> Collected GridMet data for 20103 cells\ncollecting  f7a65897-1bdd-40c3-853e-370d73c65bed\n=> Collected GridMet data for 20104 cells\ncollecting  f7f87170-56e0-4c1b-9077-5e46816d200e\n=> Collected GridMet data for 20119 cells\ncollecting  f7fd33fc-7d78-46ec-8cfc-8aff5603a032\ncollecting  f804c491-32ae-4752-bcce-86f7cdda45c4\ncollecting  f806dbd3-ded5-4b1d-b2b2-1ca7e298e38a\n=> Collected GridMet data for 20122 cells\n=> Collected GridMet data for 20134 cells\ncollecting  f85e5441-9bd9-4004-8280-289c52ab86ff\n=> Collected GridMet data for 20150 cells\ncollecting  f86590c7-abec-43bd-ae01-e05dd3afdf61\n=> Collected GridMet data for 20151 cells\ncollecting  f868f65b-9ace-4d61-ae11-5fe03ca45c57\n=> Collected GridMet data for 20152 cells\ncollecting  f86a633f-31de-4359-ab16-bf310cc75c8a\n=> Collected GridMet data for 20153 cells\ncollecting  f86aa6bf-5609-48d4-9193-552afc4d086b\n=> Collected GridMet data for 20154 cells\ncollecting  f86baed5-5a5e-47d7-afe9-1cafa9badbcd\n=> Collected GridMet data for 20155 cells\ncollecting  f86d0f7e-17ce-485f-bde9-75b489cdb805\ncollecting  f87134f1-14cb-471e-8f8e-be677f28a45a\ncollecting  f87899a1-487d-4251-97c0-711ff3280002\n=> Collected GridMet data for 20164 cells\ncollecting  f8833110-a6cc-4491-bcce-4dd7e55f3636\n=> Collected GridMet data for 20167 cells\ncollecting  f884e591-2664-4834-9d03-91bf834d57dc\ncollecting  f8890f8d-0e16-4143-a18e-9f919e660b20\n=> Collected GridMet data for 20169 cells\ncollecting  f8898b93-7a36-4022-827f-cb359db7a164\n=> Collected GridMet data for 20170 cells\n=> Collected GridMet data for 20171 cells\ncollecting  f89006ba-311c-406d-9a6b-7e0ba339cf23\n=> Collected GridMet data for 20172 cells\ncollecting  f8957177-3f46-43e9-93d5-d294d3ec71ab\n=> Collected GridMet data for 20173 cells\ncollecting  f8a06893-668d-4e29-a0ab-4274bc4eea24\n=> Collected GridMet data for 20174 cells\ncollecting  f8a0ea21-9acf-4682-b4f5-c7e796443818\n=> Collected GridMet data for 20175 cells\ncollecting  f8a2acb2-9f92-4e22-ac13-5e5266c47661\n=> Collected GridMet data for 20176 cells\ncollecting  f8a6023c-8caf-469f-8861-ba71d0b2be19\n=> Collected GridMet data for 20177 cells\ncollecting  f8a66da6-c3a0-4ed4-acff-96109a839ad8\n=> Collected GridMet data for 20178 cells\ncollecting  f8ac5c72-a6ef-45ec-8275-68076a3b7276\n=> Collected GridMet data for 20179 cells\ncollecting  f8afc2d0-acf7-478b-b661-3fe05afa2cdc\n=> Collected GridMet data for 20180 cells\ncollecting  f8b19b56-99ec-4b2b-91f3-6d94755e0cb1\n=> Collected GridMet data for 20181 cells\ncollecting  f8c02326-346c-4f4a-8308-482f7c602698\n=> Collected GridMet data for 20182 cells\ncollecting  f8c18410-b359-4d5c-a185-c71d7bcf1e43\n=> Collected GridMet data for 20183 cells\ncollecting  f8c2607c-94b3-4d95-82bb-75312c6d9462\ncollecting  f8c5100a-e363-4321-aeea-6263bc08a839\n=> Collected GridMet data for 20186 cells\ncollecting  f8c5e68a-df8a-481d-9519-0ea31e5910b8\n=> Collected GridMet data for 20187 cells\ncollecting  f8cc00dc-bb92-41fc-b770-a01365bb4872\n=> Collected GridMet data for 20188 cells\ncollecting  f8cc7259-1018-4873-8181-61ca1073a2d7\n=> Collected GridMet data for 20189 cells\ncollecting  f8dba40d-1cb2-4b98-b348-c201abe276f1\n=> Collected GridMet data for 20190 cells\ncollecting  f8de53dd-4f03-4749-9340-d6d54a878063\n=> Collected GridMet data for 20191 cells\ncollecting  f8deaf48-bcbe-4ab8-8a60-465e2ac9dcb6\n=> Collected GridMet data for 20192 cells\ncollecting  f8e1cb6b-3a72-4acd-ad72-9834c6964cee\n=> Collected GridMet data for 20193 cells\ncollecting  f8e2f819-1c12-4f5d-b32c-d6e8ce3a571d\n=> Collected GridMet data for 20194 cells\ncollecting  f8f1b8e0-e14b-49d8-ad1a-bb799536d2cc\n=> Collected GridMet data for 20195 cells\ncollecting  f8fd77aa-e6df-4373-bcac-fa542af51b1a\n=> Collected GridMet data for 20196 cells\ncollecting  f9007349-8d3d-40e1-b6a2-37a0a8f16070\n=> Collected GridMet data for 20197 cells\ncollecting  f901980c-e4a7-4172-b2b6-c0172c0d0dd2\n=> Collected GridMet data for 20198 cells\ncollecting  f90c85ef-89cd-438a-8952-6c3723ad3a11\n=> Collected GridMet data for 20199 cells\ncollecting  f912fe52-a2d0-4ab1-a5eb-05fe254086c3\n=> Collected GridMet data for 20200 cells\ncollecting  f91627e9-5b77-4d7e-af62-bac7a6915ab5\ncollecting  f919df76-4309-498e-962d-18f692ff4cc6\n=> Collected GridMet data for 20202 cells\n=> Collected GridMet data for 20203 cells\ncollecting  f92ef899-b4c7-4a6d-91a9-0dba8f86e6f9\n=> Collected GridMet data for 20210 cells\ncollecting  f93ee447-1331-44b5-a933-59e01661301b\n=> Collected GridMet data for 20211 cells\ncollecting  f94103cd-44f7-4d76-85ca-42a147dce0b7\n=> Collected GridMet data for 20212 cells\ncollecting  f944aa17-f33e-44e7-ab77-32bf7b7a1532\n=> Collected GridMet data for 20213 cells\ncollecting  f94813e1-1d1f-4bab-bf7d-fd6a2960754a\n=> Collected GridMet data for 20214 cells\ncollecting  f94a79c8-4d28-4b7e-8cfa-f068aa7f462c\n=> Collected GridMet data for 20215 cells\ncollecting  f94e2f83-08c0-41c4-aa94-ce3ae47f78b1\n=> Collected GridMet data for 20216 cells\ncollecting  f9548d88-9f1d-4645-ae9e-0d7c1e27cb20\n=> Collected GridMet data for 20218 cells\ncollecting  f95af6dd-4cba-4d9e-b887-39432bcdbd58\n=> Collected GridMet data for 20219 cells\ncollecting  f95ea72e-cc7d-4a5e-8890-fe6b9a7f3d27\n=> Collected GridMet data for 20220 cells\ncollecting  f95fd38f-a9cb-4d7e-bf19-f883e010c283\n=> Collected GridMet data for 20221 cells\n=> Collected GridMet data for 20222 cells\ncollecting  f965a162-c2be-48be-802e-6fb522ab0dde\n=> Collected GridMet data for 20223 cells\n=> Collected GridMet data for 20232 cells\ncollecting  f98332d5-b0cf-4511-994f-6baa59e479a1\ncollecting  f98c65bc-45ab-41c6-ac57-3f6fb8c188af\n=> Collected GridMet data for 20235 cells\ncollecting  f98db28a-8833-4d82-8c22-3de5791a62dd\ncollecting  f995d5a0-6711-4290-bc74-7f937c3af0d4\n=> Collected GridMet data for 20237 cells\ncollecting  f9a3449a-de93-4193-bece-9d23e7aed82b\ncollecting  f9aa3c21-006c-4c6d-b100-b057aa57dcd5\n=> Collected GridMet data for 20239 cells\ncollecting  f9ae0654-d3b4-45b7-a00a-4c38c73460a7\n=> Collected GridMet data for 20240 cells\n=> Collected GridMet data for 20241 cells\ncollecting  f9b4236d-60bf-4cc2-bf26-3d5ae58df8a2\n=> Collected GridMet data for 20242 cells\ncollecting  f9b526b2-b79a-4eb0-8c83-89879a14017b\n=> Collected GridMet data for 20243 cells\ncollecting  f9b60574-0f86-4057-9dfb-07b9d2b99520\n=> Collected GridMet data for 20244 cells\ncollecting  f9b70de2-13a0-4e2a-85a2-54f9e374b264\n=> Collected GridMet data for 20245 cells\ncollecting  f9b7b209-2cc9-4098-8f37-eb23268b4734\n=> Collected GridMet data for 20246 cells\ncollecting  f9b7ebfa-0200-4df6-806a-ac07cf505f84\n=> Collected GridMet data for 20247 cells\ncollecting  f9ba0b2c-57b2-45f0-bd70-1b2d02e2c32c\n=> Collected GridMet data for 20248 cells\ncollecting  f9bb1931-36dd-4ee3-9d07-ebef97031e35\n=> Collected GridMet data for 20249 cells\ncollecting  f9c07b72-c4fd-4d4d-b391-28c77ece4b1e\n=> Collected GridMet data for 20250 cells\ncollecting  f9c0f1e8-0594-4926-83d0-bb027887bbd1\n=> Collected GridMet data for 20251 cells\ncollecting  f9c8b955-336d-41fb-901e-562cf9d243b9\n=> Collected GridMet data for 20252 cells\ncollecting  f9cfd512-62d1-470c-b035-ffbb9de739f2\ncollecting  f9d5038d-3e9c-4a43-b93a-762b53b16e03\n=> Collected GridMet data for 20254 cells\ncollecting  f9d51ca2-be2d-490c-b61f-6676ba4b6934\n=> Collected GridMet data for 20255 cells\ncollecting  f9d5f0a4-ec46-4496-b450-8c9593fe2e43\n=> Collected GridMet data for 20256 cells\ncollecting  f9d85588-2c24-48d9-a344-4ee3ac65a98a\n=> Collected GridMet data for 20257 cells\ncollecting  f9ddfab1-9af4-4b50-ab46-8efa81961acd\n=> Collected GridMet data for 20258 cells\ncollecting  f9e498ca-73b0-42f2-b9cb-bed38ee25187\n=> Collected GridMet data for 20259 cells\ncollecting  f9ee9b3f-f266-4766-a637-d1c9e8139b21\n=> Collected GridMet data for 20260 cells\ncollecting  f9ee9e42-8604-4926-ab53-bb0ba4e5753a\n=> Collected GridMet data for 20261 cells\ncollecting  f9f1f954-97dd-446c-a715-7e81e50bdaee\n=> Collected GridMet data for 20262 cells\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\n=> Collected GridMet data for 20263 cells\ncollecting  f9f91a0b-9c9d-441b-bc0b-2ff56c513aa0\n=> Collected GridMet data for 20264 cells\ncollecting  f9fcbd34-5113-49a5-a869-299d65d78e88\n=> Collected GridMet data for 20265 cells\ncollecting  fa011dfb-c2bd-4b58-9c0f-414e62e88462\n=> Collected GridMet data for 20266 cells\ncollecting  fa01309a-004a-4f2c-9a0b-ed907674fd64\n=> Collected GridMet data for 20267 cells\ncollecting  fa057db8-b5a9-460c-9f7c-517efc944c63\n=> Collected GridMet data for 20268 cells\ncollecting  fa063e48-3ff6-4de1-a78a-addb88cdbd3d\n=> Collected GridMet data for 20269 cells\ncollecting  fa0be774-20be-40d2-ac30-ebba47b80774\n=> Collected GridMet data for 20270 cells\ncollecting  fa0c4f49-da15-4425-9ede-cb2bee368b6e\n=> Collected GridMet data for 20271 cells\ncollecting  fa0e9d9a-bceb-446a-985c-8cc024c7ec85\n=> Collected GridMet data for 20272 cells\n=> Collected GridMet data for 20273 cells\ncollecting  fa36cb12-c24e-4131-96ca-4d71c343f8e5\ncollecting  fa398039-d10f-4aee-8ebd-5255ff869905\n=> Collected GridMet data for 20286 cells\ncollecting  fa3ee3b5-9c0f-41f9-9902-eb8eaa6e5ecd\n=> Collected GridMet data for 20287 cells\ncollecting  fa3ffafa-ec9e-47cc-a34c-b490083faab0\n=> Collected GridMet data for 20288 cells\n=> Collected GridMet data for 20294 cells\n=> Collected GridMet data for 20299 cells\ncollecting  fa71723d-4999-48ee-b64e-385fcf186389\n=> Collected GridMet data for 20300 cells\ncollecting  fa7212eb-5d13-4203-ae2a-4a847d03413a\n=> Collected GridMet data for 20302 cells\ncollecting  fa76a5b8-f980-46b9-bb47-5eae3993d9e6\n=> Collected GridMet data for 20303 cells\ncollecting  fa770e0e-f7c2-463a-969e-54b234502aa9\n=> Collected GridMet data for 20304 cells\ncollecting  fa7f3703-7141-4045-acca-1dc864e8c7ab\ncollecting  fac1c203-62a2-4641-9d35-967baf407bb3\n=> Collected GridMet data for 20326 cells\ncollecting  fad1b215-1d98-416f-9a55-c1886f8ad831\n=> Collected GridMet data for 20331 cells\ncollecting  fad72d64-cbd4-4890-b847-68077f40c8df\n=> Collected GridMet data for 20332 cells\ncollecting  fad9a878-18a1-41f3-ba54-f74fd8aa065e\n=> Collected GridMet data for 20333 cells\ncollecting  fadb21f2-e936-49df-bb9f-e1ae2870d9bd\n=> Collected GridMet data for 20334 cells\ncollecting  fadb643e-284c-4245-9f6f-6d14af4c735f\n=> Collected GridMet data for 20336 cells\ncollecting  fae43664-c197-4c45-aedc-018f13233439\n=> Collected GridMet data for 20337 cells\ncollecting  fae650b1-2892-426c-969e-ed29094dfb31\n=> Collected GridMet data for 20338 cells\ncollecting  fae769b5-2cb1-481e-a7de-affecedd460e\n=> Collected GridMet data for 20339 cells\ncollecting  faeab0f6-baaf-4984-b547-1324d1120903\n=> Collected GridMet data for 20340 cells\ncollecting  faedcf82-11dc-4e28-b933-3f6b2f741fca\n=> Collected GridMet data for 20341 cells\ncollecting  faef7dd1-2105-471e-aa2b-fc2b58f4d5e2\n=> Collected GridMet data for 20342 cells\ncollecting  faf11941-6e6e-4a14-9378-e657d0b4f7dc\n=> Collected GridMet data for 20343 cells\ncollecting  faf280a6-1019-4e0c-a5f1-8d656e465c33\n=> Collected GridMet data for 20344 cells\ncollecting  faf899e1-643b-46d7-9416-dede775e963f\n=> Collected GridMet data for 20345 cells\ncollecting  fafc4a59-b870-4948-9800-7de5d59cbb1a\n=> Collected GridMet data for 20347 cells\ncollecting  fb08d075-09c2-4a20-a8b2-ae201745da37\n=> Collected GridMet data for 20348 cells\ncollecting  fb0a1cd6-2884-4fd0-88f1-348404226088\n=> Collected GridMet data for 20349 cells\ncollecting  fb0c0253-ec81-4e9b-bf9e-55060131eb2c\n=> Collected GridMet data for 20350 cells\ncollecting  fb0d8205-7052-4c4a-83c2-6ead55933c2e\n=> Collected GridMet data for 20351 cells\ncollecting  fb0e16e7-a1cd-445c-b0c8-6c456919e78e\n=> Collected GridMet data for 20352 cells\n=> Collected GridMet data for 20353 cells\n=> Collected GridMet data for 20354 cells\n=> Collected GridMet data for 20355 cells\ncollecting  fb180be1-169c-4865-a7eb-43ac46964984\n=> Collected GridMet data for 20356 cells\ncollecting  fb1914bf-6bba-4e2a-9251-f584eeab03ad\n=> Collected GridMet data for 20357 cells\n=> Collected GridMet data for 20358 cells\n=> Collected GridMet data for 20363 cells\ncollecting  fb2d6e8d-289e-40fb-9cb0-62710d438fac\n=> Collected GridMet data for 20364 cells\ncollecting  fb2dec07-7a17-474d-84b1-5c911bb8f55c\n=> Collected GridMet data for 20365 cells\n=> Collected GridMet data for 20366 cells\ncollecting  fb31603e-7d4b-4246-ae7c-aa05ddf4e3d3\n=> Collected GridMet data for 20367 cells\ncollecting  fb32a838-cf3b-47a2-9e22-395a730f4f4f\n=> Collected GridMet data for 20368 cells\ncollecting  fb333f94-adb3-46d5-a96a-bb8634b140c2\n=> Collected GridMet data for 20369 cells\ncollecting  fb3793ab-1475-4a90-a6b0-c3a09064935b\n=> Collected GridMet data for 20370 cells\ncollecting  fb42333e-64bf-4353-ae06-7b09a48937a3\n=> Collected GridMet data for 20371 cells\ncollecting  fb456bc2-dc96-463c-ab66-cd4e31b44346\n=> Collected GridMet data for 20372 cells\ncollecting  fb52c783-ad56-41e5-8167-1a3298f4b345\n=> Collected GridMet data for 20380 cells\ncollecting  fb57d226-dab7-435d-8cc7-015a2268df20\n=> Collected GridMet data for 20381 cells\ncollecting  fb581b0d-7bac-4daa-a947-bb4654dc30a8\n=> Collected GridMet data for 20382 cells\ncollecting  fb5a5b7f-7e5a-4884-ac6c-33eff5598226\ncollecting  fb603239-7c88-4c6b-adb0-e7c9fc42df4d\n=> Collected GridMet data for 20387 cells\ncollecting  fb64ae5b-4cfd-4132-b492-e994554ee4b3\n=> Collected GridMet data for 20388 cells\ncollecting  fb694a75-8929-4f49-b1fc-fdd468502e1f\n=> Collected GridMet data for 20389 cells\ncollecting  fb69f009-a89b-4d98-adc2-0da2c21aa419\n=> Collected GridMet data for 20390 cells\ncollecting  fb6ad0c2-e153-46d3-a90d-93926ad3b4d9\n=> Collected GridMet data for 20391 cells\ncollecting  fb771f1d-b6c7-40d7-9cd2-fdb933ae3ce9\ncollecting  fb83f3ae-01e8-4997-bce0-e11c82dc3a54\n=> Collected GridMet data for 20396 cells\ncollecting  fb8470e8-5c17-47b0-b616-fce0bf97be7f\n=> Collected GridMet data for 20397 cells\ncollecting  fb8784d1-2448-43b8-baac-320677228c22\n=> Collected GridMet data for 20409 cells\n=> Collected GridMet data for 20412 cells\ncollecting  fbb61a75-3734-42ae-8475-876eb2686276\n=> Collected GridMet data for 20413 cells\ncollecting  fbb84c66-5115-4904-a7da-c3401e807f82\ncollecting  fbdac0aa-5de6-469e-9861-9f5eb861f100\n=> Collected GridMet data for 20425 cells\n=> Collected GridMet data for 20427 cells\ncollecting  fbfe8071-fe79-44f1-a6ed-d53da9c31e73\n=> Collected GridMet data for 20431 cells\n=> Collected GridMet data for 20434 cells\ncollecting  fc0c67ac-4d28-4dfc-8953-7439418fe583\n=> Collected GridMet data for 20435 cells\ncollecting  fc127d86-fc81-4375-b866-8a22a87131e8\ncollecting  fc13577b-c627-4a6d-80c6-bdcb95e5b834\ncollecting  fc1437e2-0f51-41b8-928b-c4a9d902df59\n=> Collected GridMet data for 20439 cells\ncollecting  fc1616c0-dfeb-4e46-afee-0ba6ca45256b\n=> Collected GridMet data for 20440 cells\ncollecting  fc1941a7-5d2c-405f-9f92-33155688311a\n=> Collected GridMet data for 20441 cells\n=> Collected GridMet data for 20444 cells\ncollecting  fc39aa1c-d7d9-444d-9299-a8ea6262bfbb\n=> Collected GridMet data for 20462 cells\ncollecting  fc82ebf6-6282-46a2-822f-fd459e69647b\ncollecting  fc9802d6-175c-46e7-a52a-6d4029a7fa5a\n=> Collected GridMet data for 20468 cells\ncollecting  fcaeeab8-e5e6-4139-9850-cc452b2200da\ncollecting  fcdc3e7b-30fe-400b-93f5-0138eb6ed355\n=> Collected GridMet data for 20492 cells\n=> Collected GridMet data for 20498 cells\ncollecting  fd0cc046-0417-4b90-9857-fe6ff737c1be\n=> Collected GridMet data for 20499 cells\ncollecting  fd354b87-7287-4996-af35-cfc69dccbd0c\ncollecting  fd3821dd-d121-4366-affe-e6f3ee1344dd\n=> Collected GridMet data for 20514 cells\ncollecting  fd39d029-997c-45bf-9731-c10f9c0b4c4b\n=> Collected GridMet data for 20515 cells\ncollecting  fd3a71b7-2cc6-40f4-9252-a91578d5aa4c\ncollecting  fd3da13a-856a-4640-b510-1049240859bd\ncollecting  fd4d8b81-b0c4-45be-a360-d11e6800d89d\n=> Collected GridMet data for 20527 cells\ncollecting  fd52a061-a85a-4de6-bc94-73defd921e53\ncollecting  fd5edf0a-dd22-4a76-8164-c25233decc46\ncollecting  fd83414b-11f3-4a54-b382-052d1bc7d06c\n=> Collected GridMet data for 20538 cells\ncollecting  fd84c9eb-d2fd-452e-b793-1b7a16277e83\ncollecting  fd85c0c3-31ee-46e5-a816-b91675bb8f4a\n=> Collected GridMet data for 20542 cells\ncollecting  fd8601c9-3f4a-4995-b27f-ec97b288399a\n=> Collected GridMet data for 20543 cells\ncollecting  fd87af9c-8631-458c-8532-2daae4396c43\n=> Collected GridMet data for 20553 cells\ncollecting  fdc6fcab-c2bd-4385-bd92-7c29272823fb\n=> Collected GridMet data for 20566 cells\n=> Collected GridMet data for 20577 cells\ncollecting  fdeb8912-f9d1-445d-aadb-e943534f67fe\ncollecting  fdfbc223-4868-4933-8921-a18552806efe\n=> Collected GridMet data for 20584 cells\ncollecting  fe027638-a9f0-4a33-9d21-ccfbef88aef1\n=> Collected GridMet data for 20585 cells\ncollecting  fe06316c-6a2b-4dce-b330-d69ea794e198\n=> Collected GridMet data for 20586 cells\ncollecting  fe090752-daf4-472d-ade8-a5ffff02a9b5\ncollecting  fe183334-b491-4889-bcdf-66a5456c7735\ncollecting  fe2209a2-10b1-48b7-af06-ec3fea6490d9\n=> Collected GridMet data for 20599 cells\ncollecting  fe262fbd-8873-40f1-be01-a2ca53167eec\n=> Collected GridMet data for 20600 cells\ncollecting  fe26fda0-80d3-441f-aeb1-5987395bbd15\n=> Collected GridMet data for 20601 cells\n=> Collected GridMet data for 20602 cells\ncollecting  fe39a3e3-259d-443a-8762-d7a2715bb888\n=> Collected GridMet data for 20612 cells\ncollecting  fe4f8191-fd12-496a-a555-fc9fb8647906\n=> Collected GridMet data for 20616 cells\ncollecting  fe5071e4-24f3-4adf-998c-73893eec369c\n=> Collected GridMet data for 20617 cells\ncollecting  fe5df243-475d-48ca-beee-0044d116d021\n=> Collected GridMet data for 20618 cells\ncollecting  fe5ffe90-01c5-420c-a121-0e97ff77999e\n=> Collected GridMet data for 20619 cells\ncollecting  fe766019-4dbb-414d-84b7-c98d43c1d8ed\n=> Collected GridMet data for 20629 cells\n=> Collected GridMet data for 20642 cells\ncollecting  fe9c723d-a714-46c5-9649-6fbf1119f037\ncollecting  feabf390-0de2-48ca-af8c-faa2bc8b3339\n=> Collected GridMet data for 20658 cells\ncollecting  febf279b-c6a5-4da4-9b8a-659e5fbcb0a5\n=> Collected GridMet data for 20659 cells\ncollecting  fec3a8b8-aaad-4f55-bf64-9835b98830b5\n=> Collected GridMet data for 20660 cells\ncollecting  fec47c33-ecf6-4554-b2bb-3c75bdc57eae\n=> Collected GridMet data for 20661 cells\ncollecting  fec61bc4-8eaf-41b3-b675-552f7aa49835\n=> Collected GridMet data for 20662 cells\ncollecting  fec9cc1e-b0a0-46c4-9d5d-8d057af081ac\ncollecting  fecadde0-33ed-4249-b0e1-8d97a0d882cc\n=> Collected GridMet data for 20665 cells\ncollecting  fecf08ab-4580-47f2-98ab-84e21bd031e8\n=> Collected GridMet data for 20666 cells\n=> Collected GridMet data for 20671 cells\ncollecting  ff01e8c2-19a2-4a89-af0e-608b8f40ad5f\n=> Collected GridMet data for 20683 cells\n=> Collected GridMet data for 20684 cells\ncollecting  ff154d74-c550-4614-91ba-c90eefee6471\n=> Collected GridMet data for 20685 cells\ncollecting  ff18f6e0-07ca-4682-98c0-c4ce065c031b\ncollecting  ff48a035-a5ea-4fbb-87f1-56de871ab89e\n=> Collected GridMet data for 20697 cells\ncollecting  ff4b8656-129b-4062-8df0-944ad8a59768\n=> Collected GridMet data for 20698 cells\ncollecting  ff4be9a1-151b-4ec1-bb70-4d93ab266772\n=> Collected GridMet data for 20699 cells\n=> Collected GridMet data for 20702 cells\ncollecting  ff4f038e-3ff7-4579-910d-87f517a26d25\n=> Collected GridMet data for 20703 cells\n=> Collected GridMet data for 20707 cells\n=> Collected GridMet data for 20710 cells\ncollecting  ff7325d3-fcfc-4486-9eb1-4332f667cfef\n=> Collected GridMet data for 20714 cells\n=> Collected GridMet data for 20715 cells\n=> Collected GridMet data for 20720 cells\ncollecting  ff8c4a7d-9d41-4e2b-b8db-523ff5304ddd\ncollecting  ff9f3d3b-73f9-499e-9bac-790c44ca7668\n=> Collected GridMet data for 20729 cells\n=> Collected GridMet data for 20731 cells\ncollecting  ffbaaae9-582e-45b3-ba8c-813c628fe0d5\ncollecting  ffc1c613-a707-431c-8eae-638bb44c2618\ncollecting  ffc826f3-67e9-4453-a393-8d91cd41ca06\n=> Collected GridMet data for 20745 cells\n=> Collected GridMet data for 20746 cells\ncollecting  ffdab17f-e9e1-4374-8755-23abc360fc20\n=> Collected GridMet data for 20753 cells\n=> Collected GridMet data for 20754 cells\ncollecting  fff54897-9676-4f7e-8e68-da7457517b7b\n=> Collected GridMet data for 20758 cells\n=> Collected GridMet data for 20759 cells\n",
  "history_begin_time" : 1651154989194,
  "history_end_time" : 1651159329452,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "OlRQ2vc3qMvt",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-04-18\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "*** Earth Engine *** Please upgrade your Earth Engine Python client: authentication is changing! https://developers.google.com/earth-engine/guides/python_install\ntoday date = 2022-04-22\n\nStream closed",
  "history_begin_time" : 1650630295774,
  "history_end_time" : 1650633453104,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "VOUmgWmZcx4F",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n    print(f\"=> Collected GridMet data for {count} cells\")\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1649457860457,
  "history_end_time" : 1649457892815,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "rT92CvFbpOe8",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    if count % 4 == 0:\n      print(\"=> Collected GridMet data for {count} cells\")\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1649457334313,
  "history_end_time" : 1649457780282,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "HuzNNYVmr2ZC",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    if count % 100 == 0:\n      print(\"=> Collected GridMet data for {count} cells\")\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1649456043406,
  "history_end_time" : 1649457309156,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "QGDO1KNUupfy",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    if count % 1000 == 0:\n      print(\"=> Collected GridMet data for {count} cells\")\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1649455367738,
  "history_end_time" : 1649456030032,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "dXB19TZSlASB",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    if count % 1000 == 0:\n      print(\"=> Collected GridMet data for {count} cells\")\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-04-08\n/Users/joe\nEmpty DataFrame\nColumns: [cell_id, lat, lon]\nIndex: []\n/Users/joe\n(20759, 25)\n                           tmmn        tmmx  ...  latitude   longitude\ndate                                         ...                      \n2022-01-01 06:00:00  258.586855  276.292067  ...  43.51019 -109.318084\n2022-01-02 06:00:00  258.586855  276.793414  ...  43.51019 -109.318084\n2022-01-03 06:00:00  265.838093  276.246038  ...  43.51019 -109.318084\n2022-01-04 06:00:00  267.105206  277.492048  ...  43.51019 -109.318084\n2022-01-05 06:00:00  258.127683  267.981649  ...  43.51019 -109.318084\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  256.077432  269.225169  ...  40.329588 -105.949401\n2022-01-02 06:00:00  256.109020  267.177438  ...  40.329588 -105.949401\n2022-01-03 06:00:00  258.100006  268.411621  ...  40.329588 -105.949401\n2022-01-04 06:00:00  259.386464  271.620647  ...  40.329588 -105.949401\n2022-01-05 06:00:00  262.734198  267.472910  ...  40.329588 -105.949401\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  272.836352  283.463637  ...  37.734259 -119.738541\n2022-01-02 06:00:00  274.308069  280.000000  ...  37.734259 -119.738541\n2022-01-03 06:00:00  274.504041  281.675770  ...  37.734259 -119.738541\n2022-01-04 06:00:00  271.328271  279.204052  ...  37.734259 -119.738541\n2022-01-05 06:00:00  274.612127  285.104047  ...  37.734259 -119.738541\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  272.190207  283.457340  ...  37.435274 -119.325316\n2022-01-02 06:00:00  275.413299  282.652457  ...  37.435274 -119.325316\n2022-01-03 06:00:00  276.255947  283.109781  ...  37.435274 -119.325316\n2022-01-04 06:00:00  274.303487  282.257342  ...  37.435274 -119.325316\n2022-01-05 06:00:00  273.260842  283.200012  ...  37.435274 -119.325316\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  255.699997  266.899994  ...  39.592862 -105.679907\n2022-01-02 06:00:00  256.799988  265.299988  ...  39.592862 -105.679907\n2022-01-03 06:00:00  258.399994  270.000000  ...  39.592862 -105.679907\n2022-01-04 06:00:00  259.500000  272.500000  ...  39.592862 -105.679907\n2022-01-05 06:00:00  261.100006  265.700012  ...  39.592862 -105.679907\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  256.000000  268.000000  ...  40.027596 -105.643974\n2022-01-02 06:00:00  256.700012  264.700012  ...  40.027596 -105.643974\n2022-01-03 06:00:00  257.799988  268.100006  ...  40.027596 -105.643974\n2022-01-04 06:00:00  258.799988  271.899994  ...  40.027596 -105.643974\n2022-01-05 06:00:00  261.500000  264.200012  ...  40.027596 -105.643974\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  274.600006  283.200012  ...  39.779513 -121.310592\n2022-01-02 06:00:00  276.200012  279.200012  ...  39.779513 -121.310592\n2022-01-03 06:00:00  276.700012  281.600006  ...  39.779513 -121.310592\n2022-01-04 06:00:00  274.200012  278.399994  ...  39.779513 -121.310592\n2022-01-05 06:00:00  277.899994  284.899994  ...  39.779513 -121.310592\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  263.178605  275.153523  ...  36.660956 -118.525815\n2022-01-02 06:00:00  264.332099  275.960754  ...  36.660956 -118.525815\n2022-01-03 06:00:00  266.017839  276.982161  ...  36.660956 -118.525815\n2022-01-04 06:00:00  263.642819  274.842802  ...  36.660956 -118.525815\n2022-01-05 06:00:00  268.575031  280.292853  ...  36.660956 -118.525815\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  272.169332  283.453982  ...  39.391823 -120.753637\n2022-01-02 06:00:00  274.038648  278.561958  ...  39.391823 -120.753637\n2022-01-03 06:00:00  274.261640  281.215924  ...  39.391823 -120.753637\n2022-01-04 06:00:00  271.461652  278.315930  ...  39.391823 -120.753637\n2022-01-05 06:00:00  275.630684  285.431274  ...  39.391823 -120.753637\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  275.399994  282.000000  ...  37.242435 -119.433114\n2022-01-02 06:00:00  276.200012  280.899994  ...  37.242435 -119.433114\n2022-01-03 06:00:00  276.700012  281.899994  ...  37.242435 -119.433114\n2022-01-04 06:00:00  275.600006  281.200012  ...  37.242435 -119.433114\n2022-01-05 06:00:00  276.700012  283.700012  ...  37.242435 -119.433114\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  270.930279  283.348793  ...  37.762672 -119.756507\n2022-01-02 06:00:00  274.109373  280.516340  ...  37.762672 -119.756507\n2022-01-03 06:00:00  274.695406  282.251184  ...  37.762672 -119.756507\n2022-01-04 06:00:00  271.790837  279.888446  ...  37.762672 -119.756507\n2022-01-05 06:00:00  275.739636  284.000000  ...  37.762672 -119.756507\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  276.152782  283.176142  ...  39.551316 -121.301609\n2022-01-02 06:00:00  278.444660  282.931485  ...  39.551316 -121.301609\n2022-01-03 06:00:00  278.626388  285.986803  ...  39.551316 -121.301609\n2022-01-04 06:00:00  277.113203  283.776148  ...  39.551316 -121.301609\n2022-01-05 06:00:00  278.355327  287.642140  ...  39.551316 -121.301609\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...  latitude   longitude\ndate                                         ...                      \n2022-01-01 06:00:00  258.405434  271.741840  ...  38.88319 -106.802801\n2022-01-02 06:00:00  257.310883  268.305443  ...  38.88319 -106.802801\n2022-01-03 06:00:00  257.752719  271.247281  ...  38.88319 -106.802801\n2022-01-04 06:00:00  259.705437  273.405434  ...  38.88319 -106.802801\n2022-01-05 06:00:00  264.389129  269.447277  ...  38.88319 -106.802801\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  256.362749  268.700012  ...  39.599784 -105.823638\n2022-01-02 06:00:00  256.918616  265.065179  ...  39.599784 -105.823638\n2022-01-03 06:00:00  257.772055  269.981378  ...  39.599784 -105.823638\n2022-01-04 06:00:00  258.153455  272.972066  ...  39.599784 -105.823638\n2022-01-05 06:00:00  260.941895  265.737257  ...  39.599784 -105.823638\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  267.327955  278.266196  ...  40.295338 -121.310592\n2022-01-02 06:00:00  272.419111  278.716902  ...  40.295338 -121.310592\n2022-01-03 06:00:00  273.616908  278.938241  ...  40.295338 -121.310592\n2022-01-04 06:00:00  270.059562  277.814693  ...  40.295338 -121.310592\n2022-01-05 06:00:00  274.359550  282.216902  ...  40.295338 -121.310592\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  255.600006  268.700012  ...  39.613626 -105.850587\n2022-01-02 06:00:00  257.299988  266.399994  ...  39.613626 -105.850587\n2022-01-03 06:00:00  257.200012  269.600006  ...  39.613626 -105.850587\n2022-01-04 06:00:00  257.200012  272.399994  ...  39.613626 -105.850587\n2022-01-05 06:00:00  261.799988  266.500000  ...  39.613626 -105.850587\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude  longitude\ndate                                         ...                      \n2022-01-01 06:00:00  265.667287  279.447669  ...  39.329313 -119.96312\n2022-01-02 06:00:00  267.985048  273.247659  ...  39.329313 -119.96312\n2022-01-03 06:00:00  268.177584  274.340189  ...  39.329313 -119.96312\n2022-01-04 06:00:00  265.162634  271.710280  ...  39.329313 -119.96312\n2022-01-05 06:00:00  271.822416  278.202804  ...  39.329313 -119.96312\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...  latitude   longitude\ndate                                         ...                      \n2022-01-01 06:00:00  259.692642  272.239344  ...  37.75557 -108.204172\n2022-01-02 06:00:00  257.161546  271.686986  ...  37.75557 -108.204172\n2022-01-03 06:00:00  259.368615  273.031484  ...  37.75557 -108.204172\n2022-01-04 06:00:00  261.762964  277.613015  ...  37.75557 -108.204172\n2022-01-05 06:00:00  262.498789  273.576283  ...  37.75557 -108.204172\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  259.645873  271.198295  ...  37.720049 -108.042476\n2022-01-02 06:00:00  257.052336  270.212972  ...  37.720049 -108.042476\n2022-01-03 06:00:00  259.704188  271.812650  ...  37.720049 -108.042476\n2022-01-04 06:00:00  261.831809  276.685933  ...  37.720049 -108.042476\n2022-01-05 06:00:00  262.485455  271.411965  ...  37.720049 -108.042476\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  257.495304  268.605404  ...  37.783974 -107.620267\n2022-01-02 06:00:00  256.442954  268.510093  ...  37.783974 -107.620267\n2022-01-03 06:00:00  259.547655  270.762440  ...  37.783974 -107.620267\n2022-01-04 06:00:00  261.195302  274.543647  ...  37.783974 -107.620267\n2022-01-05 06:00:00  261.590600  269.143653  ...  37.783974 -107.620267\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  257.428633  270.373706  ...  39.120545 -106.102115\n2022-01-02 06:00:00  258.468067  269.755397  ...  39.120545 -106.102115\n2022-01-03 06:00:00  260.792025  272.255397  ...  39.120545 -106.102115\n2022-01-04 06:00:00  260.562889  275.213154  ...  39.120545 -106.102115\n2022-01-05 06:00:00  263.518299  269.821123  ...  39.120545 -106.102115\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  264.282750  279.286202  ...  38.778222 -119.819389\n2022-01-02 06:00:00  275.706066  281.488846  ...  38.778222 -119.819389\n2022-01-03 06:00:00  273.883643  282.940554  ...  38.778222 -119.819389\n2022-01-04 06:00:00  269.318114  280.606060  ...  38.778222 -119.819389\n2022-01-05 06:00:00  274.231037  285.457792  ...  38.778222 -119.819389\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  257.916573  269.273417  ...  38.827226 -106.982464\n2022-01-02 06:00:00  257.607949  266.764782  ...  38.827226 -106.982464\n2022-01-03 06:00:00  259.351804  270.334532  ...  38.827226 -106.982464\n2022-01-04 06:00:00  260.469082  271.873394  ...  38.827226 -106.982464\n2022-01-05 06:00:00  266.569780  269.147504  ...  38.827226 -106.982464\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  267.753026  278.349696  ...  36.415559 -118.696495\n2022-01-02 06:00:00  268.675746  279.258389  ...  36.415559 -118.696495\n2022-01-03 06:00:00  269.814047  279.440496  ...  36.415559 -118.696495\n2022-01-04 06:00:00  268.471622  279.486168  ...  36.415559 -118.696495\n2022-01-05 06:00:00  270.884039  281.848592  ...  36.415559 -118.696495\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  264.176249  279.114249  ...  39.405707 -120.493126\n2022-01-02 06:00:00  269.700012  273.780892  ...  39.405707 -120.493126\n2022-01-03 06:00:00  270.304755  275.123769  ...  39.405707 -120.493126\n2022-01-04 06:00:00  268.761882  273.380898  ...  39.405707 -120.493126\n2022-01-05 06:00:00  273.090486  278.947620  ...  39.405707 -120.493126\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  268.299988  280.000000  ...  40.391193 -121.436357\n2022-01-02 06:00:00  270.500000  276.000000  ...  40.391193 -121.436357\n2022-01-03 06:00:00  271.000000  276.399994  ...  40.391193 -121.436357\n2022-01-04 06:00:00  268.399994  275.200012  ...  40.391193 -121.436357\n2022-01-05 06:00:00  273.500000  280.000000  ...  40.391193 -121.436357\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  266.385805  278.933784  ...  39.648218 -120.448211\n2022-01-02 06:00:00  270.737849  281.138525  ...  39.648218 -120.448211\n2022-01-03 06:00:00  270.761498  281.343238  ...  39.648218 -120.448211\n2022-01-04 06:00:00  268.975670  280.591228  ...  39.648218 -120.448211\n2022-01-05 06:00:00  272.766228  284.214853  ...  39.648218 -120.448211\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  268.100006  280.799988  ...  36.848087 -118.813277\n2022-01-02 06:00:00  270.299988  281.000000  ...  36.848087 -118.813277\n2022-01-03 06:00:00  272.000000  281.500000  ...  36.848087 -118.813277\n2022-01-04 06:00:00  270.500000  281.899994  ...  36.848087 -118.813277\n2022-01-05 06:00:00  272.799988  283.100006  ...  36.848087 -118.813277\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude   longitude\ndate                                         ...                       \n2022-01-01 06:00:00  270.799988  280.500000  ...  39.537461 -120.726687\n2022-01-02 06:00:00  272.799988  275.399994  ...  39.537461 -120.726687\n2022-01-03 06:00:00  273.299988  277.500000  ...  39.537461 -120.726687\n2022-01-04 06:00:00  270.700012  275.000000  ...  39.537461 -120.726687\n2022-01-05 06:00:00  275.200012  282.000000  ...  39.537461 -120.726687\n[5 rows x 11 columns]\n                           tmmn        tmmx  ...   latitude  longitude\ndate                                         ...                      \n2022-01-01 06:00:00  268.623634  280.662644  ...  39.377937 -120.61889\n2022-01-02 06:00:00  271.425587  275.166047  ...  39.377937 -120.61889\n2022-01-03 06:00:00  272.029574  276.886669  ...  39.377937 -120.61889\n2022-01-04 06:00:00  269.812941  274.838229  ...  39.377937 -120.61889\n2022-01-05 06:00:00  274.642122  281.428597  ...  39.377937 -120.61889\n[5 rows x 11 columns]\n",
  "history_begin_time" : 1649455257783,
  "history_end_time" : 1649455352700,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "CfVDXv0QIUoP",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    if count % 1000 == 0:\n      print(\"=> Collected GridMet data for {count} cells\")\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-04-08\n/Users/joe\nEmpty DataFrame\nColumns: [cell_id, lat, lon]\nIndex: []\n/Users/joe\n(20759, 25)\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\nEmpty DataFrame\nColumns: [tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs, cell_id, latitude, longitude]\nIndex: []\n",
  "history_begin_time" : 1649455104286,
  "history_end_time" : 1649455171287,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kN4MX81Azfsw",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    #print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    if count % 1000 == 0:\n      print(\"=> Collected GridMet data for {count} cells\")\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1649455007236,
  "history_end_time" : 1649455049966,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "FcjN6j6ItIOt",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              #os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          #df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(\"Failed: \", e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-04-08\n\nStream closed",
  "history_begin_time" : 1649394240595,
  "history_end_time" : 1649453872472,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "RTpriKFbkxcq",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              #os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          #df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(\"Failed: \", e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-04-06\n/Users/joe\n/Users/joe\n(20759, 25)\nFailed:  '0001daba-dd41-4787-84ab-f7956f7829a8'\nFailed:  '0006d245-64c1-475f-a989-85f4787bae6a'\nFailed:  '000a9004-1462-4b8c-96ee-0601aff0fdf7'\nFailed:  '00118c37-43a4-4888-a95a-99a85218fda6'\nFailed:  '0013524a-f2f6-4d5c-a458-9f08a42c1228'\nFailed:  '0013ea8d-f647-4664-b40f-57bb96f800e5'\nFailed:  '001476f9-a9d5-4128-8210-e2c4879ce505'\nFailed:  '002220cf-0b83-4f58-bacb-c4318686194b'\nFailed:  '00270da4-a790-4b81-a693-e1e8c4f13e6e'\nFailed:  '002a9f10-203c-4feb-9ea4-19bcbe9a7686'\nFailed:  '00325ba7-fcbe-4bab-8c4f-f70cfe80ea46'\nFailed:  '0038be33-f5ba-4274-93b9-c7b6ea003519'\nFailed:  '003ca3a3-c298-4253-9f1b-7f6a1a097ca6'\nFailed:  '003d4c74-b631-467c-b1fa-56c4708276bc'\nFailed:  '00481126-761a-4d70-8775-c449bf498ecd'\nFailed:  '0049403d-da12-4b13-b02a-0a2dd4e01d6a'\nFailed:  '004cf556-f3dd-4c4a-9da0-cb2eb848ff0e'\nFailed:  '004e5e03-f6b6-470b-96e2-911992c8ffb4'\nFailed:  '00505b61-f978-44ee-92e8-c082c4482ac0'\nFailed:  '0050f3a5-e24d-45d7-9ce1-f046a54adb96'\nFailed:  '0051069d-cdc3-467b-9034-31f5e0eeb005'\nFailed:  '0051c2e3-a110-4460-9296-9d9c9df82473'\nFailed:  '0057c657-ac2f-4141-881c-3593859ef092'\nFailed:  '0057dca9-9c70-4708-9697-909e5711a7f0'\nFailed:  '005b6d88-4f1e-4ebd-8425-25e7236b5838'\nFailed:  '005f3676-e3dd-416a-af7b-696067815dfa'\nFailed:  '00651c0c-8687-4431-935b-8f2bfed1f429'\nFailed:  '00656c12-2000-4cb7-97b0-6d51bafb5db2'\nFailed:  '0065b17a-f2be-478b-b323-f3bb3bed4341'\nFailed:  '006eac45-1c31-45fb-99de-30a52623082c'\nFailed:  '007153b7-e0b9-41dd-a0a8-30901524ad20'\nFailed:  '0072f5ac-ec83-4183-8757-47a7e26a8d86'\nFailed:  '00743e1b-a98d-4026-9bdf-50cc52cd168e'\nFailed:  '0075950a-3452-49a7-a1d7-7fb71b984696'\nFailed:  '00778d9b-f669-4f39-b4d4-493ab085a536'\nFailed:  '007ecee3-1492-4cb9-9a53-82d951ea2f01'\nFailed:  '007edd43-d3d9-4f63-afee-8e5a95903ed6'\nFailed:  '00802ec7-1ff4-4432-8cad-8a2db176f2bd'\nFailed:  '00822a9c-dfd5-4ecf-b1fd-a445c450e7e7'\nFailed:  '008971aa-a279-40eb-998d-a2ca2a26e7a4'\nFailed:  '008e79fa-7265-404f-ab62-48f59d0e0f4c'\nFailed:  '00909645-804d-4b63-a66f-283832684bf9'\nFailed:  '009983f0-6187-4b99-9240-2299566529e2'\nFailed:  '00a9de30-4258-4863-a7f9-e9788bc29b8f'\nFailed:  '00ba0112-a5da-4264-9b86-82bf21bba65a'\nFailed:  '00c20f4b-3dba-47cd-8210-73bfc64a5591'\nFailed:  '00c6952d-223f-4661-a325-a98912335d81'\nFailed:  '00cbc9d7-ce7c-46e8-87fd-774fcd1ad03e'\nFailed:  '00d0afb7-e919-4b16-86d4-4ca059c7af09'\nFailed:  '00d3626b-3696-49ae-97d2-165f56187953'\nFailed:  '00db953c-7f4a-4de3-8772-42d7048c1ab6'\nFailed:  '00df85af-2836-4229-a654-876cf2a1767e'\nFailed:  '00e18892-bbf4-4dfb-b231-9d76b7299bee'\nFailed:  '00e1b8d6-84f5-4b79-a5a7-ce7f8fe13773'\nFailed:  '00e9c22e-949c-43c2-aed2-2e5a27dfc4bb'\nFailed:  '00ec51da-dae3-4624-960b-e0cc9a911718'\nFailed:  '00ee875c-37ea-47e9-9736-be92dd7353ca'\nFailed:  '00f12281-0861-42c1-8053-702c7b6966e1'\nFailed:  '00f1ff7a-6c24-44ae-9d47-d78533773a93'\nFailed:  '00f4f052-a244-429e-b091-08f88d1f4d09'\nFailed:  '00f7e783-ebd4-46d2-8bd1-c4ab87199426'\nFailed:  '00f9a90c-60a6-4183-814f-e50722fd2c2d'\nFailed:  '00fde10f-74b9-4eaa-a6e4-7abe055d16c4'\nFailed:  '00fff8e8-082a-4c71-a29d-ec0db786cd6b'\nFailed:  '01011989-1913-405b-a52f-80220df7876d'\nFailed:  '0103912a-8a01-45e9-83ec-146cd09f3164'\nFailed:  '010f8360-a018-4620-9de2-33a7893129af'\nFailed:  '0113dc17-2d90-4541-89cd-f209b30405f2'\nFailed:  '0114836e-3741-4224-abb1-703e87f330a7'\nFailed:  '01156105-b7fa-44b9-86c9-27909a81d63a'\nFailed:  '011df06d-650c-40e7-bd56-d2f305c1bff9'\nFailed:  '011e46e4-00bc-4fb3-be3b-d31e22e880f2'\nFailed:  '0125850a-5d2f-46d2-9873-0066edcfe334'\nFailed:  '012ea03b-8472-4adc-abf5-6352a2e9c04d'\nFailed:  '012fbbca-6dc5-4c37-b266-ac2782ca4975'\nFailed:  '01337282-fb38-45ea-a4ba-d046fa7f79f3'\nFailed:  '0136d669-a167-44d6-8c65-dbcbc4f71e5b'\nFailed:  '0138b557-850c-43a9-a5d6-7c7e96d096e1'\nFailed:  '0139bb4f-9f2b-420c-b5ea-34db9a5d0d65'\nFailed:  '0139def7-9348-42b8-8767-0edcb1d81a1e'\nFailed:  '01486dea-9406-4fb9-a080-2ce6c8889d61'\nFailed:  '014ce464-ac95-43ad-a614-5f017f8656ed'\nFailed:  '015e2c22-7766-4d19-bde1-33f6a22824ba'\nFailed:  '01609391-dfb8-42e7-9806-6b2fb7a23e07'\nFailed:  '016144d3-14da-4f27-a62a-03f7c2b0a9df'\nFailed:  '0161a423-ba7f-405d-b129-273fadc00911'\nFailed:  '01620fe7-3c4a-4b71-b45d-a3805eeaf509'\nFailed:  '01652e7e-9400-4e7c-84bf-86e67f33246f'\nFailed:  '016837dd-3b5f-4fed-a555-a05da5efbe1f'\nFailed:  '016d3736-a9d0-474c-b62a-3e90ec42eefb'\nFailed:  '016fc79d-5ee9-46b7-a84a-6e869cf4960b'\nFailed:  '01705743-de45-4cef-893f-3856b5cbb662'\nFailed:  '0174c824-3ade-474a-ae73-04963649b692'\nFailed:  '01762b10-7e89-4cf6-a227-143eab3943d8'\nFailed:  '017a7810-a518-41bd-b012-7464fad522b5'\nFailed:  '017dca0b-be33-4eba-90de-f0c2fce9f098'\nFailed:  '0182c197-ee0f-45e8-a001-4d7d7c9795a3'\nFailed:  '018481a6-b64b-49e5-9824-599dcabf2135'\nFailed:  '0186f113-1650-4e47-8de0-70cee5863d66'\nFailed:  '018acc46-9b3a-4f14-b4c0-5929776ace07'\nFailed:  '018c8a27-2b08-4705-a8aa-b0c13ceb89ad'\nFailed:  '018d455b-a485-499f-858d-b2f09c0dc75f'\nFailed:  '018e1f62-069b-48e1-b440-f6eacaa54520'\nFailed:  '0190e8ab-7af3-4baa-a959-9099350c0ae8'\nFailed:  '0193ab07-d62b-4660-9f26-5e890dbe7c46'\nFailed:  '019470f5-b5ac-4f0f-9a88-dc0e2b0af7a3'\nFailed:  '0194c7f2-1f87-449c-9c77-2f1ce6009e18'\nFailed:  '0195f974-1f43-41a6-9acc-42896477ab61'\nFailed:  '01999dd2-f622-4a97-b09b-83f5ed7523da'\nFailed:  '019d002f-2ba5-47c7-9d1e-0421d065e23f'\nFailed:  '019d3222-db52-4cd7-bee6-d335eabab91a'\nFailed:  '01a73b68-64ab-486e-a9a5-a9c9a6f3f6fb'\nFailed:  '01ad3790-e684-4829-950f-01368856c94e'\nFailed:  '01b1a490-2442-48ac-ab23-4563464468af'\nFailed:  '01b35227-af96-4f9b-894b-391bd1ad1e4b'\nFailed:  '01b7bb5e-0c0f-4263-943c-ff9a249847ee'\nFailed:  '01b81868-133a-4b56-b386-ec0e4fcc57d0'\nFailed:  '01bc3228-7fa3-460e-947c-3a365c7d533c'\nFailed:  '01c10e0e-9255-42a5-a649-9c62f74ecf86'\nFailed:  '01c8c6e4-9db3-4085-a4f6-f191bb014e70'\nFailed:  '01c95d67-a86e-4784-8473-45162188f46c'\nFailed:  '01cf8536-1488-4ee9-82e5-19ac82183b06'\nFailed:  '01d34fad-ffb3-467b-b159-41c82158f2e2'\nFailed:  '01d5fddc-8e3b-4482-a515-e69292066dc3'\nFailed:  '01d60152-b41c-4b57-8ae3-bf7bf6dcfdd8'\nFailed:  '01d9f4f1-12f2-409b-af76-8cee0ee95701'\nFailed:  '01db68d7-532e-46c9-94c3-2d4dd4cf4753'\nFailed:  '01e85eed-aa39-4a61-b720-a59b84991428'\nFailed:  '01e9eea8-0e61-4aeb-ad57-e89135510ead'\nFailed:  '01ecb4e4-bce9-4309-ac1f-4787c0be22c7'\nFailed:  '01f0f6e2-574e-424f-98a1-6b823752932a'\nFailed:  '01f39cb1-66c7-41c9-96c4-0fa4baa98851'\nFailed:  '01f53e53-8ffc-4b74-a6d4-808e242b44b7'\nFailed:  '01faba06-9dba-49f7-92cb-ceaa16bdab2c'\nFailed:  '01ff2bb4-67b6-43ae-8506-53282bf27a6a'\nFailed:  '01ffe76a-9d66-4733-b17f-bf922a54fb21'\nFailed:  '0202aaca-5ec1-4917-a75a-bff3520b72da'\nFailed:  '02062667-85cc-44c3-a52d-4f884bd1c95c'\nFailed:  '0209240a-0dba-494d-a0b5-bff00c00d0ef'\nFailed:  '0219357c-527c-4a54-a00c-9573d9ddaf47'\nFailed:  '021a84a4-6a5e-40d1-b5d2-ede15ab4d051'\nFailed:  '021e5ca1-3702-4379-81b0-60ded7294421'\nFailed:  '021e7a6a-fde4-44cf-bbda-8b096a2970c7'\nFailed:  '0227083a-cdf0-4dcd-9939-72994feb6be8'\nFailed:  '022780fb-57e6-4ffe-9212-0c7daeb13bed'\nFailed:  '022a03f3-2616-4ce3-865b-da113b76d188'\nFailed:  '022b63c5-5bb9-4fda-8489-9a41470cb07d'\nFailed:  '022e5945-f13d-4270-b147-a4d33a3d4a5f'\nFailed:  '02387350-2d78-427f-9f78-b117fde1d9e7'\nFailed:  '023b2795-12c2-4f1f-bb52-3e3ecd26f1a7'\nFailed:  '023c3c0e-9709-42bf-a778-12c929f206cc'\nFailed:  '023e4079-f8e3-4b27-abd2-93047825fd7d'\nFailed:  '0243f7ae-79d1-42e1-b60c-464d6cbddfb6'\nFailed:  '0245cef8-4d64-43ab-b37f-42f6c04c9cd0'\nFailed:  '0246e8d3-9ff4-48d6-bf5d-f602b5d38319'\nFailed:  '02486797-e82a-4007-ac80-410c03a31c6e'\nFailed:  '024d24a6-fa03-4953-b50d-b0ef42d222c2'\nFailed:  '024d4a58-ef11-4f2b-925d-657809d60ff6'\nFailed:  '02513e74-2209-4083-a8b5-a16e54fea22c'\nFailed:  '02546ef5-0e70-4c45-9582-8463dafcec86'\nFailed:  '025533c9-5fdc-4fd0-a6a6-9935ad824c32'\nFailed:  '0255cea4-8bc0-42fc-a0ce-a102af1eaac3'\nFailed:  '0263eff8-963d-4586-a3c0-8b316c5d21d9'\nFailed:  '0266bae9-30f1-43eb-8c9e-25b6d250aa1a'\nFailed:  '0268c537-5cf9-4c2b-a1fe-ff64944b1796'\nFailed:  '02690e0c-f79c-4746-82e5-5247c89c1f06'\nFailed:  '026b1ec0-027a-47a9-b37e-cd982b695240'\nFailed:  '0274c1a7-8069-41bd-88f8-5e8d9e12be31'\nFailed:  '0275628e-1bb7-4f54-a1ea-160cb2b38feb'\nFailed:  '0282bd7b-67be-4661-90ea-99fb7bbd182f'\nFailed:  '02835e9e-2bf7-400b-9a33-779563f1e930'\nFailed:  '0285b903-f5be-4a53-842a-c42282701d50'\nFailed:  '028710fa-9b38-497e-b266-6e33afe367bb'\nFailed:  '02897a1d-af9b-46e3-aec2-cf8f9ef11c30'\nFailed:  '0289c86a-1519-47a1-9c7f-ab0c626d8995'\nFailed:  '0289f22c-aab5-49dd-a8dd-9cfbe9f56d51'\nFailed:  '028c66e1-5d2b-45fb-93d1-0a44f808de34'\nFailed:  '02924296-383d-46bc-adc5-6531f741ea7c'\nFailed:  '029529bb-cea1-43ec-962f-636aa443c403'\nFailed:  '0295665e-82a7-464a-a496-0124625392d6'\nFailed:  '029758e7-b211-41c0-841b-bcfbdaa0b29d'\nFailed:  '029b4083-4edd-4cba-a77c-3a2caa76c1fe'\nFailed:  '029b869c-e14d-4951-8962-c06e9e60aa89'\nFailed:  '029e2603-322a-4f62-bc1c-f3da75cd2265'\nFailed:  '02a453da-76c8-4ba1-91d4-7c56fbf0eb60'\nFailed:  '02a4c14b-aa90-40d9-8529-a0878b09cc0c'\nFailed:  '02a4e852-c4d5-482b-a521-51a4424e3f70'\nFailed:  '02ae9a3b-126c-41ba-a529-d28deb7d3337'\nFailed:  '02bab660-283a-4a3e-b30b-939bbae5a969'\nFailed:  '02bc5e0b-b999-4403-8eeb-9e509cd00171'\nFailed:  '02bc8ca8-4bc5-4bbc-b36f-7d58dc2756f7'\nFailed:  '02c02657-0bd4-4fa2-b339-020e3412050c'\nFailed:  '02c2200a-4b11-4970-af37-2e5fa693cd1a'\nFailed:  '02c5023a-ad16-4cf3-9003-8fd77a84ddb2'\nFailed:  '02c52c70-df0c-4349-984a-8caca4cd8eb8'\nFailed:  '02c81990-3038-437a-be9f-bb76d3e7693f'\nFailed:  '02cae6ee-02f2-44b2-bd64-c7ca51cb7671'\nFailed:  '02cbb2df-9830-4fe2-b7f5-03ba8a4e34b2'\nFailed:  '02d04a43-bde7-4952-938b-37a5562d69a4'\nFailed:  '02d70e51-07db-43c3-88b4-1550cbc7855e'\nFailed:  '02d9b441-2d47-494b-8870-8d3382c17384'\nFailed:  '02e45508-e284-4c0d-b3d1-2bc402fff1a7'\nFailed:  '02ec8bce-7ef9-45bf-b3a9-58f7823f25bb'\nFailed:  '02ed331c-90ba-49dd-8b51-39a5fe448578'\nFailed:  '02eeeac2-3708-47ce-b2aa-dd7496bb5152'\nFailed:  '02f4a445-bcda-46a2-acf9-38312df92450'\nFailed:  '02f5f302-aa54-4764-a30e-5d7522b469ec'\nFailed:  '02f681c5-add3-48b6-9a37-0d9c2a6a7f9b'\nFailed:  '02f7a562-0746-4b4c-8d83-4128c873029c'\nFailed:  '02fea5e6-5b16-47c2-82ce-94e288ff20e3'\nFailed:  '0300e6f6-c6f9-4ef7-9d6d-dc7ec5f97e5a'\nFailed:  '03058382-7125-4e15-b58a-76fb220f158b'\nFailed:  '03093663-1b50-4087-a861-86cce1fdd9eb'\nFailed:  '0309ccc0-02a4-4fa9-b7fd-44e13269bc8f'\nFailed:  '03129265-0e01-4ae3-b482-cf399a0b90f8'\nFailed:  '03153931-6b5a-4b98-abed-642cb3ba953c'\nFailed:  '03186c6d-3e58-4538-9b9a-9bd96ee70218'\nFailed:  '032c487e-9eb7-4f6c-8689-e6dacbc13727'\nFailed:  '032f5da3-da09-4e3b-8ec0-68bcc4f3f9f6'\nFailed:  '0332e840-aeda-4ba1-8c6c-165c85c6da7f'\nFailed:  '033ddd98-b155-4a2b-bfeb-730cdcf07b07'\nFailed:  '0340b93d-ab1c-44b8-9ccb-8341bbf8022f'\nFailed:  '03412397-8ac4-4685-974d-3172f16acce9'\nFailed:  '03461b35-29f1-4978-a1f4-b213ff413fed'\nFailed:  '0346c906-7f5a-440a-9c13-6d254237335b'\nFailed:  '034af8da-8c17-4bfb-ac8b-3b2df079639a'\nFailed:  '03529fdc-ba2e-4f81-9d0c-88808ae0b045'\nFailed:  '035731c9-39e9-41e7-a239-da7af53e6f94'\nFailed:  '035c0ae3-5c88-4498-a7fe-d095f7d83de3'\nFailed:  '035c3ff5-ccde-4434-94f7-9d4b64b19617'\nFailed:  '035d07a1-97f6-4d29-89f4-2a3951d2084d'\nFailed:  '0361cd82-9167-4276-b16c-caa5f1e1c249'\nFailed:  '03665d3b-fbe0-496a-99fc-c8d18b379214'\nFailed:  '0366ca92-01fc-42e7-b680-03d9d1374491'\nFailed:  '0366dca6-a897-4742-a479-aec364f9488b'\nFailed:  '0366e6a7-fefa-4187-a556-cc26609d9c92'\nFailed:  '03697894-9bd1-46a1-84e7-3da027dd0aff'\nFailed:  '0369f043-8568-4f29-9800-d9b0f667f33d'\nFailed:  '036d0a25-ffee-4b07-a57b-96ff8dd23f4d'\nFailed:  '036d27dd-3835-4e33-9c08-cf52ee82afc3'\nFailed:  '03776833-19ad-4c2c-8b0b-75bfb49a183f'\nFailed:  '037c249b-9e28-45f8-9270-05c11f3cf9d9'\nFailed:  '037e8c82-798e-4785-8c9e-a98a38bd76be'\nFailed:  '037ef632-0877-49a0-9ee3-0c32878c1f61'\nFailed:  '038264ee-7ca0-41b4-8f27-55a53896ee87'\nFailed:  '03855439-0816-4ffc-9100-aa34b74bc43b'\nFailed:  '0385a03d-03ec-4e51-a05c-ef6636eac88d'\nFailed:  '03860206-6eb7-4020-beb6-fd9a748de04a'\nFailed:  '038a7de7-7704-4266-b562-5e6d6928de7d'\nFailed:  '038b20ff-28c3-4bf3-85c9-beef360f1baa'\nFailed:  '039284f5-1409-408f-a715-b95cbab4ec49'\nFailed:  '03994b68-5abb-4f04-bf70-5558125c65e0'\nFailed:  '039dca15-5d29-4cef-aad4-79d5b2de066a'\nFailed:  '03a4625b-62c1-49ad-9ae2-a43d6f2332a6'\nFailed:  '03a89ff8-7f5a-4b04-b143-771deee60255'\nFailed:  '03abc36e-7824-4b9e-9677-e79d08656817'\nFailed:  '03b29664-20a4-4f2c-82f6-d47a87506d07'\nFailed:  '03b4e5f8-e73c-44b3-9a9e-c0492f8dcc0f'\nFailed:  '03b64207-ca0c-4a82-b5ea-9435bb0d5470'\nFailed:  '03ba7e12-ff2c-4349-a712-6fd2a0a7794c'\nFailed:  '03bb5877-25d8-4172-a73c-6dba4dfda91e'\nFailed:  '03bfd3cb-c0d4-481c-986c-b89ce1656732'\nFailed:  '03c1f2b5-9ce6-479f-b540-2c7b1c060fd0'\nFailed:  '03c2ea2c-c749-4f08-8ee0-6dfe1bcddef0'\nFailed:  '03c3c363-76bd-4d36-9e82-0d9845fda7e2'\nFailed:  '03cd5120-f976-434e-84c4-526f3d2db076'\nFailed:  '03d3272d-5dad-49fa-9e21-c4e4366df738'\nFailed:  '03d82692-a06b-4a1d-b14a-e79498696337'\nFailed:  '03dac778-3739-42f7-861a-c4f32e054669'\nFailed:  '03e20c1b-af33-40ed-aa44-6ba7264f412b'\nFailed:  '03fb442d-ed22-4f6a-9a65-76ffe18380c3'\nFailed:  '04067fc1-b841-4c5c-b1b3-1fa874867445'\nFailed:  '04072ca9-0a7a-43a5-a57b-829e3525c001'\nFailed:  '041541e7-637f-49ee-8210-90e0c85092e7'\nFailed:  '041b148e-437c-4f1d-8d34-9e58760a4b11'\nFailed:  '04235ebf-f64c-44cf-b604-1868b798b27c'\nFailed:  '0426e0b0-389f-421f-a115-90f6eba81276'\nFailed:  '0434f065-1e73-4df9-862c-1cbba7e37b02'\nFailed:  '0443995b-f761-4514-a461-350f401715a1'\nFailed:  '0443d786-9adc-4aa8-bb4d-2ffeb5b4a1d1'\nFailed:  '0449e3b8-cd03-4535-8e1a-cef000a07270'\nFailed:  '044ae40a-ebf2-46bc-9b51-66d1454887b8'\nFailed:  '044b8806-634e-4d8d-a077-107658def160'\nFailed:  '044f2583-60dc-4d38-94eb-d2c77d52b845'\nFailed:  '04549cd3-b094-4c3d-af14-310178872bec'\nFailed:  '045542d2-3492-4270-8392-060a1d4eeae7'\nFailed:  '045aa3ff-f902-456c-a9f3-1e9b36bbd08c'\nFailed:  '0461cae8-c4ac-4411-8267-64bd2e23d5dc'\nFailed:  '046a2746-ef98-4576-9ff2-511a052c1aca'\nFailed:  '0475b6cf-8ca1-4d8f-8b29-d4d17f4574b7'\nFailed:  '0475bfa0-36ee-44cc-a2bf-63821bf28552'\nFailed:  '04768fa3-aa7d-47a0-be14-ba21b8b0c263'\nFailed:  '048142ef-62f3-425f-b4d7-bf7c61219135'\nFailed:  '0487436d-1d79-4471-8207-7efce42489c7'\nFailed:  '048b1d1a-1ecb-4aca-b1ea-0c3cda5dd85c'\nFailed:  '048e7290-5886-46e0-b276-992e73edeb4e'\nFailed:  '04910e5c-e613-4843-b19d-6a676e46ea90'\nFailed:  '04915a27-bedd-4ecb-ad0b-b7a38c90fb0a'\nFailed:  '04945d00-aa04-4176-b40e-5022a83e1579'\nFailed:  '049a46cd-15c2-45b8-8f73-25221c9acebe'\nFailed:  '049cb9be-c25f-4469-8721-982645acb73b'\nFailed:  '049e7f98-849c-436f-98b6-fb24e2fbc4b5'\nFailed:  '04a0d453-5988-4d8e-95cf-aa989b228a61'\nFailed:  '04a20b0c-286d-4cae-98d3-701962f098a2'\nFailed:  '04a2d21a-c9b0-4c88-bc54-ee9f65b4d1b0'\nFailed:  '04a5ab2d-5a18-4dfb-a7a6-e605f0c64692'\nFailed:  '04ac59fc-2d32-461a-9882-7e6616900aea'\nFailed:  '04ae08e6-0a38-43ae-902a-34acc8b8f98d'\nFailed:  '04afdc09-9f4f-4401-9351-25f6fce7a1b5'\nFailed:  '04afec81-b376-44cd-9d4f-70060ab6b2c6'\nFailed:  '04b0ff01-6cc0-4a4a-865f-e4a672d3d179'\nFailed:  '04b160db-c1d4-4f5e-806e-82b099a0f649'\nFailed:  '04b1b98a-d151-41cc-b5f2-0050139d5ae9'\nFailed:  '04b21d75-e0a7-4089-88c0-7b6b1771d6c3'\nFailed:  '04b2e81c-a3b6-4a37-84b4-558b2bd13c77'\nFailed:  '04b95d6b-852d-428b-ac37-c83d0f3399f6'\nFailed:  '04ba3508-4bb8-4a7f-92a4-4f16743514f5'\nFailed:  '04bdcfca-66ce-4399-b575-e215b694d3dd'\nFailed:  '04be7c6e-e796-471e-9f9f-4e9ba69e70e8'\nFailed:  '04c37019-7660-4501-b031-9c17d7ca2d60'\nFailed:  '04c57d84-19e5-41ef-9761-539fdf6cf608'\nFailed:  '04c62e68-a59f-46d5-b3e4-b311f837ed9d'\nFailed:  '04c779aa-0e3d-4062-a473-7cc1b6cd4459'\nFailed:  '04c7bb4c-52b3-4338-a413-604ed1047ac4'\nFailed:  '04ce226b-96ed-4358-9d47-335d143a6e2c'\nFailed:  '04d3cf6a-6e35-4fc3-8d02-d3b39432ea06'\nFailed:  '04df4b3d-8841-4e2f-8536-d1d9cefd0572'\nFailed:  '04df5da5-85ab-47c2-af7e-778f3db07049'\nFailed:  '04e1cf76-ea0d-49a3-95e5-e52e46135176'\nFailed:  '04e333b2-9d7f-4898-97de-40ad9b379d64'\nFailed:  '04ea7ec1-d270-4d01-a8de-6a3b6ddf2892'\nFailed:  '04ec7abb-03a7-4f7e-acb5-2be559b5e466'\nFailed:  '04ee8779-7ccd-4bc6-b4e3-38e519e5bb6b'\nFailed:  '04f277f7-3d65-43ca-b172-e3fd701418cc'\nFailed:  '04f40c2a-fd9b-46e5-8d7c-57e442234874'\nFailed:  '04f4634a-3367-4645-b2af-9719b5679f8b'\nFailed:  '04f54505-160a-48a7-bb7b-4e75650457b7'\nFailed:  '04fa0c5a-7cc7-45af-882d-0329fe7045e0'\nFailed:  '04fdface-1e2f-4c31-80e6-1e6483d29b9b'\nFailed:  '04fe66ee-becf-41b6-9110-3b70f835e06f'\nFailed:  '050635be-202d-4799-8b11-1fa7a30888a7'\nFailed:  '050c9aa7-1a3c-4198-bd6e-b71e87f6421b'\nFailed:  '050f7a2d-5feb-492a-a549-47db328ca3ea'\nFailed:  '0513d54e-45c5-48fd-9365-ea93037142f2'\nFailed:  '051b98f9-123f-48fa-977c-22015a3ebbff'\nFailed:  '052168a0-6ae4-4b8f-847c-358d78c3e891'\nFailed:  '05232be9-fdb4-4644-8d0b-793d4e4407ae'\nFailed:  '052350f3-733c-47e3-a0bb-0cf78886eda8'\nFailed:  '0523645a-ce00-432a-9d6b-777508c83a1a'\nFailed:  '0528d484-9e37-4140-a43e-894fa1ae987a'\nFailed:  '052b8ca3-3f5a-4d57-8fe6-ee55275baa48'\nFailed:  '0532172a-42b6-4bba-9e00-c7647866bc32'\nFailed:  '053288fc-7634-4b0e-83cb-7d76f072192d'\nFailed:  '0535ed57-a197-4e69-ae4a-102a6ecfe249'\nFailed:  '05360efd-326a-4afa-b28a-d5916dbb94a3'\nFailed:  '053962ee-c1e2-4a4d-b21a-de845553d5ca'\nFailed:  '053d9118-b5ed-47a3-8319-0f145f244a4c'\nFailed:  '053e8f71-fdf0-41b1-ae40-15db891a698e'\nFailed:  '05488e9b-b918-474a-8ff8-47076c95e983'\nFailed:  '0548df31-6858-4d21-8878-8d5638aa5764'\nFailed:  '0549628e-54d3-4086-b52a-1df268d87c17'\nFailed:  '054be902-2bc2-47b6-a641-29fbe99c16a5'\nFailed:  '054cf666-898f-497c-a561-c6d8f2fddf2c'\nFailed:  '05563bf5-b7dc-426d-a914-8e6ea0c27899'\nFailed:  '05575c51-5215-4fc3-b455-9ad4b56d4f86'\nFailed:  '0557cbba-861c-4f20-931e-2f33e8c2b073'\nFailed:  '055e5328-187a-498e-8893-00cb04821723'\nFailed:  '0560ca13-1058-4a8d-8629-2b720250b8ca'\nFailed:  '05694a09-1972-45b5-8a67-d1541f00f3db'\nFailed:  '056b3777-54bc-4be1-81e6-ccaead6cf064'\nFailed:  '056bbed9-0c27-48ad-9072-b532d97322cd'\nFailed:  '056d591f-d96d-4700-967f-434d0ed4cbac'\nFailed:  '05726490-fcfe-4bd3-ae8e-6b5dc39e1bfa'\nFailed:  '05746e8c-0f15-41d2-a4c1-4ddfe851e397'\nFailed:  '05749ae4-bdea-4cd1-b40f-af7643fcc157'\nFailed:  '0578020e-9bae-46ff-aaef-f64b9330e801'\nFailed:  '0578e1ff-45d7-4fe9-a28a-f4b669c123ef'\nFailed:  '05791146-2450-43bf-9ed7-db6fb507142a'\nFailed:  '057f433b-a8de-425e-843e-fb6d15276612'\nFailed:  '057f7dd4-6e33-4f6e-828a-6a3d14abf2cc'\nFailed:  '058bacc8-5d39-43b8-91d7-c9b8a8bf5d0a'\nFailed:  '058c942e-6fe4-4e67-a047-3cecf68167f6'\nFailed:  '0592fdcc-d1b8-404f-9f23-725b50760949'\nFailed:  '05936245-fb6d-4a1b-864e-e39d1dc557ab'\nFailed:  '0598145c-77b0-462c-b9c6-7bb3eabf26cf'\nFailed:  '059cfcba-89cc-4f3a-8665-3831ab242fab'\nFailed:  '05a38ac7-262d-4136-9f67-7ae62b37334b'\nFailed:  '05a391c8-b0d1-4a80-af4c-85b1a63785ec'\nFailed:  '05a68ca6-986e-400b-acf3-ef06f59ab86b'\nFailed:  '05ab3786-2df1-45eb-981a-a9ad882442c5'\nFailed:  '05ad05ff-a1f6-40e0-a441-d9a7ed8268ca'\nFailed:  '05adc967-9d21-4548-83e9-3df4f7d05cfd'\nFailed:  '05b16864-bfd7-410e-a82f-c726609d0976'\nFailed:  '05b6e9fd-c047-486d-a063-3df46ee9507b'\nFailed:  '05c08a4a-e688-4b49-97e7-6194f7e0a68a'\nFailed:  '05c13909-f845-49bb-860c-b03523352a77'\nFailed:  '05c40154-5e23-4fb2-b48f-1fe5d393527f'\nFailed:  '05c4a84b-90e5-4e19-9c62-decf47b839f5'\nFailed:  '05d3382d-7b0e-4d7c-8bbe-17e0329022d7'\nFailed:  '05d7ea55-ac46-481e-a28a-f73d008fd061'\nFailed:  '05e15184-37d6-4889-8254-3b0a3a6bbea6'\nFailed:  '05e706da-f181-48a6-a802-6b997839a3db'\nFailed:  '05eb1850-9609-4d00-ad31-603ffad3af79'\nFailed:  '05ef68b8-d89c-406b-be87-4bbac4242b75'\nFailed:  '05f06090-2b19-48df-aa89-db729161af09'\nFailed:  '05f12591-24ea-4a3b-8c0d-584803f61c62'\nFailed:  '05f24aa0-bedd-4d21-a21c-ec2306d8dbc3'\nFailed:  '05f52020-6bc7-4128-a9b3-1bc5a0631f49'\nFailed:  '05f7f64a-1a08-4758-bacb-854e72f798f7'\nFailed:  '05fcf6ec-bd96-4c5b-99f9-94561933241b'\nFailed:  '0606d5db-153d-4fc5-bb55-a3fe512fa8d4'\nFailed:  '0607cd43-6cb9-40e0-bab2-4c5a4bfcd4f9'\nFailed:  '060b0040-d2dc-49f5-91ae-e24bdd0ef807'\nFailed:  '060e6959-0f31-4da9-a31a-e09ba3cb8066'\nFailed:  '060e9025-f833-4b7f-8a66-4b1a7e28d405'\nFailed:  '0610668b-2864-464c-ab8c-ff40b9fb747c'\nFailed:  '06121571-8dbd-4fac-a0d6-aa5d3ad12359'\nFailed:  '0619dde5-26e7-4e0d-838f-91c564614a68'\nFailed:  '061a84b2-b182-45db-8895-b4990b610849'\nFailed:  '061b6cef-221c-4265-8963-a1929db71f96'\nFailed:  '061e727a-4153-4577-b716-6ff5d8ea8d75'\nFailed:  '061fdf10-ac0b-480e-a694-08c7a80e1c06'\nFailed:  '0624ef1b-5ebe-47c3-ac83-9fc757f6d5e9'\nFailed:  '06258474-812f-4912-9fb3-e518f43a5fbb'\nFailed:  '062844c5-d8c4-49c5-a714-d8ec4b512154'\nFailed:  '06292529-e9de-4238-87b5-2c65163a7d5b'\nFailed:  '06294a62-d805-4e35-bb23-d55e3c0ca591'\nFailed:  '062a4e6e-9073-47d3-8531-c66022f275b2'\nFailed:  '062eb932-aa92-413f-afff-0c716faf9311'\nFailed:  '0630090d-453d-4d3b-9c95-0eb05c36cd5d'\nFailed:  '0631580f-5b43-43f7-9700-7da9309bf620'\nFailed:  '0637f796-99e3-4f1a-9710-36ef0ce4cb79'\nFailed:  '063c8f4b-ab52-4a55-b155-1fc02d8da547'\nFailed:  '06417242-4d8c-407e-a7e4-efb84e5709c4'\nFailed:  '0647b5c6-7839-425b-96b1-330d6722f043'\nFailed:  '0647e67f-75b0-48f2-896e-592c2e776818'\nFailed:  '0649a071-216d-4e32-9746-8c5fb4781611'\nFailed:  '06531465-cca6-4076-99ee-96bb48b0a577'\nFailed:  '0656eebb-487a-4ec9-9334-f6e14fa4bc15'\nFailed:  '0659fd60-d26f-4a69-8ab6-c04b6f03dc35'\nFailed:  '065babcb-76b1-412d-8e47-b1adcabbdc70'\nFailed:  '06622f4d-c964-4762-a72d-a773037f0af6'\nFailed:  '06711527-3e20-4c94-bf71-0ea9b61fad0b'\nFailed:  '0673b6ef-454f-4b2a-a754-fbb63df39e3c'\nFailed:  '06783937-fe9c-4a22-97da-3790805f44d0'\nFailed:  '067bb9b0-0758-4e7d-bde8-78bd17397c31'\nFailed:  '06856366-6527-4209-935e-0a62ec66609a'\nFailed:  '068d151f-2874-4fee-8a27-9abfe76aaff7'\nFailed:  '069519cd-3f7c-4c90-8850-8d35439974b7'\nFailed:  '0697b5d1-0b52-40b2-bd0d-233b4765fc9b'\nFailed:  '06a556ab-afde-4404-95a4-cbdb0aceaf14'\nFailed:  '06a7deb8-7963-4485-b509-dae0ebaaeca6'\nFailed:  '06b30374-410c-4f4d-8ea2-4fcf9bcf0c56'\nFailed:  '06b50e90-1529-40ce-9355-d78d05c729c8'\nFailed:  '06b8ddce-08a4-4e6d-8745-48710adb9de7'\nFailed:  '06bb5b73-80d7-4a7e-838b-2e27f90dea48'\nFailed:  '06c1ba39-94b3-4ba1-8d4b-0589580f01cb'\nFailed:  '06c2922b-0ca6-45ec-b245-fc2337e0f5fe'\nFailed:  '06c2b4c3-1d30-45a4-bebd-779f2484422c'\nFailed:  '06c2e43a-3a6b-49b5-868d-da4db1abd78a'\nFailed:  '06c89620-9510-4b90-b60c-a871b2a80ad0'\nFailed:  '06cb985f-95e5-4f2e-9fc6-4ad813d68775'\nFailed:  '06d878e8-a2fa-455a-983d-8bef859838fe'\nFailed:  '06d893ad-4d5b-43bd-832e-392d886e7a35'\nFailed:  '06da70a3-4d77-4c62-b0a2-5d5fa11b9233'\nFailed:  '06db6a18-15e1-474f-b6c8-d2d35d843ae2'\nFailed:  '06e0e263-8f5c-4a66-8d49-70e62e235c5f'\nFailed:  '06e3a3f8-77e4-4518-af3b-e9e0083eafc8'\nFailed:  '06e706ff-e987-45a1-be71-31b45af463b0'\nFailed:  '06ead6f0-036e-4a03-821c-60a8bc238c5b'\nFailed:  '06f5be0d-81f6-4c93-9c6d-7a8b627e05b1'\nFailed:  '06f8336c-37ac-4c3c-b927-a8579c44925c'\nFailed:  '06fb42b1-60e6-45b3-bdb2-8589390ecb62'\nFailed:  '0703c155-be7f-46b5-89e8-25d65f8deff8'\nFailed:  '070428e9-16e6-4692-afc7-389c32f0b436'\nFailed:  '071391c8-16fc-4a7b-97d5-949d1848d313'\nFailed:  '0713d324-c3bb-48b7-809c-74dd6ab523f6'\nFailed:  '07170ea4-3087-430f-ac31-40335767b6a9'\nFailed:  '071ac298-7ea7-4abd-8b53-d0e2c32cce1a'\nFailed:  '071dc22a-2346-43af-8ab5-db3a5bb105e0'\nFailed:  '072003c7-3b01-4b0f-b556-6b763e9e4b19'\nFailed:  '07226700-537c-430e-adfb-85a9b8dbfb6d'\nFailed:  '072699ac-c568-411f-a6af-ab964803ab31'\nFailed:  '0729c938-0b71-46b9-8d8a-2f863516bfe0'\nFailed:  '072a4849-7825-41fb-855f-61a8e4bab1cb'\nFailed:  '072e2b2d-04c1-4259-b876-295575726506'\nFailed:  '072f287c-fa0a-48f6-a9a9-71c5d06dd7df'\nFailed:  '0735031b-b1cd-40a0-90e4-3a867f4bd9a9'\nFailed:  '073bc20c-6948-4d07-b53f-734b071e27f8'\nFailed:  '073f5e65-cc6e-4ee6-aca0-3bb465292275'\nFailed:  '073f7631-d19b-40ed-8be9-4efdc7aa5adf'\nFailed:  '073fe400-bdd4-4717-9cb0-9062f7f8c000'\nFailed:  '0742ebc5-14c9-47c8-9715-0773c3ed5818'\nFailed:  '074484c3-2fcd-4750-825e-89d388744665'\nFailed:  '07462578-d456-4906-9560-c88a4cb07b75'\nFailed:  '0749e15a-30e0-4469-bd4b-67eb1062a572'\nFailed:  '074de542-e0d6-4f29-a6f2-6ee8ae487c97'\nFailed:  '07509d76-428e-4dc1-84b2-3299c7bf7540'\nFailed:  '0757f1e4-fd8e-4de3-8f65-7cb11973b6fe'\nFailed:  '075da5e8-3295-4ec9-8932-0a4e46b1babf'\nFailed:  '075f12ed-aef6-4187-80da-7afd47b182d7'\nFailed:  '076369ea-11b8-468f-ade6-9d57ea3f3bae'\nFailed:  '0764fb45-5f94-4242-acdb-a66603d583f1'\nFailed:  '0767045b-dcd5-4bc4-8961-73c8142b9a8d'\nFailed:  '07691043-4534-4b6d-a0fb-a6fee590f217'\nFailed:  '076c422f-f9dd-4359-bd45-0efb8212007b'\nFailed:  '07722c60-7f43-4ac7-a9d8-df09d1dc5c69'\nFailed:  '07758724-4cb0-4a80-ac0f-982d96f89f3d'\nFailed:  '077b74fc-2698-4e85-99bb-b10f36ae79b0'\nFailed:  '077d90f3-090d-4349-83b9-4af91001c57f'\nFailed:  '078153e9-7f9a-49aa-a3d7-b384700a2d38'\nFailed:  '0786e0dd-b201-4ad5-840f-122aabe3fe7c'\nFailed:  '0787d099-8c6f-4be5-b4b0-2062c3134007'\nFailed:  '078a1635-2a9d-47c0-a5d4-1b902e96c268'\nFailed:  '078f28fc-e284-4b46-8a4c-5ec6c33bf99e'\nFailed:  '07933b53-0650-4fa4-8148-24dd17df5519'\nFailed:  '0793c962-058c-495d-aad1-8be7d8184639'\nFailed:  '0798f2fe-f83c-40bd-8f6e-86fe7f71a124'\nFailed:  '07999831-b2c6-4b3a-83e6-4d974a78a8ed'\nFailed:  '079ac67e-70ab-4b0c-b16f-d5ed823189e8'\nFailed:  '079c1682-17ee-4335-a456-496a29b698fb'\nFailed:  '079c19fb-0a16-4b56-997c-ddc359682df1'\nFailed:  '079c5b54-4b19-4ab2-bbd3-695eb64e4ebf'\nFailed:  '079f1f78-24a0-4cb4-9061-e9ecf47779e3'\nFailed:  '07a2154f-bbeb-4ebb-b9cc-965f9308158a'\nFailed:  '07a5603f-18fd-4ab6-b485-ac9b32df6619'\nFailed:  '07a8895b-5ff7-4c30-8c9f-8a55e00f5574'\nFailed:  '07aa8545-fb26-4377-b95b-7680c220790e'\nFailed:  '07aac397-831e-4f2f-93f6-8db3b7908c05'\nFailed:  '07aafd03-974e-47fd-ac1f-90750dad086c'\nFailed:  '07b677c1-f44a-4c20-bcaa-56fd98f1244d'\nFailed:  '07bbabba-14d5-44d8-b125-fa71579c51ac'\nFailed:  '07c7c366-cffb-4093-b100-42c18a4d3702'\nFailed:  '07cdbf98-18f5-4789-a781-2b0cf33f07c4'\nFailed:  '07cdc659-00c9-406d-83e0-46b452516699'\nFailed:  '07ce2ac4-de86-4311-bcc3-9051890d17b7'\nFailed:  '07d783c3-a709-4609-8adc-1c73f4952e97'\nFailed:  '07e5906c-bd77-4f35-9b84-fba77606ca03'\nFailed:  '07e6a197-04df-4025-8800-6ec7c27957fb'\nFailed:  '07e7755f-8b70-4a02-a3ef-8c5566aab322'\nFailed:  '07ebec08-d2aa-4d3a-961f-f4cd6cdcf807'\nFailed:  '07fa7b95-9669-46b5-881f-1a93a57903db'\nFailed:  '08087a07-1e9e-4525-bf28-8bf667734bf6'\nFailed:  '0809bc30-ed57-4a04-872c-d155a03814b9'\nFailed:  '08127b3e-597c-4eaf-a3c4-0eb3a068611b'\nFailed:  '08141bed-28f9-452f-8161-3b5214f2ddda'\nFailed:  '08145672-da29-441f-844a-dd4a9c6d43ee'\nFailed:  '0816b6fc-5c35-418e-b4a8-1ba56bc9410c'\nFailed:  '0819f584-b809-421c-a925-81422b5e9a4d'\nFailed:  '081a478f-21ef-4561-87f1-4530b0a21c86'\nFailed:  '08210676-3307-4a37-bf98-4afa28a9e212'\nFailed:  '082403cb-a0d6-488a-bfaa-d4a4a8687c96'\nFailed:  '08248582-b69e-4535-8c37-5ae97170dd8a'\nFailed:  '082584f1-d847-40f9-9074-05926b4a53a9'\nFailed:  '0828dae4-7d78-47e9-8af6-0fa6a3c854c3'\nFailed:  '082e3de7-e434-44db-b2d4-05512fb9dec0'\nFailed:  '082ee61d-8991-4d2e-ba73-9df0297aff89'\nFailed:  '082f3b2c-c325-4f5a-ae7e-11e45044c8d7'\nFailed:  '08324262-d435-467f-a07a-e289d48a4468'\nFailed:  '083b3001-2b7d-42e6-acf7-5183fb1b6f7c'\nFailed:  '083df5f7-5363-40da-82da-3f5c88b867e4'\nFailed:  '084056b9-8b02-4cc5-9c7d-d6407b5de6cc'\nFailed:  '084108ae-f947-45d7-8010-fce9dc20a051'\nFailed:  '0841fff6-e3c1-4401-a83a-7258bb4911cd'\nFailed:  '08473df4-b345-409d-90ff-09bb319f9a73'\nFailed:  '084850af-4730-4001-8a63-4083ee2687b7'\nFailed:  '084929f7-cb2e-48a2-b664-f95d6553585b'\nFailed:  '08494e9a-dfb2-4a51-9ed8-caa6c3763241'\nFailed:  '084e60b2-5a74-49ba-beaf-0cf7bb5b9d07'\nFailed:  '0856e80a-910b-40cd-b044-1c3eb6fd8bee'\nFailed:  '087444c6-44c3-42d8-aec9-e0f28d92fb8a'\nFailed:  '087d8502-ef25-4e91-ad21-14c392ee36b0'\nFailed:  '087e55f5-c526-4a03-8baf-60400a997012'\nFailed:  '0880513a-fd6d-4da0-bb30-df7dfeb6aaf2'\nFailed:  '088aa34a-51c9-4aee-abf8-f52f11dbc1f3'\nFailed:  '088d2941-d99f-430f-9024-f6dfc63f7024'\nFailed:  '089383d4-c9ac-45fd-bb48-4b1a78cf5fe0'\nFailed:  '08938e3d-abe2-41b2-9546-f56a4f0b64f8'\nFailed:  '08939b58-35b3-4ff1-aa95-0b0efccb6263'\nFailed:  '0894f954-9a39-452b-8612-80c5b0567b4a'\nFailed:  '08988ab6-3250-46f5-812c-e6669f35d51f'\nFailed:  '089a2c59-c054-4a31-a65c-375eabea6f29'\nFailed:  '089b20a1-42b0-491e-88dc-32777fb65aa6'\nFailed:  '089bdc1b-06cc-40da-bcbc-b9563eaae8d1'\nFailed:  '089c615e-1cd7-4ebe-bb6b-46850da920ab'\nFailed:  '089d27dc-ccd7-472e-a9c5-062c562ea228'\nFailed:  '089e4b87-ef4b-4513-bf59-e1f4a683cf11'\nFailed:  '08a279fb-a152-4b21-a4e2-ad8da52604bb'\nFailed:  '08ab14f8-206f-41ba-9a8f-b92c811e3056'\nFailed:  '08ac353d-7352-4ec7-9d1f-11e34acc6842'\nFailed:  '08ac50c1-1c7e-4ebc-b465-bb53f7c83025'\nFailed:  '08ace000-824f-4db1-a997-171433ef9ad5'\nFailed:  '08ad5fdb-3a25-4b22-bf3f-1dcb6b75f835'\nFailed:  '08b0596a-93db-40bc-a6c2-9e7b51b5e527'\nFailed:  '08b16a7e-3bae-4e98-a901-bc180e0b60c2'\nFailed:  '08b1c721-34c0-46f8-95b0-ad3c7f883bf1'\nFailed:  '08bf182f-7d9a-4481-bb9b-1e4a9bb50e6d'\nFailed:  '08c01515-4ccd-4fcd-af36-9d41fb2379b9'\nFailed:  '08c0f94e-f0a3-458f-84d1-d840e02b85e8'\nFailed:  '08c763ad-c866-42f7-931f-51547a983e4c'\nFailed:  '08c8235d-7721-497c-9a37-f37b0f9be896'\nFailed:  '08c99bf5-d19f-439f-b2a5-15da9ce9869a'\nFailed:  '08cb8942-f302-49b7-842f-7ad8b9a90250'\nFailed:  '08cc2379-8419-473e-99bb-ce0904cfb52c'\nFailed:  '08cc8725-592e-45be-9e84-6eac7dfa2fbe'\nFailed:  '08ce26f8-8e0a-4eee-b5f8-8f294cef795a'\nFailed:  '08d12e8b-797c-484b-9ba8-4ed86c09beaa'\nFailed:  '08d44c40-6d27-4dc3-9749-c539172bd941'\nFailed:  '08d4d7db-f6b5-4e60-a480-d0017ecf2593'\nFailed:  '08d6915b-b7a7-4dd0-bbd6-ed7855f24a52'\nFailed:  '08e0271f-adbe-4da7-96ec-0256e8e80276'\nFailed:  '08e24232-8ea1-46a4-8f0d-1ecc2a35c02a'\nFailed:  '08e9e967-b8cc-488f-b93f-7b6dc245af59'\nFailed:  '08ea38e3-0a75-401a-9dd1-9277631f54f1'\nFailed:  '08eacab7-d826-48eb-8f8f-a8c6c12fe536'\nFailed:  '08eb335b-7337-4b04-b4e1-88022109b574'\nFailed:  '08f21271-1723-4175-82c0-b7b00f8d085d'\nFailed:  '08f9adeb-ae0e-4e55-bee1-b2ad4f904406'\nFailed:  '08fc8ccc-59e8-40ea-81c8-6b55e399d5c9'\nFailed:  '08fcd0b7-cb9f-45cc-b9a7-2a51dd938622'\nFailed:  '08fcf88a-3a7f-4e26-9532-6b0a7103d56f'\nFailed:  '08fd1f60-e3e3-4e3e-be03-b7d9678b9019'\nFailed:  '09011acc-a2a7-4278-b7b2-fc2cd38a6e78'\nFailed:  '090184fb-b9a8-4ca4-99a5-fb09e9820d0c'\nFailed:  '0901adea-1382-4cb3-abb4-e567a8ce4f1f'\nFailed:  '090395c5-ebbf-45c6-935c-f1de235268c5'\nFailed:  '09055f88-9de4-4f39-948c-3261f640216c'\nFailed:  '090ca42c-7fac-4e64-bb68-fc7c6893d51c'\nFailed:  '09146419-d10b-4554-b16a-86a40cbc9703'\nFailed:  '09186a82-8079-4844-89fc-a3b66d19e34f'\nFailed:  '091c3701-c3c2-4e57-93c3-11924b030d83'\nFailed:  '092402fe-be4b-4f1a-8b8b-6ddd72822b0b'\nFailed:  '0927d441-7504-4fe1-a99d-7bfc545115d5'\nFailed:  '092a00fd-2d8d-4ff5-aae9-bddc2962f417'\nFailed:  '092a9ae7-c487-4d28-ad3b-dde5fed558b5'\nFailed:  '092bb67d-0800-4bd8-912a-c1f6822a1cdc'\nFailed:  '092c188a-9f74-4ec7-8e7d-9828748f548f'\nFailed:  '09305d9d-4c67-42a9-84ab-d92d0acc460c'\nFailed:  '0932b151-c50c-4d4f-bfa8-a1668858b493'\nFailed:  '0933290f-fb56-4e36-9384-6669a23fd0e4'\nFailed:  '0933df91-eb94-4d28-a96a-15627bcc6fca'\nFailed:  '093b489a-ff9b-4ac4-82d9-194e15b7911e'\nFailed:  '093dd684-00ac-4795-8ec8-73ad84a46aa5'\nFailed:  '093ff7c2-7e69-4d0f-9364-711d16ae9968'\nFailed:  '09403287-5645-4770-9805-7411e23512f0'\nFailed:  '0942b307-e88e-4ac4-a5cb-f49143a0ffe7'\nFailed:  '0945c272-5cbf-4cf1-b425-0f990a791d1f'\nFailed:  '09485ab7-5d8d-4620-b1d1-95b4bc2a7272'\nFailed:  '094e2741-5b83-4f65-a4c1-bddb9193af47'\nFailed:  '09519964-8bba-40f9-9607-5d0964c13907'\nFailed:  '0954b9fa-bbc4-4799-a2c8-8c9b89e17450'\nFailed:  '095c4d81-e97d-4801-9cfe-02a04e479366'\nFailed:  '095c7b2a-f9c8-46dc-9566-5e393c5f7381'\nFailed:  '0960af5e-baa8-4e91-a71b-c7aa6a5b17cf'\nFailed:  '096441bf-ad39-4d97-a7d0-e114b304a72f'\nFailed:  '096a9be7-7935-4ee8-b1c6-7ed07a8eabd8'\nFailed:  '09703185-8e97-4c42-b06f-766a2bc0cac6'\nFailed:  '0971ec17-f13d-4ff9-832d-cc757912ef05'\nFailed:  '0976fc6b-bec4-44ec-934b-e8e5176f6b45'\nFailed:  '097a8c90-3c6c-4403-8404-5c17ed759c1d'\nFailed:  '097d56f6-1d1a-4b85-b62c-00733f616d44'\nFailed:  '097fb3ae-6ae9-4cf7-a8f5-dee925e9d241'\nFailed:  '0983550f-f704-445a-97a3-0782306b8278'\nFailed:  '09855ad7-42b0-47d0-8faf-28a6871fddfb'\nFailed:  '09867bd8-938d-48d8-a76b-c3c3158de00c'\nFailed:  '09930dff-cd04-4b8c-a824-9a3007b02d92'\nFailed:  '0995cde5-b037-4990-88fc-a9fd7571ac70'\nFailed:  '09a1665e-c178-4a21-bd17-74894930fa06'\nFailed:  '09ab4d70-e430-42c7-a7b2-23b231f7ecd5'\nFailed:  '09abe368-c10f-4728-9908-051a01950307'\nFailed:  '09ad2e08-b19b-4f89-9263-6616ca4b0f8f'\nFailed:  '09ad5195-d6a8-4fde-b335-bff329a40bac'\nFailed:  '09ada9e8-207d-44a6-812d-c4561051c6b3'\nFailed:  '09b2e777-0c08-416c-96be-fa16da257c3b'\nFailed:  '09b4c2ea-95da-4eea-bde4-d6d3108d60b6'\nFailed:  '09b91bab-eece-47fc-b780-88db978b51f3'\nFailed:  '09ba8a30-0cda-4011-bd13-ba15408fde5e'\nFailed:  '09bc9ca5-a09a-45e0-82da-b235d4bda556'\nFailed:  '09bdffc8-87f8-4fc0-8a03-b756f6dee4ed'\nFailed:  \n\nStream closed",
  "history_begin_time" : 1649259406242,
  "history_end_time" : 1649259431559,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "vOTTJdvjoClM",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              #os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          #df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          #print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1649259390678,
  "history_end_time" : 1649259395347,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "GWd6s8nGxbnH",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              #os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          #df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-04-06\n/Users/joe\n/Users/joe\n(20759, 25)\n'0001daba-dd41-4787-84ab-f7956f7829a8'\n'0006d245-64c1-475f-a989-85f4787bae6a'\n'000a9004-1462-4b8c-96ee-0601aff0fdf7'\n'00118c37-43a4-4888-a95a-99a85218fda6'\n'0013524a-f2f6-4d5c-a458-9f08a42c1228'\n'0013ea8d-f647-4664-b40f-57bb96f800e5'\n'001476f9-a9d5-4128-8210-e2c4879ce505'\n'002220cf-0b83-4f58-bacb-c4318686194b'\n'00270da4-a790-4b81-a693-e1e8c4f13e6e'\n'002a9f10-203c-4feb-9ea4-19bcbe9a7686'\n'00325ba7-fcbe-4bab-8c4f-f70cfe80ea46'\n'0038be33-f5ba-4274-93b9-c7b6ea003519'\n'003ca3a3-c298-4253-9f1b-7f6a1a097ca6'\n'003d4c74-b631-467c-b1fa-56c4708276bc'\n'00481126-761a-4d70-8775-c449bf498ecd'\n'0049403d-da12-4b13-b02a-0a2dd4e01d6a'\n'004cf556-f3dd-4c4a-9da0-cb2eb848ff0e'\n'004e5e03-f6b6-470b-96e2-911992c8ffb4'\n'00505b61-f978-44ee-92e8-c082c4482ac0'\n'0050f3a5-e24d-45d7-9ce1-f046a54adb96'\n'0051069d-cdc3-467b-9034-31f5e0eeb005'\n'0051c2e3-a110-4460-9296-9d9c9df82473'\n'0057c657-ac2f-4141-881c-3593859ef092'\n'0057dca9-9c70-4708-9697-909e5711a7f0'\n'005b6d88-4f1e-4ebd-8425-25e7236b5838'\n'005f3676-e3dd-416a-af7b-696067815dfa'\n'00651c0c-8687-4431-935b-8f2bfed1f429'\n'00656c12-2000-4cb7-97b0-6d51bafb5db2'\n'0065b17a-f2be-478b-b323-f3bb3bed4341'\n'006eac45-1c31-45fb-99de-30a52623082c'\n'007153b7-e0b9-41dd-a0a8-30901524ad20'\n'0072f5ac-ec83-4183-8757-47a7e26a8d86'\n'00743e1b-a98d-4026-9bdf-50cc52cd168e'\n'0075950a-3452-49a7-a1d7-7fb71b984696'\n'00778d9b-f669-4f39-b4d4-493ab085a536'\n'007ecee3-1492-4cb9-9a53-82d951ea2f01'\n'007edd43-d3d9-4f63-afee-8e5a95903ed6'\n'00802ec7-1ff4-4432-8cad-8a2db176f2bd'\n'00822a9c-dfd5-4ecf-b1fd-a445c450e7e7'\n'008971aa-a279-40eb-998d-a2ca2a26e7a4'\n'008e79fa-7265-404f-ab62-48f59d0e0f4c'\n'00909645-804d-4b63-a66f-283832684bf9'\n'009983f0-6187-4b99-9240-2299566529e2'\n'00a9de30-4258-4863-a7f9-e9788bc29b8f'\n'00ba0112-a5da-4264-9b86-82bf21bba65a'\n'00c20f4b-3dba-47cd-8210-73bfc64a5591'\n'00c6952d-223f-4661-a325-a98912335d81'\n'00cbc9d7-ce7c-46e8-87fd-774fcd1ad03e'\n'00d0afb7-e919-4b16-86d4-4ca059c7af09'\n'00d3626b-3696-49ae-97d2-165f56187953'\n'00db953c-7f4a-4de3-8772-42d7048c1ab6'\n'00df85af-2836-4229-a654-876cf2a1767e'\n'00e18892-bbf4-4dfb-b231-9d76b7299bee'\n'00e1b8d6-84f5-4b79-a5a7-ce7f8fe13773'\n'00e9c22e-949c-43c2-aed2-2e5a27dfc4bb'\n'00ec51da-dae3-4624-960b-e0cc9a911718'\n'00ee875c-37ea-47e9-9736-be92dd7353ca'\n'00f12281-0861-42c1-8053-702c7b6966e1'\n'00f1ff7a-6c24-44ae-9d47-d78533773a93'\n'00f4f052-a244-429e-b091-08f88d1f4d09'\n'00f7e783-ebd4-46d2-8bd1-c4ab87199426'\n'00f9a90c-60a6-4183-814f-e50722fd2c2d'\n'00fde10f-74b9-4eaa-a6e4-7abe055d16c4'\n'00fff8e8-082a-4c71-a29d-ec0db786cd6b'\n'01011989-1913-405b-a52f-80220df7876d'\n'0103912a-8a01-45e9-83ec-146cd09f3164'\n'010f8360-a018-4620-9de2-33a7893129af'\n'0113dc17-2d90-4541-89cd-f209b30405f2'\n'0114836e-3741-4224-abb1-703e87f330a7'\n'01156105-b7fa-44b9-86c9-27909a81d63a'\n'011df06d-650c-40e7-bd56-d2f305c1bff9'\n'011e46e4-00bc-4fb3-be3b-d31e22e880f2'\n'0125850a-5d2f-46d2-9873-0066edcfe334'\n'012ea03b-8472-4adc-abf5-6352a2e9c04d'\n'012fbbca-6dc5-4c37-b266-ac2782ca4975'\n'01337282-fb38-45ea-a4ba-d046fa7f79f3'\n'0136d669-a167-44d6-8c65-dbcbc4f71e5b'\n'0138b557-850c-43a9-a5d6-7c7e96d096e1'\n'0139bb4f-9f2b-420c-b5ea-34db9a5d0d65'\n'0139def7-9348-42b8-8767-0edcb1d81a1e'\n'01486dea-9406-4fb9-a080-2ce6c8889d61'\n'014ce464-ac95-43ad-a614-5f017f8656ed'\n'015e2c22-7766-4d19-bde1-33f6a22824ba'\n'01609391-dfb8-42e7-9806-6b2fb7a23e07'\n'016144d3-14da-4f27-a62a-03f7c2b0a9df'\n'0161a423-ba7f-405d-b129-273fadc00911'\n'01620fe7-3c4a-4b71-b45d-a3805eeaf509'\n'01652e7e-9400-4e7c-84bf-86e67f33246f'\n'016837dd-3b5f-4fed-a555-a05da5efbe1f'\n'016d3736-a9d0-474c-b62a-3e90ec42eefb'\n'016fc79d-5ee9-46b7-a84a-6e869cf4960b'\n'01705743-de45-4cef-893f-3856b5cbb662'\n'0174c824-3ade-474a-ae73-04963649b692'\n'01762b10-7e89-4cf6-a227-143eab3943d8'\n'017a7810-a518-41bd-b012-7464fad522b5'\n'017dca0b-be33-4eba-90de-f0c2fce9f098'\n'0182c197-ee0f-45e8-a001-4d7d7c9795a3'\n'018481a6-b64b-49e5-9824-599dcabf2135'\n'0186f113-1650-4e47-8de0-70cee5863d66'\n'018acc46-9b3a-4f14-b4c0-5929776ace07'\n'018c8a27-2b08-4705-a8aa-b0c13ceb89ad'\n'018d455b-a485-499f-858d-b2f09c0dc75f'\n'018e1f62-069b-48e1-b440-f6eacaa54520'\n'0190e8ab-7af3-4baa-a959-9099350c0ae8'\n'0193ab07-d62b-4660-9f26-5e890dbe7c46'\n'019470f5-b5ac-4f0f-9a88-dc0e2b0af7a3'\n'0194c7f2-1f87-449c-9c77-2f1ce6009e18'\n'0195f974-1f43-41a6-9acc-42896477ab61'\n'01999dd2-f622-4a97-b09b-83f5ed7523da'\n'019d002f-2ba5-47c7-9d1e-0421d065e23f'\n'019d3222-db52-4cd7-bee6-d335eabab91a'\n'01a73b68-64ab-486e-a9a5-a9c9a6f3f6fb'\n'01ad3790-e684-4829-950f-01368856c94e'\n'01b1a490-2442-48ac-ab23-4563464468af'\n'01b35227-af96-4f9b-894b-391bd1ad1e4b'\n'01b7bb5e-0c0f-4263-943c-ff9a249847ee'\n'01b81868-133a-4b56-b386-ec0e4fcc57d0'\n'01bc3228-7fa3-460e-947c-3a365c7d533c'\n'01c10e0e-9255-42a5-a649-9c62f74ecf86'\n'01c8c6e4-9db3-4085-a4f6-f191bb014e70'\n'01c95d67-a86e-4784-8473-45162188f46c'\n'01cf8536-1488-4ee9-82e5-19ac82183b06'\n'01d34fad-ffb3-467b-b159-41c82158f2e2'\n'01d5fddc-8e3b-4482-a515-e69292066dc3'\n'01d60152-b41c-4b57-8ae3-bf7bf6dcfdd8'\n'01d9f4f1-12f2-409b-af76-8cee0ee95701'\n'01db68d7-532e-46c9-94c3-2d4dd4cf4753'\n'01e85eed-aa39-4a61-b720-a59b84991428'\n'01e9eea8-0e61-4aeb-ad57-e89135510ead'\n'01ecb4e4-bce9-4309-ac1f-4787c0be22c7'\n'01f0f6e2-574e-424f-98a1-6b823752932a'\n'01f39cb1-66c7-41c9-96c4-0fa4baa98851'\n'01f53e53-8ffc-4b74-a6d4-808e242b44b7'\n'01faba06-9dba-49f7-92cb-ceaa16bdab2c'\n'01ff2bb4-67b6-43ae-8506-53282bf27a6a'\n'01ffe76a-9d66-4733-b17f-bf922a54fb21'\n'0202aaca-5ec1-4917-a75a-bff3520b72da'\n'02062667-85cc-44c3-a52d-4f884bd1c95c'\n'0209240a-0dba-494d-a0b5-bff00c00d0ef'\n'0219357c-527c-4a54-a00c-9573d9ddaf47'\n'021a84a4-6a5e-40d1-b5d2-ede15ab4d051'\n'021e5ca1-3702-4379-81b0-60ded7294421'\n'021e7a6a-fde4-44cf-bbda-8b096a2970c7'\n'0227083a-cdf0-4dcd-9939-72994feb6be8'\n'022780fb-57e6-4ffe-9212-0c7daeb13bed'\n'022a03f3-2616-4ce3-865b-da113b76d188'\n'022b63c5-5bb9-4fda-8489-9a41470cb07d'\n'022e5945-f13d-4270-b147-a4d33a3d4a5f'\n'02387350-2d78-427f-9f78-b117fde1d9e7'\n'023b2795-12c2-4f1f-bb52-3e3ecd26f1a7'\n'023c3c0e-9709-42bf-a778-12c929f206cc'\n'023e4079-f8e3-4b27-abd2-93047825fd7d'\n'0243f7ae-79d1-42e1-b60c-464d6cbddfb6'\n'0245cef8-4d64-43ab-b37f-42f6c04c9cd0'\n'0246e8d3-9ff4-48d6-bf5d-f602b5d38319'\n'02486797-e82a-4007-ac80-410c03a31c6e'\n'024d24a6-fa03-4953-b50d-b0ef42d222c2'\n'024d4a58-ef11-4f2b-925d-657809d60ff6'\n'02513e74-2209-4083-a8b5-a16e54fea22c'\n'02546ef5-0e70-4c45-9582-8463dafcec86'\n'025533c9-5fdc-4fd0-a6a6-9935ad824c32'\n'0255cea4-8bc0-42fc-a0ce-a102af1eaac3'\n'0263eff8-963d-4586-a3c0-8b316c5d21d9'\n'0266bae9-30f1-43eb-8c9e-25b6d250aa1a'\n'0268c537-5cf9-4c2b-a1fe-ff64944b1796'\n'02690e0c-f79c-4746-82e5-5247c89c1f06'\n'026b1ec0-027a-47a9-b37e-cd982b695240'\n'0274c1a7-8069-41bd-88f8-5e8d9e12be31'\n'0275628e-1bb7-4f54-a1ea-160cb2b38feb'\n'0282bd7b-67be-4661-90ea-99fb7bbd182f'\n'02835e9e-2bf7-400b-9a33-779563f1e930'\n'0285b903-f5be-4a53-842a-c42282701d50'\n'028710fa-9b38-497e-b266-6e33afe367bb'\n'02897a1d-af9b-46e3-aec2-cf8f9ef11c30'\n'0289c86a-1519-47a1-9c7f-ab0c626d8995'\n'0289f22c-aab5-49dd-a8dd-9cfbe9f56d51'\n'028c66e1-5d2b-45fb-93d1-0a44f808de34'\n'02924296-383d-46bc-adc5-6531f741ea7c'\n'029529bb-cea1-43ec-962f-636aa443c403'\n'0295665e-82a7-464a-a496-0124625392d6'\n'029758e7-b211-41c0-841b-bcfbdaa0b29d'\n'029b4083-4edd-4cba-a77c-3a2caa76c1fe'\n'029b869c-e14d-4951-8962-c06e9e60aa89'\n'029e2603-322a-4f62-bc1c-f3da75cd2265'\n'02a453da-76c8-4ba1-91d4-7c56fbf0eb60'\n'02a4c14b-aa90-40d9-8529-a0878b09cc0c'\n'02a4e852-c4d5-482b-a521-51a4424e3f70'\n'02ae9a3b-126c-41ba-a529-d28deb7d3337'\n'02bab660-283a-4a3e-b30b-939bbae5a969'\n'02bc5e0b-b999-4403-8eeb-9e509cd00171'\n'02bc8ca8-4bc5-4bbc-b36f-7d58dc2756f7'\n'02c02657-0bd4-4fa2-b339-020e3412050c'\n'02c2200a-4b11-4970-af37-2e5fa693cd1a'\n'02c5023a-ad16-4cf3-9003-8fd77a84ddb2'\n'02c52c70-df0c-4349-984a-8caca4cd8eb8'\n'02c81990-3038-437a-be9f-bb76d3e7693f'\n'02cae6ee-02f2-44b2-bd64-c7ca51cb7671'\n'02cbb2df-9830-4fe2-b7f5-03ba8a4e34b2'\n'02d04a43-bde7-4952-938b-37a5562d69a4'\n'02d70e51-07db-43c3-88b4-1550cbc7855e'\n'02d9b441-2d47-494b-8870-8d3382c17384'\n'02e45508-e284-4c0d-b3d1-2bc402fff1a7'\n'02ec8bce-7ef9-45bf-b3a9-58f7823f25bb'\n'02ed331c-90ba-49dd-8b51-39a5fe448578'\n'02eeeac2-3708-47ce-b2aa-dd7496bb5152'\n'02f4a445-bcda-46a2-acf9-38312df92450'\n'02f5f302-aa54-4764-a30e-5d7522b469ec'\n'02f681c5-add3-48b6-9a37-0d9c2a6a7f9b'\n'02f7a562-0746-4b4c-8d83-4128c873029c'\n'02fea5e6-5b16-47c2-82ce-94e288ff20e3'\n'0300e6f6-c6f9-4ef7-9d6d-dc7ec5f97e5a'\n'03058382-7125-4e15-b58a-76fb220f158b'\n'03093663-1b50-4087-a861-86cce1fdd9eb'\n'0309ccc0-02a4-4fa9-b7fd-44e13269bc8f'\n'03129265-0e01-4ae3-b482-cf399a0b90f8'\n'03153931-6b5a-4b98-abed-642cb3ba953c'\n'03186c6d-3e58-4538-9b9a-9bd96ee70218'\n'032c487e-9eb7-4f6c-8689-e6dacbc13727'\n'032f5da3-da09-4e3b-8ec0-68bcc4f3f9f6'\n'0332e840-aeda-4ba1-8c6c-165c85c6da7f'\n'033ddd98-b155-4a2b-bfeb-730cdcf07b07'\n'0340b93d-ab1c-44b8-9ccb-8341bbf8022f'\n'03412397-8ac4-4685-974d-3172f16acce9'\n'03461b35-29f1-4978-a1f4-b213ff413fed'\n'0346c906-7f5a-440a-9c13-6d254237335b'\n'034af8da-8c17-4bfb-ac8b-3b2df079639a'\n'03529fdc-ba2e-4f81-9d0c-88808ae0b045'\n'035731c9-39e9-41e7-a239-da7af53e6f94'\n'035c0ae3-5c88-4498-a7fe-d095f7d83de3'\n'035c3ff5-ccde-4434-94f7-9d4b64b19617'\n'035d07a1-97f6-4d29-89f4-2a3951d2084d'\n'0361cd82-9167-4276-b16c-caa5f1e1c249'\n'03665d3b-fbe0-496a-99fc-c8d18b379214'\n'0366ca92-01fc-42e7-b680-03d9d1374491'\n'0366dca6-a897-4742-a479-aec364f9488b'\n'0366e6a7-fefa-4187-a556-cc26609d9c92'\n'03697894-9bd1-46a1-84e7-3da027dd0aff'\n'0369f043-8568-4f29-9800-d9b0f667f33d'\n'036d0a25-ffee-4b07-a57b-96ff8dd23f4d'\n'036d27dd-3835-4e33-9c08-cf52ee82afc3'\n'03776833-19ad-4c2c-8b0b-75bfb49a183f'\n'037c249b-9e28-45f8-9270-05c11f3cf9d9'\n'037e8c82-798e-4785-8c9e-a98a38bd76be'\n'037ef632-0877-49a0-9ee3-0c32878c1f61'\n'038264ee-7ca0-41b4-8f27-55a53896ee87'\n'03855439-0816-4ffc-9100-aa34b74bc43b'\n'0385a03d-03ec-4e51-a05c-ef6636eac88d'\n'03860206-6eb7-4020-beb6-fd9a748de04a'\n'038a7de7-7704-4266-b562-5e6d6928de7d'\n'038b20ff-28c3-4bf3-85c9-beef360f1baa'\n'039284f5-1409-408f-a715-b95cbab4ec49'\n'03994b68-5abb-4f04-bf70-5558125c65e0'\n'039dca15-5d29-4cef-aad4-79d5b2de066a'\n'03a4625b-62c1-49ad-9ae2-a43d6f2332a6'\n'03a89ff8-7f5a-4b04-b143-771deee60255'\n'03abc36e-7824-4b9e-9677-e79d08656817'\n'03b29664-20a4-4f2c-82f6-d47a87506d07'\n'03b4e5f8-e73c-44b3-9a9e-c0492f8dcc0f'\n'03b64207-ca0c-4a82-b5ea-9435bb0d5470'\n'03ba7e12-ff2c-4349-a712-6fd2a0a7794c'\n'03bb5877-25d8-4172-a73c-6dba4dfda91e'\n'03bfd3cb-c0d4-481c-986c-b89ce1656732'\n'03c1f2b5-9ce6-479f-b540-2c7b1c060fd0'\n'03c2ea2c-c749-4f08-8ee0-6dfe1bcddef0'\n'03c3c363-76bd-4d36-9e82-0d9845fda7e2'\n'03cd5120-f976-434e-84c4-526f3d2db076'\n'03d3272d-5dad-49fa-9e21-c4e4366df738'\n'03d82692-a06b-4a1d-b14a-e79498696337'\n'03dac778-3739-42f7-861a-c4f32e054669'\n'03e20c1b-af33-40ed-aa44-6ba7264f412b'\n'03fb442d-ed22-4f6a-9a65-76ffe18380c3'\n'04067fc1-b841-4c5c-b1b3-1fa874867445'\n'04072ca9-0a7a-43a5-a57b-829e3525c001'\n'041541e7-637f-49ee-8210-90e0c85092e7'\n'041b148e-437c-4f1d-8d34-9e58760a4b11'\n'04235ebf-f64c-44cf-b604-1868b798b27c'\n'0426e0b0-389f-421f-a115-90f6eba81276'\n'0434f065-1e73-4df9-862c-1cbba7e37b02'\n'0443995b-f761-4514-a461-350f401715a1'\n'0443d786-9adc-4aa8-bb4d-2ffeb5b4a1d1'\n'0449e3b8-cd03-4535-8e1a-cef000a07270'\n'044ae40a-ebf2-46bc-9b51-66d1454887b8'\n'044b8806-634e-4d8d-a077-107658def160'\n'044f2583-60dc-4d38-94eb-d2c77d52b845'\n'04549cd3-b094-4c3d-af14-310178872bec'\n'045542d2-3492-4270-8392-060a1d4eeae7'\n'045aa3ff-f902-456c-a9f3-1e9b36bbd08c'\n'0461cae8-c4ac-4411-8267-64bd2e23d5dc'\n'046a2746-ef98-4576-9ff2-511a052c1aca'\n'0475b6cf-8ca1-4d8f-8b29-d4d17f4574b7'\n'0475bfa0-36ee-44cc-a2bf-63821bf28552'\n'04768fa3-aa7d-47a0-be14-ba21b8b0c263'\n'048142ef-62f3-425f-b4d7-bf7c61219135'\n'0487436d-1d79-4471-8207-7efce42489c7'\n'048b1d1a-1ecb-4aca-b1ea-0c3cda5dd85c'\n'048e7290-5886-46e0-b276-992e73edeb4e'\n'04910e5c-e613-4843-b19d-6a676e46ea90'\n'04915a27-bedd-4ecb-ad0b-b7a38c90fb0a'\n'04945d00-aa04-4176-b40e-5022a83e1579'\n'049a46cd-15c2-45b8-8f73-25221c9acebe'\n'049cb9be-c25f-4469-8721-982645acb73b'\n'049e7f98-849c-436f-98b6-fb24e2fbc4b5'\n'04a0d453-5988-4d8e-95cf-aa989b228a61'\n'04a20b0c-286d-4cae-98d3-701962f098a2'\n'04a2d21a-c9b0-4c88-bc54-ee9f65b4d1b0'\n'04a5ab2d-5a18-4dfb-a7a6-e605f0c64692'\n'04ac59fc-2d32-461a-9882-7e6616900aea'\n'04ae08e6-0a38-43ae-902a-34acc8b8f98d'\n'04afdc09-9f4f-4401-9351-25f6fce7a1b5'\n'04afec81-b376-44cd-9d4f-70060ab6b2c6'\n'04b0ff01-6cc0-4a4a-865f-e4a672d3d179'\n'04b160db-c1d4-4f5e-806e-82b099a0f649'\n'04b1b98a-d151-41cc-b5f2-0050139d5ae9'\n'04b21d75-e0a7-4089-88c0-7b6b1771d6c3'\n'04b2e81c-a3b6-4a37-84b4-558b2bd13c77'\n'04b95d6b-852d-428b-ac37-c83d0f3399f6'\n'04ba3508-4bb8-4a7f-92a4-4f16743514f5'\n'04bdcfca-66ce-4399-b575-e215b694d3dd'\n'04be7c6e-e796-471e-9f9f-4e9ba69e70e8'\n'04c37019-7660-4501-b031-9c17d7ca2d60'\n'04c57d84-19e5-41ef-9761-539fdf6cf608'\n'04c62e68-a59f-46d5-b3e4-b311f837ed9d'\n'04c779aa-0e3d-4062-a473-7cc1b6cd4459'\n'04c7bb4c-52b3-4338-a413-604ed1047ac4'\n'04ce226b-96ed-4358-9d47-335d143a6e2c'\n'04d3cf6a-6e35-4fc3-8d02-d3b39432ea06'\n'04df4b3d-8841-4e2f-8536-d1d9cefd0572'\n'04df5da5-85ab-47c2-af7e-778f3db07049'\n'04e1cf76-ea0d-49a3-95e5-e52e46135176'\n'04e333b2-9d7f-4898-97de-40ad9b379d64'\n'04ea7ec1-d270-4d01-a8de-6a3b6ddf2892'\n'04ec7abb-03a7-4f7e-acb5-2be559b5e466'\n'04ee8779-7ccd-4bc6-b4e3-38e519e5bb6b'\n'04f277f7-3d65-43ca-b172-e3fd701418cc'\n'04f40c2a-fd9b-46e5-8d7c-57e442234874'\n'04f4634a-3367-4645-b2af-9719b5679f8b'\n'04f54505-160a-48a7-bb7b-4e75650457b7'\n'04fa0c5a-7cc7-45af-882d-0329fe7045e0'\n'04fdface-1e2f-4c31-80e6-1e6483d29b9b'\n'04fe66ee-becf-41b6-9110-3b70f835e06f'\n'050635be-202d-4799-8b11-1fa7a30888a7'\n'050c9aa7-1a3c-4198-bd6e-b71e87f6421b'\n'050f7a2d-5feb-492a-a549-47db328ca3ea'\n'0513d54e-45c5-48fd-9365-ea93037142f2'\n'051b98f9-123f-48fa-977c-22015a3ebbff'\n'052168a0-6ae4-4b8f-847c-358d78c3e891'\n'05232be9-fdb4-4644-8d0b-793d4e4407ae'\n'052350f3-733c-47e3-a0bb-0cf78886eda8'\n'0523645a-ce00-432a-9d6b-777508c83a1a'\n'0528d484-9e37-4140-a43e-894fa1ae987a'\n'052b8ca3-3f5a-4d57-8fe6-ee55275baa48'\n'0532172a-42b6-4bba-9e00-c7647866bc32'\n'053288fc-7634-4b0e-83cb-7d76f072192d'\n'0535ed57-a197-4e69-ae4a-102a6ecfe249'\n'05360efd-326a-4afa-b28a-d5916dbb94a3'\n'053962ee-c1e2-4a4d-b21a-de845553d5ca'\n'053d9118-b5ed-47a3-8319-0f145f244a4c'\n'053e8f71-fdf0-41b1-ae40-15db891a698e'\n'05488e9b-b918-474a-8ff8-47076c95e983'\n'0548df31-6858-4d21-8878-8d5638aa5764'\n'0549628e-54d3-4086-b52a-1df268d87c17'\n'054be902-2bc2-47b6-a641-29fbe99c16a5'\n'054cf666-898f-497c-a561-c6d8f2fddf2c'\n'05563bf5-b7dc-426d-a914-8e6ea0c27899'\n'05575c51-5215-4fc3-b455-9ad4b56d4f86'\n'0557cbba-861c-4f20-931e-2f33e8c2b073'\n'055e5328-187a-498e-8893-00cb04821723'\n'0560ca13-1058-4a8d-8629-2b720250b8ca'\n'05694a09-1972-45b5-8a67-d1541f00f3db'\n'056b3777-54bc-4be1-81e6-ccaead6cf064'\n'056bbed9-0c27-48ad-9072-b532d97322cd'\n'056d591f-d96d-4700-967f-434d0ed4cbac'\n'05726490-fcfe-4bd3-ae8e-6b5dc39e1bfa'\n'05746e8c-0f15-41d2-a4c1-4ddfe851e397'\n'05749ae4-bdea-4cd1-b40f-af7643fcc157'\n'0578020e-9bae-46ff-aaef-f64b9330e801'\n'0578e1ff-45d7-4fe9-a28a-f4b669c123ef'\n'05791146-2450-43bf-9ed7-db6fb507142a'\n'057f433b-a8de-425e-843e-fb6d15276612'\n'057f7dd4-6e33-4f6e-828a-6a3d14abf2cc'\n'058bacc8-5d39-43b8-91d7-c9b8a8bf5d0a'\n'058c942e-6fe4-4e67-a047-3cecf68167f6'\n'0592fdcc-d1b8-404f-9f23-725b50760949'\n'05936245-fb6d-4a1b-864e-e39d1dc557ab'\n'0598145c-77b0-462c-b9c6-7bb3eabf26cf'\n'059cfcba-89cc-4f3a-8665-3831ab242fab'\n'05a38ac7-262d-4136-9f67-7ae62b37334b'\n'05a391c8-b0d1-4a80-af4c-85b1a63785ec'\n'05a68ca6-986e-400b-acf3-ef06f59ab86b'\n'05ab3786-2df1-45eb-981a-a9ad882442c5'\n'05ad05ff-a1f6-40e0-a441-d9a7ed8268ca'\n'05adc967-9d21-4548-83e9-3df4f7d05cfd'\n'05b16864-bfd7-410e-a82f-c726609d0976'\n'05b6e9fd-c047-486d-a063-3df46ee9507b'\n'05c08a4a-e688-4b49-97e7-6194f7e0a68a'\n'05c13909-f845-49bb-860c-b03523352a77'\n'05c40154-5e23-4fb2-b48f-1fe5d393527f'\n'05c4a84b-90e5-4e19-9c62-decf47b839f5'\n'05d3382d-7b0e-4d7c-8bbe-17e0329022d7'\n'05d7ea55-ac46-481e-a28a-f73d008fd061'\n'05e15184-37d6-4889-8254-3b0a3a6bbea6'\n'05e706da-f181-48a6-a802-6b997839a3db'\n'05eb1850-9609-4d00-ad31-603ffad3af79'\n'05ef68b8-d89c-406b-be87-4bbac4242b75'\n'05f06090-2b19-48df-aa89-db729161af09'\n'05f12591-24ea-4a3b-8c0d-584803f61c62'\n'05f24aa0-bedd-4d21-a21c-ec2306d8dbc3'\n'05f52020-6bc7-4128-a9b3-1bc5a0631f49'\n'05f7f64a-1a08-4758-bacb-854e72f798f7'\n'05fcf6ec-bd96-4c5b-99f9-94561933241b'\n'0606d5db-153d-4fc5-bb55-a3fe512fa8d4'\n'0607cd43-6cb9-40e0-bab2-4c5a4bfcd4f9'\n'060b0040-d2dc-49f5-91ae-e24bdd0ef807'\n'060e6959-0f31-4da9-a31a-e09ba3cb8066'\n'060e9025-f833-4b7f-8a66-4b1a7e28d405'\n'0610668b-2864-464c-ab8c-ff40b9fb747c'\n'06121571-8dbd-4fac-a0d6-aa5d3ad12359'\n'0619dde5-26e7-4e0d-838f-91c564614a68'\n'061a84b2-b182-45db-8895-b4990b610849'\n'0624ef1b-5ebe-47c3-ac83-9fc757f6d5e9'\n'06258474-812f-4912-9fb3-e518f43a5fbb'\n'06292529-e9de-4238-87b5-2c65163a7d5b'\n'062a4e6e-9073-47d3-8531-c66022f275b2'\n'0630090d-453d-4d3b-9c95-0eb05c36cd5d'\n'0637f796-99e3-4f1a-9710-36ef0ce4cb79'\n'063c8f4b-ab52-4a55-b155-1fc02d8da547'\n'0656eebb-487a-4ec9-9334-f6e14fa4bc15'\n'065babcb-76b1-412d-8e47-b1adcabbdc70'\n'06622f4d-c964-4762-a72d-a773037f0af6'\n'0673b6ef-454f-4b2a-a754-fbb63df39e3c'\n'06856366-6527-4209-935e-0a62ec66609a'\n'068d151f-2874-4fee-8a27-9abfe76aaff7'\n'069519cd-3f7c-4c90-8850-8d35439974b7'\n'06a556ab-afde-4404-95a4-cbdb0aceaf14'\n'06b30374-410c-4f4d-8ea2-4fcf9bcf0c56'\n'06bb5b73-80d7-4a7e-838b-2e27f90dea48'\n'06c2922b-0ca6-45ec-b245-fc2337e0f5fe'\n'06c2b4c3-1d30-45a4-bebd-779f2484422c'\n'06c2e43a-3a6b-49b5-868d-da4db1abd78a'\n'06c89620-9510-4b90-b60c-a871b2a80ad0'\n'06cb985f-95e5-4f2e-9fc6-4ad813d68775'\n'06d893ad-4d5b-43bd-832e-392d886e7a35'\n'06db6a18-15e1-474f-b6c8-d2d35d843ae2'\n'06e0e263-8f5c-4a66-8d49-70e62e235c5f'\n'06e706ff-e987-45a1-be71-31b45af463b0'\n'06f5be0d-81f6-4c93-9c6d-7a8b627e05b1'\n'06f8336c-37ac-4c3c-b927-a8579c44925c'\n'06fb42b1-60e6-45b3-bdb2-8589390ecb62'\n'0703c155-be7f-46b5-89e8-25d65f8deff8'\n'070428e9-16e6-4692-afc7-389c32f0b436'\n'0713d324-c3bb-48b7-809c-74dd6ab523f6'\n'071dc22a-2346-43af-8ab5-db3a5bb105e0'\n'07226700-537c-430e-adfb-85a9b8dbfb6d'\n'0729c938-0b71-46b9-8d8a-2f863516bfe0'\n'072a4849-7825-41fb-855f-61a8e4bab1cb'\n'072f287c-fa0a-48f6-a9a9-71c5d06dd7df'\n'073f5e65-cc6e-4ee6-aca0-3bb465292275'\n'073fe400-bdd4-4717-9cb0-9062f7f8c000'\n'07462578-d456-4906-9560-c88a4cb07b75'\n'0749e15a-30e0-4469-bd4b-67eb1062a572'\n'074de542-e0d6-4f29-a6f2-6ee8ae487c97'\n'075da5e8-3295-4ec9-8932-0a4e46b1babf'\n'076369ea-11b8-468f-ade6-9d57ea3f3bae'\n'07691043-4534-4b6d-a0fb-a6fee590f217'\n'07722c60-7f43-4ac7-a9d8-df09d1dc5c69'\n'077b74fc-2698-4e85-99bb-b10f36ae79b0'\n'0786e0dd-b201-4ad5-840f-122aabe3fe7c'\n'078a1635-2a9d-47c0-a5d4-1b902e96c268'\n'07933b53-0650-4fa4-8148-24dd17df5519'\n'0798f2fe-f83c-40bd-8f6e-86fe7f71a124'\n'079ac67e-70ab-4b0c-b16f-d5ed823189e8'\n'079c19fb-0a16-4b56-997c-ddc359682df1'\n'07aac397-831e-4f2f-93f6-8db3b7908c05'\n'07c7c366-cffb-4093-b100-42c18a4d3702'\n'07cdbf98-18f5-4789-a781-2b0cf33f07c4'\n'07cdc659-00c9-406d-83e0-46b452516699'\n'07ce2ac4-de86-4311-bcc3-9051890d17b7'\n'07e5906c-bd77-4f35-9b84-fba77606ca03'\n'07e6a197-04df-4025-8800-6ec7c27957fb'\n'07ebec08-d2aa-4d3a-961f-f4cd6cdcf807'\n'08127b3e-597c-4eaf-a3c4-0eb3a068611b'\n'08145672-da29-441f-844a-dd4a9c6d43ee'\n'0819f584-b809-421c-a925-81422b5e9a4d'\n'08210676-3307-4a37-bf98-4afa28a9e212'\n'082403cb-a0d6-488a-bfaa-d4a4a8687c96'\n'08248582-b69e-4535-8c37-5ae97170dd8a'\n'08324262-d435-467f-a07a-e289d48a4468'\n'084108ae-f947-45d7-8010-fce9dc20a051'\n'0841fff6-e3c1-4401-a83a-7258bb4911cd'\n'08473df4-b345-409d-90ff-09bb319f9a73'\n'084850af-4730-4001-8a63-4083ee2687b7'\n'084929f7-cb2e-48a2-b664-f95d6553585b'\n'087444c6-44c3-42d8-aec9-e0f28d92fb8a'\n'087d8502-ef25-4e91-ad21-14c392ee36b0'\n'088d2941-d99f-430f-9024-f6dfc63f7024'\n'08939b58-35b3-4ff1-aa95-0b0efccb6263'\n'0894f954-9a39-452b-8612-80c5b0567b4a'\n'089b20a1-42b0-491e-88dc-32777fb65aa6'\n'089c615e-1cd7-4ebe-bb6b-46850da920ab'\n'089d27dc-ccd7-472e-a9c5-062c562ea228'\n'08a279fb-a152-4b21-a4e2-ad8da52604bb'\n'08ac50c1-1c7e-4ebc-b465-bb53f7c83025'\n'08ad5fdb-3a25-4b22-bf3f-1dcb6b75f835'\n'08b16a7e-3bae-4e98-a901-bc180e0b60c2'\n'08bf182f-7d9a-4481-bb9b-1e4a9bb50e6d'\n'08c0f94e-f0a3-458f-84d1-d840e02b85e8'\n'08ce26f8-8e0a-4eee-b5f8-8f294cef795a'\n'08d44c40-6d27-4dc3-9749-c539172bd941'\n'08e0271f-adbe-4da7-96ec-0256e8e80276'\n'08f9adeb-ae0e-4e55-bee1-b2ad4f904406'\n'08fcf88a-3a7f-4e26-9532-6b0a7103d56f'\n'09011acc-a2a7-4278-b7b2-fc2cd38a6e78'\n'090184fb-b9a8-4ca4-99a5-fb09e9820d0c'\n'090395c5-ebbf-45c6-935c-f1de235268c5'\n'09055f88-9de4-4f39-948c-3261f640216c'\n'09146419-d10b-4554-b16a-86a40cbc9703'\n'091c3701-c3c2-4e57-93c3-11924b030d83'\n'0927d441-7504-4fe1-a99d-7bfc545115d5'\n'092a9ae7-c487-4d28-ad3b-dde5fed558b5'\n'092c188a-9f74-4ec7-8e7d-9828748f548f'\n'0932b151-c50c-4d4f-bfa8-a1668858b493'\n'0933df91-eb94-4d28-a96a-15627bcc6fca'\n'093dd684-00ac-4795-8ec8-73ad84a46aa5'\n'0945c272-5cbf-4cf1-b425-0f990a791d1f'\n'09519964-8bba-40f9-9607-5d0964c13907'\n'0954b9fa-bbc4-4799-a2c8-8c9b89e17450'\n'095c4d81-e97d-4801-9cfe-02a04e479366'\n'095c7b2a-f9c8-46dc-9566-5e393c5f7381'\n'0960af5e-baa8-4e91-a71b-c7aa6a5b17cf'\n'097a8c90-3c6c-4403-8404-5c17ed759c1d'\n'097fb3ae-6ae9-4cf7-a8f5-dee925e9d241'\n'0983550f-f704-445a-97a3-0782306b8278'\n'09855ad7-42b0-47d0-8faf-28a6871fddfb'\n'09867bd8-938d-48d8-a76b-c3c3158de00c'\n'0995cde5-b037-4990-88fc-a9fd7571ac70'\n'09ab4d70-e430-42c7-a7b2-23b231f7ecd5'\n'09ad2e08-b19b-4f89-9263-6616ca4b0f8f'\n'09ada9e8-207d-44a6-812d-c4561051c6b3'\n'09b2e777-0c08-416c-96be-fa16da257c3b'\n'09b4c2ea-95da-4eea-bde4-d6d3108d60b6'\n'09bdffc8-87f8-4fc0-8a03-b756f6dee4ed'\n'09be9d4a-85c4-4f1f-b886-c0ca8b9f586f'\n'09c16013-fd3b-4ffc-aa8a-02a9652fa6fd'\n'09c31481-cf94-4425-a14d-b7d62e6a4fbf'\n'09c91ccc-9fb8-4c99-a082-8eb57a03c45a'\n'09d5ce40-915e-45c0-ac16-36ff85d36d66'\n'09d8b7f9-703a-44ad-9526-4e464196151a'\n'09dca6c3-9802-46e1-9a85-0ea7c9477724'\n'09e62f58-0d1c-40e6-bf1f-1ee4ca776449'\n'09f6e4cc-ca73-4485-bfff-395c0196bbb4'\n'0a067213-9188-490f-9c83-f01207d95192'\n'0a08dc99-865b-449b-8ef0-a91d38e13c3e'\n'0a0a4dc6-87be-4ac6-b540-28d76b64cd6f'\n'0a18246d-5b64-4e0e-9ff7-d98634342a50'\n'0a2550e3-e265-4b41-81ab-1865cbbf5785'\n'0a2a5e48-003f-4f22-9429-b5ee939a5018'\n'0a4e3e85-b393-4d38-a2da-3c3e34612fab'\n'0a5484c8-fa95-4d26-8fa9-1f7783f4cb7f'\n'0a56003f-4918-4997-b049-5d0d8ebfd07d'\n'0a5d9163-a21b-406f-84e7-5d2e4ecc7752'\n'0a64800e-fbe2-44f7-87cf-c141ede2433a'\n'0a7006c0-b3b2-47e1-830e-7da7f86e5c27'\n'0a814153-e468-46ab-827c-d436ec52dc12'\n'0a92bf1a-b52d-4fda-a0b9-99cb3eeb6e44'\n'0a94cd29-78f1-4d5d-88e0-e7cc62b3e3c3'\n'0a980b2b-a214-4b29-87e3-0e710c2d5eda'\n'0a9d50c0-a9b8-4a22-b518-547216fd8f56'\n'0aa5b39b-c79e-4538-adb3-1594e11bc90d'\n'0aaa98ac-70ec-4323-b718-b78fd64b0af5'\n'0aac8dd3-6976-405e-aa00-57bd7362ef9c'\n'0ab804f3-22bd-4246-8b7b-c7a2af143bda'\n'0abe09c3-a34f-4164-b72f-2be9c390d05d'\n'0ac57d9d-1b4d-4350-a930-c532ff4789e8'\n'0ac8834f-a98c-4f36-ba02-39478bc0e0d9'\n'0acedd67-5334-4cf0-9327-fd737c2c55a1'\n'0adbd1c4-dc8d-40fd-bea1-842fba2b8167'\n'0ae0166e-2951-42c9-bbd6-f4a4b45864d7'\n'0aea9bdc-0d69-42cd-afc5-cffb6662e80d'\n'0aeae4c1-337e-4476-9d8c-073955d45887'\n'0af67fd5-8561-4875-8be5-64dfd32cbcef'\n'0afcc042-f120-4d7b-b7a4-5afc4b5970a6'\n'0afebe6b-b16f-4a1b-9e4c-92ac1a9c35e4'\n'0b095026-e914-43bc-84db-ef96433e3852'\n'0b0dda5d-e350-4e49-8ecc-d5f8d084bcc2'\n'0b164252-e501-4a9e-84ea-30f86fa66eec'\n'0b1ac29c-a06c-4418-98f4-44a5dfced85a'\n'0b1cc888-4f7a-4a9a-9bd6-1403d81d81d4'\n'0b1ce129-e769-4711-a46d-8d3d61556443'\n'0b1fba9e-7ddf-4698-8dbe-914fcd64a12d'\n'0b266e44-cf7e-4a22-b9f4-90df9d29df8d'\n'0b26dc64-00e5-4bd6-89bc-064a4dadaad7'\n'0b27fc0b-3846-4b00-99b3-21e433fd4adc'\n'0b2ed16f-d41d-41b4-bf39-2d5cb227e716'\n'0b395470-0ae0-4b68-8c01-e84739d91527'\n'0b3b4670-fa97-4294-9f10-d6fcc720e9c2'\n'0b3df019-6452-4544-bc30-c26246bf1166'\n'0b3f6112-4d18-4970-b348-dc18af76ecf8'\n'0b435bb1-2afd-4b40-8c00-40f2bf91c7d0'\n'0b5b6ad9-84f3-4eab-a305-6a0230814e2a'\n'0b5e4f08-a325-4290-86cc-08c477c22226'\n'0b61a853-905d-4227-8ad4-562c64ebbe80'\n'0b61f9a0-1030-4fe5-aee8-b8f9d2d38c4f'\n'0b7e4306-bfac-4544-bd53-8b0836d153ed'\n'0b8849e7-2b18-4151-a36f-b792c1b82aff'\n'0b8f6567-2c62-45bb-ac34-02c0df726b27'\n'0bac901f-52ca-4567-ad42-ba62610feca8'\n'0bb36e89-ae7c-4c44-8f1e-096e1e12b677'\n'0bbae0c8-16ae-4b7a-8ec8-40ae8f0114bf'\n'0bbfa881-c7b3-4481-8ea4-a8ee5da4200e'\n'0bd7a121-e468-45b8-b73f-743ed2cf083c'\n'0be43379-b1f5-4877-96e0-53dbcef32bd6'\n'0bfc308f-3fef-4aa9-b821-932fa1742245'\n'0bfcaf8c-d884-4aa0-92cb-b61b53c46fd7'\n'0c06d2de-f108-4014-a04e-01e8e3b0adee'\n'0c091211-9a45-4698-9876-109eb4daddbf'\n'0c0a65e9-ca16-43c3-b2db-2881b5915a7d'\n'0c0ba3ce-fdf8-4765-9da7-dcc3afbca19b'\n'0c0bfbd2-d561-4c05-a4e2-de43b4679944'\n'0c11e979-e496-4ef0-ac00-88e9e1e34d09'\n'0c143938-7ce6-48b5-8d7b-caf70ab1629f'\n'0c18b648-35c9-4123-9027-998e8b93ef2a'\n'0c218b21-6e54-49ed-aa03-11d70761a170'\n'0c336bbc-b124-4805-a11f-4c50c2353797'\n'0c397dc2-794a-412e-b348-c2746b2d6aaa'\n'0c4b3177-b58d-4c5e-9207-64cc1e0db668'\n'0c50e6f2-3628-4bb3-92db-d6160183583a'\n'0c5e7a0d-82a5-4eb1-a150-3ae0717e22dd'\n'0c612697-ddf1-4304-a397-4cdc6df2d292'\n'0c6b3d20-4cba-40c9-9744-c288d2553a71'\n'0c7f4b78-584f-4985-b4a2-dede8bd7db84'\n'0c860edd-84c0-4509-8880-e20675b8da07'\n'0c8ed2d1-d007-47f6-a6ca-65f9f55c446d'\n'0c996eed-0e6e-47bb-b6b5-67268ef82c98'\n'0c9a4043-4cdc-47fb-a56d-cfb9f20b6b8b'\n'0c9cd276-93f6-455b-be60-5b85d1f02b53'\n'0c9d470a-7d99-4454-9737-caf635024e24'\n'0c9f3535-9977-43b1-bd93-b88b050ac049'\n'0ca0638d-109e-4a19-87ac-3dc22bd026e8'\n'0ca2eda8-ffd1-47e3-a623-5ba7d7259f53'\n'0ca81060-4d78-4621-887a-cf5a245bada9'\n'0cb0685c-3331-47b9-a011-e72958932a82'\n'0cb63431-d5b0-4fdb-8f42-a8afb4926993'\n'0cba5117-78d8-4489-bd63-737bd81b1678'\n'0cbc07e8-3f14-4de1-8b80-6443533b6005'\n'0cc0581e-89d7-44ca-923e-5b521dbd0783'\n'0cc78ee5-7a0a-43c8-804d-1fbd5a573eea'\n'0cd59e3c-4330-4578-ba44-9d668da845cc'\n'0cd5a466-a3bf-4ec0-89b7-67a4f6a96b1a'\n'0ce45d53-854b-4c90-ac5b-4d01961985c6'\n'0ce6fa8f-77dd-4747-bf68-bec164ecbfa0'\n'0cea9a14-6e2b-41d6-866b-6b11e56c349d'\n'0ceb89db-15f2-4faa-8a9f-46f52991752f'\n'0cf450c0-131b-4e54-acec-9de295d13bda'\n'0cf7507d-6221-448d-90b9-b82c8df577d1'\n'0cf88965-57d5-4e09-85e3-f957339b9e13'\n'0cfd8c31-fbf9-465b-9ed4-f8d45d303844'\n'0d0eeebf-db09-432a-bb32-0eaf43c984bb'\n'0d125226-7318-4cc8-b976-33ae5c9cdf75'\n'0d188271-5920-4646-9ace-09caa3f057ab'\n'0d196645-1338-4f37-8a73-ef380da316bd'\n'0d254d8e-1d33-4894-8bfc-6fdaafd81b0e'\n'0d2f77fa-461b-4371-96af-d5f05fb88f68'\n'0d30a78f-6b09-4985-b403-718382e2e8ca'\n'0d37f0bf-8249-424c-85e8-4fdaef9d90d9'\n'0d3f68d6-d6b2-4de5-bf54-02cef602bd8f'\n'0d4d6c93-2994-472a-92bd-daea82a90f58'\n'0d4e27a6-a3f8-440e-9073-4f87dd160303'\n'0d4fc87d-1b06-4786-a1bb-a56f285110a6'\n'0d51f9e3-d121-40e0-a3cd-082b72d035d0'\n'0d569ee9-48e5-48d8-9862-c6bb17088e3f'\n'0d612704-69c1-4419-bca7-58d949b3210e'\n'0d7e7342-e265-476f-a7bd-160440b74153'\n'0d861a89-ea20-4be3-9771-2ef62636099b'\n'0d86bb2e-6eda-453e-b684-b85be130baf6'\n'0d87fc2f-6eb9-4448-9046-4f7284a621b2'\n'0d97538f-311c-4290-85c3-c7c1c229e979'\n'0d97fcd0-1403-49d1-a1e7-adb61660a147'\n'0da6d7e9-9b0c-4dc7-ab6b-73583e80f45f'\n'0db10713-aa7f-4457-8212-3be1264f494a'\n'0db9d7b8-0875-436d-9d8e-9839e207a675'\n'0dc8524b-19bb-45a2-aa4d-fb494881428a'\n'0dc9437e-b2db-4650-81d6-e01d23dde5a5'\n'0dcbf9ff-2533-4f81-9e2a-3011d88fdc4f'\n'0dd27b60-b4f9-4047-8c51-48e1562076c2'\n'0dd4fcba-1e6f-4b95-8a10-95e8bad5d9ea'\n'0dd5bd82-eb98-450e-93a8-18ddb1d1bb5d'\n'0dd5f64b-7b7d-4c00-8b69-6f5fde5156e9'\n'0dd6002a-1b47-45a2-a3a7-1da5b48e250c'\n'0ddb8074-cf3d-4e3c-83c5-64dd408a3ed1'\n'0deace7d-fefa-4e01-b74e-13c83da40539'\n'0df07dfa-7ada-4d07-b83b-9818396c6703'\n'0df62e2f-a3ba-4e10-bb98-9cdc7fef7136'\n'0df79512-52e6-4852-b6c5-ceb3bba54c67'\n'0e001917-c5ea-47c0-8fb9-5fcd46cd2fd4'\n'0e0189e2-215f-451b-a641-03136032acf9'\n'0e05e4a5-1161-466b-9e00-8bf8691021a3'\n'0e0b9dc9-12e5-4d90-910e-b10a22de4a9e'\n'0e1217db-6835-43f1-94c1-fee5dc668c87'\n'0e2c6e3a-15dd-4bf2-8157-8e972f2090db'\n'0e34fba8-2463-4a62-837d-9d998a5a3480'\n'0e3c2113-26ea-4cd1-8610-282ddc20a595'\n'0e3db324-bfea-4f76-bddb-83d30c2999fe'\n'0e40cb7c-297b-4453-afea-cd9535654dad'\n'0e440081-e269-4a82-b5dc-924028a6866d'\n'0e4ede84-2db9-4026-8c08-995e5ccaca29'\n'0e531a2f-9292-4d6b-be47-3649ab962bb0'\n'0e5711e6-b578-4b8e-988b-9ad7d4f1b534'\n'0e636bf1-312a-4444-8812-2044b60d0fe5'\n'0e647371-034c-49b6-8c3f-18116c562e9c'\n'0e67506d-b2c1-4160-ac50-1952dd34b7c1'\n'0e685be1-c86e-4808-b770-557b76638680'\n'0e781c52-ecb5-459b-9aec-b34266999dff'\n'0e81182e-af64-4ad7-b353-3d4c1e55fa88'\n'0e8d33ab-87d7-4cab-a46c-6b4456c6caa3'\n'0e8fb2f6-8141-4b59-97ba-358c948e256f'\n'0e96feb1-6973-4c67-a9f7-928fc3dc7f6e'\n'0ea05f44-0ba7-430f-8f73-d37ea036292c'\n'0ea13864-da66-4337-9ea5-996460dca56c'\n'0ea1ec4a-e898-48c1-bc29-9d6bcda14afd'\n'0ea23dc1-e9ed-4d86-bdf1-97a08a4fd12f'\n'0ea7ff13-9bda-4efd-9ff2-014cb57ff0d5'\n'0eb724bd-0fe7-43fc-bdf2-1536adff92ad'\n'0ec8096d-9885-4e77-b9d1-25e29c615232'\n'0ecbbd9d-e199-47c8-9a2f-ef8a2e5f0df7'\n'0ecd4fff-09ce-4306-90b1-cdba720c4212'\n'0ed0532a-ec4a-4162-8270-3d081b0f8994'\n'0ed5ec87-4dd3-4a6a-960d-4e04ece80ed2'\n'0ed8c5af-5f36-4392-918e-cf10c73f6a9f'\n'0eeb602f-b461-407e-8b80-d2493950c7b7'\n'0ef4c7c7-35a0-4f9d-a43d-734f532a2f0d'\n'0f058ccc-9d3a-4f85-b317-1bfb6b8ca2fb'\n'0f0cac24-bddd-4b97-9405-ce1160837534'\n'0f11508a-6162-436a-b0cf-6ff63844e551'\n'0f14ffba-8ae5-449e-9323-89d2e2ce51cb'\n'0f24fe15-73a7-486a-8957-9d74cc61abab'\n'0f26745b-afbe-4156-89dc-a162903ad5b3'\n'0f2725f1-af04-407e-b73e-8c4fc4b23b9a'\n'0f47e301-caf2-4fb1-878a-802a004f1478'\n'0f5166d9-b5d7-4662-abcd-b9d8b4e3dabd'\n'0f540fcf-6216-4af2-a9c5-0b4512956e6c'\n'0f5939ee-5c6e-46e9-9e03-0d6afd9c6b9f'\n'0f5dbba2-563b-4250-9036-2bc60ad29e41'\n'0f624ff5-7d5f-466a-8354-bbd5f59a708d'\n'0f68b820-c6bb-489d-b358-8a89786eecb7'\n'0f6f1dce-da76-4c43-af23-a604b6a2d706'\n'0f701112-bfd6-414d-8817-6da17c218267'\n'0f72e7ac-5dd4-48a5-9e45-c4f26de72809'\n'0f747d26-64dd-4b5b-a42c-6ca9dacd4d78'\n'0f776622-eeab-42cc-9572-0b8ffe4258ee'\n'0f8009f4-a7f1-49c6-9d79-fde54413a1f1'\n'0f82d1c5-d8a8-453c-97e5-52e99adf95e1'\n'0fa261f8-09c6-4fd3-bbd3-8037f5470042'\n'0fa38200-35c5-450b-bb19-8f6b3bef9995'\n'0fa924eb-43e5-4d03-a85e-c97f9a4d3f4a'\n'0faaaa17-8479-48a0-a66d-f3fae3803a6c'\n'0fae42b0-dd41-4823-8708-69ef48adfa6d'\n'0fb025ea-00ab-48b1-b075-55d95b6113e8'\n'0fb36da4-76b7-40fe-8adb-bab1d206a69b'\n'0fb3a882-1267-4ce6-9cc6-ec00421cce5b'\n'0fb668ed-40e6-4ce7-ade4-074c23652c28'\n'0fba0b6a-9b91-4a96-bec2-80c5c5741d10'\n'0fbbf198-9c28-472e-9cc5-3cd9f95f9abc'\n'0fbd7ff0-8d43-4502-9b69-1b1e4eff0080'\n'0fbf810c-07fd-4115-90ae-7458ef5ce6aa'\n'0fcb7810-02d4-4941-9aae-b348223dca2e'\n'0fda8e51-be46-4f09-b552-3201c1f33649'\n'0fe225b9-c7b7-495a-9f06-264443c0d922'\n'0ff12496-d2d2-4b16-bdd7-3683aabb7821'\n'101559c7-e3f2-4746-a0e7-42556008c82b'\n'101b5ebf-84b5-4bdc-a43e-32e1ea95ee21'\n'10206cb2-7430-4a69-a9b6-00a2f436a890'\n'10312ed6-e59d-48a1-85b3-31a5532bd86a'\n'1032c2ab-b4ee-48ec-9d67-4ccfa05d50ff'\n'1047c798-967b-424b-9381-cdc5e0b2ca7b'\n'1048af85-2dde-4ee4-8058-444fda05f292'\n'10490468-ed5d-40bb-8b3e-62638ec342c0'\n'10593f59-0948-4ade-9888-75e6c31d55ca'\n'106130b5-2f95-4447-8eee-28012e91eaed'\n'107b27d9-8852-4539-a4b0-e4c28afd1857'\n'10a940ff-ac39-4eb9-afc2-a392e25dd7d0'\n'10bfd636-2937-4b24-a8ca-873caaa1fe9b'\n'10c1b159-2957-4ec5-91cc-c910b206842a'\n'10c847ea-54eb-4bc9-b642-76228fac19b0'\n'10d6c907-0818-49df-84e1-5df8e84f3148'\n'10d70975-815e-48bf-b729-ae7728adb19e'\n'10d8c239-6cd1-4c55-b675-74bfc449ffc8'\n'10e00bfe-c7b4-4ab5-9376-b07cf562221b'\n'10e18575-7527-4017-b6f9-a1c0700ced77'\n'10eb6dcb-7b19-46f0-9fa7-789be6621b10'\n'10ec899f-3f98-4924-8927-55e280340807'\n'10f16df3-93d1-4f4f-9dce-1b12b950a23c'\n'1118b6e1-88e5-4077-bdcb-763d45e2c85c'\n'111d3c27-0a03-4d4c-9d9e-f92b32da90dd'\n'11211f7f-3c8c-40e3-9268-fbc77225bf23'\n'1126a01a-c3b7-4165-b169-de61d1d6afec'\n'11270530-41f3-4dd1-ac6c-6070858824a2'\n'11360d41-2368-4e5b-9c2a-9d9555692cde'\n'11374ae2-1e3b-4ee1-9d6c-cbf01b70564f'\n'1138ef64-5cf2-4a6c-82d0-0cd06a386f05'\n'113cbb38-2b46-4129-8cb6-3e97a8a234b0'\n'11435830-eab0-4bef-8215-f0b5a2084e3c'\n'114ad001-09b6-4ffb-8b7e-2622d03fd01e'\n'11537d9f-d57d-4a7c-8d03-4558c10bb36b'\n'11633ac9-e9ee-4018-86ae-ae724611efe1'\n'11680fb8-3b51-441c-862f-619f57a27121'\n'1186b831-2840-464f-b625-820ee7e6db77'\n'118e8fd4-90d0-4495-a9fe-1c59f7f7e32a'\n'118eea2a-aefa-4602-b538-7c0b0f69cf3f'\n'118f3ae2-d0bd-40ac-9ecc-bf9a629a33f5'\n'1196c17e-4a6a-477c-9ecf-6e06f49135ca'\n'1197d732-735d-490c-ba73-23bd8bdc80ce'\n'119ceab7-5951-4559-ae1c-231ac27c46a4'\n'11b7ed09-8637-4d39-a0d0-d68eb9871f14'\n'11bb44ab-b800-4e3f-a119-79ef67034a66'\n'11bf8809-8ee1-44fe-b475-785d4acf9c7c'\n'11d2f8ad-4a6f-4fcc-99ed-0bea6a1f048b'\n'11d79751-b1d5-4b99-b3ad-7a1369a94b3c'\n'11d84147-8c6f-4705-b98d-ac38219929e2'\n'11d9d08e-0406-41f3-bcd4-b92b81376f78'\n'11dc66ec-5a17-4df9-ad5a-7fedfadec9ac'\n'11e05f2e-27e6-48c5-8157-5d59f30a737f'\n'11e0b08f-69ca-417c-9983-51387e010983'\n'11e2e5d5-d8f6-4e98-ac7b-bf9fdf49696b'\n'11e7b820-892a-493f-9697-ee175e8e8601'\n'11eec598-b652-4ac6-97fe-f74d573232da'\n'11f75022-558c-418e-a3c6-232d839ae000'\n'11f8d153-eb7e-4117-a18e-9f2f71521bc4'\n'12009e99-8600-490f-b402-285112236d53'\n'12246948-0f70-442e-9b43-70699ea915f5'\n'122ebdce-53b2-4cf8-8189-5035ed54c71d'\n'12308c59-91ff-4c1c-847b-6baa673edaf9'\n'1231cf80-5571-4018-8625-de1251209909'\n'123591ae-ade1-443c-8dca-7d62e9dcde31'\n'123886fb-e01c-4ab7-9e32-dd493fe62fba'\n'123d86cd-1836-4ad4-81ed-10b73d09b0c3'\n'12400318-d3c1-44a6-acb1-025cb9416055'\n'1243bd00-e3b6-4920-9f84-0c44cc7436d7'\n'124530c3-5904-4104-8d4b-a68d8492ae9d'\n'12499266-cfdb-4810-9f8f-eec2cd81feae'\n'125246ba-1c82-416a-8442-d44a70a0858d'\n'1254cb8c-edf1-4d02-9276-c7b9ce99d857'\n'12579e85-dd4e-431e-88ea-2fe34578498c'\n'1258e250-4cd9-4e4b-905c-698a4af37106'\n'125abfe1-03a0-4972-bb7c-cb120c6bc400'\n'125ac7f7-6d41-489e-8419-2b205bccca86'\n'126ab73a-0d38-445e-b672-82b96980e5bb'\n'1274f545-ee19-4d2c-8e06-e86a736b1991'\n'1276fa08-e541-414c-b811-f20c5483f0ad'\n'1285d585-fa2c-4085-b25a-bbc86c2d7313'\n'12883991-d1c5-48df-8488-9f218db70c9c'\n'128cb048-7772-4b21-a09d-ece539fc37ae'\n'12960c79-42be-48c8-8517-a6bedb9e22bb'\n'12987e59-a24d-449a-aed4-e1c6d3e6ce2a'\n'1299f131-69d5-49b4-bac8-b6803adda4d7'\n'129b890f-bb26-467e-8766-45213df18c3a'\n'12a04728-db95-42b6-aad0-bcb16d7b9c35'\n'12a4d8fd-ee5e-4cbc-8706-b7e2adcf53ea'\n'12a686a1-fbac-4e45-bf69-ea3e39aca9ad'\n'12acb549-ee08-4067-88e8-e7f6fb138968'\n'12b98326-de22-4107-b357-365d36201fe7'\n'12c7303f-778b-4541-95e6-2c5d242a46ae'\n'12d973bf-888e-4af7-bad6-2261375e2a23'\n'12dac0fb-f891-413b-ae06-f337ba49e649'\n'12de14c3-9205-47d4-ae03-261b07569587'\n'12ea879c-5d74-47fb-a4cc-c447d18e9f90'\n'12ef3af1-8c99-4cb3-a69b-95f396a2dd0a'\n'12f94dcd-ea74-4024-baff-a5ac7b837e0c'\n'12fddbc5-5322-44d0-8958-04b51d750ed1'\n'13014f5e-205f-49f5-9a9d-333817471ff7'\n'13018a6a-d06e-4ddd-a733-f8d0461d0575'\n'13072015-8d55-4122-bb6a-74654d87f19c'\n'130aa1a3-5c31-4faa-9e5d-ad502b511f80'\n'131e0fa2-1b94-4e75-8b62-d8e9831b8323'\n'1329a456-4996-412b-9560-c9aa9c60cf82'\n'132f6127-9f4d-4787-9158-52a4546e6c77'\n'133486eb-e8ee-432f-9426-70d56b91b65d'\n'133dbb15-a9a6-4064-b8be-b126c1856435'\n'13409ee3-ad90-44d4-bc84-36dff88c3a05'\n'13442073-be92-4534-9daf-a1123a4b606a'\n'13472a65-055e-4a22-a90b-4fab6a5cca61'\n'134e2e14-2af9-4e9a-8ab0-460930a57972'\n'134f6fbd-a72e-4337-956d-13bfae55ef69'\n'1352b3f4-9484-4091-8727-e552191ff7ab'\n'13615727-aa36-4905-afd2-3dfeb1e3b8d1'\n'13668a6e-7869-4162-ad0c-8a937ae1865c'\n'136f1010-92f3-4f63-9f6b-792448f7b79f'\n'137a152a-86ca-4d9a-8a9b-9cc2a4b92b59'\n'139c6f52-9f16-440e-b51a-7724eb7159cf'\n'13a0831b-18f0-46c1-93de-e27b86def7de'\n'13a4643c-5a0a-4856-be01-d99f19e5c8c7'\n'13c07c62-a606-4fb3-a89f-2970156b20a0'\n'13c1c1ea-73ec-4bea-b057-3e24b0201458'\n'13c259db-49de-490d-9f15-133c3155aae9'\n'13c30ac7-a5b3-4f20-a1c0-de83d9826ee6'\n'13c355f2-c561-4281-bb86-02ce7c71d814'\n'13c3b806-1977-486f-a5f6-40498f2e5277'\n'13d0a16a-7107-41e0-98a0-b365345a64ed'\n'13d7a56f-9426-482d-9925-b9c71cc6e77a'\n'13db3c24-94a2-4540-94ab-7660bf8ace3c'\n'13dde06f-b3ad-4b92-9fbf-283b5e447a6b'\n'13de74e3-cc39-4bf5-8f00-1a19ec767c67'\n'13df20ac-6c4f-4415-a62f-822348ed3ff3'\n'13e08d77-63e5-491d-8148-ba490fd2fc03'\n'13e3c5b4-b5ab-4ec3-8860-a709490ad1ae'\n'13e4e4d4-09a5-44c4-bce2-cd8f543ef95e'\n'13e4f690-4826-45af-95d9-c31ddf7a88f0'\n'13e747a8-6522-49a0-ab87-59d991a958b7'\n'13ef876c-1cb5-4615-9c3c-08a87e0ea6a4'\n'1430cd03-7bea-4ae6-a220-96ba6719e5a2'\n'14379c03-b61f-42ee-acdf-2185591571d8'\n'143849ce-8008-4d76-bf9f-9fd4fb5d7999'\n'1438a219-985c-4983-b1c4-9cb75bc4c1e6'\n'143cb779-f3e8-44ad-999f-9f5b3230c5ff'\n'143f87a1-4119-4c26-ac36-ded501ce6478'\n'1451ec32-0e10-40d5-8e73-c5dfbc202dcd'\n'14589b02-e99d-4223-a36d-3d41d0c909f5'\n'1479b48d-e4a5-4a5b-b49c-4df10c2df94b'\n'148150bf-2d91-4a53-9d43-f54f8accfea0'\n'14934aba-a54c-4bdc-9b48-34ba67defecb'\n'149a666c-2c99-4cad-ba3d-279ad0cc1414'\n'14a156bf-3ccc-4b72-94e7-ce04009e2ae5'\n'14ad21f2-e35f-4f98-ace1-070e565e10c9'\n'14b23592-df1b-4142-9b74-c5df7ad31ed5'\n'14b4f532-e6da-4c22-8169-54c845c5f32b'\n'14b762ca-637b-4883-bee3-dc26f9d23fee'\n'14b7feab-bc3f-4dc2-99f5-796d1e7e6547'\n'14be60ea-cfd2-484c-8f81-958764dc8463'\n'14c32e0f-b108-43d1-b0d4-189aae41dc80'\n'14c55edc-233f-45a7-b573-df57424b23cc'\n'14c5b15e-efd3-4881-a6a2-3a846f59970b'\n'14cf3905-8a26-44c6-958e-59e79f3c474a'\n'14cf9bf4-f7d5-41d4-a647-a74abe47fec5'\n'14d001d3-95a6-41cb-b92a-ddf30f79e54f'\n'14d5c050-9601-4e87-be21-84a6e25673ab'\n'14e0086c-c77a-4510-ab60-985fbd659efe'\n'14e778e0-2e5f-40b5-bd27-bc8718ac8341'\n'14ebf7a5-d3fc-46f6-ade6-9fe3799b2a89'\n'14f1e651-bd4a-47ad-97b3-d0a45ba70292'\n'14f61e05-f02f-409f-9d73-431461904e69'\n'15026142-b8cf-4b45-95ee-243dd627c473'\n'15084518-811e-43b3-b846-9c2cb970de3f'\n'151342c0-cee4-4514-980e-7545e4cf8e9e'\n'1513830d-853d-4910-932d-a725b23f7e45'\n'151e1eaa-3cb4-475c-a112-31732c1c829d'\n'152902f9-6a07-4514-a7ed-7d2308e6adf7'\n'1533036c-4394-47f0-ad54-56de4a444a49'\n'153fdb4d-acd5-4808-b0b1-7987ada06b29'\n'15481ba4-c753-441f-b839-3017b81a86f8'\n'15495bdc-91b9-4493-85f5-f55bb4ed4ae5'\n'154dba22-9554-483a-bb0f-76d7b32307f0'\n'156799db-5285-4a04-9ee3-fde0b43ddb89'\n'156848a5-f177-4116-a8f6-3fcc327426ea'\n'156b5ab1-e55c-4829-8720-0b652e7b697c'\n'156bb739-1aba-4f63-ae40-f578a1fa247b'\n'1579762b-cfaa-4fb1-9f7a-fed97c485149'\n'15813b7d-08bc-40a5-b593-59275659da9c'\n'158cc185-85d6-4d1a-b0fa-baad01e25b9b'\n'1592bd36-feea-4c2b-9953-d58de80ca9d0'\n'15979b0f-cd79-487f-b13e-510278f3dacd'\n'159c83b0-0f42-42d7-ade2-cea6616047cc'\n'159e29fd-3c47-42dc-ac22-811a080e4a09'\n'159e38b4-2d95-4419-92f7-51ebe0fe22e2'\n'159f446b-9260-47f0-9615-238b8cfbe9ee'\n'15a29ccf-6bcd-48ca-bdd1-28ef33c3c202'\n'15a82484-84e3-4b34-99d7-e148c9b658b5'\n'15b0e46a-c39a-4e18-b18f-4f3dae529bc4'\n'15ba33fe-0d22-47bd-809c-b6bdeaa0cfa4'\n'15c4f9fc-c00e-4806-9d5a-0f3f66f12d1f'\n'15cea6d5-3699-4550-ac59-00b3f44a00fb'\n'15d5083e-6001-4721-a8c6-f237dd0fc193'\n'15e6c4ad-5b64-4b68-a414-c22b3cf2a4c9'\n'15ee6573-5850-42d3-b44e-c0edc222c44a'\n'15f0da2a-5660-4c2b-b968-6cf2559f7190'\n'15f35447-57cf-4443-901d-f0c2f59df7aa'\n'160e68f9-ce13-4cd8-9257-f1fd29c864ed'\n'16146b8b-58d5-46d7-aa31-4dac9a5962cd'\n'1614b886-813c-432b-b08b-eccfae8705bb'\n'1620992b-c734-4f7d-a605-52497985eeb1'\n'163084ba-d175-410d-9bc1-151e408712cc'\n'163185e3-02c8-487c-a1ce-0f51bf0a666c'\n'1632a24f-fc19-4fa6-8446-f0218726c9a5'\n'1635dd04-fc67-40bf-9c0a-bef78924e294'\n'163ee869-e22b-4455-addc-7f57c142063d'\n'16460ab0-a4e2-4204-b1ab-49a2a60d1112'\n'16529613-4ecd-4732-8c63-28d85db13163'\n'16554611-fa7c-412d-baa7-62d269400f5f'\n'165b9fc8-5fb0-4e13-9673-d67f99fcd8bf'\n'165fdfdd-2a02-4074-a21b-42e4b189c2e8'\n'16603d90-cd12-4be8-8b0f-6ba572d20995'\n'1671151a-6446-405f-97c8-4a894aa9b423'\n'167764ab-17a3-400b-bfb4-0f75a63779de'\n'16ac0e1d-c331-4a4b-8722-ad0721b3666d'\n'16d32e45-268a-4417-aef0-4f2ed5c4cdf9'\n'16e402c1-892a-4495-b7f5-c6bf35718243'\n'16eb50eb-af40-4d97-8482-26cfa0650642'\n'16ec019c-31ec-44ff-8147-25d895cfdda5'\n'16f01852-531f-46ce-8351-43911ef31c5b'\n'16f33c15-bfb1-4223-aeb6-a235f612aaeb'\n'16f55760-907f-46ab-96cb-f210d95947f5'\n'16fca960-c119-4561-99b4-aab1622f2fce'\n'170bffa3-583b-4f8e-92d6-ac020fd7d24f'\n'17122897-9882-4a41-baf6-f9966714d71c'\n'1715dfd4-0f69-4545-bfbf-2cd1750eb160'\n'171a33f0-681b-4529-99cb-1aa5238461df'\n'171b9987-ff41-42c0-a380-810189504830'\n'1721676d-31a6-404e-a129-4c9cdd0c672a'\n'172330c0-c6c7-404c-88af-d6ca97dd0273'\n'172a9500-f45e-4961-8f66-bf78c7a9e109'\n'1731444d-f122-499b-9df0-f8a4c3220447'\n'1747cd45-3f94-438a-aed3-c09fd885e67b'\n'1748ad33-ce2c-44c0-9a66-3793e342e3ef'\n'174e8501-6487-4195-a39f-96b34c658804'\n'17539b7e-77e5-43a4-b848-47020db409ec'\n'1753acaa-2b59-4866-8886-3b097fb7997a'\n'175411e7-0a3f-4d66-afac-d81c0282985b'\n'1758eb49-8874-4df9-859d-9be9a6cd01e5'\n'1773a162-075e-4379-bec1-b04c02393084'\n'1774bf9c-9616-427c-bb42-f517a509b2d2'\n'177fef65-0707-4dd7-b6fa-84dc50332de4'\n'1784f4da-6b89-4e19-a972-646224b3c5a9'\n'178bfe70-a9e5-44ff-a632-e3ce85d57098'\n'178e7259-c84e-4088-aeee-97518f642627'\n'17928299-f98d-4061-b848-192ef20f22fe'\n'179f8f02-6fe6-4914-aec3-43515bc969b2'\n'17a02e1f-f677-4bfa-b2d1-52663e3e22b4'\n'17a4fbbf-a5d0-49d8-b8c9-6b97079d4567'\n'17a8b6c2-7015-408b-b0ac-b49a235807d8'\n'17aa5b6f-0bee-4a77-bece-cee639cf20c9'\n'17ab06e9-ebab-464a-8bfd-aaaa3ec4a9e2'\n'17ac3090-bb71-4225-b11f-d290d7a8c56e'\n'17acc4a7-6a9b-46ed-97e9-c896071d419f'\n'17b62d86-322e-4b80-ad1a-585a9121ca73'\n'17b6f947-b6e0-4633-9451-2b753e589eee'\n'17c24166-acea-43bf-bac1-aefbec688523'\n'17c27031-eeb9-495f-9550-be9f4001ba64'\n'17c75268-3db0-4d2c-b73d-87027799555f'\n'17dbe6f4-1323-4b2c-a409-7a8620db9229'\n'17e22674-7206-4fd9-b952-418514460a21'\n'17e51ed9-dbec-4e6d-8547-3c1d916c7dd9'\n'17f6e80f-41bf-40d3-b98a-09c519550416'\n'17f8e906-5eb2-4324-a9bc-02233e3a5a40'\n'17fa2e9e-3583-48fb-a539-ae06e88d639d'\n'17fad2b7-1683-48c0-a94c-1c23adf7fcd7'\n'1803b2ff-7c6d-4a6f-8e59-166a60527298'\n'1809adee-c441-4434-9eb6-541791d078c0'\n'180d6a77-50d7-4dc0-ac00-2376447d3b2f'\n'1810445b-bca3-4ee4-8264-3ed550508a51'\n'18115e45-86f5-494a-9e07-7781ef84096f'\n'1813b350-11f4-49e2-a815-2b3da9b6e4ca'\n'1818bf4f-ebb6-4b54-b327-ded184d72104'\n'184750bc-a751-47ba-a82d-cb76560c3e62'\n'1849b376-b921-47cf-9a8d-72ac54929257'\n'1851fcb1-7eeb-4f6e-9e67-3ff2083098bb'\n'18579294-352f-4967-b1b4-f28cf1ac0a62'\n'1858a07f-8400-48fe-9379-0337a705b6fa'\n'185ebeea-025e-437d-9952-f865ae8a7243'\n'186283bb-504b-4763-9d79-58ce256c7cc2'\n'1863a136-bde0-4f56-a081-4e6fc4794f8a'\n'1879954c-6bc5-4f95-a41c-03f68ab49b5c'\n'18851bd1-7a5b-486d-b66f-b39e0607fd51'\n'188ad487-9b7a-45de-aa86-5b0426fa9e40'\n'1890b830-0def-4240-aa4f-4ce7649169bd'\n'18c25ccb-4a07-4372-82ef-4775c2cb49d3'\n\nStream closed",
  "history_begin_time" : 1649259329298,
  "history_end_time" : 1649259385045,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "3FfKev4ScjH1",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              #os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          #df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1649212438356,
  "history_end_time" : 1649259338091,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "jzqtkmzR3htj",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_columns = submission_format_df.index.insert(0,'date')\n    all_cell_df = pd.DataFrame(columns = all_columns)\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n          return img\n\n      print(\"test1\")\n      poi_reduced_imgs = viirs.map(poi_mean)\n      col_len = 1+len(submission_format_df.index)\n      print(\"test2\", poi_reduced_imgs)\n      reduce_cols = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(col_len), all_columns)\n      print(reduce_cols)\n      reduce_vals = reduce_cols.values(col_len)\n      print(reduce_vals)\n      nested_list = reduce_vals.get(0)\n      print(nested_list)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n\nStream closed",
  "history_begin_time" : 1648271793920,
  "history_end_time" : 1648284858108,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "aZWLc98N0CRb",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_columns = submission_format_df.index.insert(0,'date')\n    all_cell_df = pd.DataFrame(columns = all_columns)\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n          return img\n\n      print(\"test1\")\n      poi_reduced_imgs = viirs.map(poi_mean)\n      col_len = 1+len(submission_format_df.index)\n      print(\"test2\", str(col_len))\n      reduce_cols = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(col_len), all_columns)\n      print(reduce_cols)\n      reduce_vals = reduce_cols.values(col_len)\n      print(reduce_vals)\n      nested_list = reduce_vals.get(0)\n      print(nested_list)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n/Users/joe\n/Users/joe\n(9066, 57)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\n",
  "history_begin_time" : 1648271695840,
  "history_end_time" : 1648271715786,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "JLqwCOOdNICw",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_columns = submission_format_df.index.insert(0,'date')\n    all_cell_df = pd.DataFrame(columns = all_columns)\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n          return img\n\n      print(\"test1\")\n      poi_reduced_imgs = viirs.map(poi_mean)\n      col_len = 1+len(submission_format_df.index)\n      print(\"test2\", str(col_len))\n      reduce_cols = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(), all_columns)\n      print(reduce_cols)\n      reduce_vals = reduce_cols.values(col_len)\n      print(reduce_vals)\n      nested_list = reduce_vals.get(0)\n      print(nested_list)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n/Users/joe\n/Users/joe\n(9066, 57)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\n",
  "history_begin_time" : 1648271550459,
  "history_end_time" : 1648271571936,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "wRHYLud9W3rm",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_columns = submission_format_df.index.insert(0,'date')\n    all_cell_df = pd.DataFrame(columns = all_columns)\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n          return img\n\n      print(\"test1\")\n      poi_reduced_imgs = viirs.map(poi_mean)\n      col_len = 1+len(submission_format_df.index)\n      print(\"test2\", str(col_len))\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(), all_columns).values(col_len).get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n/Users/joe\n/Users/joe\n(9066, 57)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2 9067\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\n",
  "history_begin_time" : 1648271460713,
  "history_end_time" : 1648271481231,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "PVQFvTblo6Zv",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_columns = submission_format_df.index.insert(0,'date')\n    all_cell_df = pd.DataFrame(columns = all_columns)\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n          return img\n\n      print(\"test1\")\n      poi_reduced_imgs = viirs.map(poi_mean)\n      print(\"test2\")\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(1+len(submission_format_df.index)), all_columns).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n/Users/joe\n/Users/joe\n(9066, 57)\ntest1\ntest2\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\ntest1\ntest2\nInvalid argument specified for ee.List(): Index(['date', '000863e7-21e6-477d-b799-f5675c348627',\n       '000ba8d9-d6d5-48da-84a2-1fa54951fae1',\n       '00146204-d4e9-4cd8-8f86-d1ef133c5b6d',\n       '00211c19-7ea8-4f21-a2de-1d6216186a96',\n       '00226e82-e747-4f03-9c5d-3eef8ebe515e',\n       '0027a004-df14-4d66-a3e4-e987336b8814',\n       '003bc010-4187-4fba-9c3c-29ca50b15a78',\n       '003ccf34-6c35-4546-b8c5-b926fbe5ffbb',\n       '003d08c8-fcf3-406c-a2e2-e67f1553f767',\n       ...\n       'ffb7b4a6-a0b4-4f57-9767-3258cb75c4b6',\n       'ffb91c7c-4115-4da0-919f-479b63423a8a',\n       'ffbaaae9-582e-45b3-ba8c-813c628fe0d5',\n       'ffbaf762-b379-4b60-8f2d-6e08146f42c9',\n       'ffc68dfc-74b2-43bb-a93e-827765e80cbb',\n       'ffcc02b0-5185-4f6a-bdfd-1ae1b6c68e99',\n       'ffce8731-d78f-4c06-ace2-7029b611f1ba',\n       'ffd1aa25-27a5-4b28-abb6-e6577d1575be',\n       'ffdfb5a4-91a0-41a9-a4d5-501b04ef6326',\n       'ffeabc13-7c6f-4b63-b043-19c8f15e0345'],\n      dtype='object', length=9067)\n",
  "history_begin_time" : 1648271281454,
  "history_end_time" : 1648271301443,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "RYUY8nTkiLLe",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_columns = submission_format_df.index.insert(0,'date')\n    all_cell_df = pd.DataFrame(columns = all_columns)\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n          return img\n\n      print(\"test1\")\n      poi_reduced_imgs = viirs.map(poi_mean)\n      print(\"test2\")\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(1+len(submission_format_df.index)), all_columns).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n/Users/joe\n/Users/joe\n(9066, 57)\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\n",
  "history_begin_time" : 1648271230893,
  "history_end_time" : 1648271234871,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "DxlCqH1wYRvt",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_columns = submission_format_df.index.insert(0,'date')\n    all_cell_df = pd.DataFrame(columns = all_columns)\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n          return img\n\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n      \n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(1+len(submission_format_df.index)), all_columns).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n/Users/joe\n/Users/joe\n(9066, 57)\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\n",
  "history_begin_time" : 1648271200792,
  "history_end_time" : 1648271204284,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "3WsfyNqotFTy",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n            return img\n\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      all_columns = submission_format_df.index.insert(0,'date')\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(1+len(submission_format_df.index)), all_columns).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n/Users/joe\n/Users/joe\n(9066, 57)\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\n",
  "history_begin_time" : 1648271088761,
  "history_end_time" : 1648271092015,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "xjSS7BU1ts8j",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = \"2022-03-16\"#test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\t\n    try:\n      \n      single_csv_file = f\"{dfolder}/{column_name}_new.csv\"\n\n      if os.path.exists(single_csv_file):\n        os.remove(single_csv_file)\n        #print(\"exists skipping..\")\n        #    continue\n\n      # identify a 1000 meter buffer around our Point Of Interest (POI)\n      viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n      def poi_mean(img):\n          img.set('date', img.date().format())\n          for current_cell_id in submission_format_df.index:\n            longitude = all_cell_coords_pd['lon'][current_cell_id]\n            latitude = all_cell_coords_pd['lat'][current_cell_id]\n            poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n            reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n            mean = reducer.get(var_name)\n            img.set(current_cell_id,mean)\n            return img\n\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      all_columns = submission_format_df.index.insert(0,'date')\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(1+len(submission_format_df.index)), all_columns).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=all_columns)\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df.to_csv(single_csv_file)\n\n    except Exception as e:\n\n      print(e)\n    \n\n",
  "history_output" : "today date = 2022-03-26\n/Users/joe\n/Users/joe\n(9066, 57)\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\nname 'poi' is not defined\n",
  "history_begin_time" : 1648270995041,
  "history_end_time" : 1648270998619,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "zZ4rjl0gvOTz",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              #os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1648268477754,
  "history_end_time" : 1648304007239,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "khwo1Ocux57v",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              #os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1648268302925,
  "history_end_time" : 1648268465702,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "fdURNf5loZye",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              #os.remove(single_csv_file)\n              print(\"exists skipping..\")\n              continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1648265417739,
  "history_end_time" : 1648268284940,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "gZjYoN3XZCma",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              #continue\n\n          longitude = all_cell_coords_pd['lon'][current_cell_id]\n          latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1648185841251,
  "history_end_time" : 1648265414260,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "eki7Ix0nsgcT",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              #continue\n\n          longitude = station_cell_mapper_df['lon'][ind]\n          latitude = station_cell_mapper_df['lat'][ind]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1648183467409,
  "history_end_time" : 1648183499097,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "deSMjZ5PTUAU",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for current_cell_id in submission_format_df.index:\n\n        try:\n          #print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              os.remove(single_csv_file)\n              #print(\"exists skipping..\")\n              #continue\n\n          longitude = station_cell_mapper_df['lon'][ind]\n          latitude = station_cell_mapper_df['lat'][ind]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-03-25\n/Users/joe\n/Users/joe\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/deSMjZ5PTUAU/data_gee_gridmet_real_time.py\", line 32, in <module>\n    submission_format_df = pd.read_csv(submission_format_file, header=0, index=0)\n  File \"/Users/l21-n02609-comm/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\nTypeError: read_csv() got an unexpected keyword argument 'index'\n",
  "history_begin_time" : 1648183357920,
  "history_end_time" : 1648183361729,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "X3ApTkhaR4RL",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nimport snowcast_utils\n\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file)\n\nprint(station_cell_mapper_df.shape)\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = test_start_date\nend_date = test_end_date\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for ind in station_cell_mapper_df.index:\n\n        try:\n\n          current_cell_id = station_cell_mapper_df['cell_id'][ind]\n          print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              print(\"exists skipping..\")\n              continue\n\n          longitude = station_cell_mapper_df['lon'][ind]\n          latitude = station_cell_mapper_df['lat'][ind]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-03-24\n/Users/joe\n(700, 5)\n(9066, 58)\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/X3ApTkhaR4RL/data_gee_gridmet_real_time.py\", line 46, in <module>\n    start_date = test_start_date\nNameError: name 'test_start_date' is not defined\n",
  "history_begin_time" : 1648180518620,
  "history_end_time" : 1648180523679,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "f4zqipyffp5",
  "history_input" : "# Write first python in Geoweaver",
  "history_output" : "",
  "history_begin_time" : 1647826063979,
  "history_end_time" : 1647826064074,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4k25twojkh2",
  "history_input" : "# Write first python in Geoweaver",
  "history_output" : "",
  "history_begin_time" : 1647225910451,
  "history_end_time" : 1647225910546,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ir4k1380ynf",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809171455,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "ldoclj9yds0",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678201703968,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "7j2u9vyw0jb",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1694185611218,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "cjntghjdfp0",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677785529429,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "41xuasumt8c",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677797113222,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "n9hlzfowhbc",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809840742,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "mcu6fcn8l84",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677959722629,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "lo01vmq7v3j",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677784516783,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "76wxh0dpny7",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677785383328,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "4bi88z0x0yz",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677796528249,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "vdro9iyl43z",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809306582,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "knwrntlj2t7",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809554683,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "xbv0cpx89t2",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677809573427,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "u996218gxs1",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677867648577,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "1k8ua6jpg8e",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677958291198,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "mr0hq8i5uyb",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677958754119,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "yisvqb9hwuw",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677958849882,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "dm9op5thrt1",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677958952859,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "6vi4kvyqjl3",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1677959583136,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "bv40jngy5yb",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678201687053,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "rdrd6tlzddl",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206143096,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "uq5ak1o73m6",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678206378252,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "09cqz4kt739",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678888215693,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "fxh2svuw9ey",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678884535342,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "yixkt5s9j3f",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678648341630,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "9ch590zpwm1",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678884042274,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "4hcxy7q2zym",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678884140258,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "8xlrvepij7k",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678887010625,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},{
  "history_id" : "3qj5ps7xq9w",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1678887836229,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "45wlwr",
  "indicator" : "Stopped"
},]
